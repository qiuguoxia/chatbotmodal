[training]
# Main .py file which will be used for the model
model_type: rnnlm

# how much validation period will we wait
# to do early stopping
patience: 10

# Maximum number of epochs before stopping training
max_epochs: 5

# Validation start in terms of epochs
# validation frequency in terms of minibatch updates
valid_start: 2
valid_freq: 5000

# 0: no, otherwise weight decay factor
decay_c: 0

# -1: no, otherwise maximum gradient norm
clip_c: 1.0
seed: 1234

[model]
# Using the same embedding for output and previous
tied_trg_emb: True
layer_norm: False

# Sort batches by target length or not
shuffle_mode: None

# 0: no, otherwise dropout probability
dropout: 0.0

# Embedding vector dimension
embedding_dim: 512
in_emb_dim: 512
out_emb_dim: 512

# RNN's hidden layer dimension
rnn_dim: 1024

# Number of jobs while translating
njobs: 15

# adadelta, adam, sgd or rmsprop
optimizer: adadelta

# Learning rate (only for SGD)
lrate: 1

# batch size
batch_size: 3

#Normalization of the cost
norm_cost: False

# Use BLEU as additional validation metric
valid_metric: loss

weight_init: xavier

# 0: use all vocabulary, otherwise upper limit as integer
n_words: 30000

# Where to save model params, weights and training log file
save_path:  ~/Documents/Stage/GAN_NMT_model/models

[model.dicts]
src: ~/Documents/Stage/GAN_NMT_model/data/train.fr.vocab.pkl


[model.data]
train_src: ~/Documents/Stage/GAN_NMT_model/data/train.fr
valid_src: ~/Documents/Stage/GAN_NMT_model/data/valid.fr
