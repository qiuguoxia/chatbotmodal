THEANO_FLAGS = device=gpu,floatX=float32
Using device: auto (on machine n2)
Theano version: 0.9.0.dev-RELEASE
Training options:
-----------------------------------
                alpha_init : 0
                alpha_rate : 0.001
                    clip_c : 1.0
                   decay_c : 0
                 device_id : auto
    discriminator_loop_num : 1
        generator_loop_num : 1
                      init : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/attention-e512-r1024-adadelta_1e+00-bs80-bleu-each5000_do_d0.0-gc1-init_xavier-s1234.1-val001-bleu_38.850.npz
                   initdis : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/models/discriminator_en_fr_not_MC/cnn_discriminator-e512-adadelta_1e+00-bs80-bleu-each50-gc1-init_xavier-s1234.1-val014-loss_0.165.npz
                    initlm : None
                   max_acc : 0.85
                max_epochs : 1000000
             max_iteration : 1000000
                    maxlen : 50
                   min_acc : 0.8
  model_discriminator_type : cnn_discriminator
 model_language_model_type : None
                model_type : attention_GAN_gradient
        monte_carlo_search : False
                  patience : 1000
                   rollnum : 20
               sample_freq : 0
               save_best_n : 4
                      seed : 1234
             snapshot_freq : 0
                valid_beam : 12
                valid_freq : 100
              valid_metric : bleu
               valid_njobs : 16
            valid_save_hyp : False
               valid_start : 1

Model options:
-----------------------------------
                batch_size : 80
                  dec_type : gru_cond
                   dropout : 0.0
             embedding_dim : 512
                  enc_type : gru
                in_emb_dim : 512
                layer_norm : False
                     lrate : 1
                   n_words : 30000
               n_words_src : 30000
               n_words_trg : 30000
                     njobs : 15
                 norm_cost : False
                 optimizer : adadelta
               out_emb_dim : 512
                   rnn_dim : 1024
                 save_path : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/models/nmt_GAN_en_fr_not_MC_gradient/attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
              shuffle_mode : None
              tied_trg_emb : True
              valid_metric : bleu
               weight_init : xavier
                     dicts =
                       src : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/train.en.vocab.pkl
                    src_lm : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/train.fr.vocab.pkl
                       trg : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/train.fr.vocab.pkl
                      data =
                 train_src : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/train.en
                 train_trg : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/train.fr
                 valid_src : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/valid.en
                 valid_trg : /users/limsi_nmt/ngoho/Stage/GAN_NMT_model/data/valid.fr

Initializing parameters
Creating shared variables
Will override parameters from pre-trained weights init Generator
  attention-e512-r1024-adadelta_1e+00-bs80-bleu-each5000_do_d0.0-gc1-init_xavier-s1234.1-val001-bleu_38.850.npz
Will override parameters from pre-trained weights init Discriminator
  cnn_discriminator-e512-adadelta_1e+00-bs80-bleu-each50-gc1-init_xavier-s1234.1-val014-loss_0.165.npz
Number of parameters generator    : 42.4M
Number of parameters discriminator: 8.7M
No language model
Loading data
Shuffle mode: None
Source vocabulary size: 7751
Target vocabulary size: 9067
19972 training samples
506 validation samples
dropout (emb,ctx,out): 0.00, 0.00, 0.00
Building model
Input tensor order: 
[x, x_mask, y, y_mask]
Building sampler
Building optimizer adadelta (initial lr=1.00000)
Starting Epoch 1
----------------
Gradient discriminator: 8.192217
Gradient professor: 19.256291
Loss Generator D: 7.123084
Loss Generator P: 1.323062
Discriminator: Epoch:      1, update:       1, cost:   0.667694
Gradient discriminator: -17.019568
Gradient professor: -12.661756
Loss Generator D: 8.256836
Loss Generator P: 1.131819
Discriminator: Epoch:      1, update:       2, cost:   0.654031
Gradient discriminator: 5.250476
Gradient professor: -28.675127
Loss Generator D: 8.394757
Loss Generator P: 1.165765
Discriminator: Epoch:      1, update:       3, cost:   0.597730
Gradient discriminator: 22.545278
Gradient professor: -30.602518
Loss Generator D: 7.108110
Loss Generator P: 1.181938
Discriminator: Epoch:      1, update:       4, cost:   0.356026
Gradient discriminator: -29.031161
Gradient professor: -7.989549
Loss Generator D: 8.441205
Loss Generator P: 1.011314
Discriminator: Epoch:      1, update:       5, cost:   0.378598
Gradient discriminator: 13.571561
Gradient professor: 2.602674
Loss Generator D: 6.695227
Loss Generator P: 1.089156
Gradient discriminator: -21.958833
Gradient professor: -6.511166
Loss Generator D: 7.309110
Loss Generator P: 1.092217
Gradient discriminator: -37.346153
Gradient professor: -4.065415
Loss Generator D: 6.501869
Loss Generator P: 1.040430
Gradient discriminator: 29.261922
Gradient professor: 9.915844
Loss Generator D: 7.101787
Loss Generator P: 1.263222
Gradient discriminator: -7.786240
Gradient professor: 4.380863
Loss Generator D: 6.501235
Loss Generator P: 1.372993
Generator    : Epoch:      1, update:      10, cost:   1.372993
Gradient discriminator: 20.653037
Gradient professor: 25.846395
Loss Generator D: 7.176278
Loss Generator P: 1.392510
Gradient discriminator: -11.057625
Gradient professor: 14.768622
Loss Generator D: 6.251216
Loss Generator P: 1.176810
Gradient discriminator: 28.126065
Gradient professor: -32.005953
Loss Generator D: 5.643122
Loss Generator P: 1.253650
Gradient discriminator: 54.860753
Gradient professor: 22.067754
Loss Generator D: 6.829599
Loss Generator P: 1.227774
Gradient discriminator: -22.104825
Gradient professor: -6.516722
Loss Generator D: 6.605599
Loss Generator P: 1.049931
Gradient discriminator: 8.500059
Gradient professor: 17.530220
Loss Generator D: 5.892186
Loss Generator P: 0.844102
Gradient discriminator: 0.917369
Gradient professor: 7.051893
Loss Generator D: 5.641655
Loss Generator P: 1.100640
Gradient discriminator: 9.172971
Gradient professor: 17.966480
Loss Generator D: 5.500234
Loss Generator P: 1.059401
Gradient discriminator: 20.523977
Gradient professor: -37.683147
Loss Generator D: 5.291230
Loss Generator P: 1.120646
Gradient discriminator: 22.267821
Gradient professor: 42.465705
Loss Generator D: 5.425569
Loss Generator P: 1.209464
Generator    : Epoch:      1, update:      20, cost:   1.209464
Gradient discriminator: 12.739560
Gradient professor: -39.057818
Loss Generator D: 5.846086
Loss Generator P: 1.103583
Gradient discriminator: -2.895580
Gradient professor: 24.507153
Loss Generator D: 5.745489
Loss Generator P: 1.116772
Gradient discriminator: 0.932177
Gradient professor: -32.490236
Loss Generator D: 5.469995
Loss Generator P: 1.003500
Gradient discriminator: -9.132584
Gradient professor: 23.236657
Loss Generator D: 5.760660
Loss Generator P: 1.362620
Gradient discriminator: 9.051526
Gradient professor: 5.899956
Loss Generator D: 6.057127
Loss Generator P: 1.318864
Gradient discriminator: 5.767009
Gradient professor: 19.556884
Loss Generator D: 6.129144
Loss Generator P: 1.192430
Discriminator: Epoch:      1, update:      26, cost:   0.259828
Gradient discriminator: -42.849276
Gradient professor: -35.202404
Loss Generator D: 4.726428
Loss Generator P: 0.993454
Gradient discriminator: 24.293740
Gradient professor: -11.400769
Loss Generator D: 5.127317
Loss Generator P: 1.131020
Discriminator: Epoch:      1, update:      28, cost:   0.330279
Gradient discriminator: 2.126457
Gradient professor: 36.189347
Loss Generator D: 5.092871
Loss Generator P: 0.984731
Gradient discriminator: -10.278576
Gradient professor: 42.279815
Loss Generator D: 5.448839
Loss Generator P: 1.078419
Generator    : Epoch:      1, update:      30, cost:   1.078419
Gradient discriminator: 82.850112
Gradient professor: -15.662191
Loss Generator D: 5.406155
Loss Generator P: 0.963133
Gradient discriminator: -8.571420
Gradient professor: 25.859267
Loss Generator D: 5.086476
Loss Generator P: 0.931568
Gradient discriminator: -11.452534
Gradient professor: -7.641673
Loss Generator D: 5.350696
Loss Generator P: 1.421872
Gradient discriminator: 22.200099
Gradient professor: -21.018866
Loss Generator D: 5.468682
Loss Generator P: 1.304536
Gradient discriminator: -18.321250
Gradient professor: -12.478780
Loss Generator D: 5.981820
Loss Generator P: 1.052684
Gradient discriminator: -32.795536
Gradient professor: -19.010594
Loss Generator D: 5.040347
Loss Generator P: 1.076205
Gradient discriminator: 21.732251
Gradient professor: -20.146530
Loss Generator D: 5.671067
Loss Generator P: 1.001810
Gradient discriminator: -4.102903
Gradient professor: -10.386095
Loss Generator D: 5.124965
Loss Generator P: 1.095140
Gradient discriminator: -3.202166
Gradient professor: -7.732666
Loss Generator D: 4.626262
Loss Generator P: 1.114469
Gradient discriminator: -2.672052
Gradient professor: 21.324414
Loss Generator D: 6.589568
Loss Generator P: 1.302048
Generator    : Epoch:      1, update:      40, cost:   1.302048
Gradient discriminator: 15.327678
Gradient professor: 38.758425
Loss Generator D: 5.804124
Loss Generator P: 1.155447
Gradient discriminator: -12.604205
Gradient professor: 19.755541
Loss Generator D: 4.955728
Loss Generator P: 1.089288
Gradient discriminator: -14.424606
Gradient professor: -29.521261
Loss Generator D: 5.331163
Loss Generator P: 1.113218
Gradient discriminator: 10.420163
Gradient professor: -28.864762
Loss Generator D: 5.777602
Loss Generator P: 1.026277
Gradient discriminator: 9.116640
Gradient professor: 6.513419
Loss Generator D: 5.260671
Loss Generator P: 1.269818
Gradient discriminator: -8.685038
Gradient professor: 4.518442
Loss Generator D: 5.722044
Loss Generator P: 1.243562
Gradient discriminator: 1.645843
Gradient professor: 28.531931
Loss Generator D: 5.573632
Loss Generator P: 1.114033
Gradient discriminator: 6.677481
Gradient professor: 2.250014
Loss Generator D: 4.549000
Loss Generator P: 1.279905
Gradient discriminator: 9.084697
Gradient professor: 12.811832
Loss Generator D: 6.407796
Loss Generator P: 1.423940
Gradient discriminator: 16.796644
Gradient professor: 23.401771
Loss Generator D: 5.755834
Loss Generator P: 1.153041
Generator    : Epoch:      1, update:      50, cost:   1.153041
Gradient discriminator: -8.214068
Gradient professor: 43.189178
Loss Generator D: 5.914277
Loss Generator P: 1.161673
Gradient discriminator: -22.068785
Gradient professor: -36.231425
Loss Generator D: 6.078022
Loss Generator P: 1.197992
Gradient discriminator: -55.687228
Gradient professor: -7.125897
Loss Generator D: 5.180423
Loss Generator P: 0.929290
Gradient discriminator: 2.726568
Gradient professor: -15.721931
Loss Generator D: 5.480657
Loss Generator P: 1.239983
Gradient discriminator: -1.594673
Gradient professor: -9.274738
Loss Generator D: 5.627331
Loss Generator P: 1.195199
Gradient discriminator: 24.248630
Gradient professor: -15.024249
Loss Generator D: 5.685178
Loss Generator P: 1.044081
Gradient discriminator: 13.220155
Gradient professor: 22.641900
Loss Generator D: 5.354712
Loss Generator P: 1.071902
Discriminator: Epoch:      1, update:      57, cost:   0.242905
Gradient discriminator: -5.004482
Gradient professor: -13.591239
Loss Generator D: 6.297454
Loss Generator P: 1.070083
Gradient discriminator: 46.675840
Gradient professor: 14.868835
Loss Generator D: 5.624110
Loss Generator P: 1.235684
Gradient discriminator: 11.604646
Gradient professor: 0.987025
Loss Generator D: 5.805746
Loss Generator P: 1.174642
Generator    : Epoch:      1, update:      60, cost:   1.174642
Gradient discriminator: 50.354896
Gradient professor: 5.832430
Loss Generator D: 5.730067
Loss Generator P: 1.139087
Gradient discriminator: -1.868323
Gradient professor: 21.265439
Loss Generator D: 6.239764
Loss Generator P: 1.435236
Gradient discriminator: 28.160286
Gradient professor: 7.368717
Loss Generator D: 5.372921
Loss Generator P: 1.035504
Gradient discriminator: 0.740932
Gradient professor: -16.981446
Loss Generator D: 5.508716
Loss Generator P: 1.142325
Gradient discriminator: 16.511443
Gradient professor: 10.726642
Loss Generator D: 4.917016
Loss Generator P: 1.070868
Gradient discriminator: 19.865894
Gradient professor: -28.800681
Loss Generator D: 4.990085
Loss Generator P: 1.134147
Gradient discriminator: 3.308560
Gradient professor: -18.876215
Loss Generator D: 6.115482
Loss Generator P: 1.248336
Gradient discriminator: 7.420986
Gradient professor: -19.248534
Loss Generator D: 5.194228
Loss Generator P: 1.301743
Gradient discriminator: 28.536945
Gradient professor: 9.965853
Loss Generator D: 4.676561
Loss Generator P: 1.322153
Gradient discriminator: -26.775167
Gradient professor: -4.639686
Loss Generator D: 4.995819
Loss Generator P: 1.256036
Generator    : Epoch:      1, update:      70, cost:   1.256036
Gradient discriminator: -3.993928
Gradient professor: -4.925480
Loss Generator D: 5.768772
Loss Generator P: 1.079697
Gradient discriminator: -12.564091
Gradient professor: -27.186841
Loss Generator D: 5.760556
Loss Generator P: 0.989087
Gradient discriminator: 24.630544
Gradient professor: 6.136141
Loss Generator D: 5.788822
Loss Generator P: 1.281253
Gradient discriminator: 30.050898
Gradient professor: 13.936560
Loss Generator D: 4.391632
Loss Generator P: 1.217663
Gradient discriminator: -15.841830
Gradient professor: 8.612458
Loss Generator D: 5.439391
Loss Generator P: 1.114108
Gradient discriminator: 17.564242
Gradient professor: -6.899568
Loss Generator D: 4.192050
Loss Generator P: 1.035003
Gradient discriminator: 2.462878
Gradient professor: -34.030915
Loss Generator D: 5.568167
Loss Generator P: 1.064389
Gradient discriminator: 8.725745
Gradient professor: 28.521067
Loss Generator D: 5.605190
Loss Generator P: 1.285156
Gradient discriminator: 4.631134
Gradient professor: -26.132986
Loss Generator D: 4.357000
Loss Generator P: 0.915736
Gradient discriminator: 2.442300
Gradient professor: 5.336803
Loss Generator D: 4.760095
Loss Generator P: 0.959554
Generator    : Epoch:      1, update:      80, cost:   0.959554
Gradient discriminator: 5.257862
Gradient professor: 7.322353
Loss Generator D: 5.238888
Loss Generator P: 0.999479
Gradient discriminator: 13.567694
Gradient professor: -27.306477
Loss Generator D: 5.710200
Loss Generator P: 1.035178
Gradient discriminator: 11.879233
Gradient professor: -4.799970
Loss Generator D: 5.504861
Loss Generator P: 1.007426
Gradient discriminator: 6.677876
Gradient professor: -31.975612
Loss Generator D: 5.420030
Loss Generator P: 0.813678
Gradient discriminator: -6.483017
Gradient professor: 5.896037
Loss Generator D: 5.762983
Loss Generator P: 0.944690
Gradient discriminator: 3.912960
Gradient professor: -7.685889
Loss Generator D: 5.212940
Loss Generator P: 1.037621
Gradient discriminator: 4.031432
Gradient professor: -31.166553
Loss Generator D: 5.475029
Loss Generator P: 1.027990
Gradient discriminator: -39.749260
Gradient professor: -33.305589
Loss Generator D: 4.720028
Loss Generator P: 1.202053
Gradient discriminator: 22.543849
Gradient professor: -19.690506
Loss Generator D: 5.726226
Loss Generator P: 1.051021
Gradient discriminator: 9.095586
Gradient professor: 11.483039
Loss Generator D: 4.224303
Loss Generator P: 1.257687
Generator    : Epoch:      1, update:      90, cost:   1.257687
Gradient discriminator: -43.482259
Gradient professor: 15.992720
Loss Generator D: 4.574059
Loss Generator P: 1.005883
Gradient discriminator: 3.869986
Gradient professor: 20.512623
Loss Generator D: 4.416959
Loss Generator P: 1.388233
Gradient discriminator: 4.240062
Gradient professor: -18.238001
Loss Generator D: 5.320121
Loss Generator P: 1.018192
Gradient discriminator: -3.235698
Gradient professor: 10.910489
Loss Generator D: 4.879182
Loss Generator P: 0.884399
Gradient discriminator: 2.248068
Gradient professor: 11.668504
Loss Generator D: 4.564104
Loss Generator P: 1.041894
Gradient discriminator: 24.928677
Gradient professor: -30.156069
Loss Generator D: 4.367889
Loss Generator P: 1.161104
Gradient discriminator: -17.995046
Gradient professor: -54.364485
Loss Generator D: 4.509280
Loss Generator P: 0.964349
Gradient discriminator: 22.957355
Gradient professor: 20.957839
Loss Generator D: 4.033463
Loss Generator P: 0.942090
Gradient discriminator: -4.194768
Gradient professor: -15.218497
Loss Generator D: 5.991940
Loss Generator P: 1.008514
Gradient discriminator: -14.828872
Gradient professor: -1.244158
Loss Generator D: 5.190700
Loss Generator P: 1.154314
Generator    : Epoch:      1, update:     100, cost:   1.154314
Validation  1 - LOSS = 1.686 (PPL: 5.397)
Calling beam-search process
Beam-search ended, took 2.21182 minutes.
Validation  1 - BLEU = 8.43, 15.8/10.0/6.8/4.7 (BP=1.000, ratio=3.787, hyp_len=15980, ref_len=4220)
Saving model with best validation BLEU
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.686 (PPL: 5.397) at validation 1
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -10.305150
Gradient professor: 5.146339
Loss Generator D: 5.782018
Loss Generator P: 1.199680
Gradient discriminator: 17.204378
Gradient professor: 6.732160
Loss Generator D: 4.884341
Loss Generator P: 1.307939
Gradient discriminator: 4.698850
Gradient professor: -0.211600
Loss Generator D: 4.515143
Loss Generator P: 1.004063
Gradient discriminator: 45.835398
Gradient professor: 9.129035
Loss Generator D: 4.243567
Loss Generator P: 1.037651
Gradient discriminator: 21.797023
Gradient professor: 10.306020
Loss Generator D: 4.621396
Loss Generator P: 0.892082
Gradient discriminator: -7.669131
Gradient professor: -27.029573
Loss Generator D: 3.980346
Loss Generator P: 1.249474
Gradient discriminator: -9.319319
Gradient professor: -33.910596
Loss Generator D: 3.337804
Loss Generator P: 0.978748
Gradient discriminator: -4.309864
Gradient professor: 13.567751
Loss Generator D: 4.767642
Loss Generator P: 1.006155
Gradient discriminator: 13.116545
Gradient professor: 15.674116
Loss Generator D: 4.328311
Loss Generator P: 1.140479
Gradient discriminator: 21.079763
Gradient professor: 16.212595
Loss Generator D: 3.743389
Loss Generator P: 1.009261
Generator    : Epoch:      1, update:     110, cost:   1.009261
Gradient discriminator: 60.885708
Gradient professor: 17.542833
Loss Generator D: 3.169704
Loss Generator P: 1.140912
Gradient discriminator: 15.690378
Gradient professor: 18.497902
Loss Generator D: 3.017772
Loss Generator P: 1.010103
Gradient discriminator: 6.707298
Gradient professor: 15.290111
Loss Generator D: 4.149796
Loss Generator P: 1.115926
Gradient discriminator: 26.065527
Gradient professor: 15.453985
Loss Generator D: 4.322515
Loss Generator P: 0.852866
Gradient discriminator: 12.232751
Gradient professor: -21.714318
Loss Generator D: 4.261498
Loss Generator P: 1.220135
Gradient discriminator: 17.832452
Gradient professor: 2.549468
Loss Generator D: 4.470595
Loss Generator P: 1.200229
Gradient discriminator: 3.521316
Gradient professor: 35.908713
Loss Generator D: 5.012440
Loss Generator P: 0.935103
Gradient discriminator: 19.051347
Gradient professor: 3.906294
Loss Generator D: 5.086750
Loss Generator P: 1.272512
Gradient discriminator: 4.128360
Gradient professor: 21.289430
Loss Generator D: 3.975189
Loss Generator P: 1.038688
Gradient discriminator: 17.248754
Gradient professor: -36.563190
Loss Generator D: 4.170129
Loss Generator P: 1.177129
Generator    : Epoch:      1, update:     120, cost:   1.177129
Gradient discriminator: 36.002254
Gradient professor: 144.836004
Loss Generator D: 4.585472
Loss Generator P: 1.214526
Gradient discriminator: 18.736184
Gradient professor: 7.540700
Loss Generator D: 3.205683
Loss Generator P: 1.229480
Gradient discriminator: 5.246059
Gradient professor: -8.716697
Loss Generator D: 4.150239
Loss Generator P: 1.180328
Gradient discriminator: 30.201461
Gradient professor: 17.696987
Loss Generator D: 4.754584
Loss Generator P: 1.218084
Gradient discriminator: 39.631141
Gradient professor: 41.297050
Loss Generator D: 3.645793
Loss Generator P: 1.259990
Gradient discriminator: 36.236998
Gradient professor: 35.048846
Loss Generator D: 3.029167
Loss Generator P: 1.194385
Gradient discriminator: 6.287359
Gradient professor: 1.947411
Loss Generator D: 4.234551
Loss Generator P: 1.230351
Gradient discriminator: 32.695768
Gradient professor: 40.667420
Loss Generator D: 4.305233
Loss Generator P: 1.266597
Gradient discriminator: -2.303046
Gradient professor: 20.719598
Loss Generator D: 4.784712
Loss Generator P: 1.121107
Gradient discriminator: -30.999997
Gradient professor: -56.002791
Loss Generator D: 4.934537
Loss Generator P: 1.224548
Generator    : Epoch:      1, update:     130, cost:   1.224548
Gradient discriminator: 9.324632
Gradient professor: -7.290789
Loss Generator D: 4.152181
Loss Generator P: 0.918168
Gradient discriminator: 9.286488
Gradient professor: 3.346103
Loss Generator D: 4.848037
Loss Generator P: 1.034177
Gradient discriminator: -6.006252
Gradient professor: 16.585389
Loss Generator D: 3.587086
Loss Generator P: 0.912846
Gradient discriminator: 4.508012
Gradient professor: -9.029072
Loss Generator D: 3.861718
Loss Generator P: 1.212853
Gradient discriminator: -1.460804
Gradient professor: 21.670109
Loss Generator D: 4.141444
Loss Generator P: 1.190640
Gradient discriminator: 18.029143
Gradient professor: -23.269007
Loss Generator D: 4.315152
Loss Generator P: 0.854145
Gradient discriminator: 8.525537
Gradient professor: 9.911529
Loss Generator D: 4.690400
Loss Generator P: 1.139148
Gradient discriminator: -30.301721
Gradient professor: 3.528197
Loss Generator D: 3.919682
Loss Generator P: 0.871149
Gradient discriminator: -11.853248
Gradient professor: 32.096165
Loss Generator D: 4.820911
Loss Generator P: 1.183172
Gradient discriminator: -5.306516
Gradient professor: -9.925559
Loss Generator D: 4.077687
Loss Generator P: 1.072168
Generator    : Epoch:      1, update:     140, cost:   1.072168
Gradient discriminator: 6.948246
Gradient professor: -2.288329
Loss Generator D: 4.849437
Loss Generator P: 1.054361
Gradient discriminator: -7.491651
Gradient professor: -2.811207
Loss Generator D: 4.467269
Loss Generator P: 1.152321
Gradient discriminator: 13.765838
Gradient professor: 18.579376
Loss Generator D: 4.304950
Loss Generator P: 1.363188
Gradient discriminator: 1.940438
Gradient professor: -31.550157
Loss Generator D: 4.503307
Loss Generator P: 1.171125
Gradient discriminator: 14.430947
Gradient professor: -18.164253
Loss Generator D: 3.642800
Loss Generator P: 1.356496
Gradient discriminator: 5.358799
Gradient professor: -48.045103
Loss Generator D: 4.278164
Loss Generator P: 1.382698
Gradient discriminator: 8.433606
Gradient professor: 19.780816
Loss Generator D: 4.486166
Loss Generator P: 0.974008
Gradient discriminator: 5.349047
Gradient professor: -5.056731
Loss Generator D: 3.995456
Loss Generator P: 0.933326
Gradient discriminator: 9.027830
Gradient professor: -13.420521
Loss Generator D: 4.460754
Loss Generator P: 0.966013
Gradient discriminator: 8.386325
Gradient professor: -25.835788
Loss Generator D: 4.729251
Loss Generator P: 1.074660
Generator    : Epoch:      1, update:     150, cost:   1.074660
Gradient discriminator: -9.983419
Gradient professor: 9.506652
Loss Generator D: 4.289694
Loss Generator P: 1.303648
Gradient discriminator: 0.943107
Gradient professor: 52.921805
Loss Generator D: 4.204110
Loss Generator P: 1.083548
Gradient discriminator: 10.966811
Gradient professor: -19.568591
Loss Generator D: 4.019223
Loss Generator P: 1.194221
Gradient discriminator: 24.185620
Gradient professor: 12.588436
Loss Generator D: 4.142212
Loss Generator P: 1.136480
Gradient discriminator: 10.098206
Gradient professor: 2.485458
Loss Generator D: 4.677039
Loss Generator P: 1.239902
Gradient discriminator: 1.495894
Gradient professor: -19.708242
Loss Generator D: 4.149689
Loss Generator P: 1.070345
Gradient discriminator: 13.632242
Gradient professor: 38.477558
Loss Generator D: 4.234780
Loss Generator P: 1.097122
Gradient discriminator: 21.575105
Gradient professor: -16.354382
Loss Generator D: 3.830290
Loss Generator P: 0.925015
Gradient discriminator: 13.464327
Gradient professor: -21.845264
Loss Generator D: 4.179106
Loss Generator P: 1.007001
Gradient discriminator: -29.015551
Gradient professor: 19.696049
Loss Generator D: 3.939305
Loss Generator P: 0.984044
Generator    : Epoch:      1, update:     160, cost:   0.984044
Gradient discriminator: 1.576140
Gradient professor: 14.103852
Loss Generator D: 3.879071
Loss Generator P: 1.025827
Gradient discriminator: -7.795857
Gradient professor: 15.799036
Loss Generator D: 4.648961
Loss Generator P: 1.299110
Gradient discriminator: 10.209884
Gradient professor: 31.317916
Loss Generator D: 3.769778
Loss Generator P: 1.367482
Gradient discriminator: 23.872211
Gradient professor: 32.933298
Loss Generator D: 4.201447
Loss Generator P: 1.415960
Gradient discriminator: 11.970305
Gradient professor: -40.981366
Loss Generator D: 4.082874
Loss Generator P: 1.309961
Gradient discriminator: 20.691380
Gradient professor: 92.800058
Loss Generator D: 3.713608
Loss Generator P: 1.319159
Gradient discriminator: 31.660345
Gradient professor: -57.141583
Loss Generator D: 4.515508
Loss Generator P: 1.304143
Gradient discriminator: -12.006746
Gradient professor: -4.161439
Loss Generator D: 4.739219
Loss Generator P: 1.146139
Gradient discriminator: 0.915301
Gradient professor: -11.736997
Loss Generator D: 4.590926
Loss Generator P: 1.205137
Gradient discriminator: 1.275092
Gradient professor: -8.438937
Loss Generator D: 4.916338
Loss Generator P: 1.282928
Generator    : Epoch:      1, update:     170, cost:   1.282928
Gradient discriminator: 3.146554
Gradient professor: 18.044594
Loss Generator D: 6.039732
Loss Generator P: 0.962268
Gradient discriminator: -8.764389
Gradient professor: -0.825149
Loss Generator D: 4.767251
Loss Generator P: 1.013927
Gradient discriminator: 24.765143
Gradient professor: 11.245078
Loss Generator D: 5.305571
Loss Generator P: 1.077208
Gradient discriminator: 5.420710
Gradient professor: 3.942514
Loss Generator D: 4.341283
Loss Generator P: 0.919107
Gradient discriminator: 14.465307
Gradient professor: 4.079527
Loss Generator D: 6.175311
Loss Generator P: 1.139789
Gradient discriminator: 7.154818
Gradient professor: 20.565160
Loss Generator D: 6.056799
Loss Generator P: 1.140050
Gradient discriminator: -17.585041
Gradient professor: -5.309538
Loss Generator D: 4.570137
Loss Generator P: 1.350772
Gradient discriminator: 6.518769
Gradient professor: 15.820155
Loss Generator D: 4.953581
Loss Generator P: 1.454556
Gradient discriminator: 1.375465
Gradient professor: 6.320326
Loss Generator D: 4.253776
Loss Generator P: 1.333269
Gradient discriminator: 10.569820
Gradient professor: 4.705849
Loss Generator D: 5.289888
Loss Generator P: 1.062165
Generator    : Epoch:      1, update:     180, cost:   1.062165
Gradient discriminator: -9.823193
Gradient professor: 18.205160
Loss Generator D: 4.670910
Loss Generator P: 1.149122
Gradient discriminator: 5.477621
Gradient professor: -27.336227
Loss Generator D: 4.238000
Loss Generator P: 1.273973
Gradient discriminator: 4.799851
Gradient professor: 27.005478
Loss Generator D: 4.475211
Loss Generator P: 1.169955
Gradient discriminator: 19.876267
Gradient professor: -9.065071
Loss Generator D: 4.243746
Loss Generator P: 1.349919
Gradient discriminator: -26.645745
Gradient professor: 11.218153
Loss Generator D: 4.743270
Loss Generator P: 1.323115
Gradient discriminator: 17.939914
Gradient professor: -10.617659
Loss Generator D: 5.440653
Loss Generator P: 1.140912
Gradient discriminator: 15.083018
Gradient professor: 43.606081
Loss Generator D: 4.390555
Loss Generator P: 1.246255
Gradient discriminator: 1.255872
Gradient professor: -12.475766
Loss Generator D: 4.740418
Loss Generator P: 1.274217
Gradient discriminator: -10.095073
Gradient professor: 13.549148
Loss Generator D: 5.872181
Loss Generator P: 1.459248
Gradient discriminator: -66.871266
Gradient professor: 8.309639
Loss Generator D: 4.411309
Loss Generator P: 1.256356
Generator    : Epoch:      1, update:     190, cost:   1.256356
Gradient discriminator: -1.119263
Gradient professor: 10.442616
Loss Generator D: 4.537289
Loss Generator P: 1.361033
Gradient discriminator: -13.737706
Gradient professor: -4.799227
Loss Generator D: 4.034106
Loss Generator P: 1.169213
Gradient discriminator: 1.861666
Gradient professor: 40.443656
Loss Generator D: 3.858012
Loss Generator P: 1.533585
Gradient discriminator: -3.042807
Gradient professor: 13.545066
Loss Generator D: 4.398267
Loss Generator P: 1.513263
Gradient discriminator: -4.702308
Gradient professor: 16.422220
Loss Generator D: 3.897778
Loss Generator P: 0.988442
Gradient discriminator: 41.772292
Gradient professor: -32.979187
Loss Generator D: 4.139632
Loss Generator P: 1.258371
Gradient discriminator: 18.200258
Gradient professor: 19.746031
Loss Generator D: 4.384915
Loss Generator P: 1.217456
Gradient discriminator: 12.607837
Gradient professor: -28.417388
Loss Generator D: 3.185961
Loss Generator P: 1.249292
Gradient discriminator: 36.363535
Gradient professor: 32.096631
Loss Generator D: 3.682662
Loss Generator P: 1.263409
Gradient discriminator: 18.986532
Gradient professor: 0.767119
Loss Generator D: 4.100614
Loss Generator P: 1.188718
Generator    : Epoch:      1, update:     200, cost:   1.188718
Validation  2 - LOSS = 1.683 (PPL: 5.383)
Calling beam-search process
Beam-search ended, took 2.80589 minutes.
Validation  2 - BLEU = 5.45, 11.1/6.7/4.3/2.7 (BP=1.000, ratio=4.927, hyp_len=20794, ref_len=4220)
Early stopping patience: 999 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.683 (PPL: 5.383) at validation 2
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 19.161192
Gradient professor: 28.239023
Loss Generator D: 4.018116
Loss Generator P: 1.147935
Gradient discriminator: 7.430560
Gradient professor: 16.211023
Loss Generator D: 3.655218
Loss Generator P: 1.142565
Gradient discriminator: 8.404562
Gradient professor: 18.001562
Loss Generator D: 4.748297
Loss Generator P: 1.142759
Gradient discriminator: 9.682220
Gradient professor: -11.146405
Loss Generator D: 4.677342
Loss Generator P: 1.176995
Gradient discriminator: 17.387456
Gradient professor: 10.966273
Loss Generator D: 3.976963
Loss Generator P: 1.075643
Gradient discriminator: 6.551047
Gradient professor: 17.236986
Loss Generator D: 4.067449
Loss Generator P: 1.084601
Gradient discriminator: 4.921810
Gradient professor: 10.084044
Loss Generator D: 3.234583
Loss Generator P: 1.212311
Gradient discriminator: 16.326898
Gradient professor: -10.295684
Loss Generator D: 3.842388
Loss Generator P: 1.241925
Gradient discriminator: 18.799634
Gradient professor: -7.887061
Loss Generator D: 3.765312
Loss Generator P: 1.151773
Gradient discriminator: -34.964760
Gradient professor: -68.612724
Loss Generator D: 3.424252
Loss Generator P: 1.209691
Generator    : Epoch:      1, update:     210, cost:   1.209691
Gradient discriminator: -26.136276
Gradient professor: 26.467817
Loss Generator D: 3.850918
Loss Generator P: 1.232691
Gradient discriminator: 10.857258
Gradient professor: 20.170112
Loss Generator D: 3.466534
Loss Generator P: 1.388246
Gradient discriminator: -8.147741
Gradient professor: -42.031927
Loss Generator D: 4.475164
Loss Generator P: 1.200718
Gradient discriminator: -31.100542
Gradient professor: 50.600201
Loss Generator D: 3.042646
Loss Generator P: 1.140749
Gradient discriminator: 20.090139
Gradient professor: 44.359018
Loss Generator D: 3.329705
Loss Generator P: 1.327248
Gradient discriminator: -1.823990
Gradient professor: 18.611933
Loss Generator D: 4.233150
Loss Generator P: 1.285524
Gradient discriminator: 12.099750
Gradient professor: -32.538237
Loss Generator D: 3.998101
Loss Generator P: 1.322861
Gradient discriminator: 9.882299
Gradient professor: -6.852891
Loss Generator D: 4.894248
Loss Generator P: 1.092823
Gradient discriminator: 8.968469
Gradient professor: 46.437658
Loss Generator D: 4.939201
Loss Generator P: 0.953729
Gradient discriminator: 2.474791
Gradient professor: -3.046277
Loss Generator D: 4.409698
Loss Generator P: 1.148762
Generator    : Epoch:      1, update:     220, cost:   1.148762
Gradient discriminator: 10.658859
Gradient professor: 2.441101
Loss Generator D: 4.120420
Loss Generator P: 1.149304
Gradient discriminator: 9.293384
Gradient professor: 19.525742
Loss Generator D: 3.688908
Loss Generator P: 1.170375
Gradient discriminator: -4.870682
Gradient professor: 15.504519
Loss Generator D: 4.091446
Loss Generator P: 1.260816
Gradient discriminator: 2.531854
Gradient professor: -6.997887
Loss Generator D: 5.580241
Loss Generator P: 1.112740
Gradient discriminator: -6.788696
Gradient professor: 26.062919
Loss Generator D: 4.523280
Loss Generator P: 1.152755
Gradient discriminator: 7.451085
Gradient professor: -22.559002
Loss Generator D: 3.504462
Loss Generator P: 1.105290
Gradient discriminator: 8.551614
Gradient professor: 14.646862
Loss Generator D: 3.582076
Loss Generator P: 1.101553
Gradient discriminator: -1.835113
Gradient professor: -1.368045
Loss Generator D: 4.506490
Loss Generator P: 1.025050
Gradient discriminator: 8.465200
Gradient professor: -0.505367
Loss Generator D: 4.519217
Loss Generator P: 1.100236
Gradient discriminator: -2.172084
Gradient professor: 3.180578
Loss Generator D: 4.317462
Loss Generator P: 1.089106
Generator    : Epoch:      1, update:     230, cost:   1.089106
Gradient discriminator: 22.899904
Gradient professor: -20.097316
Loss Generator D: 4.497382
Loss Generator P: 1.286978
Gradient discriminator: 0.838280
Gradient professor: 24.058483
Loss Generator D: 3.946446
Loss Generator P: 1.260867
Gradient discriminator: 3.549283
Gradient professor: -18.964136
Loss Generator D: 3.631757
Loss Generator P: 1.242440
Gradient discriminator: -16.989701
Gradient professor: -1.632674
Loss Generator D: 3.170100
Loss Generator P: 0.918195
Gradient discriminator: -1.822109
Gradient professor: 8.564404
Loss Generator D: 2.780224
Loss Generator P: 0.990436
Gradient discriminator: -6.550457
Gradient professor: -11.499415
Loss Generator D: 3.940179
Loss Generator P: 1.050893
Gradient discriminator: 11.606963
Gradient professor: 13.171499
Loss Generator D: 3.571873
Loss Generator P: 0.947820
Gradient discriminator: -7.027778
Gradient professor: -24.074847
Loss Generator D: 3.074074
Loss Generator P: 1.181222
Discriminator: Epoch:      1, update:     238, cost:   0.316240
Gradient discriminator: -7.368312
Gradient professor: 7.023746
Loss Generator D: 4.289524
Loss Generator P: 1.098610
Gradient discriminator: -3.981371
Gradient professor: 29.738499
Loss Generator D: 3.549009
Loss Generator P: 1.127956
Generator    : Epoch:      1, update:     240, cost:   1.127956
Gradient discriminator: -28.015307
Gradient professor: 23.331676
Loss Generator D: 3.844582
Loss Generator P: 1.081428
Gradient discriminator: 15.856168
Gradient professor: -63.801538
Loss Generator D: 3.855979
Loss Generator P: 1.178208
Discriminator: Epoch:      1, update:     242, cost:   0.329917
Gradient discriminator: 5.870889
Gradient professor: 28.821961
Loss Generator D: 3.303922
Loss Generator P: 1.037189
Gradient discriminator: 13.907662
Gradient professor: -5.752630
Loss Generator D: 3.953363
Loss Generator P: 1.162682
Gradient discriminator: 8.225351
Gradient professor: 43.203186
Loss Generator D: 4.052444
Loss Generator P: 1.218133
Gradient discriminator: 4.569555
Gradient professor: 25.962439
Loss Generator D: 3.231806
Loss Generator P: 1.113001
Discriminator: Epoch:      1, update:     246, cost:   0.313832
Gradient discriminator: 5.858756
Gradient professor: 2.396166
Loss Generator D: 4.419333
Loss Generator P: 1.085646
Discriminator: Epoch:      1, update:     247, cost:   0.359388
Gradient discriminator: -4.345805
Gradient professor: 23.386634
Loss Generator D: 3.357570
Loss Generator P: 1.007888
Gradient discriminator: 22.079963
Gradient professor: -22.569228
Loss Generator D: 3.960562
Loss Generator P: 1.240706
Gradient discriminator: 13.541244
Gradient professor: 3.206604
Loss Generator D: 4.414766
Loss Generator P: 0.847063
Generator    : Epoch:      1, update:     250, cost:   0.847063
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 1 finished with mean loss 2.96567 (PPL: 19.40775)
--> Epoch took 355.961 minutes, 85.431 sec/update
Epoch summary of Discriminator:
--> Epoch 1 finished with mean loss 0.40054 (PPL: 1.49263)
--> Epoch took 355.961 minutes, 85.431 sec/update
---------------------------------------------------------
Starting Epoch 2
----------------
Gradient discriminator: -1.334049
Gradient professor: 17.288923
Loss Generator D: 3.956734
Loss Generator P: 1.446091
Gradient discriminator: -14.355178
Gradient professor: 0.520400
Loss Generator D: 3.846898
Loss Generator P: 1.248016
Gradient discriminator: -9.145386
Gradient professor: 23.737562
Loss Generator D: 4.902389
Loss Generator P: 1.202421
Gradient discriminator: -10.537344
Gradient professor: -46.251402
Loss Generator D: 4.420957
Loss Generator P: 1.318637
Gradient discriminator: 10.330139
Gradient professor: -7.105345
Loss Generator D: 3.911087
Loss Generator P: 1.058406
Gradient discriminator: -8.817489
Gradient professor: 6.432073
Loss Generator D: 4.094971
Loss Generator P: 1.103674
Gradient discriminator: 0.173463
Gradient professor: -6.179535
Loss Generator D: 5.066152
Loss Generator P: 1.161345
Gradient discriminator: 5.407649
Gradient professor: 48.017849
Loss Generator D: 3.743504
Loss Generator P: 1.098383
Gradient discriminator: 3.767147
Gradient professor: -18.694527
Loss Generator D: 4.532973
Loss Generator P: 1.266853
Gradient discriminator: 10.151838
Gradient professor: 3.209134
Loss Generator D: 4.547971
Loss Generator P: 1.360922
Generator    : Epoch:      2, update:     260, cost:   1.360922
Gradient discriminator: 3.884186
Gradient professor: 3.678543
Loss Generator D: 4.831742
Loss Generator P: 1.339055
Gradient discriminator: -5.236465
Gradient professor: 13.799996
Loss Generator D: 4.575004
Loss Generator P: 1.092689
Gradient discriminator: -6.742823
Gradient professor: -38.125159
Loss Generator D: 4.243377
Loss Generator P: 1.389206
Gradient discriminator: 5.386964
Gradient professor: -20.876696
Loss Generator D: 5.641123
Loss Generator P: 1.311049
Gradient discriminator: 6.885570
Gradient professor: 28.054988
Loss Generator D: 5.824659
Loss Generator P: 1.058212
Gradient discriminator: -11.226750
Gradient professor: -18.804962
Loss Generator D: 5.452972
Loss Generator P: 0.875678
Gradient discriminator: -5.362412
Gradient professor: -2.305786
Loss Generator D: 5.179486
Loss Generator P: 1.089592
Gradient discriminator: -6.797168
Gradient professor: 1.914637
Loss Generator D: 5.390359
Loss Generator P: 1.099903
Gradient discriminator: 8.288798
Gradient professor: -1.772211
Loss Generator D: 4.127759
Loss Generator P: 1.169653
Gradient discriminator: -15.087587
Gradient professor: 23.999959
Loss Generator D: 3.632816
Loss Generator P: 1.298835
Generator    : Epoch:      2, update:     270, cost:   1.298835
Gradient discriminator: -0.225430
Gradient professor: -16.687631
Loss Generator D: 4.763741
Loss Generator P: 1.162799
Gradient discriminator: 2.674592
Gradient professor: -4.584262
Loss Generator D: 4.330290
Loss Generator P: 1.053360
Gradient discriminator: -3.199275
Gradient professor: 8.400930
Loss Generator D: 3.519884
Loss Generator P: 1.070632
Gradient discriminator: 11.836419
Gradient professor: -20.179252
Loss Generator D: 4.605451
Loss Generator P: 1.373155
Gradient discriminator: -1.146428
Gradient professor: -8.074821
Loss Generator D: 5.413368
Loss Generator P: 1.227098
Gradient discriminator: -3.532937
Gradient professor: 14.638028
Loss Generator D: 3.907651
Loss Generator P: 1.145922
Gradient discriminator: -4.181297
Gradient professor: 5.971635
Loss Generator D: 3.454202
Loss Generator P: 0.997546
Gradient discriminator: 6.103220
Gradient professor: 0.092815
Loss Generator D: 3.475350
Loss Generator P: 1.118378
Gradient discriminator: -5.014188
Gradient professor: 2.933839
Loss Generator D: 3.689090
Loss Generator P: 1.068748
Gradient discriminator: -5.687141
Gradient professor: -44.317240
Loss Generator D: 4.148959
Loss Generator P: 1.096472
Generator    : Epoch:      2, update:     280, cost:   1.096472
Gradient discriminator: 7.337322
Gradient professor: -3.796293
Loss Generator D: 3.870843
Loss Generator P: 0.920673
Gradient discriminator: -5.043465
Gradient professor: 36.426675
Loss Generator D: 3.583641
Loss Generator P: 1.034943
Gradient discriminator: 4.086672
Gradient professor: -12.840167
Loss Generator D: 4.042811
Loss Generator P: 1.418838
Gradient discriminator: -4.649638
Gradient professor: 30.102027
Loss Generator D: 3.355912
Loss Generator P: 1.316189
Gradient discriminator: -8.968102
Gradient professor: 7.357032
Loss Generator D: 3.715298
Loss Generator P: 1.120838
Gradient discriminator: -5.614396
Gradient professor: 12.945777
Loss Generator D: 3.712735
Loss Generator P: 1.051113
Gradient discriminator: 24.551401
Gradient professor: -54.115391
Loss Generator D: 4.292756
Loss Generator P: 1.012461
Gradient discriminator: -18.680866
Gradient professor: 15.674032
Loss Generator D: 3.828251
Loss Generator P: 1.152432
Gradient discriminator: 21.995902
Gradient professor: -15.396590
Loss Generator D: 3.904727
Loss Generator P: 1.095662
Gradient discriminator: 5.635710
Gradient professor: -34.762258
Loss Generator D: 5.096944
Loss Generator P: 1.330525
Generator    : Epoch:      2, update:     290, cost:   1.330525
Gradient discriminator: -2.533723
Gradient professor: 25.305926
Loss Generator D: 4.392225
Loss Generator P: 1.047583
Gradient discriminator: 3.304455
Gradient professor: -10.428748
Loss Generator D: 3.975356
Loss Generator P: 1.079535
Gradient discriminator: -10.611998
Gradient professor: 33.579547
Loss Generator D: 4.757125
Loss Generator P: 1.078189
Gradient discriminator: -6.147636
Gradient professor: -20.233042
Loss Generator D: 5.359229
Loss Generator P: 0.986469
Gradient discriminator: -9.499081
Gradient professor: 4.538734
Loss Generator D: 5.208519
Loss Generator P: 1.218047
Gradient discriminator: 8.261131
Gradient professor: 21.254404
Loss Generator D: 5.075323
Loss Generator P: 1.223018
Gradient discriminator: -1.898546
Gradient professor: -0.230710
Loss Generator D: 4.380009
Loss Generator P: 1.097023
Gradient discriminator: 4.091040
Gradient professor: -0.149072
Loss Generator D: 4.025285
Loss Generator P: 1.209365
Gradient discriminator: 13.289197
Gradient professor: -1.884005
Loss Generator D: 4.620021
Loss Generator P: 1.443616
Gradient discriminator: -10.972903
Gradient professor: 13.446544
Loss Generator D: 3.398071
Loss Generator P: 1.121707
Generator    : Epoch:      2, update:     300, cost:   1.121707
Validation  3 - LOSS = 1.712 (PPL: 5.540)
Calling beam-search process
Beam-search ended, took 2.83557 minutes.
Validation  3 - BLEU = 4.39, 8.8/5.3/3.5/2.3 (BP=1.000, ratio=5.760, hyp_len=24309, ref_len=4220)
Early stopping patience: 998 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.683 (PPL: 5.383) at validation 2
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 9.738206
Gradient professor: 14.184159
Loss Generator D: 3.502367
Loss Generator P: 1.247647
Gradient discriminator: -11.356924
Gradient professor: -25.153696
Loss Generator D: 3.506847
Loss Generator P: 1.124552
Gradient discriminator: 16.986021
Gradient professor: 8.077333
Loss Generator D: 2.826079
Loss Generator P: 0.931455
Gradient discriminator: 9.998668
Gradient professor: -9.930845
Loss Generator D: 3.950736
Loss Generator P: 1.331087
Gradient discriminator: 6.986721
Gradient professor: -4.902237
Loss Generator D: 3.519604
Loss Generator P: 1.195807
Gradient discriminator: 8.326136
Gradient professor: -24.529469
Loss Generator D: 3.756670
Loss Generator P: 1.107316
Gradient discriminator: 23.769553
Gradient professor: 30.101666
Loss Generator D: 2.995350
Loss Generator P: 0.969890
Gradient discriminator: 7.941184
Gradient professor: -30.157118
Loss Generator D: 4.643264
Loss Generator P: 1.112114
Gradient discriminator: -3.880716
Gradient professor: -10.586869
Loss Generator D: 4.091891
Loss Generator P: 1.111138
Gradient discriminator: -9.255921
Gradient professor: -8.544522
Loss Generator D: 3.805070
Loss Generator P: 1.135506
Generator    : Epoch:      2, update:     310, cost:   1.135506
Gradient discriminator: 2.760010
Gradient professor: -16.066984
Loss Generator D: 3.723884
Loss Generator P: 1.107054
Gradient discriminator: -17.982185
Gradient professor: 6.668521
Loss Generator D: 3.420113
Loss Generator P: 1.413318
Gradient discriminator: 17.760865
Gradient professor: -1.408667
Loss Generator D: 3.534107
Loss Generator P: 1.017260
Gradient discriminator: 15.447455
Gradient professor: -24.494910
Loss Generator D: 3.355590
Loss Generator P: 1.133664
Gradient discriminator: -7.773674
Gradient professor: -2.621530
Loss Generator D: 2.888777
Loss Generator P: 1.075869
Gradient discriminator: 5.597588
Gradient professor: -14.235800
Loss Generator D: 3.020141
Loss Generator P: 1.105790
Gradient discriminator: -0.233753
Gradient professor: 17.159043
Loss Generator D: 3.691710
Loss Generator P: 1.154502
Gradient discriminator: 1.006134
Gradient professor: 5.011974
Loss Generator D: 4.124647
Loss Generator P: 1.116179
Gradient discriminator: 2.377368
Gradient professor: -15.041352
Loss Generator D: 4.208667
Loss Generator P: 1.229414
Gradient discriminator: -8.309788
Gradient professor: 8.995986
Loss Generator D: 4.008026
Loss Generator P: 1.149085
Generator    : Epoch:      2, update:     320, cost:   1.149085
Gradient discriminator: 4.418473
Gradient professor: 11.843973
Loss Generator D: 4.687379
Loss Generator P: 1.038608
Gradient discriminator: 10.286015
Gradient professor: -7.095892
Loss Generator D: 4.588671
Loss Generator P: 0.975090
Gradient discriminator: 9.139842
Gradient professor: -5.506836
Loss Generator D: 3.397918
Loss Generator P: 1.200194
Gradient discriminator: 12.118386
Gradient professor: -18.122660
Loss Generator D: 3.901999
Loss Generator P: 1.270441
Gradient discriminator: -9.728910
Gradient professor: 24.710053
Loss Generator D: 3.792885
Loss Generator P: 1.068058
Gradient discriminator: 15.636671
Gradient professor: -11.241588
Loss Generator D: 3.481230
Loss Generator P: 1.020745
Gradient discriminator: -2.525282
Gradient professor: -2.859412
Loss Generator D: 3.741244
Loss Generator P: 1.123502
Gradient discriminator: 8.529273
Gradient professor: 2.988615
Loss Generator D: 3.852850
Loss Generator P: 1.359698
Gradient discriminator: 21.187473
Gradient professor: 32.820389
Loss Generator D: 3.231713
Loss Generator P: 0.849113
Gradient discriminator: 5.411873
Gradient professor: -13.717731
Loss Generator D: 3.040124
Loss Generator P: 0.951646
Generator    : Epoch:      2, update:     330, cost:   0.951646
Gradient discriminator: 3.607384
Gradient professor: 2.387420
Loss Generator D: 3.735486
Loss Generator P: 0.986404
Gradient discriminator: -0.076787
Gradient professor: -15.796009
Loss Generator D: 4.157041
Loss Generator P: 1.051522
Gradient discriminator: 0.357292
Gradient professor: -8.889776
Loss Generator D: 3.371194
Loss Generator P: 1.019786
Gradient discriminator: -3.305560
Gradient professor: -32.557541
Loss Generator D: 4.045487
Loss Generator P: 0.884829
Gradient discriminator: 2.317733
Gradient professor: 0.692762
Loss Generator D: 4.050307
Loss Generator P: 0.979371
Gradient discriminator: 14.940897
Gradient professor: -23.994632
Loss Generator D: 3.282528
Loss Generator P: 0.847251
Gradient discriminator: -1.753492
Gradient professor: 13.872698
Loss Generator D: 3.775655
Loss Generator P: 0.972343
Gradient discriminator: 13.050434
Gradient professor: 11.416825
Loss Generator D: 3.941257
Loss Generator P: 1.195660
Gradient discriminator: -2.718091
Gradient professor: 8.300792
Loss Generator D: 3.829480
Loss Generator P: 1.109041
Gradient discriminator: 4.157954
Gradient professor: -20.967431
Loss Generator D: 4.049955
Loss Generator P: 1.160140
Generator    : Epoch:      2, update:     340, cost:   1.160140
Gradient discriminator: -3.782866
Gradient professor: 12.531494
Loss Generator D: 3.605270
Loss Generator P: 0.977942
Gradient discriminator: 4.635424
Gradient professor: 15.453451
Loss Generator D: 3.548779
Loss Generator P: 1.402420
Gradient discriminator: 3.670133
Gradient professor: 7.556079
Loss Generator D: 3.614293
Loss Generator P: 1.007040
Gradient discriminator: 2.049579
Gradient professor: -4.498260
Loss Generator D: 3.556729
Loss Generator P: 0.902090
Gradient discriminator: 7.795138
Gradient professor: 0.890373
Loss Generator D: 4.091057
Loss Generator P: 1.043997
Gradient discriminator: 13.806173
Gradient professor: -42.924647
Loss Generator D: 3.525226
Loss Generator P: 1.108371
Gradient discriminator: 14.672523
Gradient professor: -11.637358
Loss Generator D: 4.604168
Loss Generator P: 0.931680
Gradient discriminator: 0.792407
Gradient professor: 7.273866
Loss Generator D: 3.560757
Loss Generator P: 0.878469
Gradient discriminator: -4.181563
Gradient professor: -0.303120
Loss Generator D: 3.240153
Loss Generator P: 1.086329
Gradient discriminator: -16.744693
Gradient professor: 25.197730
Loss Generator D: 3.681581
Loss Generator P: 1.086295
Generator    : Epoch:      2, update:     350, cost:   1.086295
Gradient discriminator: 22.294472
Gradient professor: -20.346722
Loss Generator D: 4.085203
Loss Generator P: 1.136747
Gradient discriminator: 23.207188
Gradient professor: -24.803641
Loss Generator D: 4.188544
Loss Generator P: 1.147913
Gradient discriminator: 8.757472
Gradient professor: -2.511713
Loss Generator D: 4.035301
Loss Generator P: 0.930718
Gradient discriminator: -6.583421
Gradient professor: 29.965197
Loss Generator D: 3.607983
Loss Generator P: 0.995217
Gradient discriminator: 3.222310
Gradient professor: -34.020631
Loss Generator D: 3.646095
Loss Generator P: 0.891357
Gradient discriminator: 6.582302
Gradient professor: -15.197013
Loss Generator D: 4.434602
Loss Generator P: 1.172843
Gradient discriminator: 13.773861
Gradient professor: -13.934184
Loss Generator D: 3.574021
Loss Generator P: 0.939628
Gradient discriminator: -8.698789
Gradient professor: -10.519744
Loss Generator D: 3.517141
Loss Generator P: 0.990128
Gradient discriminator: -4.969517
Gradient professor: -16.577597
Loss Generator D: 3.540733
Loss Generator P: 1.092880
Gradient discriminator: 6.412525
Gradient professor: 4.368385
Loss Generator D: 3.771770
Loss Generator P: 0.929621
Generator    : Epoch:      2, update:     360, cost:   0.929621
Gradient discriminator: 21.502559
Gradient professor: 10.805461
Loss Generator D: 3.052625
Loss Generator P: 1.145054
Gradient discriminator: 5.684898
Gradient professor: 11.837657
Loss Generator D: 3.230875
Loss Generator P: 0.964521
Gradient discriminator: 23.002759
Gradient professor: 12.502423
Loss Generator D: 3.940379
Loss Generator P: 0.968630
Gradient discriminator: 2.540671
Gradient professor: -22.094612
Loss Generator D: 3.259286
Loss Generator P: 0.893228
Gradient discriminator: 1.657929
Gradient professor: 23.554012
Loss Generator D: 3.670770
Loss Generator P: 1.142199
Gradient discriminator: 7.128302
Gradient professor: -35.071286
Loss Generator D: 3.568817
Loss Generator P: 1.193400
Gradient discriminator: 1.474711
Gradient professor: 22.501267
Loss Generator D: 3.469334
Loss Generator P: 0.891631
Gradient discriminator: -8.367382
Gradient professor: 31.309065
Loss Generator D: 3.869933
Loss Generator P: 1.217046
Gradient discriminator: -1.509928
Gradient professor: -12.284411
Loss Generator D: 4.436630
Loss Generator P: 1.023397
Gradient discriminator: 0.995489
Gradient professor: 37.641971
Loss Generator D: 3.959878
Loss Generator P: 0.999202
Generator    : Epoch:      2, update:     370, cost:   0.999202
Gradient discriminator: 10.457010
Gradient professor: 36.829654
Loss Generator D: 3.910629
Loss Generator P: 1.170494
Gradient discriminator: 5.711469
Gradient professor: -26.218289
Loss Generator D: 3.300984
Loss Generator P: 1.143092
Gradient discriminator: 1.837238
Gradient professor: 8.643618
Loss Generator D: 3.681262
Loss Generator P: 1.163101
Gradient discriminator: 10.874708
Gradient professor: 35.493229
Loss Generator D: 3.813001
Loss Generator P: 1.140067
Gradient discriminator: 5.857152
Gradient professor: 23.114123
Loss Generator D: 3.438791
Loss Generator P: 1.195494
Gradient discriminator: 8.081575
Gradient professor: 21.556727
Loss Generator D: 3.311082
Loss Generator P: 1.109641
Gradient discriminator: 1.950342
Gradient professor: 12.177465
Loss Generator D: 2.998441
Loss Generator P: 1.047198
Gradient discriminator: 6.586873
Gradient professor: 10.516666
Loss Generator D: 3.977673
Loss Generator P: 1.326125
Gradient discriminator: 2.439095
Gradient professor: 21.252790
Loss Generator D: 3.652335
Loss Generator P: 1.078707
Gradient discriminator: 2.219337
Gradient professor: -13.634653
Loss Generator D: 3.870490
Loss Generator P: 1.174957
Generator    : Epoch:      2, update:     380, cost:   1.174957
Gradient discriminator: 1.546629
Gradient professor: -0.858705
Loss Generator D: 3.328551
Loss Generator P: 0.946322
Gradient discriminator: -10.263032
Gradient professor: 18.095639
Loss Generator D: 3.605419
Loss Generator P: 1.003102
Gradient discriminator: -10.114551
Gradient professor: 7.449636
Loss Generator D: 3.121621
Loss Generator P: 0.879819
Gradient discriminator: 8.220274
Gradient professor: 18.779368
Loss Generator D: 3.247815
Loss Generator P: 1.121915
Gradient discriminator: 5.055179
Gradient professor: 9.975828
Loss Generator D: 3.301003
Loss Generator P: 1.098879
Gradient discriminator: 17.870565
Gradient professor: -10.479502
Loss Generator D: 3.776633
Loss Generator P: 0.788126
Gradient discriminator: -5.659474
Gradient professor: 29.611696
Loss Generator D: 3.747638
Loss Generator P: 1.060003
Gradient discriminator: 7.195550
Gradient professor: -32.388205
Loss Generator D: 3.968378
Loss Generator P: 0.815176
Gradient discriminator: -6.919672
Gradient professor: 30.443019
Loss Generator D: 3.903982
Loss Generator P: 1.180749
Gradient discriminator: 16.857582
Gradient professor: -3.708483
Loss Generator D: 4.312691
Loss Generator P: 1.055789
Generator    : Epoch:      2, update:     390, cost:   1.055789
Gradient discriminator: -0.251040
Gradient professor: -5.444479
Loss Generator D: 4.353364
Loss Generator P: 0.937545
Gradient discriminator: 15.614894
Gradient professor: -0.432488
Loss Generator D: 4.476699
Loss Generator P: 1.099564
Gradient discriminator: -0.495684
Gradient professor: 6.218513
Loss Generator D: 4.438281
Loss Generator P: 1.290959
Gradient discriminator: -10.649458
Gradient professor: -7.430667
Loss Generator D: 3.890522
Loss Generator P: 1.092296
Gradient discriminator: -0.097654
Gradient professor: -4.938890
Loss Generator D: 3.434905
Loss Generator P: 1.207748
Gradient discriminator: 5.914407
Gradient professor: -9.886153
Loss Generator D: 3.336167
Loss Generator P: 1.348373
Gradient discriminator: 6.270802
Gradient professor: 15.512161
Loss Generator D: 3.374680
Loss Generator P: 0.997117
Gradient discriminator: 7.266103
Gradient professor: 7.497606
Loss Generator D: 3.948465
Loss Generator P: 0.931121
Gradient discriminator: 12.453680
Gradient professor: -5.439368
Loss Generator D: 4.199984
Loss Generator P: 0.900935
Gradient discriminator: -4.030345
Gradient professor: -17.830121
Loss Generator D: 3.984023
Loss Generator P: 0.973087
Generator    : Epoch:      2, update:     400, cost:   0.973087
Validation  4 - LOSS = 1.694 (PPL: 5.443)
Calling beam-search process
Beam-search ended, took 2.16266 minutes.
Validation  4 - BLEU = 7.33, 14.6/8.9/5.8/3.8 (BP=1.000, ratio=3.841, hyp_len=16210, ref_len=4220)
Early stopping patience: 997 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.683 (PPL: 5.383) at validation 2
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -15.210548
Gradient professor: 19.108586
Loss Generator D: 4.059406
Loss Generator P: 1.196594
Gradient discriminator: 14.031994
Gradient professor: 52.295827
Loss Generator D: 4.073304
Loss Generator P: 1.069465
Gradient discriminator: -10.142936
Gradient professor: -5.319293
Loss Generator D: 4.488047
Loss Generator P: 1.062735
Gradient discriminator: 13.077557
Gradient professor: -26.223620
Loss Generator D: 3.600029
Loss Generator P: 1.159523
Gradient discriminator: 3.796796
Gradient professor: -15.286574
Loss Generator D: 4.235838
Loss Generator P: 1.189110
Gradient discriminator: 0.117992
Gradient professor: 27.647584
Loss Generator D: 3.287926
Loss Generator P: 0.988742
Gradient discriminator: 9.521172
Gradient professor: 2.530744
Loss Generator D: 4.017500
Loss Generator P: 1.096601
Gradient discriminator: 1.023058
Gradient professor: 4.117155
Loss Generator D: 3.167511
Loss Generator P: 0.951955
Gradient discriminator: -3.858092
Gradient professor: -10.682950
Loss Generator D: 3.836101
Loss Generator P: 0.812366
Gradient discriminator: -2.170715
Gradient professor: -3.796433
Loss Generator D: 3.665607
Loss Generator P: 1.014033
Generator    : Epoch:      2, update:     410, cost:   1.014033
Gradient discriminator: 4.932020
Gradient professor: -11.705084
Loss Generator D: 3.716066
Loss Generator P: 0.951434
Gradient discriminator: -11.075602
Gradient professor: 10.517184
Loss Generator D: 3.756464
Loss Generator P: 1.277946
Gradient discriminator: 0.230800
Gradient professor: 58.540322
Loss Generator D: 3.722502
Loss Generator P: 1.222019
Gradient discriminator: 1.066431
Gradient professor: 25.682957
Loss Generator D: 4.120574
Loss Generator P: 1.369592
Gradient discriminator: 9.786528
Gradient professor: 2.966574
Loss Generator D: 3.228238
Loss Generator P: 1.346990
Gradient discriminator: 6.040223
Gradient professor: 10.889717
Loss Generator D: 3.203971
Loss Generator P: 1.293710
Gradient discriminator: 16.615237
Gradient professor: 28.254550
Loss Generator D: 3.863149
Loss Generator P: 1.255990
Gradient discriminator: 19.082577
Gradient professor: -19.729514
Loss Generator D: 4.038014
Loss Generator P: 1.106972
Gradient discriminator: 11.207105
Gradient professor: -35.871327
Loss Generator D: 3.372342
Loss Generator P: 1.107490
Gradient discriminator: 38.738724
Gradient professor: -21.457621
Loss Generator D: 3.787803
Loss Generator P: 1.218063
Generator    : Epoch:      2, update:     420, cost:   1.218063
Gradient discriminator: -2.599166
Gradient professor: 10.855711
Loss Generator D: 3.508703
Loss Generator P: 0.929963
Gradient discriminator: -12.916937
Gradient professor: 18.564843
Loss Generator D: 3.378740
Loss Generator P: 1.003396
Gradient discriminator: 14.976538
Gradient professor: 16.709099
Loss Generator D: 3.528473
Loss Generator P: 1.066278
Gradient discriminator: 5.516046
Gradient professor: -21.141080
Loss Generator D: 3.830455
Loss Generator P: 0.833059
Gradient discriminator: -42.856040
Gradient professor: -6.218684
Loss Generator D: 3.320191
Loss Generator P: 1.004395
Gradient discriminator: -2.314772
Gradient professor: 35.083842
Loss Generator D: 3.874375
Loss Generator P: 1.007512
Gradient discriminator: 1.915560
Gradient professor: 27.489295
Loss Generator D: 3.059533
Loss Generator P: 1.346830
Gradient discriminator: 2.477338
Gradient professor: -0.599407
Loss Generator D: 3.390180
Loss Generator P: 1.435080
Gradient discriminator: 51.186889
Gradient professor: -15.616055
Loss Generator D: 3.290109
Loss Generator P: 1.202290
Gradient discriminator: -6.656804
Gradient professor: 9.861469
Loss Generator D: 3.858999
Loss Generator P: 0.944923
Generator    : Epoch:      2, update:     430, cost:   0.944923
Gradient discriminator: -12.264038
Gradient professor: 35.049133
Loss Generator D: 3.860099
Loss Generator P: 1.030176
Gradient discriminator: 0.769022
Gradient professor: -29.388357
Loss Generator D: 2.666101
Loss Generator P: 1.104262
Gradient discriminator: 6.275381
Gradient professor: -21.523148
Loss Generator D: 3.627327
Loss Generator P: 1.050453
Gradient discriminator: 22.757009
Gradient professor: 26.232831
Loss Generator D: 2.851351
Loss Generator P: 1.333490
Gradient discriminator: 2.800764
Gradient professor: -21.789323
Loss Generator D: 3.370484
Loss Generator P: 1.266863
Gradient discriminator: 47.469385
Gradient professor: 9.627438
Loss Generator D: 3.010321
Loss Generator P: 1.124806
Gradient discriminator: -33.839597
Gradient professor: 10.329167
Loss Generator D: 2.720628
Loss Generator P: 1.159917
Gradient discriminator: 12.249577
Gradient professor: -31.568241
Loss Generator D: 3.213429
Loss Generator P: 1.230517
Gradient discriminator: 8.412131
Gradient professor: 25.769694
Loss Generator D: 3.680801
Loss Generator P: 1.230344
Gradient discriminator: 1.470543
Gradient professor: -33.483632
Loss Generator D: 2.840162
Loss Generator P: 1.114638
Generator    : Epoch:      2, update:     440, cost:   1.114638
Gradient discriminator: 14.871373
Gradient professor: 32.942603
Loss Generator D: 3.136822
Loss Generator P: 1.224113
Gradient discriminator: -2.245957
Gradient professor: -2.199733
Loss Generator D: 2.899009
Loss Generator P: 1.053886
Gradient discriminator: -6.721517
Gradient professor: 61.440876
Loss Generator D: 3.041167
Loss Generator P: 1.416000
Gradient discriminator: 8.407423
Gradient professor: 5.037739
Loss Generator D: 2.043899
Loss Generator P: 1.367517
Gradient discriminator: 7.420585
Gradient professor: 5.882164
Loss Generator D: 2.197364
Loss Generator P: 0.830825
Gradient discriminator: -3.447774
Gradient professor: -3.687016
Loss Generator D: 3.065485
Loss Generator P: 1.186628
Gradient discriminator: 19.204170
Gradient professor: -5.072943
Loss Generator D: 2.821671
Loss Generator P: 1.124349
Gradient discriminator: 23.566103
Gradient professor: -5.942371
Loss Generator D: 2.327085
Loss Generator P: 1.132277
Gradient discriminator: -0.306402
Gradient professor: 13.551231
Loss Generator D: 2.920766
Loss Generator P: 1.185733
Gradient discriminator: 3.602952
Gradient professor: 8.245393
Loss Generator D: 3.455386
Loss Generator P: 0.984188
Generator    : Epoch:      2, update:     450, cost:   0.984188
Gradient discriminator: 22.073500
Gradient professor: -0.490087
Loss Generator D: 2.989698
Loss Generator P: 1.063780
Gradient discriminator: 20.820431
Gradient professor: -18.287868
Loss Generator D: 2.891656
Loss Generator P: 1.076493
Gradient discriminator: 33.385826
Gradient professor: 23.501676
Loss Generator D: 3.056305
Loss Generator P: 1.075379
Gradient discriminator: 5.183315
Gradient professor: -18.515801
Loss Generator D: 3.298254
Loss Generator P: 1.051167
Gradient discriminator: -7.046373
Gradient professor: -17.113007
Loss Generator D: 2.522495
Loss Generator P: 0.921594
Gradient discriminator: -2.635445
Gradient professor: -6.693650
Loss Generator D: 2.687803
Loss Generator P: 0.933191
Gradient discriminator: 3.167611
Gradient professor: -23.401574
Loss Generator D: 3.176299
Loss Generator P: 1.079303
Gradient discriminator: 10.497661
Gradient professor: -1.894026
Loss Generator D: 2.818791
Loss Generator P: 1.184201
Gradient discriminator: 27.643345
Gradient professor: 6.233926
Loss Generator D: 2.582986
Loss Generator P: 0.987297
Gradient discriminator: 0.377616
Gradient professor: -9.837816
Loss Generator D: 3.078626
Loss Generator P: 1.087803
Generator    : Epoch:      2, update:     460, cost:   1.087803
Gradient discriminator: -1.130174
Gradient professor: -6.564818
Loss Generator D: 2.890351
Loss Generator P: 1.161391
Gradient discriminator: 17.726314
Gradient professor: 41.345298
Loss Generator D: 2.561042
Loss Generator P: 1.206192
Gradient discriminator: -1.351036
Gradient professor: 6.292881
Loss Generator D: 2.512894
Loss Generator P: 1.148350
Gradient discriminator: -4.071495
Gradient professor: 12.873696
Loss Generator D: 2.433780
Loss Generator P: 0.952775
Gradient discriminator: 1.610914
Gradient professor: 15.647955
Loss Generator D: 2.447068
Loss Generator P: 1.146605
Gradient discriminator: 10.315308
Gradient professor: -18.287077
Loss Generator D: 2.750977
Loss Generator P: 1.235096
Gradient discriminator: -31.478378
Gradient professor: 0.418122
Loss Generator D: 2.662023
Loss Generator P: 1.173418
Gradient discriminator: 12.351032
Gradient professor: -17.173637
Loss Generator D: 2.850348
Loss Generator P: 1.072883
Gradient discriminator: 27.786890
Gradient professor: 21.858753
Loss Generator D: 2.469706
Loss Generator P: 0.925458
Gradient discriminator: 11.626877
Gradient professor: -26.709739
Loss Generator D: 2.462812
Loss Generator P: 0.931817
Generator    : Epoch:      2, update:     470, cost:   0.931817
Gradient discriminator: -1.558638
Gradient professor: -28.930361
Loss Generator D: 3.169728
Loss Generator P: 1.201348
Gradient discriminator: 7.460071
Gradient professor: -24.718344
Loss Generator D: 2.204768
Loss Generator P: 1.121669
Gradient discriminator: 10.559236
Gradient professor: -8.295792
Loss Generator D: 3.032088
Loss Generator P: 1.183401
Gradient discriminator: 1.890814
Gradient professor: -1.867154
Loss Generator D: 2.624486
Loss Generator P: 1.029067
Gradient discriminator: -11.003316
Gradient professor: 10.971219
Loss Generator D: 3.542393
Loss Generator P: 0.939306
Gradient discriminator: -15.679190
Gradient professor: -14.265337
Loss Generator D: 2.727711
Loss Generator P: 0.926918
Gradient discriminator: 44.769055
Gradient professor: 13.957594
Loss Generator D: 3.107054
Loss Generator P: 0.995257
Gradient discriminator: 8.661501
Gradient professor: 7.895894
Loss Generator D: 3.375665
Loss Generator P: 0.916008
Gradient discriminator: -17.161413
Gradient professor: -0.189081
Loss Generator D: 2.982140
Loss Generator P: 0.927301
Gradient discriminator: 10.231188
Gradient professor: -3.726900
Loss Generator D: 2.651838
Loss Generator P: 1.087215
Generator    : Epoch:      2, update:     480, cost:   1.087215
Gradient discriminator: 20.739350
Gradient professor: 26.327901
Loss Generator D: 2.803185
Loss Generator P: 1.189310
Gradient discriminator: 3.703886
Gradient professor: -11.303257
Loss Generator D: 3.002389
Loss Generator P: 1.169119
Gradient discriminator: 2.371283
Gradient professor: 31.189979
Loss Generator D: 2.576828
Loss Generator P: 1.140100
Gradient discriminator: 18.220272
Gradient professor: 18.359860
Loss Generator D: 2.961361
Loss Generator P: 0.836740
Gradient discriminator: 4.989326
Gradient professor: 37.966127
Loss Generator D: 2.317401
Loss Generator P: 0.934455
Gradient discriminator: -3.744343
Gradient professor: -35.132679
Loss Generator D: 2.486556
Loss Generator P: 0.986687
Gradient discriminator: 18.826011
Gradient professor: 13.515174
Loss Generator D: 2.638588
Loss Generator P: 0.862667
Gradient discriminator: -3.254577
Gradient professor: -27.575097
Loss Generator D: 2.634952
Loss Generator P: 1.050516
Gradient discriminator: -12.856380
Gradient professor: 14.649438
Loss Generator D: 2.673509
Loss Generator P: 1.006975
Gradient discriminator: 35.691579
Gradient professor: 7.984755
Loss Generator D: 2.259185
Loss Generator P: 1.001946
Generator    : Epoch:      2, update:     490, cost:   1.001946
Gradient discriminator: 12.768041
Gradient professor: -12.854819
Loss Generator D: 2.144097
Loss Generator P: 1.041625
Gradient discriminator: 8.801946
Gradient professor: 29.061566
Loss Generator D: 2.594774
Loss Generator P: 0.984407
Gradient discriminator: 21.397379
Gradient professor: -22.648373
Loss Generator D: 2.235058
Loss Generator P: 0.964662
Gradient discriminator: 6.911394
Gradient professor: -0.392471
Loss Generator D: 1.992841
Loss Generator P: 1.049919
Gradient discriminator: 12.914429
Gradient professor: 31.268252
Loss Generator D: 3.095544
Loss Generator P: 1.150574
Gradient discriminator: 6.651073
Gradient professor: -37.346047
Loss Generator D: 2.900635
Loss Generator P: 0.907986
Gradient discriminator: 2.113420
Gradient professor: 15.375635
Loss Generator D: 2.594081
Loss Generator P: 0.967588
Gradient discriminator: 11.401278
Gradient professor: 4.617423
Loss Generator D: 2.710772
Loss Generator P: 0.871321
Gradient discriminator: 11.862123
Gradient professor: 23.896858
Loss Generator D: 2.583572
Loss Generator P: 1.117047
Gradient discriminator: 5.178846
Gradient professor: -9.614167
Loss Generator D: 2.518133
Loss Generator P: 0.749833
Generator    : Epoch:      2, update:     500, cost:   0.749833
Validation  5 - LOSS = 1.655 (PPL: 5.231)
Calling beam-search process
Beam-search ended, took 3.02051 minutes.
Validation  5 - BLEU = 5.71, 11.0/6.9/4.6/3.0 (BP=1.000, ratio=5.307, hyp_len=22395, ref_len=4220)
Early stopping patience: 996 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.655 (PPL: 5.231) at validation 5
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 2 finished with mean loss 2.34013 (PPL: 10.38256)
--> Epoch took 408.005 minutes, 97.921 sec/update
Epoch summary of Discriminator:
--> Epoch 2 finished with mean loss nan (PPL:  nan)
--> Epoch took 408.005 minutes, 97.921 sec/update
---------------------------------------------------------
Starting Epoch 3
----------------
Gradient discriminator: 9.680123
Gradient professor: 32.486929
Loss Generator D: 2.515386
Loss Generator P: 1.321248
Gradient discriminator: 5.015810
Gradient professor: 25.954553
Loss Generator D: 2.591098
Loss Generator P: 1.145961
Gradient discriminator: 4.978848
Gradient professor: 88.776901
Loss Generator D: 2.967495
Loss Generator P: 1.061964
Gradient discriminator: -3.956748
Gradient professor: -12.623783
Loss Generator D: 2.848912
Loss Generator P: 1.209139
Gradient discriminator: 19.733085
Gradient professor: 2.025489
Loss Generator D: 2.892923
Loss Generator P: 0.936428
Gradient discriminator: 3.276670
Gradient professor: 15.213422
Loss Generator D: 2.131176
Loss Generator P: 1.034017
Gradient discriminator: 9.649363
Gradient professor: 15.546452
Loss Generator D: 2.770838
Loss Generator P: 1.080256
Gradient discriminator: 16.996976
Gradient professor: 17.173284
Loss Generator D: 2.900696
Loss Generator P: 0.949303
Gradient discriminator: -4.254558
Gradient professor: 4.044152
Loss Generator D: 2.676614
Loss Generator P: 1.232775
Gradient discriminator: 9.651730
Gradient professor: -7.411488
Loss Generator D: 2.443827
Loss Generator P: 1.300524
Generator    : Epoch:      3, update:     510, cost:   1.300524
Gradient discriminator: 17.246169
Gradient professor: 33.601598
Loss Generator D: 2.623984
Loss Generator P: 1.296356
Gradient discriminator: 45.972749
Gradient professor: -20.316940
Loss Generator D: 2.989026
Loss Generator P: 1.097726
Gradient discriminator: 4.787930
Gradient professor: 30.680159
Loss Generator D: 2.757219
Loss Generator P: 1.251081
Gradient discriminator: 30.524387
Gradient professor: -24.713026
Loss Generator D: 2.903277
Loss Generator P: 1.187999
Gradient discriminator: 15.406507
Gradient professor: 14.006599
Loss Generator D: 2.356957
Loss Generator P: 0.934653
Gradient discriminator: 3.172463
Gradient professor: -32.664806
Loss Generator D: 2.564278
Loss Generator P: 0.731340
Gradient discriminator: 44.147541
Gradient professor: -15.391064
Loss Generator D: 2.919067
Loss Generator P: 1.005809
Gradient discriminator: 28.543259
Gradient professor: 32.896589
Loss Generator D: 3.130040
Loss Generator P: 0.999439
Gradient discriminator: 14.850985
Gradient professor: -3.642878
Loss Generator D: 3.338160
Loss Generator P: 1.138639
Gradient discriminator: 22.308436
Gradient professor: 34.676264
Loss Generator D: 2.597722
Loss Generator P: 1.148692
Generator    : Epoch:      3, update:     520, cost:   1.148692
Gradient discriminator: 21.346525
Gradient professor: -13.230003
Loss Generator D: 2.672950
Loss Generator P: 1.116254
Gradient discriminator: 33.631525
Gradient professor: -0.137142
Loss Generator D: 2.979644
Loss Generator P: 1.022777
Gradient discriminator: 74.067007
Gradient professor: -29.078760
Loss Generator D: 2.423104
Loss Generator P: 0.988251
Gradient discriminator: -3.756621
Gradient professor: 14.515236
Loss Generator D: 2.857729
Loss Generator P: 1.256399
Gradient discriminator: 35.025786
Gradient professor: -5.551768
Loss Generator D: 2.999328
Loss Generator P: 1.176332
Gradient discriminator: 5.368638
Gradient professor: 32.124904
Loss Generator D: 2.575544
Loss Generator P: 0.980478
Gradient discriminator: 19.707546
Gradient professor: -19.808356
Loss Generator D: 3.050665
Loss Generator P: 0.936983
Gradient discriminator: 28.035599
Gradient professor: 37.397094
Loss Generator D: 2.658944
Loss Generator P: 1.054833
Gradient discriminator: 30.811166
Gradient professor: -25.513263
Loss Generator D: 2.732404
Loss Generator P: 1.008403
Gradient discriminator: 4.230070
Gradient professor: 15.103556
Loss Generator D: 2.236723
Loss Generator P: 1.033315
Generator    : Epoch:      3, update:     530, cost:   1.033315
Gradient discriminator: 27.996004
Gradient professor: 2.332120
Loss Generator D: 2.758498
Loss Generator P: 0.896159
Gradient discriminator: 45.743238
Gradient professor: 41.090548
Loss Generator D: 2.152301
Loss Generator P: 0.926989
Gradient discriminator: 20.881637
Gradient professor: 0.002690
Loss Generator D: 2.697159
Loss Generator P: 1.226759
Gradient discriminator: -15.113273
Gradient professor: 5.104992
Loss Generator D: 2.786370
Loss Generator P: 1.223720
Gradient discriminator: -2.231139
Gradient professor: -13.517626
Loss Generator D: 3.181980
Loss Generator P: 0.958955
Gradient discriminator: 22.545607
Gradient professor: -17.868841
Loss Generator D: 2.870936
Loss Generator P: 0.958121
Gradient discriminator: 24.609633
Gradient professor: 2.774828
Loss Generator D: 2.745457
Loss Generator P: 0.906799
Gradient discriminator: 6.136335
Gradient professor: 17.490404
Loss Generator D: 2.876000
Loss Generator P: 1.025100
Gradient discriminator: 12.302539
Gradient professor: -2.036722
Loss Generator D: 2.245821
Loss Generator P: 1.006171
Gradient discriminator: 14.953243
Gradient professor: -9.911496
Loss Generator D: 3.406087
Loss Generator P: 1.359903
Generator    : Epoch:      3, update:     540, cost:   1.359903
Gradient discriminator: 2.065955
Gradient professor: 30.228372
Loss Generator D: 2.801749
Loss Generator P: 1.012354
Gradient discriminator: 18.785206
Gradient professor: 7.631026
Loss Generator D: 3.255698
Loss Generator P: 0.979692
Gradient discriminator: 2.339333
Gradient professor: -20.092722
Loss Generator D: 2.672079
Loss Generator P: 1.030990
Gradient discriminator: 15.310664
Gradient professor: 21.537727
Loss Generator D: 2.566806
Loss Generator P: 0.884990
Gradient discriminator: -4.309575
Gradient professor: -11.334485
Loss Generator D: 2.910629
Loss Generator P: 1.168730
Gradient discriminator: 2.294102
Gradient professor: -9.724218
Loss Generator D: 2.889535
Loss Generator P: 1.169779
Gradient discriminator: 3.252419
Gradient professor: 26.204540
Loss Generator D: 2.659078
Loss Generator P: 1.004490
Gradient discriminator: 5.869666
Gradient professor: -1.426332
Loss Generator D: 2.769559
Loss Generator P: 1.185472
Gradient discriminator: 10.284696
Gradient professor: 6.522365
Loss Generator D: 2.593993
Loss Generator P: 1.364579
Gradient discriminator: -17.524686
Gradient professor: 5.733969
Loss Generator D: 2.411256
Loss Generator P: 1.135167
Generator    : Epoch:      3, update:     550, cost:   1.135167
Gradient discriminator: 6.279136
Gradient professor: 33.165654
Loss Generator D: 2.753331
Loss Generator P: 1.121717
Gradient discriminator: -12.212940
Gradient professor: 10.359222
Loss Generator D: 2.291565
Loss Generator P: 1.070526
Gradient discriminator: 16.813373
Gradient professor: 7.791158
Loss Generator D: 1.826454
Loss Generator P: 0.927122
Gradient discriminator: 3.842971
Gradient professor: -3.195275
Loss Generator D: 2.493402
Loss Generator P: 1.204199
Gradient discriminator: -14.730376
Gradient professor: -27.620492
Loss Generator D: 2.493368
Loss Generator P: 1.060103
Gradient discriminator: 4.961865
Gradient professor: 16.368795
Loss Generator D: 2.516698
Loss Generator P: 0.939922
Gradient discriminator: 3.945396
Gradient professor: 19.089799
Loss Generator D: 2.127792
Loss Generator P: 0.971589
Gradient discriminator: 4.951400
Gradient professor: -17.822634
Loss Generator D: 2.475468
Loss Generator P: 1.002356
Gradient discriminator: 0.282855
Gradient professor: 9.685825
Loss Generator D: 2.494073
Loss Generator P: 1.027311
Gradient discriminator: -40.102790
Gradient professor: 5.513994
Loss Generator D: 2.495907
Loss Generator P: 1.060841
Generator    : Epoch:      3, update:     560, cost:   1.060841
Gradient discriminator: 19.686742
Gradient professor: -17.587838
Loss Generator D: 2.390280
Loss Generator P: 1.059746
Gradient discriminator: 4.944000
Gradient professor: 20.329625
Loss Generator D: 1.882419
Loss Generator P: 1.283755
Gradient discriminator: 15.673392
Gradient professor: 3.188896
Loss Generator D: 2.157876
Loss Generator P: 0.969684
Gradient discriminator: 4.333394
Gradient professor: -9.499118
Loss Generator D: 2.200771
Loss Generator P: 0.971575
Gradient discriminator: 29.660555
Gradient professor: -22.070811
Loss Generator D: 2.575093
Loss Generator P: 1.012891
Gradient discriminator: 25.924074
Gradient professor: 23.456052
Loss Generator D: 2.131170
Loss Generator P: 1.048576
Gradient discriminator: 5.810157
Gradient professor: -11.725379
Loss Generator D: 2.813482
Loss Generator P: 1.039643
Gradient discriminator: 14.907837
Gradient professor: 6.245279
Loss Generator D: 2.557052
Loss Generator P: 1.035890
Gradient discriminator: 10.645102
Gradient professor: 0.529660
Loss Generator D: 2.663928
Loss Generator P: 1.162485
Gradient discriminator: 3.691053
Gradient professor: -16.619924
Loss Generator D: 2.157249
Loss Generator P: 1.137353
Generator    : Epoch:      3, update:     570, cost:   1.137353
Gradient discriminator: 19.802803
Gradient professor: 10.638897
Loss Generator D: 2.935748
Loss Generator P: 0.943354
Gradient discriminator: 26.501806
Gradient professor: -31.283996
Loss Generator D: 1.923672
Loss Generator P: 0.866477
Gradient discriminator: 30.160076
Gradient professor: 31.671034
Loss Generator D: 2.116850
Loss Generator P: 1.021559
Gradient discriminator: 12.072623
Gradient professor: -2.778612
Loss Generator D: 2.068335
Loss Generator P: 1.096229
Gradient discriminator: -2.170053
Gradient professor: 20.592652
Loss Generator D: 2.475332
Loss Generator P: 0.934516
Gradient discriminator: -4.373540
Gradient professor: -13.519480
Loss Generator D: 2.318751
Loss Generator P: 0.937897
Gradient discriminator: 8.498605
Gradient professor: 7.161098
Loss Generator D: 2.511489
Loss Generator P: 1.035269
Gradient discriminator: 37.151224
Gradient professor: 18.899436
Loss Generator D: 2.644805
Loss Generator P: 1.118314
Gradient discriminator: 16.564892
Gradient professor: -7.243834
Loss Generator D: 2.162938
Loss Generator P: 0.717215
Gradient discriminator: -19.898944
Gradient professor: -6.844380
Loss Generator D: 2.332811
Loss Generator P: 0.776856
Generator    : Epoch:      3, update:     580, cost:   0.776856
Gradient discriminator: 13.493756
Gradient professor: 17.662460
Loss Generator D: 3.189770
Loss Generator P: 0.872632
Gradient discriminator: 27.041157
Gradient professor: -12.904257
Loss Generator D: 2.786094
Loss Generator P: 0.956116
Gradient discriminator: 16.699729
Gradient professor: 17.575971
Loss Generator D: 2.159591
Loss Generator P: 0.957524
Gradient discriminator: 29.531584
Gradient professor: 2.901191
Loss Generator D: 2.673454
Loss Generator P: 0.726869
Gradient discriminator: 20.113899
Gradient professor: 5.622945
Loss Generator D: 2.594786
Loss Generator P: 0.809431
Gradient discriminator: 13.935311
Gradient professor: -15.130037
Loss Generator D: 2.407372
Loss Generator P: 0.790193
Gradient discriminator: 6.440541
Gradient professor: 1.064037
Loss Generator D: 3.425292
Loss Generator P: 0.831521
Gradient discriminator: 33.278219
Gradient professor: -0.628870
Loss Generator D: 2.358295
Loss Generator P: 1.092491
Gradient discriminator: -3.204370
Gradient professor: -5.307001
Loss Generator D: 2.579440
Loss Generator P: 0.981949
Gradient discriminator: 21.601752
Gradient professor: 3.998493
Loss Generator D: 2.440636
Loss Generator P: 1.071648
Generator    : Epoch:      3, update:     590, cost:   1.071648
Gradient discriminator: 3.144702
Gradient professor: 9.312056
Loss Generator D: 2.658927
Loss Generator P: 0.921512
Gradient discriminator: 5.350803
Gradient professor: -7.246743
Loss Generator D: 2.140764
Loss Generator P: 1.248839
Gradient discriminator: 5.725276
Gradient professor: 2.190748
Loss Generator D: 2.529338
Loss Generator P: 0.900346
Gradient discriminator: -0.056118
Gradient professor: -4.645096
Loss Generator D: 2.218598
Loss Generator P: 0.766959
Gradient discriminator: 3.592299
Gradient professor: -9.471460
Loss Generator D: 2.391019
Loss Generator P: 0.963503
Gradient discriminator: -1.869405
Gradient professor: -14.211043
Loss Generator D: 1.983914
Loss Generator P: 1.030634
Gradient discriminator: -15.218289
Gradient professor: -14.315040
Loss Generator D: 2.317138
Loss Generator P: 0.887621
Gradient discriminator: 10.945727
Gradient professor: 23.404511
Loss Generator D: 1.839943
Loss Generator P: 0.833612
Gradient discriminator: 3.897070
Gradient professor: 0.310010
Loss Generator D: 2.222738
Loss Generator P: 0.991988
Gradient discriminator: 4.114209
Gradient professor: 0.506186
Loss Generator D: 2.584283
Loss Generator P: 1.037330
Generator    : Epoch:      3, update:     600, cost:   1.037330
Validation  6 - LOSS = 1.646 (PPL: 5.188)
Calling beam-search process
Beam-search ended, took 3.44946 minutes.
Validation  6 - BLEU = 4.00, 7.7/4.9/3.2/2.1 (BP=1.000, ratio=7.362, hyp_len=31066, ref_len=4220)
Early stopping patience: 995 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.646 (PPL: 5.188) at validation 6
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -3.669794
Gradient professor: -41.570531
Loss Generator D: 2.214385
Loss Generator P: 1.027977
Gradient discriminator: 56.254926
Gradient professor: -17.979820
Loss Generator D: 2.223907
Loss Generator P: 1.022377
Gradient discriminator: 11.276592
Gradient professor: 1.461608
Loss Generator D: 3.100275
Loss Generator P: 0.799476
Gradient discriminator: 9.560810
Gradient professor: -10.878646
Loss Generator D: 2.089400
Loss Generator P: 0.929735
Gradient discriminator: -11.919330
Gradient professor: -12.551339
Loss Generator D: 2.140562
Loss Generator P: 0.798379
Gradient discriminator: 15.153420
Gradient professor: -0.812018
Loss Generator D: 2.409143
Loss Generator P: 1.057259
Gradient discriminator: 9.751457
Gradient professor: -0.767654
Loss Generator D: 1.791154
Loss Generator P: 0.864576
Gradient discriminator: 11.681894
Gradient professor: -29.149801
Loss Generator D: 2.424487
Loss Generator P: 0.919281
Gradient discriminator: 4.510708
Gradient professor: -14.642400
Loss Generator D: 2.363004
Loss Generator P: 0.963279
Gradient discriminator: -8.891746
Gradient professor: -8.800862
Loss Generator D: 2.514100
Loss Generator P: 0.850132
Generator    : Epoch:      3, update:     610, cost:   0.850132
Gradient discriminator: 1.600833
Gradient professor: -10.566448
Loss Generator D: 2.284766
Loss Generator P: 1.170698
Gradient discriminator: -24.290389
Gradient professor: 0.007786
Loss Generator D: 2.040627
Loss Generator P: 0.951474
Gradient discriminator: 10.457418
Gradient professor: 3.878857
Loss Generator D: 2.796853
Loss Generator P: 0.893118
Gradient discriminator: 0.275630
Gradient professor: -2.946477
Loss Generator D: 2.547163
Loss Generator P: 0.748135
Gradient discriminator: -10.681718
Gradient professor: -3.646197
Loss Generator D: 2.612831
Loss Generator P: 1.037584
Gradient discriminator: 29.102401
Gradient professor: -42.972137
Loss Generator D: 2.537695
Loss Generator P: 1.105721
Gradient discriminator: 6.235864
Gradient professor: -11.531629
Loss Generator D: 2.103442
Loss Generator P: 0.796623
Gradient discriminator: 28.368055
Gradient professor: 6.417498
Loss Generator D: 2.266593
Loss Generator P: 1.079001
Gradient discriminator: 20.111179
Gradient professor: 0.349652
Loss Generator D: 2.200107
Loss Generator P: 0.907682
Gradient discriminator: 7.738888
Gradient professor: -1.620278
Loss Generator D: 2.982840
Loss Generator P: 0.903287
Generator    : Epoch:      3, update:     620, cost:   0.903287
Gradient discriminator: 5.769917
Gradient professor: 9.409546
Loss Generator D: 2.593978
Loss Generator P: 1.061395
Gradient discriminator: -0.137612
Gradient professor: 2.229751
Loss Generator D: 2.391189
Loss Generator P: 1.015573
Gradient discriminator: 2.004351
Gradient professor: 11.701628
Loss Generator D: 2.655361
Loss Generator P: 1.101692
Gradient discriminator: 13.777955
Gradient professor: 36.625069
Loss Generator D: 2.558597
Loss Generator P: 1.004043
Gradient discriminator: -0.819020
Gradient professor: 10.783890
Loss Generator D: 2.589539
Loss Generator P: 1.131603
Gradient discriminator: -1.217741
Gradient professor: -10.613718
Loss Generator D: 2.323927
Loss Generator P: 0.981039
Gradient discriminator: 13.853013
Gradient professor: 28.485364
Loss Generator D: 2.263835
Loss Generator P: 1.050697
Gradient discriminator: 10.553950
Gradient professor: 23.220118
Loss Generator D: 2.521401
Loss Generator P: 1.178320
Gradient discriminator: 2.063986
Gradient professor: -0.154489
Loss Generator D: 2.269061
Loss Generator P: 1.046224
Gradient discriminator: 1.337653
Gradient professor: -28.760274
Loss Generator D: 2.433206
Loss Generator P: 1.039273
Generator    : Epoch:      3, update:     630, cost:   1.039273
Gradient discriminator: 21.876164
Gradient professor: -0.019043
Loss Generator D: 2.302517
Loss Generator P: 0.890856
Gradient discriminator: -2.497639
Gradient professor: 16.883628
Loss Generator D: 1.937140
Loss Generator P: 0.932197
Gradient discriminator: -5.881291
Gradient professor: 1.678360
Loss Generator D: 2.096078
Loss Generator P: 0.863329
Gradient discriminator: -34.474903
Gradient professor: -2.481471
Loss Generator D: 2.010077
Loss Generator P: 1.082413
Gradient discriminator: -15.250828
Gradient professor: 10.399586
Loss Generator D: 2.150571
Loss Generator P: 1.033294
Gradient discriminator: 12.804997
Gradient professor: 0.789837
Loss Generator D: 2.155292
Loss Generator P: 0.756126
Gradient discriminator: 1.653780
Gradient professor: -4.878947
Loss Generator D: 1.899283
Loss Generator P: 0.973516
Gradient discriminator: 4.468524
Gradient professor: -7.682062
Loss Generator D: 2.412295
Loss Generator P: 0.770073
Gradient discriminator: 13.404793
Gradient professor: 19.101548
Loss Generator D: 2.406267
Loss Generator P: 1.078265
Gradient discriminator: -6.328966
Gradient professor: 6.293607
Loss Generator D: 2.186769
Loss Generator P: 0.934905
Generator    : Epoch:      3, update:     640, cost:   0.934905
Gradient discriminator: 28.774016
Gradient professor: -21.365493
Loss Generator D: 2.265028
Loss Generator P: 0.912800
Gradient discriminator: 0.081310
Gradient professor: 0.287571
Loss Generator D: 2.586459
Loss Generator P: 1.043468
Gradient discriminator: 2.982074
Gradient professor: 6.241939
Loss Generator D: 3.499158
Loss Generator P: 1.067419
Gradient discriminator: -2.191887
Gradient professor: -46.706077
Loss Generator D: 3.228360
Loss Generator P: 1.047362
Gradient discriminator: 3.099896
Gradient professor: 5.604481
Loss Generator D: 3.462174
Loss Generator P: 1.206672
Gradient discriminator: -1.399919
Gradient professor: 37.994898
Loss Generator D: 2.984604
Loss Generator P: 1.243736
Gradient discriminator: -2.903717
Gradient professor: -3.018107
Loss Generator D: 3.578897
Loss Generator P: 0.803434
Gradient discriminator: 1.254970
Gradient professor: 13.946841
Loss Generator D: 3.301390
Loss Generator P: 0.850788
Gradient discriminator: -1.521893
Gradient professor: 15.324125
Loss Generator D: 3.078340
Loss Generator P: 0.871672
Gradient discriminator: 7.552790
Gradient professor: -36.674371
Loss Generator D: 3.815463
Loss Generator P: 0.864703
Generator    : Epoch:      3, update:     650, cost:   0.864703
Gradient discriminator: 25.403539
Gradient professor: 38.769675
Loss Generator D: 3.154299
Loss Generator P: 1.056821
Gradient discriminator: -9.867562
Gradient professor: 11.228806
Loss Generator D: 3.825642
Loss Generator P: 1.019185
Gradient discriminator: 0.890286
Gradient professor: 20.190135
Loss Generator D: 2.946045
Loss Generator P: 1.077659
Gradient discriminator: -2.335995
Gradient professor: -7.069381
Loss Generator D: 2.844702
Loss Generator P: 0.995869
Gradient discriminator: 14.417565
Gradient professor: 23.498272
Loss Generator D: 3.461957
Loss Generator P: 1.051050
Gradient discriminator: 4.699307
Gradient professor: -23.083375
Loss Generator D: 3.287234
Loss Generator P: 0.901179
Gradient discriminator: -0.143997
Gradient professor: 4.082388
Loss Generator D: 3.130890
Loss Generator P: 0.991779
Gradient discriminator: 0.476705
Gradient professor: -8.480197
Loss Generator D: 3.201697
Loss Generator P: 0.831873
Gradient discriminator: 1.974470
Gradient professor: 2.903686
Loss Generator D: 3.072721
Loss Generator P: 0.816566
Gradient discriminator: 2.584809
Gradient professor: -15.230460
Loss Generator D: 3.061247
Loss Generator P: 0.861628
Generator    : Epoch:      3, update:     660, cost:   0.861628
Gradient discriminator: 11.972999
Gradient professor: 21.348021
Loss Generator D: 2.972014
Loss Generator P: 0.878590
Gradient discriminator: 0.827215
Gradient professor: 20.448232
Loss Generator D: 3.503149
Loss Generator P: 1.162698
Gradient discriminator: -14.289715
Gradient professor: 17.770890
Loss Generator D: 3.202321
Loss Generator P: 1.144793
Gradient discriminator: 10.021071
Gradient professor: -5.583357
Loss Generator D: 3.632443
Loss Generator P: 1.200878
Gradient discriminator: -0.813222
Gradient professor: 32.905666
Loss Generator D: 3.150684
Loss Generator P: 1.197207
Gradient discriminator: 10.401416
Gradient professor: 13.038720
Loss Generator D: 2.961362
Loss Generator P: 1.153389
Gradient discriminator: -13.311860
Gradient professor: 48.437762
Loss Generator D: 3.352682
Loss Generator P: 1.151118
Gradient discriminator: 6.362253
Gradient professor: -14.573842
Loss Generator D: 3.443605
Loss Generator P: 0.978418
Gradient discriminator: -4.765090
Gradient professor: -4.523015
Loss Generator D: 3.165209
Loss Generator P: 1.064305
Gradient discriminator: -0.930457
Gradient professor: -16.178090
Loss Generator D: 3.575989
Loss Generator P: 1.110790
Generator    : Epoch:      3, update:     670, cost:   1.110790
Gradient discriminator: 0.918545
Gradient professor: -6.525082
Loss Generator D: 3.074217
Loss Generator P: 0.898065
Gradient discriminator: 3.985893
Gradient professor: 1.465181
Loss Generator D: 3.072306
Loss Generator P: 0.960099
Gradient discriminator: 16.701393
Gradient professor: 13.871503
Loss Generator D: 2.486280
Loss Generator P: 0.984243
Gradient discriminator: -4.152265
Gradient professor: -21.798071
Loss Generator D: 3.189256
Loss Generator P: 0.811754
Gradient discriminator: -1.504425
Gradient professor: -16.025845
Loss Generator D: 3.014311
Loss Generator P: 0.898978
Gradient discriminator: 5.370631
Gradient professor: 31.920830
Loss Generator D: 3.143323
Loss Generator P: 0.943370
Gradient discriminator: 7.276572
Gradient professor: -14.519033
Loss Generator D: 2.604406
Loss Generator P: 1.239178
Gradient discriminator: 4.706405
Gradient professor: 13.166431
Loss Generator D: 3.044122
Loss Generator P: 1.270349
Gradient discriminator: 2.404862
Gradient professor: -1.716404
Loss Generator D: 3.137155
Loss Generator P: 1.112881
Gradient discriminator: 5.381463
Gradient professor: 7.070862
Loss Generator D: 3.225121
Loss Generator P: 0.912694
Generator    : Epoch:      3, update:     680, cost:   0.912694
Gradient discriminator: -4.696748
Gradient professor: 23.671579
Loss Generator D: 3.383188
Loss Generator P: 0.973550
Gradient discriminator: -0.389724
Gradient professor: -25.561709
Loss Generator D: 2.547723
Loss Generator P: 1.048407
Gradient discriminator: 16.698204
Gradient professor: 13.420190
Loss Generator D: 2.917584
Loss Generator P: 0.959163
Gradient discriminator: 8.575884
Gradient professor: -44.757086
Loss Generator D: 3.083994
Loss Generator P: 1.293015
Gradient discriminator: -24.894862
Gradient professor: 11.225688
Loss Generator D: 2.666967
Loss Generator P: 1.070159
Gradient discriminator: -1.753247
Gradient professor: -3.605958
Loss Generator D: 3.666441
Loss Generator P: 0.973359
Gradient discriminator: -3.771645
Gradient professor: 19.648037
Loss Generator D: 2.686312
Loss Generator P: 1.096150
Gradient discriminator: -13.663599
Gradient professor: -7.211554
Loss Generator D: 3.061349
Loss Generator P: 1.142610
Gradient discriminator: 1.562091
Gradient professor: 25.239860
Loss Generator D: 4.322037
Loss Generator P: 1.215298
Gradient discriminator: 1.135195
Gradient professor: -41.130018
Loss Generator D: 3.354752
Loss Generator P: 1.103184
Generator    : Epoch:      3, update:     690, cost:   1.103184
Gradient discriminator: 3.995268
Gradient professor: -7.530647
Loss Generator D: 3.556514
Loss Generator P: 1.178363
Gradient discriminator: 10.070264
Gradient professor: 20.300407
Loss Generator D: 3.171600
Loss Generator P: 0.990267
Gradient discriminator: 4.375178
Gradient professor: -26.539516
Loss Generator D: 3.149961
Loss Generator P: 1.409130
Gradient discriminator: 14.215299
Gradient professor: 36.326679
Loss Generator D: 2.613669
Loss Generator P: 1.296109
Gradient discriminator: 12.464772
Gradient professor: -17.006775
Loss Generator D: 2.739410
Loss Generator P: 0.885474
Gradient discriminator: 8.622082
Gradient professor: 5.248604
Loss Generator D: 2.792283
Loss Generator P: 1.091254
Gradient discriminator: 3.180604
Gradient professor: -54.952139
Loss Generator D: 3.362092
Loss Generator P: 1.112087
Gradient discriminator: 40.743124
Gradient professor: -16.899909
Loss Generator D: 2.426095
Loss Generator P: 1.127715
Gradient discriminator: 20.710636
Gradient professor: 11.052247
Loss Generator D: 2.839836
Loss Generator P: 1.197815
Gradient discriminator: 3.566172
Gradient professor: -8.393553
Loss Generator D: 3.467527
Loss Generator P: 0.968482
Generator    : Epoch:      3, update:     700, cost:   0.968482
Validation  7 - LOSS = 1.629 (PPL: 5.098)
Calling beam-search process
Beam-search ended, took 2.53205 minutes.
Validation  7 - BLEU = 6.29, 12.1/7.5/5.1/3.4 (BP=1.000, ratio=4.918, hyp_len=20755, ref_len=4220)
Early stopping patience: 994 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.629 (PPL: 5.098) at validation 7
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -6.404264
Gradient professor: -16.920569
Loss Generator D: 2.884305
Loss Generator P: 1.013661
Gradient discriminator: 23.914846
Gradient professor: 8.673610
Loss Generator D: 3.022584
Loss Generator P: 1.033354
Gradient discriminator: 4.840242
Gradient professor: 17.125218
Loss Generator D: 3.030027
Loss Generator P: 1.031958
Gradient discriminator: 8.213079
Gradient professor: -5.582105
Loss Generator D: 3.307361
Loss Generator P: 0.991005
Gradient discriminator: 5.849676
Gradient professor: -10.040764
Loss Generator D: 2.909964
Loss Generator P: 0.871315
Gradient discriminator: 1.548191
Gradient professor: -15.448231
Loss Generator D: 3.176189
Loss Generator P: 0.917707
Gradient discriminator: -1.873469
Gradient professor: 1.091016
Loss Generator D: 3.647499
Loss Generator P: 1.054835
Gradient discriminator: 13.162861
Gradient professor: -7.812081
Loss Generator D: 3.569794
Loss Generator P: 1.044611
Gradient discriminator: 28.071728
Gradient professor: -2.084594
Loss Generator D: 2.582624
Loss Generator P: 0.935771
Gradient discriminator: -4.175780
Gradient professor: -8.843958
Loss Generator D: 3.047494
Loss Generator P: 1.048149
Generator    : Epoch:      3, update:     710, cost:   1.048149
Gradient discriminator: -0.838052
Gradient professor: 62.585762
Loss Generator D: 3.290630
Loss Generator P: 1.078785
Gradient discriminator: 4.173944
Gradient professor: -31.541781
Loss Generator D: 2.953692
Loss Generator P: 1.244864
Gradient discriminator: 3.776047
Gradient professor: 32.501703
Loss Generator D: 2.970563
Loss Generator P: 1.135501
Gradient discriminator: 11.275223
Gradient professor: 0.859758
Loss Generator D: 2.381736
Loss Generator P: 0.858504
Gradient discriminator: 1.599255
Gradient professor: 28.304650
Loss Generator D: 2.766696
Loss Generator P: 1.043863
Gradient discriminator: 13.805736
Gradient professor: -15.039252
Loss Generator D: 2.920076
Loss Generator P: 1.082854
Gradient discriminator: 1.914978
Gradient professor: -14.100810
Loss Generator D: 2.312975
Loss Generator P: 1.050594
Gradient discriminator: 6.168611
Gradient professor: 6.553094
Loss Generator D: 2.670264
Loss Generator P: 0.883293
Gradient discriminator: -36.835084
Gradient professor: 6.600206
Loss Generator D: 2.491314
Loss Generator P: 0.748583
Gradient discriminator: 8.052019
Gradient professor: -14.093706
Loss Generator D: 2.608276
Loss Generator P: 0.840680
Generator    : Epoch:      3, update:     720, cost:   0.840680
Gradient discriminator: 8.544769
Gradient professor: -1.494576
Loss Generator D: 2.319593
Loss Generator P: 0.975081
Gradient discriminator: 3.306826
Gradient professor: -22.294893
Loss Generator D: 2.280433
Loss Generator P: 1.025022
Gradient discriminator: -18.750951
Gradient professor: 7.094978
Loss Generator D: 2.514364
Loss Generator P: 1.077471
Gradient discriminator: 14.011045
Gradient professor: -13.709938
Loss Generator D: 2.755620
Loss Generator P: 0.954882
Gradient discriminator: -26.202063
Gradient professor: 7.086605
Loss Generator D: 1.911674
Loss Generator P: 0.922490
Gradient discriminator: -0.640506
Gradient professor: -87.145320
Loss Generator D: 1.834725
Loss Generator P: 0.891304
Gradient discriminator: 38.871959
Gradient professor: 11.666759
Loss Generator D: 1.703825
Loss Generator P: 0.909477
Gradient discriminator: -18.083670
Gradient professor: 2.142374
Loss Generator D: 2.533214
Loss Generator P: 0.875926
Discriminator: Epoch:      3, update:     728, cost:   0.240412
Gradient discriminator: -9.228483
Gradient professor: 19.700022
Loss Generator D: 2.548762
Loss Generator P: 0.980052
Gradient discriminator: 9.488952
Gradient professor: 4.700643
Loss Generator D: 2.193912
Loss Generator P: 1.052289
Generator    : Epoch:      3, update:     730, cost:   1.052289
Gradient discriminator: 3.386996
Gradient professor: 20.462290
Loss Generator D: 2.536897
Loss Generator P: 1.152710
Gradient discriminator: -22.106956
Gradient professor: -12.877096
Loss Generator D: 2.860215
Loss Generator P: 1.097597
Gradient discriminator: 19.332837
Gradient professor: 1.491039
Loss Generator D: 2.719791
Loss Generator P: 1.162783
Gradient discriminator: -7.093579
Gradient professor: 4.475660
Loss Generator D: 2.227335
Loss Generator P: 0.817993
Gradient discriminator: 4.881439
Gradient professor: 1.972001
Loss Generator D: 2.291646
Loss Generator P: 0.878872
Gradient discriminator: 3.951544
Gradient professor: -24.089830
Loss Generator D: 2.346774
Loss Generator P: 0.995029
Gradient discriminator: -5.129581
Gradient professor: -6.746744
Loss Generator D: 2.446816
Loss Generator P: 0.817589
Gradient discriminator: 19.914360
Gradient professor: -22.640395
Loss Generator D: 2.289074
Loss Generator P: 0.980080
Gradient discriminator: 20.525124
Gradient professor: -3.794109
Loss Generator D: 2.180574
Loss Generator P: 0.973346
Gradient discriminator: -0.933999
Gradient professor: -1.288532
Loss Generator D: 2.443107
Loss Generator P: 0.947349
Generator    : Epoch:      3, update:     740, cost:   0.947349
Gradient discriminator: -18.627260
Gradient professor: -9.190680
Loss Generator D: 2.319031
Loss Generator P: 0.888397
Gradient discriminator: -4.363079
Gradient professor: 20.680036
Loss Generator D: 2.342113
Loss Generator P: 0.996109
Gradient discriminator: -9.723929
Gradient professor: 20.817649
Loss Generator D: 2.524379
Loss Generator P: 0.857034
Gradient discriminator: 26.337922
Gradient professor: -18.611248
Loss Generator D: 2.666236
Loss Generator P: 1.008611
Gradient discriminator: 34.373970
Gradient professor: 15.869499
Loss Generator D: 2.986536
Loss Generator P: 1.041668
Gradient discriminator: -104.615067
Gradient professor: -1.593798
Loss Generator D: 2.853790
Loss Generator P: 0.823842
Gradient discriminator: 5.505141
Gradient professor: -8.352486
Loss Generator D: 2.789340
Loss Generator P: 0.915643
Gradient discriminator: -4.660443
Gradient professor: 0.931285
Loss Generator D: 2.390357
Loss Generator P: 0.818656
Gradient discriminator: 30.606305
Gradient professor: 16.577654
Loss Generator D: 2.158058
Loss Generator P: 1.015084
Gradient discriminator: 19.278380
Gradient professor: -16.005480
Loss Generator D: 2.787234
Loss Generator P: 0.681651
Generator    : Epoch:      3, update:     750, cost:   0.681651
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 3 finished with mean loss 1.84939 (PPL: 6.35596)
--> Epoch took 577.153 minutes, 138.517 sec/update
Epoch summary of Discriminator:
--> Epoch 3 finished with mean loss 0.24041 (PPL: 1.27177)
--> Epoch took 577.153 minutes, 138.517 sec/update
---------------------------------------------------------
Starting Epoch 4
----------------
Gradient discriminator: -11.248770
Gradient professor: 25.194358
Loss Generator D: 2.000255
Loss Generator P: 1.214172
Gradient discriminator: -4.297474
Gradient professor: -10.837652
Loss Generator D: 2.132465
Loss Generator P: 1.051514
Gradient discriminator: 30.790993
Gradient professor: 16.534012
Loss Generator D: 2.833615
Loss Generator P: 0.992682
Gradient discriminator: -4.717866
Gradient professor: -6.850580
Loss Generator D: 2.093567
Loss Generator P: 1.089558
Gradient discriminator: -10.434681
Gradient professor: -19.199415
Loss Generator D: 2.685019
Loss Generator P: 0.896504
Gradient discriminator: -2.949117
Gradient professor: -18.527551
Loss Generator D: 2.400147
Loss Generator P: 0.969646
Gradient discriminator: 3.529576
Gradient professor: 21.983607
Loss Generator D: 2.819149
Loss Generator P: 1.018315
Gradient discriminator: -60.632458
Gradient professor: 22.592054
Loss Generator D: 2.384435
Loss Generator P: 0.896970
Gradient discriminator: -5.473883
Gradient professor: 18.096863
Loss Generator D: 3.382377
Loss Generator P: 1.183320
Gradient discriminator: 27.635477
Gradient professor: -8.464002
Loss Generator D: 2.576925
Loss Generator P: 1.250497
Generator    : Epoch:      4, update:     760, cost:   1.250497
Gradient discriminator: 33.156541
Gradient professor: -4.298437
Loss Generator D: 3.105108
Loss Generator P: 1.247634
Gradient discriminator: 14.436426
Gradient professor: -5.402082
Loss Generator D: 2.379991
Loss Generator P: 1.043636
Gradient discriminator: 3.960879
Gradient professor: -15.408767
Loss Generator D: 2.878995
Loss Generator P: 1.267435
Gradient discriminator: 7.564681
Gradient professor: 2.074703
Loss Generator D: 3.459193
Loss Generator P: 1.134041
Gradient discriminator: -17.227065
Gradient professor: 29.096049
Loss Generator D: 2.975029
Loss Generator P: 0.848522
Gradient discriminator: -1.553147
Gradient professor: -4.446838
Loss Generator D: 3.177853
Loss Generator P: 0.738680
Gradient discriminator: 11.557166
Gradient professor: -11.608783
Loss Generator D: 3.202948
Loss Generator P: 1.053362
Gradient discriminator: -9.245821
Gradient professor: 31.804121
Loss Generator D: 3.711278
Loss Generator P: 0.926123
Gradient discriminator: -5.968629
Gradient professor: -39.750668
Loss Generator D: 3.471948
Loss Generator P: 1.040362
Gradient discriminator: 37.869388
Gradient professor: 10.951836
Loss Generator D: 2.472164
Loss Generator P: 1.096174
Generator    : Epoch:      4, update:     770, cost:   1.096174
Gradient discriminator: -1.340845
Gradient professor: -13.925643
Loss Generator D: 3.380170
Loss Generator P: 1.007384
Gradient discriminator: 5.166901
Gradient professor: -15.790806
Loss Generator D: 3.639371
Loss Generator P: 0.867063
Gradient discriminator: 11.225185
Gradient professor: 1.346727
Loss Generator D: 2.946558
Loss Generator P: 0.854827
Gradient discriminator: 37.061964
Gradient professor: -34.263389
Loss Generator D: 3.627149
Loss Generator P: 1.185039
Gradient discriminator: 7.747258
Gradient professor: 28.054533
Loss Generator D: 3.469836
Loss Generator P: 1.096496
Gradient discriminator: 22.875028
Gradient professor: 34.329157
Loss Generator D: 3.554614
Loss Generator P: 1.037755
Gradient discriminator: 37.607614
Gradient professor: -4.320928
Loss Generator D: 2.845580
Loss Generator P: 0.863383
Gradient discriminator: 21.582042
Gradient professor: 1.743601
Loss Generator D: 2.601588
Loss Generator P: 0.990586
Gradient discriminator: 8.642591
Gradient professor: 5.789836
Loss Generator D: 2.650690
Loss Generator P: 0.952608
Gradient discriminator: -15.695425
Gradient professor: -20.463677
Loss Generator D: 3.191899
Loss Generator P: 1.006140
Generator    : Epoch:      4, update:     780, cost:   1.006140
Gradient discriminator: 33.406142
Gradient professor: 18.415821
Loss Generator D: 2.734894
Loss Generator P: 0.878252
Gradient discriminator: 11.350108
Gradient professor: 16.496641
Loss Generator D: 3.110659
Loss Generator P: 0.905449
Gradient discriminator: 44.519960
Gradient professor: 12.465610
Loss Generator D: 3.652789
Loss Generator P: 1.098010
Gradient discriminator: 42.968526
Gradient professor: -12.641095
Loss Generator D: 2.864360
Loss Generator P: 1.191656
Gradient discriminator: 13.662384
Gradient professor: -14.866604
Loss Generator D: 3.127105
Loss Generator P: 0.949591
Gradient discriminator: 22.575934
Gradient professor: -11.343696
Loss Generator D: 2.845258
Loss Generator P: 0.920266
Gradient discriminator: -8.457289
Gradient professor: -13.435234
Loss Generator D: 2.888140
Loss Generator P: 0.789907
Gradient discriminator: -0.287843
Gradient professor: 1.034422
Loss Generator D: 3.002632
Loss Generator P: 0.914104
Gradient discriminator: -31.049034
Gradient professor: -4.521264
Loss Generator D: 2.866701
Loss Generator P: 0.931686
Gradient discriminator: 10.183619
Gradient professor: 14.821209
Loss Generator D: 3.711137
Loss Generator P: 1.205791
Generator    : Epoch:      4, update:     790, cost:   1.205791
Gradient discriminator: 11.690070
Gradient professor: 8.681721
Loss Generator D: 2.910179
Loss Generator P: 0.937698
Gradient discriminator: 18.683740
Gradient professor: 20.631023
Loss Generator D: 3.391421
Loss Generator P: 0.915998
Gradient discriminator: 12.094223
Gradient professor: -38.566085
Loss Generator D: 3.559188
Loss Generator P: 0.942262
Gradient discriminator: 9.327533
Gradient professor: 12.404368
Loss Generator D: 3.443971
Loss Generator P: 0.898819
Gradient discriminator: 4.915933
Gradient professor: -15.965026
Loss Generator D: 3.171698
Loss Generator P: 1.133721
Gradient discriminator: 12.863819
Gradient professor: 3.713221
Loss Generator D: 2.802801
Loss Generator P: 1.108066
Gradient discriminator: 26.804710
Gradient professor: 40.010723
Loss Generator D: 3.011116
Loss Generator P: 0.963140
Gradient discriminator: 8.689711
Gradient professor: 1.434200
Loss Generator D: 2.361498
Loss Generator P: 1.136968
Gradient discriminator: -42.336663
Gradient professor: -2.318432
Loss Generator D: 2.911606
Loss Generator P: 1.235829
Gradient discriminator: 10.320664
Gradient professor: -26.867794
Loss Generator D: 2.834324
Loss Generator P: 1.003546
Generator    : Epoch:      4, update:     800, cost:   1.003546
Validation  8 - LOSS = 1.662 (PPL: 5.271)
Calling beam-search process
Beam-search ended, took 2.61511 minutes.
Validation  8 - BLEU = 5.89, 11.7/7.1/4.7/3.1 (BP=1.000, ratio=5.126, hyp_len=21633, ref_len=4220)
Early stopping patience: 993 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.629 (PPL: 5.098) at validation 7
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 2.360637
Gradient professor: 42.777729
Loss Generator D: 3.123763
Loss Generator P: 1.113780
Gradient discriminator: -1.185460
Gradient professor: -38.046404
Loss Generator D: 2.838324
Loss Generator P: 1.051228
Gradient discriminator: -7.382205
Gradient professor: -3.025740
Loss Generator D: 2.214919
Loss Generator P: 0.902409
Gradient discriminator: 2.472868
Gradient professor: 2.003940
Loss Generator D: 2.009667
Loss Generator P: 1.110232
Gradient discriminator: 16.085828
Gradient professor: -33.882794
Loss Generator D: 2.762256
Loss Generator P: 1.087545
Gradient discriminator: 60.281932
Gradient professor: 13.442217
Loss Generator D: 2.404238
Loss Generator P: 0.934075
Gradient discriminator: -1.321781
Gradient professor: 23.333403
Loss Generator D: 2.435815
Loss Generator P: 0.851213
Gradient discriminator: 2.189828
Gradient professor: -2.015410
Loss Generator D: 2.223059
Loss Generator P: 0.913061
Gradient discriminator: -0.872598
Gradient professor: -10.073986
Loss Generator D: 2.213483
Loss Generator P: 0.937225
Discriminator: Epoch:      4, update:     809, cost:   0.343309
Gradient discriminator: -13.371112
Gradient professor: 9.449662
Loss Generator D: 2.327514
Loss Generator P: 1.013309
Discriminator: Epoch:      4, update:     810, cost:   0.333081
Generator    : Epoch:      4, update:     810, cost:   1.013309
Gradient discriminator: 38.442847
Gradient professor: -0.043067
Loss Generator D: 1.607137
Loss Generator P: 0.970463
Discriminator: Epoch:      4, update:     811, cost:   0.239924
Gradient discriminator: 24.240418
Gradient professor: -14.407079
Loss Generator D: 1.579161
Loss Generator P: 1.225828
Gradient discriminator: 9.392210
Gradient professor: 0.379345
Loss Generator D: 1.947162
Loss Generator P: 0.895355
Discriminator: Epoch:      4, update:     813, cost:   0.323220
Gradient discriminator: -7.605446
Gradient professor: 6.015294
Loss Generator D: 2.354731
Loss Generator P: 0.928610
Discriminator: Epoch:      4, update:     814, cost:   0.293916
Gradient discriminator: 18.021614
Gradient professor: -44.584867
Loss Generator D: 2.107555
Loss Generator P: 0.929713
Gradient discriminator: 15.965202
Gradient professor: -11.712249
Loss Generator D: 1.939470
Loss Generator P: 1.005921
Gradient discriminator: 5.321547
Gradient professor: 7.502835
Loss Generator D: 2.120340
Loss Generator P: 0.984627
Discriminator: Epoch:      4, update:     817, cost:   0.239738
Gradient discriminator: -11.213735
Gradient professor: 1.572742
Loss Generator D: 2.485514
Loss Generator P: 0.965843
Gradient discriminator: -16.496221
Gradient professor: 29.356604
Loss Generator D: 2.225368
Loss Generator P: 1.157910
Gradient discriminator: 16.359491
Gradient professor: -35.397811
Loss Generator D: 1.779039
Loss Generator P: 1.051414
Generator    : Epoch:      4, update:     820, cost:   1.051414
Gradient discriminator: -47.672334
Gradient professor: -2.870091
Loss Generator D: 2.233601
Loss Generator P: 0.905065
Gradient discriminator: 24.428906
Gradient professor: -6.339645
Loss Generator D: 2.244752
Loss Generator P: 0.852624
Gradient discriminator: -20.541829
Gradient professor: -9.289503
Loss Generator D: 1.983866
Loss Generator P: 1.015168
Gradient discriminator: -12.223499
Gradient professor: 17.611934
Loss Generator D: 2.674519
Loss Generator P: 1.080352
Gradient discriminator: 12.073768
Gradient professor: -0.142004
Loss Generator D: 2.289855
Loss Generator P: 0.901471
Gradient discriminator: 21.373605
Gradient professor: -8.639487
Loss Generator D: 2.025142
Loss Generator P: 0.907094
Gradient discriminator: 0.059610
Gradient professor: -19.023019
Loss Generator D: 2.696237
Loss Generator P: 0.993948
Gradient discriminator: -18.549783
Gradient professor: -2.163702
Loss Generator D: 3.144028
Loss Generator P: 1.096202
Gradient discriminator: 11.067147
Gradient professor: 20.866866
Loss Generator D: 2.636801
Loss Generator P: 0.729370
Gradient discriminator: 26.450384
Gradient professor: -14.938551
Loss Generator D: 2.481931
Loss Generator P: 0.767489
Generator    : Epoch:      4, update:     830, cost:   0.767489
Gradient discriminator: 12.607983
Gradient professor: 23.017352
Loss Generator D: 3.520984
Loss Generator P: 0.794226
Gradient discriminator: 9.988041
Gradient professor: -6.549694
Loss Generator D: 3.051804
Loss Generator P: 0.924144
Gradient discriminator: -7.984307
Gradient professor: -19.307160
Loss Generator D: 2.229180
Loss Generator P: 0.872467
Gradient discriminator: 25.129341
Gradient professor: -18.141628
Loss Generator D: 2.688542
Loss Generator P: 0.712028
Gradient discriminator: -4.291686
Gradient professor: 12.062103
Loss Generator D: 3.260153
Loss Generator P: 0.771175
Gradient discriminator: -17.872227
Gradient professor: -37.466239
Loss Generator D: 3.005586
Loss Generator P: 0.784811
Gradient discriminator: 8.160151
Gradient professor: -11.983686
Loss Generator D: 3.805865
Loss Generator P: 0.821177
Gradient discriminator: 10.687033
Gradient professor: -17.111039
Loss Generator D: 3.605859
Loss Generator P: 1.144686
Gradient discriminator: -3.325175
Gradient professor: -2.174269
Loss Generator D: 3.149410
Loss Generator P: 0.941784
Gradient discriminator: -9.198707
Gradient professor: -22.290053
Loss Generator D: 3.762681
Loss Generator P: 1.047513
Generator    : Epoch:      4, update:     840, cost:   1.047513
Gradient discriminator: 7.122555
Gradient professor: -6.813553
Loss Generator D: 3.586076
Loss Generator P: 0.917371
Gradient discriminator: 14.733064
Gradient professor: -20.036435
Loss Generator D: 3.155830
Loss Generator P: 1.201411
Gradient discriminator: -15.870642
Gradient professor: -3.919330
Loss Generator D: 3.469634
Loss Generator P: 0.871319
Gradient discriminator: -11.372985
Gradient professor: -33.447452
Loss Generator D: 4.027383
Loss Generator P: 0.739994
Gradient discriminator: 19.166767
Gradient professor: -18.953871
Loss Generator D: 3.413238
Loss Generator P: 0.846056
Gradient discriminator: 25.257617
Gradient professor: 23.879017
Loss Generator D: 3.225046
Loss Generator P: 0.968562
Gradient discriminator: -9.906047
Gradient professor: -34.617258
Loss Generator D: 3.942875
Loss Generator P: 0.849241
Gradient discriminator: 6.462027
Gradient professor: 2.658867
Loss Generator D: 3.367355
Loss Generator P: 0.839637
Gradient discriminator: 0.429226
Gradient professor: 22.231663
Loss Generator D: 4.168433
Loss Generator P: 0.889254
Gradient discriminator: 18.132280
Gradient professor: 6.326862
Loss Generator D: 2.907189
Loss Generator P: 0.971504
Generator    : Epoch:      4, update:     850, cost:   0.971504
Gradient discriminator: 6.472311
Gradient professor: 0.510310
Loss Generator D: 2.291335
Loss Generator P: 1.027862
Gradient discriminator: 22.303118
Gradient professor: -32.049172
Loss Generator D: 2.304391
Loss Generator P: 0.949358
Gradient discriminator: -5.372555
Gradient professor: -15.253790
Loss Generator D: 3.574391
Loss Generator P: 0.793417
Gradient discriminator: -2.270340
Gradient professor: 38.288037
Loss Generator D: 2.650539
Loss Generator P: 0.919522
Gradient discriminator: 34.243227
Gradient professor: -2.305668
Loss Generator D: 2.771379
Loss Generator P: 0.732221
Gradient discriminator: -24.202742
Gradient professor: -6.368085
Loss Generator D: 2.951780
Loss Generator P: 0.991128
Gradient discriminator: 12.925641
Gradient professor: -32.160544
Loss Generator D: 3.052049
Loss Generator P: 0.851659
Gradient discriminator: 8.473146
Gradient professor: -0.514843
Loss Generator D: 3.159976
Loss Generator P: 0.812609
Gradient discriminator: -4.956332
Gradient professor: -13.437819
Loss Generator D: 3.796732
Loss Generator P: 0.990425
Gradient discriminator: 23.465870
Gradient professor: -10.274354
Loss Generator D: 2.813815
Loss Generator P: 0.816020
Generator    : Epoch:      4, update:     860, cost:   0.816020
Gradient discriminator: 29.103373
Gradient professor: 10.804140
Loss Generator D: 3.302242
Loss Generator P: 1.026367
Gradient discriminator: 46.735291
Gradient professor: 7.000743
Loss Generator D: 2.839723
Loss Generator P: 0.924424
Gradient discriminator: 4.692173
Gradient professor: 14.369066
Loss Generator D: 4.154002
Loss Generator P: 0.866134
Gradient discriminator: 5.073765
Gradient professor: -7.105730
Loss Generator D: 3.508927
Loss Generator P: 0.745710
Gradient discriminator: -4.330560
Gradient professor: -33.388341
Loss Generator D: 3.582906
Loss Generator P: 1.016598
Gradient discriminator: 22.848289
Gradient professor: -13.589804
Loss Generator D: 3.419217
Loss Generator P: 1.136543
Gradient discriminator: 18.566736
Gradient professor: 17.301219
Loss Generator D: 3.001683
Loss Generator P: 0.738415
Gradient discriminator: 13.708513
Gradient professor: 7.177923
Loss Generator D: 3.500369
Loss Generator P: 1.041126
Gradient discriminator: 9.817686
Gradient professor: -6.863698
Loss Generator D: 3.963665
Loss Generator P: 0.872672
Gradient discriminator: 15.339105
Gradient professor: 37.402037
Loss Generator D: 3.088646
Loss Generator P: 0.958417
Generator    : Epoch:      4, update:     870, cost:   0.958417
Gradient discriminator: -14.365908
Gradient professor: 20.123278
Loss Generator D: 3.633727
Loss Generator P: 0.985312
Gradient discriminator: -3.781431
Gradient professor: -20.454461
Loss Generator D: 2.914906
Loss Generator P: 0.985270
Gradient discriminator: 7.440182
Gradient professor: 27.674272
Loss Generator D: 3.224985
Loss Generator P: 1.015581
Gradient discriminator: 5.706892
Gradient professor: -30.031584
Loss Generator D: 3.136776
Loss Generator P: 1.091000
Gradient discriminator: 1.988696
Gradient professor: -12.503298
Loss Generator D: 3.013521
Loss Generator P: 1.097303
Gradient discriminator: -5.606881
Gradient professor: 21.953948
Loss Generator D: 2.943368
Loss Generator P: 0.978107
Gradient discriminator: -11.879570
Gradient professor: -25.938005
Loss Generator D: 2.778193
Loss Generator P: 0.980031
Gradient discriminator: -1.446334
Gradient professor: 58.506100
Loss Generator D: 2.979785
Loss Generator P: 1.147099
Gradient discriminator: 12.634083
Gradient professor: -17.524133
Loss Generator D: 3.309857
Loss Generator P: 0.982719
Gradient discriminator: -1.201995
Gradient professor: -31.900492
Loss Generator D: 3.695088
Loss Generator P: 1.017481
Generator    : Epoch:      4, update:     880, cost:   1.017481
Gradient discriminator: -12.098442
Gradient professor: -6.300422
Loss Generator D: 3.119236
Loss Generator P: 0.837464
Gradient discriminator: -7.949775
Gradient professor: 27.256207
Loss Generator D: 3.421114
Loss Generator P: 0.870086
Gradient discriminator: -15.869302
Gradient professor: 20.218796
Loss Generator D: 2.856107
Loss Generator P: 0.790831
Gradient discriminator: 7.579038
Gradient professor: 5.892838
Loss Generator D: 3.122007
Loss Generator P: 1.030463
Gradient discriminator: 6.057853
Gradient professor: 8.901487
Loss Generator D: 2.452525
Loss Generator P: 0.945598
Gradient discriminator: -8.379659
Gradient professor: -4.358255
Loss Generator D: 2.968969
Loss Generator P: 0.742463
Gradient discriminator: 5.430068
Gradient professor: 18.358277
Loss Generator D: 3.596198
Loss Generator P: 0.921718
Gradient discriminator: 2.852204
Gradient professor: 7.144975
Loss Generator D: 3.314597
Loss Generator P: 0.695506
Gradient discriminator: 9.611080
Gradient professor: 1.277569
Loss Generator D: 3.483371
Loss Generator P: 1.116392
Gradient discriminator: -0.299793
Gradient professor: 7.207083
Loss Generator D: 2.936582
Loss Generator P: 0.923279
Generator    : Epoch:      4, update:     890, cost:   0.923279
Gradient discriminator: -12.999525
Gradient professor: -17.114518
Loss Generator D: 3.117113
Loss Generator P: 0.771947
Gradient discriminator: 0.180643
Gradient professor: 9.534231
Loss Generator D: 3.068616
Loss Generator P: 1.105928
Gradient discriminator: 8.149867
Gradient professor: 42.781665
Loss Generator D: 3.328393
Loss Generator P: 1.181025
Gradient discriminator: 0.991311
Gradient professor: -39.705385
Loss Generator D: 3.285725
Loss Generator P: 1.055794
Gradient discriminator: 11.771342
Gradient professor: 26.735897
Loss Generator D: 2.625783
Loss Generator P: 1.091166
Gradient discriminator: -60.786068
Gradient professor: -2.265486
Loss Generator D: 2.622441
Loss Generator P: 1.161850
Gradient discriminator: -5.498203
Gradient professor: 15.452572
Loss Generator D: 3.075262
Loss Generator P: 0.816354
Gradient discriminator: 2.659829
Gradient professor: 9.015321
Loss Generator D: 3.209373
Loss Generator P: 0.787478
Gradient discriminator: -10.212021
Gradient professor: 12.979176
Loss Generator D: 3.510333
Loss Generator P: 0.820305
Gradient discriminator: 24.917414
Gradient professor: -11.146440
Loss Generator D: 3.348677
Loss Generator P: 0.822055
Generator    : Epoch:      4, update:     900, cost:   0.822055
Validation  9 - LOSS = 1.651 (PPL: 5.212)
Calling beam-search process
Beam-search ended, took 2.53319 minutes.
Validation  9 - BLEU = 6.49, 12.7/7.8/5.2/3.4 (BP=1.000, ratio=4.654, hyp_len=19641, ref_len=4220)
Early stopping patience: 992 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.629 (PPL: 5.098) at validation 7
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 2.778802
Gradient professor: 21.612203
Loss Generator D: 3.159636
Loss Generator P: 1.087304
Gradient discriminator: 13.990112
Gradient professor: -14.809689
Loss Generator D: 2.577376
Loss Generator P: 0.957918
Gradient discriminator: 6.890392
Gradient professor: 15.003061
Loss Generator D: 2.558787
Loss Generator P: 0.962388
Gradient discriminator: -32.966011
Gradient professor: -37.417490
Loss Generator D: 2.581465
Loss Generator P: 0.920929
Gradient discriminator: 10.035545
Gradient professor: 13.638939
Loss Generator D: 2.913905
Loss Generator P: 1.026917
Gradient discriminator: 22.463362
Gradient professor: 1.992161
Loss Generator D: 2.851164
Loss Generator P: 0.806124
Gradient discriminator: 22.546438
Gradient professor: 3.828693
Loss Generator D: 3.743647
Loss Generator P: 0.948373
Gradient discriminator: 13.224073
Gradient professor: 8.037057
Loss Generator D: 2.738458
Loss Generator P: 0.796466
Gradient discriminator: -6.877469
Gradient professor: -16.839769
Loss Generator D: 3.218505
Loss Generator P: 0.727445
Gradient discriminator: 4.682930
Gradient professor: 4.715189
Loss Generator D: 3.153056
Loss Generator P: 0.832696
Generator    : Epoch:      4, update:     910, cost:   0.832696
Gradient discriminator: -1.539533
Gradient professor: 0.134539
Loss Generator D: 3.194043
Loss Generator P: 0.871099
Gradient discriminator: 23.530602
Gradient professor: 23.486789
Loss Generator D: 3.198326
Loss Generator P: 1.208866
Gradient discriminator: 20.126910
Gradient professor: 13.831839
Loss Generator D: 3.021818
Loss Generator P: 1.104602
Gradient discriminator: 5.767745
Gradient professor: 37.416401
Loss Generator D: 3.671111
Loss Generator P: 1.097698
Gradient discriminator: 10.168183
Gradient professor: -11.697969
Loss Generator D: 2.540818
Loss Generator P: 1.143752
Gradient discriminator: -26.290411
Gradient professor: 19.782737
Loss Generator D: 2.755157
Loss Generator P: 1.056631
Gradient discriminator: -0.373655
Gradient professor: 15.670119
Loss Generator D: 2.834215
Loss Generator P: 1.149484
Gradient discriminator: -12.433875
Gradient professor: -12.596784
Loss Generator D: 3.090165
Loss Generator P: 0.908591
Gradient discriminator: -6.011514
Gradient professor: -37.325739
Loss Generator D: 2.593842
Loss Generator P: 0.976796
Gradient discriminator: -17.812897
Gradient professor: 22.764964
Loss Generator D: 2.494862
Loss Generator P: 1.006451
Generator    : Epoch:      4, update:     920, cost:   1.006451
Gradient discriminator: -3.429487
Gradient professor: -1.270952
Loss Generator D: 2.770947
Loss Generator P: 0.823039
Gradient discriminator: 18.042231
Gradient professor: 0.550150
Loss Generator D: 2.289013
Loss Generator P: 0.875866
Gradient discriminator: 7.765063
Gradient professor: -12.334312
Loss Generator D: 2.660492
Loss Generator P: 0.912413
Gradient discriminator: 0.037805
Gradient professor: -19.991893
Loss Generator D: 2.759173
Loss Generator P: 0.787944
Gradient discriminator: 0.487571
Gradient professor: -8.547995
Loss Generator D: 2.654860
Loss Generator P: 0.850921
Gradient discriminator: -9.491192
Gradient professor: -6.885067
Loss Generator D: 2.269735
Loss Generator P: 0.898131
Gradient discriminator: 25.120178
Gradient professor: 38.400273
Loss Generator D: 1.761469
Loss Generator P: 1.156592
Gradient discriminator: 4.253077
Gradient professor: 7.601790
Loss Generator D: 1.998972
Loss Generator P: 1.271440
Gradient discriminator: 11.849304
Gradient professor: 0.391328
Loss Generator D: 2.372301
Loss Generator P: 1.070074
Gradient discriminator: 12.473802
Gradient professor: -8.917666
Loss Generator D: 2.569587
Loss Generator P: 0.821220
Generator    : Epoch:      4, update:     930, cost:   0.821220
Gradient discriminator: -2.602034
Gradient professor: 4.558751
Loss Generator D: 2.910466
Loss Generator P: 0.913906
Gradient discriminator: 57.063580
Gradient professor: -8.139054
Loss Generator D: 2.125884
Loss Generator P: 0.950375
Gradient discriminator: -23.061433
Gradient professor: 11.394528
Loss Generator D: 1.873598
Loss Generator P: 0.914243
Gradient discriminator: -1.026230
Gradient professor: -28.619901
Loss Generator D: 2.343582
Loss Generator P: 1.168311
Gradient discriminator: 15.332987
Gradient professor: -34.848490
Loss Generator D: 1.995179
Loss Generator P: 1.112787
Gradient discriminator: 17.509391
Gradient professor: 1.203439
Loss Generator D: 2.255161
Loss Generator P: 0.969036
Gradient discriminator: 7.660890
Gradient professor: -3.513819
Loss Generator D: 2.426985
Loss Generator P: 0.954721
Gradient discriminator: -15.217164
Gradient professor: 2.370367
Loss Generator D: 1.887207
Loss Generator P: 1.128160
Gradient discriminator: -20.688888
Gradient professor: -27.862504
Loss Generator D: 2.553681
Loss Generator P: 1.106277
Gradient discriminator: 0.015953
Gradient professor: -23.807807
Loss Generator D: 2.509727
Loss Generator P: 1.070862
Generator    : Epoch:      4, update:     940, cost:   1.070862
Gradient discriminator: 9.348395
Gradient professor: 7.679428
Loss Generator D: 2.676017
Loss Generator P: 1.118999
Gradient discriminator: -4.862134
Gradient professor: -16.034979
Loss Generator D: 2.806777
Loss Generator P: 0.983746
Gradient discriminator: 23.660783
Gradient professor: 19.650848
Loss Generator D: 2.562814
Loss Generator P: 1.360973
Gradient discriminator: 17.804647
Gradient professor: 19.186928
Loss Generator D: 1.811073
Loss Generator P: 1.235019
Gradient discriminator: -0.280695
Gradient professor: -32.626842
Loss Generator D: 2.302759
Loss Generator P: 0.831720
Gradient discriminator: 5.640272
Gradient professor: -14.936764
Loss Generator D: 2.453649
Loss Generator P: 0.997713
Gradient discriminator: 2.928982
Gradient professor: 1.432095
Loss Generator D: 2.352467
Loss Generator P: 1.021571
Gradient discriminator: 33.957841
Gradient professor: -7.577695
Loss Generator D: 2.410901
Loss Generator P: 1.026357
Gradient discriminator: -19.084065
Gradient professor: 6.774604
Loss Generator D: 2.228009
Loss Generator P: 1.025439
Gradient discriminator: 64.601897
Gradient professor: -10.599045
Loss Generator D: 2.423452
Loss Generator P: 0.864850
Generator    : Epoch:      4, update:     950, cost:   0.864850
Gradient discriminator: -6.215035
Gradient professor: 7.129957
Loss Generator D: 2.657494
Loss Generator P: 0.987086
Gradient discriminator: 0.083483
Gradient professor: -3.600264
Loss Generator D: 2.391851
Loss Generator P: 0.990180
Gradient discriminator: 7.004041
Gradient professor: 25.326142
Loss Generator D: 2.217577
Loss Generator P: 0.935120
Gradient discriminator: 10.520754
Gradient professor: -27.841676
Loss Generator D: 2.669343
Loss Generator P: 0.995134
Gradient discriminator: -11.250917
Gradient professor: -13.591582
Loss Generator D: 2.033339
Loss Generator P: 0.781443
Gradient discriminator: -3.704172
Gradient professor: -23.871434
Loss Generator D: 2.041590
Loss Generator P: 0.834641
Gradient discriminator: -7.586604
Gradient professor: -0.439366
Loss Generator D: 2.550241
Loss Generator P: 0.995170
Gradient discriminator: 70.655882
Gradient professor: -2.589694
Loss Generator D: 2.824158
Loss Generator P: 1.050898
Gradient discriminator: 9.390484
Gradient professor: -6.933678
Loss Generator D: 2.421550
Loss Generator P: 0.893803
Gradient discriminator: -0.824640
Gradient professor: -26.916112
Loss Generator D: 2.391752
Loss Generator P: 1.009061
Generator    : Epoch:      4, update:     960, cost:   1.009061
Gradient discriminator: -3.282096
Gradient professor: -11.908111
Loss Generator D: 2.597874
Loss Generator P: 1.062438
Gradient discriminator: -4.044366
Gradient professor: 23.396859
Loss Generator D: 2.300289
Loss Generator P: 1.068775
Gradient discriminator: 5.078576
Gradient professor: -9.459292
Loss Generator D: 2.333020
Loss Generator P: 1.031605
Gradient discriminator: 5.097501
Gradient professor: 8.525831
Loss Generator D: 2.231030
Loss Generator P: 0.847761
Gradient discriminator: 9.234768
Gradient professor: 5.415407
Loss Generator D: 2.189126
Loss Generator P: 0.964070
Gradient discriminator: 2.516722
Gradient professor: -5.154164
Loss Generator D: 2.518481
Loss Generator P: 1.005907
Gradient discriminator: 6.733788
Gradient professor: -18.021804
Loss Generator D: 2.193021
Loss Generator P: 0.964980
Gradient discriminator: -5.078611
Gradient professor: -19.097839
Loss Generator D: 2.011757
Loss Generator P: 0.834423
Gradient discriminator: -11.055298
Gradient professor: 11.405581
Loss Generator D: 2.783795
Loss Generator P: 0.771497
Gradient discriminator: -10.354879
Gradient professor: -26.660822
Loss Generator D: 2.239935
Loss Generator P: 0.866098
Generator    : Epoch:      4, update:     970, cost:   0.866098
Gradient discriminator: 24.531144
Gradient professor: 12.796182
Loss Generator D: 2.055336
Loss Generator P: 0.968588
Gradient discriminator: 7.714860
Gradient professor: 0.843378
Loss Generator D: 1.716555
Loss Generator P: 0.996971
Gradient discriminator: -3.161729
Gradient professor: 6.734129
Loss Generator D: 2.384911
Loss Generator P: 0.993127
Gradient discriminator: -13.120495
Gradient professor: 19.692668
Loss Generator D: 2.657724
Loss Generator P: 0.893350
Gradient discriminator: 8.972685
Gradient professor: 15.654703
Loss Generator D: 2.705112
Loss Generator P: 0.919342
Gradient discriminator: -14.076131
Gradient professor: -14.197074
Loss Generator D: 2.304195
Loss Generator P: 0.928640
Gradient discriminator: 19.784052
Gradient professor: 8.820544
Loss Generator D: 2.484882
Loss Generator P: 0.949825
Gradient discriminator: -2.684365
Gradient professor: -8.924581
Loss Generator D: 2.662503
Loss Generator P: 0.890387
Gradient discriminator: 15.353438
Gradient professor: -10.567850
Loss Generator D: 2.510097
Loss Generator P: 0.945068
Gradient discriminator: 0.892726
Gradient professor: 6.062868
Loss Generator D: 2.465554
Loss Generator P: 0.979016
Generator    : Epoch:      4, update:     980, cost:   0.979016
Gradient discriminator: 14.736488
Gradient professor: 12.862071
Loss Generator D: 2.849676
Loss Generator P: 1.117145
Gradient discriminator: -8.745507
Gradient professor: -20.269218
Loss Generator D: 2.550197
Loss Generator P: 1.091705
Gradient discriminator: 8.780778
Gradient professor: -7.735434
Loss Generator D: 2.549591
Loss Generator P: 1.097970
Gradient discriminator: -19.069101
Gradient professor: -3.144104
Loss Generator D: 2.330031
Loss Generator P: 0.741502
Gradient discriminator: 1.127349
Gradient professor: 3.130634
Loss Generator D: 2.232304
Loss Generator P: 0.853496
Gradient discriminator: -11.892282
Gradient professor: -25.364046
Loss Generator D: 2.204379
Loss Generator P: 0.906741
Gradient discriminator: -0.770511
Gradient professor: 18.397355
Loss Generator D: 2.754650
Loss Generator P: 0.798234
Gradient discriminator: 2.407748
Gradient professor: -9.450931
Loss Generator D: 2.089690
Loss Generator P: 0.962048
Gradient discriminator: 1.786956
Gradient professor: 0.848029
Loss Generator D: 2.433954
Loss Generator P: 1.008243
Gradient discriminator: 37.219837
Gradient professor: 3.728356
Loss Generator D: 2.071373
Loss Generator P: 0.888005
Generator    : Epoch:      4, update:     990, cost:   0.888005
Gradient discriminator: 36.713867
Gradient professor: -9.129766
Loss Generator D: 2.167745
Loss Generator P: 0.898605
Gradient discriminator: 0.400634
Gradient professor: -5.563593
Loss Generator D: 2.205437
Loss Generator P: 0.872577
Gradient discriminator: -2.409248
Gradient professor: 17.291966
Loss Generator D: 2.047187
Loss Generator P: 0.829729
Gradient discriminator: -45.645054
Gradient professor: -17.528187
Loss Generator D: 1.969962
Loss Generator P: 0.883783
Gradient discriminator: 1.553265
Gradient professor: 14.931469
Loss Generator D: 3.070505
Loss Generator P: 0.953938
Gradient discriminator: 44.762783
Gradient professor: -6.945769
Loss Generator D: 2.505662
Loss Generator P: 0.821253
Gradient discriminator: -8.778326
Gradient professor: 0.622422
Loss Generator D: 2.742030
Loss Generator P: 0.860091
Gradient discriminator: -5.706754
Gradient professor: -3.166516
Loss Generator D: 2.503213
Loss Generator P: 0.810727
Gradient discriminator: 7.387369
Gradient professor: 16.416506
Loss Generator D: 2.039661
Loss Generator P: 0.947416
Gradient discriminator: 20.086711
Gradient professor: -3.471640
Loss Generator D: 2.323003
Loss Generator P: 0.707617
Generator    : Epoch:      4, update:    1000, cost:   0.707617
Validation 10 - LOSS = 1.635 (PPL: 5.128)
Calling beam-search process
Beam-search ended, took 2.97400 minutes.
Validation 10 - BLEU = 5.15, 10.1/6.2/4.1/2.7 (BP=1.000, ratio=5.698, hyp_len=24045, ref_len=4220)
Early stopping patience: 991 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.629 (PPL: 5.098) at validation 7
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 4 finished with mean loss 1.86776 (PPL: 6.47377)
--> Epoch took 500.981 minutes, 120.235 sec/update
Epoch summary of Discriminator:
--> Epoch 4 finished with mean loss 0.29553 (PPL: 1.34384)
--> Epoch took 500.981 minutes, 120.235 sec/update
---------------------------------------------------------
Starting Epoch 5
----------------
Gradient discriminator: -10.547274
Gradient professor: 26.214774
Loss Generator D: 2.023229
Loss Generator P: 1.133261
Gradient discriminator: 24.880391
Gradient professor: -8.442698
Loss Generator D: 1.948954
Loss Generator P: 0.995690
Gradient discriminator: 17.370126
Gradient professor: 6.042678
Loss Generator D: 1.785732
Loss Generator P: 0.980920
Gradient discriminator: 2.432854
Gradient professor: -8.626371
Loss Generator D: 1.832466
Loss Generator P: 1.067668
Gradient discriminator: 12.991442
Gradient professor: -17.730081
Loss Generator D: 2.182030
Loss Generator P: 0.896790
Gradient discriminator: -2.920172
Gradient professor: 4.985452
Loss Generator D: 1.803192
Loss Generator P: 0.930931
Gradient discriminator: 18.244288
Gradient professor: 12.578164
Loss Generator D: 2.001245
Loss Generator P: 1.040209
Gradient discriminator: 10.884999
Gradient professor: 43.275605
Loss Generator D: 1.995448
Loss Generator P: 0.945039
Gradient discriminator: 6.785251
Gradient professor: -2.202542
Loss Generator D: 2.186172
Loss Generator P: 1.117923
Gradient discriminator: -22.098989
Gradient professor: 3.020507
Loss Generator D: 1.670036
Loss Generator P: 1.188141
Generator    : Epoch:      5, update:    1010, cost:   1.188141
Gradient discriminator: -24.634409
Gradient professor: -10.569605
Loss Generator D: 2.279450
Loss Generator P: 1.177741
Gradient discriminator: 10.664922
Gradient professor: 0.778736
Loss Generator D: 2.413233
Loss Generator P: 0.931839
Gradient discriminator: 9.967741
Gradient professor: 14.885747
Loss Generator D: 1.960716
Loss Generator P: 1.216370
Gradient discriminator: 16.454290
Gradient professor: -19.933083
Loss Generator D: 2.787088
Loss Generator P: 1.086824
Gradient discriminator: 2.108837
Gradient professor: -0.164004
Loss Generator D: 2.557231
Loss Generator P: 0.785925
Gradient discriminator: -1.437675
Gradient professor: -9.655722
Loss Generator D: 2.400850
Loss Generator P: 0.695608
Gradient discriminator: 4.074803
Gradient professor: 11.720375
Loss Generator D: 2.256651
Loss Generator P: 0.926039
Gradient discriminator: 9.756861
Gradient professor: -13.191093
Loss Generator D: 2.938744
Loss Generator P: 0.877622
Gradient discriminator: -9.904204
Gradient professor: -0.897632
Loss Generator D: 2.654987
Loss Generator P: 0.977050
Gradient discriminator: 16.489172
Gradient professor: 35.617435
Loss Generator D: 2.478176
Loss Generator P: 1.029665
Generator    : Epoch:      5, update:    1020, cost:   1.029665
Gradient discriminator: 6.312656
Gradient professor: -8.100824
Loss Generator D: 2.855037
Loss Generator P: 0.927809
Gradient discriminator: 4.233365
Gradient professor: -23.306742
Loss Generator D: 3.062241
Loss Generator P: 0.894925
Gradient discriminator: -2.687537
Gradient professor: 6.663930
Loss Generator D: 2.542187
Loss Generator P: 0.849621
Gradient discriminator: -18.713990
Gradient professor: 53.936143
Loss Generator D: 2.764466
Loss Generator P: 1.123346
Gradient discriminator: -23.549280
Gradient professor: -4.415211
Loss Generator D: 3.212421
Loss Generator P: 1.117389
Gradient discriminator: 19.422915
Gradient professor: -0.670453
Loss Generator D: 2.952199
Loss Generator P: 0.926088
Gradient discriminator: 4.036305
Gradient professor: 11.248246
Loss Generator D: 2.625436
Loss Generator P: 0.783720
Gradient discriminator: -3.671243
Gradient professor: 13.473826
Loss Generator D: 2.485569
Loss Generator P: 0.963065
Gradient discriminator: -16.215740
Gradient professor: -8.675014
Loss Generator D: 2.297730
Loss Generator P: 0.868995
Gradient discriminator: -4.003741
Gradient professor: 9.148083
Loss Generator D: 2.314037
Loss Generator P: 0.895187
Generator    : Epoch:      5, update:    1030, cost:   0.895187
Gradient discriminator: -3.697413
Gradient professor: 13.829832
Loss Generator D: 2.916574
Loss Generator P: 0.812728
Gradient discriminator: 15.554554
Gradient professor: 20.277697
Loss Generator D: 2.034609
Loss Generator P: 0.809535
Gradient discriminator: -4.845710
Gradient professor: -6.778105
Loss Generator D: 2.528889
Loss Generator P: 1.102541
Gradient discriminator: -19.789298
Gradient professor: 21.018454
Loss Generator D: 2.174939
Loss Generator P: 1.092149
Gradient discriminator: 21.249610
Gradient professor: -3.228484
Loss Generator D: 2.639814
Loss Generator P: 0.869535
Gradient discriminator: 12.975332
Gradient professor: 14.997888
Loss Generator D: 2.645670
Loss Generator P: 0.818073
Gradient discriminator: -0.131445
Gradient professor: -29.816102
Loss Generator D: 2.436787
Loss Generator P: 0.825799
Gradient discriminator: 6.874602
Gradient professor: 7.127989
Loss Generator D: 2.077780
Loss Generator P: 0.891588
Gradient discriminator: 11.696767
Gradient professor: -2.778365
Loss Generator D: 2.520688
Loss Generator P: 0.887292
Gradient discriminator: 10.853204
Gradient professor: -5.273209
Loss Generator D: 2.622926
Loss Generator P: 1.127957
Generator    : Epoch:      5, update:    1040, cost:   1.127957
Gradient discriminator: 2.833451
Gradient professor: -23.862419
Loss Generator D: 2.775529
Loss Generator P: 1.058477
Gradient discriminator: 14.170961
Gradient professor: 13.829802
Loss Generator D: 2.374740
Loss Generator P: 0.864979
Gradient discriminator: 13.337067
Gradient professor: -20.173952
Loss Generator D: 2.636900
Loss Generator P: 0.941870
Gradient discriminator: 12.143811
Gradient professor: 12.402793
Loss Generator D: 2.583868
Loss Generator P: 0.816357
Gradient discriminator: 2.572172
Gradient professor: -29.616940
Loss Generator D: 1.637567
Loss Generator P: 1.029897
Gradient discriminator: -44.320983
Gradient professor: -8.741701
Loss Generator D: 1.841655
Loss Generator P: 1.095245
Gradient discriminator: -1.782015
Gradient professor: -14.111937
Loss Generator D: 1.749742
Loss Generator P: 0.872636
Gradient discriminator: -0.411320
Gradient professor: 7.850436
Loss Generator D: 2.042498
Loss Generator P: 1.033566
Gradient discriminator: 9.198488
Gradient professor: -21.062540
Loss Generator D: 2.076287
Loss Generator P: 1.274109
Gradient discriminator: -0.145767
Gradient professor: 13.983641
Loss Generator D: 1.945054
Loss Generator P: 0.908069
Generator    : Epoch:      5, update:    1050, cost:   0.908069
Gradient discriminator: 2.844833
Gradient professor: 16.406372
Loss Generator D: 2.237451
Loss Generator P: 0.993571
Gradient discriminator: -1.509840
Gradient professor: -28.756442
Loss Generator D: 2.068177
Loss Generator P: 1.006129
Gradient discriminator: 27.288375
Gradient professor: 2.025825
Loss Generator D: 1.823463
Loss Generator P: 0.917129
Gradient discriminator: -1.814217
Gradient professor: 1.828473
Loss Generator D: 2.129844
Loss Generator P: 1.057374
Gradient discriminator: 13.869821
Gradient professor: -29.355911
Loss Generator D: 2.068140
Loss Generator P: 1.063220
Gradient discriminator: 19.852061
Gradient professor: 2.951028
Loss Generator D: 2.531894
Loss Generator P: 0.852414
Gradient discriminator: -16.710814
Gradient professor: 30.889148
Loss Generator D: 1.878612
Loss Generator P: 0.839976
Gradient discriminator: 11.363855
Gradient professor: -23.794056
Loss Generator D: 2.285552
Loss Generator P: 0.860169
Gradient discriminator: -10.839658
Gradient professor: 15.686259
Loss Generator D: 2.630197
Loss Generator P: 0.862215
Gradient discriminator: 3.146911
Gradient professor: -20.508831
Loss Generator D: 2.281243
Loss Generator P: 0.944185
Generator    : Epoch:      5, update:    1060, cost:   0.944185
Gradient discriminator: 0.783848
Gradient professor: -27.760133
Loss Generator D: 2.239361
Loss Generator P: 0.897190
Gradient discriminator: 6.047916
Gradient professor: 32.313108
Loss Generator D: 1.530145
Loss Generator P: 1.168692
Gradient discriminator: -20.745817
Gradient professor: 6.191860
Loss Generator D: 1.867752
Loss Generator P: 0.867998
Gradient discriminator: -9.397963
Gradient professor: -3.127301
Loss Generator D: 2.217741
Loss Generator P: 0.882190
Gradient discriminator: 13.269316
Gradient professor: 6.503029
Loss Generator D: 1.968571
Loss Generator P: 0.934846
Gradient discriminator: 4.579603
Gradient professor: -2.883433
Loss Generator D: 1.803650
Loss Generator P: 1.036007
Gradient discriminator: 8.811368
Gradient professor: 23.175085
Loss Generator D: 2.503042
Loss Generator P: 0.905634
Gradient discriminator: -1.339406
Gradient professor: -1.202798
Loss Generator D: 2.241781
Loss Generator P: 0.891930
Gradient discriminator: 9.169999
Gradient professor: 13.135925
Loss Generator D: 2.286969
Loss Generator P: 1.109422
Gradient discriminator: 18.655063
Gradient professor: -14.154678
Loss Generator D: 2.581366
Loss Generator P: 0.956708
Generator    : Epoch:      5, update:    1070, cost:   0.956708
Gradient discriminator: -8.740747
Gradient professor: -7.156664
Loss Generator D: 2.110984
Loss Generator P: 0.819333
Gradient discriminator: -6.101283
Gradient professor: -0.464330
Loss Generator D: 2.351848
Loss Generator P: 0.771033
Gradient discriminator: 6.666099
Gradient professor: -18.625883
Loss Generator D: 1.821795
Loss Generator P: 0.986571
Gradient discriminator: 2.971294
Gradient professor: -7.232739
Loss Generator D: 1.579237
Loss Generator P: 1.070072
Gradient discriminator: -41.877436
Gradient professor: -6.762175
Loss Generator D: 1.812766
Loss Generator P: 0.834491
Gradient discriminator: -8.501697
Gradient professor: 12.905071
Loss Generator D: 2.031891
Loss Generator P: 0.821593
Gradient discriminator: -2.188359
Gradient professor: -1.438574
Loss Generator D: 2.334803
Loss Generator P: 0.923470
Gradient discriminator: 9.159178
Gradient professor: 5.064526
Loss Generator D: 2.595835
Loss Generator P: 1.095506
Gradient discriminator: 5.747844
Gradient professor: -0.468581
Loss Generator D: 1.666605
Loss Generator P: 0.683913
Gradient discriminator: 6.529971
Gradient professor: -23.278475
Loss Generator D: 2.011911
Loss Generator P: 0.744425
Generator    : Epoch:      5, update:    1080, cost:   0.744425
Gradient discriminator: 8.624766
Gradient professor: 25.424977
Loss Generator D: 2.645533
Loss Generator P: 0.770747
Gradient discriminator: 15.202534
Gradient professor: 7.154413
Loss Generator D: 2.267917
Loss Generator P: 0.842021
Gradient discriminator: 26.348105
Gradient professor: -15.481070
Loss Generator D: 1.963379
Loss Generator P: 0.845377
Gradient discriminator: -3.662611
Gradient professor: -0.055689
Loss Generator D: 2.927551
Loss Generator P: 0.619013
Gradient discriminator: 11.132545
Gradient professor: 20.600133
Loss Generator D: 2.515027
Loss Generator P: 0.665733
Gradient discriminator: -5.335222
Gradient professor: 2.896548
Loss Generator D: 1.919584
Loss Generator P: 0.705633
Gradient discriminator: 7.332930
Gradient professor: -15.738139
Loss Generator D: 2.242132
Loss Generator P: 0.777743
Gradient discriminator: 25.823997
Gradient professor: 3.084019
Loss Generator D: 2.572371
Loss Generator P: 1.063355
Gradient discriminator: 9.741877
Gradient professor: -4.503441
Loss Generator D: 1.987532
Loss Generator P: 0.847349
Gradient discriminator: -6.875468
Gradient professor: -1.867233
Loss Generator D: 1.874417
Loss Generator P: 0.987489
Generator    : Epoch:      5, update:    1090, cost:   0.987489
Gradient discriminator: 12.381061
Gradient professor: 14.455715
Loss Generator D: 2.014019
Loss Generator P: 0.799074
Gradient discriminator: 9.333899
Gradient professor: 16.118601
Loss Generator D: 2.001868
Loss Generator P: 1.157574
Gradient discriminator: -8.733830
Gradient professor: -17.069869
Loss Generator D: 1.838648
Loss Generator P: 0.828757
Gradient discriminator: 8.859930
Gradient professor: -2.178105
Loss Generator D: 2.003243
Loss Generator P: 0.708716
Gradient discriminator: -7.421795
Gradient professor: 5.856719
Loss Generator D: 2.124593
Loss Generator P: 0.788561
Gradient discriminator: -10.928377
Gradient professor: -13.988508
Loss Generator D: 2.073754
Loss Generator P: 0.888365
Gradient discriminator: 10.488833
Gradient professor: -10.188793
Loss Generator D: 2.351478
Loss Generator P: 0.801881
Gradient discriminator: -10.871899
Gradient professor: 0.452414
Loss Generator D: 2.232423
Loss Generator P: 0.733499
Gradient discriminator: 5.786998
Gradient professor: 13.232181
Loss Generator D: 2.213795
Loss Generator P: 0.844924
Gradient discriminator: -13.902366
Gradient professor: -10.991404
Loss Generator D: 2.596246
Loss Generator P: 0.906857
Generator    : Epoch:      5, update:    1100, cost:   0.906857
Validation 11 - LOSS = 1.621 (PPL: 5.060)
Calling beam-search process
Beam-search ended, took 2.39995 minutes.
Validation 11 - BLEU = 6.69, 12.7/8.1/5.5/3.6 (BP=1.000, ratio=4.695, hyp_len=19812, ref_len=4220)
Early stopping patience: 990 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.621 (PPL: 5.060) at validation 11
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -7.132771
Gradient professor: -2.021191
Loss Generator D: 3.085601
Loss Generator P: 0.939160
Gradient discriminator: 9.014842
Gradient professor: -22.081649
Loss Generator D: 2.155110
Loss Generator P: 0.921687
Gradient discriminator: -7.575328
Gradient professor: -15.740422
Loss Generator D: 2.786498
Loss Generator P: 0.724125
Gradient discriminator: -0.581463
Gradient professor: 2.308081
Loss Generator D: 2.816128
Loss Generator P: 0.847850
Gradient discriminator: 19.802553
Gradient professor: 7.259098
Loss Generator D: 2.764475
Loss Generator P: 0.662987
Gradient discriminator: -6.273259
Gradient professor: -16.621810
Loss Generator D: 2.869694
Loss Generator P: 0.970748
Gradient discriminator: 7.787744
Gradient professor: -22.011769
Loss Generator D: 2.776390
Loss Generator P: 0.752831
Gradient discriminator: -1.136305
Gradient professor: 14.692806
Loss Generator D: 2.704550
Loss Generator P: 0.776878
Gradient discriminator: 7.331531
Gradient professor: -6.886710
Loss Generator D: 2.912088
Loss Generator P: 0.930706
Gradient discriminator: -4.106842
Gradient professor: -43.979907
Loss Generator D: 2.329479
Loss Generator P: 0.830293
Generator    : Epoch:      5, update:    1110, cost:   0.830293
Gradient discriminator: 3.465868
Gradient professor: 9.446859
Loss Generator D: 2.404360
Loss Generator P: 0.997730
Gradient discriminator: -0.539044
Gradient professor: 15.585632
Loss Generator D: 2.220717
Loss Generator P: 0.824331
Gradient discriminator: -5.181930
Gradient professor: 4.903109
Loss Generator D: 2.550529
Loss Generator P: 0.802449
Gradient discriminator: 15.797469
Gradient professor: -21.577244
Loss Generator D: 2.719421
Loss Generator P: 0.674461
Gradient discriminator: 8.764820
Gradient professor: -0.143087
Loss Generator D: 2.304654
Loss Generator P: 0.984491
Gradient discriminator: -2.149133
Gradient professor: -41.649174
Loss Generator D: 2.876471
Loss Generator P: 1.023248
Gradient discriminator: -10.266179
Gradient professor: 18.604184
Loss Generator D: 2.470126
Loss Generator P: 0.674415
Gradient discriminator: 8.428457
Gradient professor: -10.228211
Loss Generator D: 2.980607
Loss Generator P: 1.049214
Gradient discriminator: -1.057671
Gradient professor: -2.978689
Loss Generator D: 1.966103
Loss Generator P: 0.815895
Gradient discriminator: -9.566144
Gradient professor: 27.029206
Loss Generator D: 2.713813
Loss Generator P: 0.819040
Generator    : Epoch:      5, update:    1120, cost:   0.819040
Gradient discriminator: -1.650952
Gradient professor: -12.364956
Loss Generator D: 2.636435
Loss Generator P: 0.909870
Gradient discriminator: 4.266544
Gradient professor: 3.221248
Loss Generator D: 1.846545
Loss Generator P: 0.922037
Gradient discriminator: 2.683835
Gradient professor: 20.531246
Loss Generator D: 2.527888
Loss Generator P: 0.935366
Gradient discriminator: 10.037897
Gradient professor: 6.629850
Loss Generator D: 2.038653
Loss Generator P: 0.933141
Gradient discriminator: 8.325841
Gradient professor: 6.949622
Loss Generator D: 2.263769
Loss Generator P: 1.023535
Gradient discriminator: 4.741903
Gradient professor: 6.925583
Loss Generator D: 1.923089
Loss Generator P: 0.898182
Gradient discriminator: 17.258498
Gradient professor: -12.441337
Loss Generator D: 2.351099
Loss Generator P: 0.966510
Gradient discriminator: 14.388717
Gradient professor: 15.313222
Loss Generator D: 2.564807
Loss Generator P: 1.044827
Gradient discriminator: 8.870601
Gradient professor: 15.565823
Loss Generator D: 2.763216
Loss Generator P: 0.914533
Gradient discriminator: 5.943084
Gradient professor: -38.850239
Loss Generator D: 2.674421
Loss Generator P: 0.966705
Generator    : Epoch:      5, update:    1130, cost:   0.966705
Gradient discriminator: 4.367177
Gradient professor: -8.542022
Loss Generator D: 2.184054
Loss Generator P: 0.820713
Gradient discriminator: -23.238258
Gradient professor: -15.057219
Loss Generator D: 2.270405
Loss Generator P: 0.805548
Gradient discriminator: 13.809052
Gradient professor: 18.275961
Loss Generator D: 1.961264
Loss Generator P: 0.808647
Gradient discriminator: 10.809817
Gradient professor: 23.040674
Loss Generator D: 1.818950
Loss Generator P: 1.020152
Gradient discriminator: -12.258460
Gradient professor: 5.949821
Loss Generator D: 1.624773
Loss Generator P: 0.894706
Gradient discriminator: 3.468481
Gradient professor: 4.303951
Loss Generator D: 2.335347
Loss Generator P: 0.684620
Gradient discriminator: -1.179469
Gradient professor: -11.234285
Loss Generator D: 2.027703
Loss Generator P: 0.959223
Gradient discriminator: 0.391827
Gradient professor: -4.253689
Loss Generator D: 3.095072
Loss Generator P: 0.670320
Gradient discriminator: -3.603211
Gradient professor: 20.780695
Loss Generator D: 2.637587
Loss Generator P: 0.970497
Gradient discriminator: 8.594989
Gradient professor: -1.963380
Loss Generator D: 2.185081
Loss Generator P: 0.910885
Generator    : Epoch:      5, update:    1140, cost:   0.910885
Gradient discriminator: -15.205111
Gradient professor: -28.221054
Loss Generator D: 2.175829
Loss Generator P: 0.833077
Gradient discriminator: 10.020749
Gradient professor: 21.097839
Loss Generator D: 2.437826
Loss Generator P: 0.937894
Gradient discriminator: 14.207149
Gradient professor: -8.556418
Loss Generator D: 2.411821
Loss Generator P: 1.083070
Gradient discriminator: -8.205790
Gradient professor: -18.867080
Loss Generator D: 2.816104
Loss Generator P: 0.940840
Gradient discriminator: -1.929984
Gradient professor: 8.539098
Loss Generator D: 2.813961
Loss Generator P: 1.025875
Gradient discriminator: 2.304745
Gradient professor: 13.247631
Loss Generator D: 2.897662
Loss Generator P: 1.101215
Gradient discriminator: 0.039543
Gradient professor: 16.933494
Loss Generator D: 2.643453
Loss Generator P: 0.757687
Gradient discriminator: 9.554735
Gradient professor: -4.357148
Loss Generator D: 2.700856
Loss Generator P: 0.738802
Gradient discriminator: -25.047858
Gradient professor: 7.160547
Loss Generator D: 2.940990
Loss Generator P: 0.729256
Gradient discriminator: -3.707939
Gradient professor: -11.602022
Loss Generator D: 2.852036
Loss Generator P: 0.762682
Generator    : Epoch:      5, update:    1150, cost:   0.762682
Gradient discriminator: -8.744848
Gradient professor: -9.351211
Loss Generator D: 2.769096
Loss Generator P: 1.026101
Gradient discriminator: 3.037736
Gradient professor: 27.745293
Loss Generator D: 2.832408
Loss Generator P: 0.901878
Gradient discriminator: -46.145893
Gradient professor: 0.295467
Loss Generator D: 2.693432
Loss Generator P: 0.893872
Gradient discriminator: -15.002104
Gradient professor: -18.612982
Loss Generator D: 2.516307
Loss Generator P: 0.854006
Gradient discriminator: -2.813159
Gradient professor: 19.141311
Loss Generator D: 2.805909
Loss Generator P: 0.990377
Gradient discriminator: -9.338897
Gradient professor: -13.452536
Loss Generator D: 2.635243
Loss Generator P: 0.780563
Gradient discriminator: -22.417680
Gradient professor: -0.162341
Loss Generator D: 2.938875
Loss Generator P: 0.898178
Gradient discriminator: -7.400179
Gradient professor: -1.919877
Loss Generator D: 2.687659
Loss Generator P: 0.750374
Gradient discriminator: -11.856741
Gradient professor: -5.396627
Loss Generator D: 2.579364
Loss Generator P: 0.650793
Gradient discriminator: 14.065884
Gradient professor: 8.476973
Loss Generator D: 2.312494
Loss Generator P: 0.856952
Generator    : Epoch:      5, update:    1160, cost:   0.856952
Gradient discriminator: -11.404032
Gradient professor: 10.488952
Loss Generator D: 2.399853
Loss Generator P: 0.811257
Gradient discriminator: -1.726793
Gradient professor: 12.919628
Loss Generator D: 2.160035
Loss Generator P: 1.079759
Gradient discriminator: -10.937142
Gradient professor: -8.502579
Loss Generator D: 2.495524
Loss Generator P: 1.034843
Gradient discriminator: -5.262961
Gradient professor: 22.320691
Loss Generator D: 2.540013
Loss Generator P: 1.037017
Gradient discriminator: 11.716117
Gradient professor: -0.643173
Loss Generator D: 2.525728
Loss Generator P: 1.039241
Gradient discriminator: 7.052194
Gradient professor: 15.884849
Loss Generator D: 2.412114
Loss Generator P: 1.037741
Gradient discriminator: -2.340643
Gradient professor: 18.222109
Loss Generator D: 2.660537
Loss Generator P: 1.029548
Gradient discriminator: 2.846556
Gradient professor: -15.343356
Loss Generator D: 2.859551
Loss Generator P: 0.829850
Gradient discriminator: -9.232959
Gradient professor: -16.094012
Loss Generator D: 2.059202
Loss Generator P: 0.907595
Gradient discriminator: 14.138705
Gradient professor: -35.336711
Loss Generator D: 2.787926
Loss Generator P: 0.980449
Generator    : Epoch:      5, update:    1170, cost:   0.980449
Gradient discriminator: 12.035223
Gradient professor: -2.269084
Loss Generator D: 2.491357
Loss Generator P: 0.844439
Gradient discriminator: -15.040176
Gradient professor: -6.522989
Loss Generator D: 1.673359
Loss Generator P: 0.800225
Gradient discriminator: -5.340475
Gradient professor: 5.659561
Loss Generator D: 2.257666
Loss Generator P: 0.863646
Gradient discriminator: -11.583327
Gradient professor: -10.421595
Loss Generator D: 2.989258
Loss Generator P: 0.676915
Gradient discriminator: 4.759419
Gradient professor: -25.456867
Loss Generator D: 2.439376
Loss Generator P: 0.773470
Gradient discriminator: -6.466609
Gradient professor: 25.775432
Loss Generator D: 2.711023
Loss Generator P: 0.848527
Gradient discriminator: 31.752037
Gradient professor: 39.628949
Loss Generator D: 2.311755
Loss Generator P: 1.114562
Gradient discriminator: -4.446800
Gradient professor: -14.092984
Loss Generator D: 2.586532
Loss Generator P: 1.154338
Gradient discriminator: -3.700138
Gradient professor: 4.378663
Loss Generator D: 2.281004
Loss Generator P: 1.035463
Gradient discriminator: -3.214837
Gradient professor: 10.033178
Loss Generator D: 2.744695
Loss Generator P: 0.804644
Generator    : Epoch:      5, update:    1180, cost:   0.804644
Gradient discriminator: -9.432566
Gradient professor: 3.571518
Loss Generator D: 2.407258
Loss Generator P: 0.852465
Gradient discriminator: -8.444938
Gradient professor: -9.880026
Loss Generator D: 2.097412
Loss Generator P: 0.945155
Gradient discriminator: -0.715094
Gradient professor: -0.029529
Loss Generator D: 2.501006
Loss Generator P: 0.856271
Gradient discriminator: 18.377823
Gradient professor: -9.608861
Loss Generator D: 2.604921
Loss Generator P: 1.078879
Gradient discriminator: -2.785391
Gradient professor: -21.496269
Loss Generator D: 2.189509
Loss Generator P: 1.032339
Gradient discriminator: 0.870092
Gradient professor: 14.025553
Loss Generator D: 2.670754
Loss Generator P: 0.894941
Gradient discriminator: -6.465331
Gradient professor: -5.743104
Loss Generator D: 2.450741
Loss Generator P: 1.002610
Gradient discriminator: -3.810453
Gradient professor: -2.590754
Loss Generator D: 2.251006
Loss Generator P: 1.025471
Gradient discriminator: 8.724122
Gradient professor: -17.674441
Loss Generator D: 2.706535
Loss Generator P: 1.130621
Gradient discriminator: 11.525259
Gradient professor: -47.119272
Loss Generator D: 2.083928
Loss Generator P: 1.044344
Generator    : Epoch:      5, update:    1190, cost:   1.044344
Gradient discriminator: -1.962516
Gradient professor: -0.084845
Loss Generator D: 2.656459
Loss Generator P: 1.078700
Gradient discriminator: -0.441707
Gradient professor: 24.361267
Loss Generator D: 2.503383
Loss Generator P: 0.891862
Gradient discriminator: 6.409497
Gradient professor: -4.581774
Loss Generator D: 2.974110
Loss Generator P: 1.253132
Gradient discriminator: 5.728179
Gradient professor: 15.991890
Loss Generator D: 2.163929
Loss Generator P: 1.191874
Gradient discriminator: -7.130546
Gradient professor: 7.859919
Loss Generator D: 2.084064
Loss Generator P: 0.758674
Gradient discriminator: 10.507405
Gradient professor: -26.507753
Loss Generator D: 2.412746
Loss Generator P: 1.043903
Gradient discriminator: 8.049608
Gradient professor: -10.006229
Loss Generator D: 2.021320
Loss Generator P: 0.986147
Gradient discriminator: 24.106233
Gradient professor: -7.384809
Loss Generator D: 2.023000
Loss Generator P: 0.974967
Gradient discriminator: 1.802933
Gradient professor: 10.182608
Loss Generator D: 2.064678
Loss Generator P: 1.050770
Gradient discriminator: 17.621435
Gradient professor: -6.400206
Loss Generator D: 2.712743
Loss Generator P: 0.811805
Generator    : Epoch:      5, update:    1200, cost:   0.811805
Validation 12 - LOSS = 1.627 (PPL: 5.091)
Calling beam-search process
Beam-search ended, took 2.16812 minutes.
Validation 12 - BLEU = 7.57, 14.9/9.1/6.1/4.0 (BP=1.000, ratio=3.885, hyp_len=16394, ref_len=4220)
Early stopping patience: 989 validation left
--> Current BEST BLEU = 8.430 at validation 1
--> Current BEST LOSS = 1.621 (PPL: 5.060) at validation 11
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 3.065012
Gradient professor: -11.436945
Loss Generator D: 2.522359
Loss Generator P: 0.922038
Gradient discriminator: -7.757714
Gradient professor: 4.120766
Loss Generator D: 2.566727
Loss Generator P: 0.919578
Gradient discriminator: 30.602720
Gradient professor: 11.700565
Loss Generator D: 2.425187
Loss Generator P: 0.876912
Gradient discriminator: -4.525117
Gradient professor: -13.978385
Loss Generator D: 2.472900
Loss Generator P: 0.927055
Gradient discriminator: 8.829931
Gradient professor: -12.319068
Loss Generator D: 2.478570
Loss Generator P: 0.711202
Gradient discriminator: -8.552238
Gradient professor: -24.677036
Loss Generator D: 1.932198
Loss Generator P: 0.796131
Gradient discriminator: 12.898869
Gradient professor: -4.703957
Loss Generator D: 2.292862
Loss Generator P: 0.926368
Gradient discriminator: 33.654242
Gradient professor: 5.710864
Loss Generator D: 1.907042
Loss Generator P: 1.060299
Gradient discriminator: 12.112016
Gradient professor: 6.630087
Loss Generator D: 2.154573
Loss Generator P: 0.793293
Gradient discriminator: 3.591286
Gradient professor: -22.557572
Loss Generator D: 2.499793
Loss Generator P: 0.929796
Generator    : Epoch:      5, update:    1210, cost:   0.929796
Gradient discriminator: 26.476979
Gradient professor: -0.474771
Loss Generator D: 2.037579
Loss Generator P: 1.017593
Gradient discriminator: 26.307381
Gradient professor: 10.939776
Loss Generator D: 1.696938
Loss Generator P: 1.033608
Gradient discriminator: 3.563072
Gradient professor: 6.191770
Loss Generator D: 1.156900
Loss Generator P: 0.983774
Gradient discriminator: 13.279802
Gradient professor: -2.528283
Loss Generator D: 1.397062
Loss Generator P: 0.819065
Gradient discriminator: -0.315437
Gradient professor: 32.494710
Loss Generator D: 1.624844
Loss Generator P: 0.933523
Gradient discriminator: 7.765381
Gradient professor: -11.790592
Loss Generator D: 2.198424
Loss Generator P: 1.013390
Gradient discriminator: 11.157830
Gradient professor: 12.962497
Loss Generator D: 2.153150
Loss Generator P: 0.942002
Gradient discriminator: 1.351046
Gradient professor: -0.100487
Loss Generator D: 1.599618
Loss Generator P: 0.800339
Gradient discriminator: 5.735305
Gradient professor: 19.897170
Loss Generator D: 1.571218
Loss Generator P: 0.827643
Gradient discriminator: 7.949944
Gradient professor: -10.456326
Loss Generator D: 2.327684
Loss Generator P: 0.796175
Generator    : Epoch:      5, update:    1220, cost:   0.796175
Gradient discriminator: 7.222317
Gradient professor: 13.845870
Loss Generator D: 1.983652
Loss Generator P: 0.959775
Gradient discriminator: 13.728201
Gradient professor: -14.881568
Loss Generator D: 2.381207
Loss Generator P: 0.891636
Gradient discriminator: -20.604318
Gradient professor: 14.095723
Loss Generator D: 3.064141
Loss Generator P: 0.918728
Gradient discriminator: 19.400179
Gradient professor: 11.862459
Loss Generator D: 3.251201
Loss Generator P: 0.811649
Gradient discriminator: 13.828771
Gradient professor: 19.708086
Loss Generator D: 3.408779
Loss Generator P: 0.842660
Gradient discriminator: 0.344191
Gradient professor: 3.215033
Loss Generator D: 2.910551
Loss Generator P: 0.850739
Gradient discriminator: -1.224994
Gradient professor: 3.762658
Loss Generator D: 2.572736
Loss Generator P: 0.835340
Gradient discriminator: 10.822434
Gradient professor: 0.553721
Loss Generator D: 3.906420
Loss Generator P: 0.780384
Gradient discriminator: 10.513206
Gradient professor: -29.110693
Loss Generator D: 4.040976
Loss Generator P: 0.851217
Gradient discriminator: 3.697692
Gradient professor: -20.510036
Loss Generator D: 3.189509
Loss Generator P: 0.875299
Generator    : Epoch:      5, update:    1230, cost:   0.875299
Gradient discriminator: 6.838749
Gradient professor: 31.262118
Loss Generator D: 3.526157
Loss Generator P: 1.017773
Gradient discriminator: 18.660822
Gradient professor: -27.049620
Loss Generator D: 4.968524
Loss Generator P: 1.036772
Gradient discriminator: 11.147179
Gradient professor: 14.775733
Loss Generator D: 5.926708
Loss Generator P: 1.066186
Gradient discriminator: 22.365546
Gradient professor: 6.784853
Loss Generator D: 5.516828
Loss Generator P: 0.698973
Gradient discriminator: 5.583236
Gradient professor: 7.582767
Loss Generator D: 4.087829
Loss Generator P: 0.829723
Gradient discriminator: 0.558401
Gradient professor: -26.116468
Loss Generator D: 4.762179
Loss Generator P: 0.865952
Gradient discriminator: -6.229378
Gradient professor: 9.613906
Loss Generator D: 4.381025
Loss Generator P: 0.746309
Gradient discriminator: 10.556012
Gradient professor: -35.616752
Loss Generator D: 3.949558
Loss Generator P: 0.920773
Gradient discriminator: -0.933827
Gradient professor: 5.727419
Loss Generator D: 4.670578
Loss Generator P: 0.878403
Gradient discriminator: 11.158940
Gradient professor: -1.984330
Loss Generator D: 4.656943
Loss Generator P: 0.854612
Generator    : Epoch:      5, update:    1240, cost:   0.854612
Gradient discriminator: 17.946318
Gradient professor: 10.646581
Loss Generator D: 4.261440
Loss Generator P: 0.837436
Gradient discriminator: 3.120824
Gradient professor: 17.755657
Loss Generator D: 4.542270
Loss Generator P: 0.866391
Gradient discriminator: 6.027589
Gradient professor: 8.820496
Loss Generator D: 5.029205
Loss Generator P: 0.860349
Gradient discriminator: 12.824982
Gradient professor: -15.106413
Loss Generator D: 3.844138
Loss Generator P: 0.869778
Gradient discriminator: 2.007790
Gradient professor: 20.009465
Loss Generator D: 4.176533
Loss Generator P: 0.971248
Gradient discriminator: 12.534631
Gradient professor: -13.053328
Loss Generator D: 4.634821
Loss Generator P: 0.814696
Gradient discriminator: 2.513864
Gradient professor: -6.056698
Loss Generator D: 3.844723
Loss Generator P: 0.918843
Gradient discriminator: 2.734378
Gradient professor: -8.504212
Loss Generator D: 4.277258
Loss Generator P: 0.814929
Gradient discriminator: 3.583662
Gradient professor: 12.201707
Loss Generator D: 3.651618
Loss Generator P: 0.914068
Gradient discriminator: 19.906112
Gradient professor: 7.104163
Loss Generator D: 3.229004
Loss Generator P: 0.663870
Generator    : Epoch:      5, update:    1250, cost:   0.663870
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 5 finished with mean loss 1.72355 (PPL: 5.60441)
--> Epoch took 513.192 minutes, 123.166 sec/update
Epoch summary of Discriminator:
--> Epoch 5 finished with mean loss nan (PPL:  nan)
--> Epoch took 513.192 minutes, 123.166 sec/update
---------------------------------------------------------
Starting Epoch 6
----------------
Gradient discriminator: 4.689753
Gradient professor: 18.889874
Loss Generator D: 2.499490
Loss Generator P: 1.077195
Gradient discriminator: -2.745389
Gradient professor: 19.661017
Loss Generator D: 2.909187
Loss Generator P: 0.884391
Gradient discriminator: 2.325256
Gradient professor: 14.852189
Loss Generator D: 3.226801
Loss Generator P: 0.927120
Gradient discriminator: -0.406523
Gradient professor: -28.509411
Loss Generator D: 3.165828
Loss Generator P: 1.003828
Gradient discriminator: 5.463553
Gradient professor: -17.730803
Loss Generator D: 3.153923
Loss Generator P: 0.824461
Gradient discriminator: -8.034023
Gradient professor: -0.980943
Loss Generator D: 2.628660
Loss Generator P: 0.897873
Gradient discriminator: -6.352288
Gradient professor: 4.747555
Loss Generator D: 3.085461
Loss Generator P: 0.935637
Gradient discriminator: 7.494256
Gradient professor: 5.312142
Loss Generator D: 2.556467
Loss Generator P: 0.883452
Gradient discriminator: 19.114500
Gradient professor: 16.805242
Loss Generator D: 2.118317
Loss Generator P: 1.059662
Gradient discriminator: 2.366162
Gradient professor: -12.658173
Loss Generator D: 1.922916
Loss Generator P: 1.184941
Generator    : Epoch:      6, update:    1260, cost:   1.184941
Gradient discriminator: -8.173205
Gradient professor: 2.437995
Loss Generator D: 1.678054
Loss Generator P: 1.170752
Gradient discriminator: -3.041442
Gradient professor: -10.840529
Loss Generator D: 2.062600
Loss Generator P: 0.946046
Gradient discriminator: 8.155611
Gradient professor: 17.140732
Loss Generator D: 2.070238
Loss Generator P: 1.092092
Gradient discriminator: 2.601050
Gradient professor: -9.474964
Loss Generator D: 2.565089
Loss Generator P: 0.974521
Gradient discriminator: -4.966579
Gradient professor: 11.319711
Loss Generator D: 3.125244
Loss Generator P: 0.751262
Gradient discriminator: -7.829249
Gradient professor: -1.043226
Loss Generator D: 2.704028
Loss Generator P: 0.630131
Gradient discriminator: 6.413840
Gradient professor: -19.158870
Loss Generator D: 2.967318
Loss Generator P: 0.932849
Gradient discriminator: -1.743224
Gradient professor: 8.250028
Loss Generator D: 3.373303
Loss Generator P: 0.820218
Gradient discriminator: -3.395570
Gradient professor: 37.621393
Loss Generator D: 3.757040
Loss Generator P: 0.929637
Gradient discriminator: 2.534814
Gradient professor: -0.830594
Loss Generator D: 2.951895
Loss Generator P: 1.024501
Generator    : Epoch:      6, update:    1270, cost:   1.024501
Gradient discriminator: 8.723286
Gradient professor: -10.676924
Loss Generator D: 3.683725
Loss Generator P: 0.847584
Gradient discriminator: -5.200454
Gradient professor: -15.992379
Loss Generator D: 3.319601
Loss Generator P: 0.779772
Gradient discriminator: 1.731325
Gradient professor: 47.223506
Loss Generator D: 2.534028
Loss Generator P: 0.850080
Gradient discriminator: 5.937548
Gradient professor: 10.018834
Loss Generator D: 3.051506
Loss Generator P: 1.060161
Gradient discriminator: -2.875676
Gradient professor: 20.504190
Loss Generator D: 2.923824
Loss Generator P: 1.048814
Gradient discriminator: 0.811150
Gradient professor: -6.730544
Loss Generator D: 2.944543
Loss Generator P: 0.877730
Gradient discriminator: 5.647373
Gradient professor: 6.321784
Loss Generator D: 2.514031
Loss Generator P: 0.730152
Gradient discriminator: 13.095344
Gradient professor: 14.808615
Loss Generator D: 2.674211
Loss Generator P: 0.886026
Gradient discriminator: -7.425192
Gradient professor: -26.979222
Loss Generator D: 1.999144
Loss Generator P: 0.792496
Gradient discriminator: 3.831492
Gradient professor: 14.823391
Loss Generator D: 2.534083
Loss Generator P: 0.841644
Generator    : Epoch:      6, update:    1280, cost:   0.841644
Gradient discriminator: -7.460903
Gradient professor: 0.727690
Loss Generator D: 2.514725
Loss Generator P: 0.738563
Gradient discriminator: 2.775635
Gradient professor: 8.621257
Loss Generator D: 3.076813
Loss Generator P: 0.704971
Gradient discriminator: 22.836766
Gradient professor: -22.578108
Loss Generator D: 3.370776
Loss Generator P: 1.071324
Gradient discriminator: -1.141631
Gradient professor: 32.474107
Loss Generator D: 3.057349
Loss Generator P: 1.051563
Gradient discriminator: 12.746359
Gradient professor: -1.833346
Loss Generator D: 3.258173
Loss Generator P: 0.836718
Gradient discriminator: 2.203594
Gradient professor: -4.513801
Loss Generator D: 3.619394
Loss Generator P: 0.769353
Gradient discriminator: -6.941209
Gradient professor: -30.276419
Loss Generator D: 3.163066
Loss Generator P: 0.740815
Gradient discriminator: -3.368854
Gradient professor: 7.506538
Loss Generator D: 2.890346
Loss Generator P: 0.808853
Gradient discriminator: 5.446550
Gradient professor: 4.949651
Loss Generator D: 2.942165
Loss Generator P: 0.874456
Gradient discriminator: 1.222965
Gradient professor: -4.039253
Loss Generator D: 2.831631
Loss Generator P: 1.036577
Generator    : Epoch:      6, update:    1290, cost:   1.036577
Gradient discriminator: -6.533910
Gradient professor: 25.171951
Loss Generator D: 2.914641
Loss Generator P: 0.923954
Gradient discriminator: 1.424976
Gradient professor: -5.895756
Loss Generator D: 2.605192
Loss Generator P: 0.863746
Gradient discriminator: -3.523228
Gradient professor: -3.195177
Loss Generator D: 2.606825
Loss Generator P: 0.855118
Gradient discriminator: 3.979580
Gradient professor: 7.249315
Loss Generator D: 2.782082
Loss Generator P: 0.737772
Gradient discriminator: 1.581919
Gradient professor: 6.755608
Loss Generator D: 2.496649
Loss Generator P: 1.034775
Gradient discriminator: 10.476651
Gradient professor: 1.216564
Loss Generator D: 2.422273
Loss Generator P: 1.014911
Gradient discriminator: 11.568328
Gradient professor: 3.765307
Loss Generator D: 2.112691
Loss Generator P: 0.800771
Gradient discriminator: 11.334675
Gradient professor: -2.487565
Loss Generator D: 2.580801
Loss Generator P: 0.945283
Gradient discriminator: 6.730088
Gradient professor: -4.498165
Loss Generator D: 2.686233
Loss Generator P: 1.157447
Gradient discriminator: 19.201156
Gradient professor: -9.000968
Loss Generator D: 2.650011
Loss Generator P: 0.889024
Generator    : Epoch:      6, update:    1300, cost:   0.889024
Validation 13 - LOSS = 1.652 (PPL: 5.216)
Calling beam-search process
Beam-search ended, took 1.77940 minutes.
Validation 13 - BLEU = 11.59, 22.0/13.7/9.4/6.4 (BP=1.000, ratio=2.766, hyp_len=11672, ref_len=4220)
Saving model with best validation BLEU
--> Current BEST BLEU = 11.590 at validation 13
--> Current BEST LOSS = 1.621 (PPL: 5.060) at validation 11
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 7.218134
Gradient professor: 43.855185
Loss Generator D: 3.527033
Loss Generator P: 0.994227
Gradient discriminator: 8.705791
Gradient professor: -28.772670
Loss Generator D: 2.898521
Loss Generator P: 0.921679
Gradient discriminator: 6.015358
Gradient professor: -0.459211
Loss Generator D: 2.823634
Loss Generator P: 0.916468
Gradient discriminator: 6.291441
Gradient professor: -0.262423
Loss Generator D: 2.807386
Loss Generator P: 1.040914
Gradient discriminator: 2.804940
Gradient professor: -27.688411
Loss Generator D: 2.781218
Loss Generator P: 0.979057
Gradient discriminator: 2.002601
Gradient professor: 13.384849
Loss Generator D: 3.015001
Loss Generator P: 0.831641
Gradient discriminator: 2.940478
Gradient professor: 8.990883
Loss Generator D: 3.047003
Loss Generator P: 0.765981
Gradient discriminator: 7.385978
Gradient professor: 15.446943
Loss Generator D: 3.150823
Loss Generator P: 0.749538
Gradient discriminator: -1.108911
Gradient professor: 9.794595
Loss Generator D: 2.447984
Loss Generator P: 0.820589
Gradient discriminator: 31.104867
Gradient professor: -7.105757
Loss Generator D: 2.990494
Loss Generator P: 0.864765
Generator    : Epoch:      6, update:    1310, cost:   0.864765
Gradient discriminator: -3.186015
Gradient professor: 9.176470
Loss Generator D: 2.765318
Loss Generator P: 0.828993
Gradient discriminator: 24.735024
Gradient professor: -30.128984
Loss Generator D: 2.182085
Loss Generator P: 1.079013
Gradient discriminator: 3.551975
Gradient professor: 23.574384
Loss Generator D: 2.438926
Loss Generator P: 0.752295
Gradient discriminator: 8.865718
Gradient professor: 0.876310
Loss Generator D: 2.565394
Loss Generator P: 0.817776
Gradient discriminator: 59.354627
Gradient professor: -32.491307
Loss Generator D: 2.186181
Loss Generator P: 0.832452
Gradient discriminator: 37.036000
Gradient professor: -45.291952
Loss Generator D: 1.824295
Loss Generator P: 0.951380
Gradient discriminator: 9.856123
Gradient professor: 13.685381
Loss Generator D: 2.285243
Loss Generator P: 0.879214
Gradient discriminator: -19.504860
Gradient professor: -20.219008
Loss Generator D: 1.896338
Loss Generator P: 0.795813
Gradient discriminator: 35.170705
Gradient professor: -7.498830
Loss Generator D: 1.776003
Loss Generator P: 1.018952
Gradient discriminator: 15.974194
Gradient professor: -12.427049
Loss Generator D: 1.887179
Loss Generator P: 0.894293
Generator    : Epoch:      6, update:    1320, cost:   0.894293
Gradient discriminator: -6.986768
Gradient professor: 2.714654
Loss Generator D: 1.889106
Loss Generator P: 0.792588
Gradient discriminator: 5.333961
Gradient professor: -21.887247
Loss Generator D: 1.713211
Loss Generator P: 0.697661
Gradient discriminator: -10.040715
Gradient professor: -9.313766
Loss Generator D: 2.148385
Loss Generator P: 0.913260
Gradient discriminator: -5.696953
Gradient professor: 17.129257
Loss Generator D: 2.112801
Loss Generator P: 0.943324
Gradient discriminator: 0.414135
Gradient professor: -21.180098
Loss Generator D: 2.326824
Loss Generator P: 0.822443
Gradient discriminator: -9.260581
Gradient professor: 0.339710
Loss Generator D: 2.154245
Loss Generator P: 0.779198
Gradient discriminator: -19.966497
Gradient professor: 3.289638
Loss Generator D: 2.652253
Loss Generator P: 0.770422
Gradient discriminator: 25.113707
Gradient professor: -22.868230
Loss Generator D: 2.489916
Loss Generator P: 0.968094
Gradient discriminator: 23.093334
Gradient professor: -10.962487
Loss Generator D: 2.097379
Loss Generator P: 0.623184
Gradient discriminator: 23.038806
Gradient professor: -18.155192
Loss Generator D: 1.831511
Loss Generator P: 0.736907
Generator    : Epoch:      6, update:    1330, cost:   0.736907
Gradient discriminator: 14.761046
Gradient professor: 20.561089
Loss Generator D: 2.644306
Loss Generator P: 0.735517
Gradient discriminator: 12.353917
Gradient professor: -2.273803
Loss Generator D: 1.920518
Loss Generator P: 0.875336
Gradient discriminator: 13.163211
Gradient professor: -1.603287
Loss Generator D: 2.011351
Loss Generator P: 0.742588
Gradient discriminator: 10.531997
Gradient professor: 4.688143
Loss Generator D: 2.074365
Loss Generator P: 0.642058
Gradient discriminator: 5.718741
Gradient professor: 0.631598
Loss Generator D: 1.735788
Loss Generator P: 0.655358
Gradient discriminator: -13.950410
Gradient professor: -18.105197
Loss Generator D: 1.574551
Loss Generator P: 0.643481
Gradient discriminator: 16.226210
Gradient professor: -6.139451
Loss Generator D: 2.097087
Loss Generator P: 0.724703
Gradient discriminator: 7.790943
Gradient professor: -7.285914
Loss Generator D: 1.962053
Loss Generator P: 0.962628
Gradient discriminator: 0.587717
Gradient professor: -13.312638
Loss Generator D: 1.819753
Loss Generator P: 0.776090
Gradient discriminator: 11.045094
Gradient professor: 7.683605
Loss Generator D: 1.940223
Loss Generator P: 0.909632
Generator    : Epoch:      6, update:    1340, cost:   0.909632
Gradient discriminator: -21.703273
Gradient professor: 17.843228
Loss Generator D: 2.060596
Loss Generator P: 0.795025
Gradient discriminator: 3.635961
Gradient professor: 5.635536
Loss Generator D: 2.308836
Loss Generator P: 1.029969
Gradient discriminator: -9.955239
Gradient professor: 1.480883
Loss Generator D: 2.417393
Loss Generator P: 0.733941
Gradient discriminator: -3.892627
Gradient professor: -8.420625
Loss Generator D: 2.225573
Loss Generator P: 0.688557
Gradient discriminator: 2.432522
Gradient professor: -2.981249
Loss Generator D: 2.323699
Loss Generator P: 0.746844
Gradient discriminator: -2.218545
Gradient professor: -27.477757
Loss Generator D: 2.485164
Loss Generator P: 0.796417
Gradient discriminator: 1.344108
Gradient professor: -8.611729
Loss Generator D: 3.218004
Loss Generator P: 0.737860
Gradient discriminator: -5.375589
Gradient professor: -5.725014
Loss Generator D: 2.923354
Loss Generator P: 0.721324
Gradient discriminator: -4.327812
Gradient professor: 10.669282
Loss Generator D: 3.085455
Loss Generator P: 0.734901
Gradient discriminator: -8.144415
Gradient professor: 4.853968
Loss Generator D: 3.232713
Loss Generator P: 0.806936
Generator    : Epoch:      6, update:    1350, cost:   0.806936
Gradient discriminator: 7.659179
Gradient professor: -11.462849
Loss Generator D: 3.421098
Loss Generator P: 0.870715
Gradient discriminator: 4.104208
Gradient professor: -8.550169
Loss Generator D: 3.392581
Loss Generator P: 0.864139
Gradient discriminator: 2.415777
Gradient professor: -15.417179
Loss Generator D: 4.456033
Loss Generator P: 0.668303
Gradient discriminator: 11.462457
Gradient professor: -10.615059
Loss Generator D: 3.955627
Loss Generator P: 0.831505
Gradient discriminator: 30.096289
Gradient professor: 3.355645
Loss Generator D: 3.880653
Loss Generator P: 0.663668
Gradient discriminator: -5.039244
Gradient professor: -5.627091
Loss Generator D: 3.872583
Loss Generator P: 0.907507
Gradient discriminator: -12.792017
Gradient professor: -23.442641
Loss Generator D: 3.204538
Loss Generator P: 0.731600
Gradient discriminator: 7.322800
Gradient professor: -11.435667
Loss Generator D: 3.114565
Loss Generator P: 0.710225
Gradient discriminator: 8.225241
Gradient professor: -17.722279
Loss Generator D: 3.430962
Loss Generator P: 0.865867
Gradient discriminator: -7.132752
Gradient professor: -4.128377
Loss Generator D: 2.899985
Loss Generator P: 0.753981
Generator    : Epoch:      6, update:    1360, cost:   0.753981
Gradient discriminator: -6.313509
Gradient professor: -36.349952
Loss Generator D: 2.940981
Loss Generator P: 0.924327
Gradient discriminator: 2.366874
Gradient professor: 8.503808
Loss Generator D: 2.596276
Loss Generator P: 0.840157
Gradient discriminator: -0.165374
Gradient professor: 0.877574
Loss Generator D: 3.022877
Loss Generator P: 0.754397
Gradient discriminator: 7.752824
Gradient professor: -19.177104
Loss Generator D: 2.993781
Loss Generator P: 0.641021
Gradient discriminator: 13.241424
Gradient professor: 18.967912
Loss Generator D: 2.702195
Loss Generator P: 0.896352
Gradient discriminator: 7.743807
Gradient professor: -22.036180
Loss Generator D: 2.879955
Loss Generator P: 1.028703
Gradient discriminator: 17.026928
Gradient professor: 22.781691
Loss Generator D: 3.264324
Loss Generator P: 0.616000
Gradient discriminator: 4.306610
Gradient professor: 6.352378
Loss Generator D: 3.613411
Loss Generator P: 1.039025
Gradient discriminator: 0.929571
Gradient professor: 0.447052
Loss Generator D: 3.407708
Loss Generator P: 0.796251
Gradient discriminator: 2.118360
Gradient professor: 11.863815
Loss Generator D: 3.618227
Loss Generator P: 0.885689
Generator    : Epoch:      6, update:    1370, cost:   0.885689
Gradient discriminator: -0.502975
Gradient professor: -26.758734
Loss Generator D: 4.559923
Loss Generator P: 0.881581
Gradient discriminator: -3.841311
Gradient professor: 2.490371
Loss Generator D: 3.435896
Loss Generator P: 0.855080
Gradient discriminator: 2.831860
Gradient professor: -24.929158
Loss Generator D: 3.357879
Loss Generator P: 0.923381
Gradient discriminator: 14.158072
Gradient professor: 1.003159
Loss Generator D: 3.639224
Loss Generator P: 0.938389
Gradient discriminator: -3.746179
Gradient professor: -19.450957
Loss Generator D: 2.431865
Loss Generator P: 0.983122
Gradient discriminator: 7.563282
Gradient professor: 15.774066
Loss Generator D: 3.003922
Loss Generator P: 0.819798
Gradient discriminator: 5.611546
Gradient professor: -11.719496
Loss Generator D: 3.096067
Loss Generator P: 0.878967
Gradient discriminator: 2.128529
Gradient professor: 19.051557
Loss Generator D: 2.981620
Loss Generator P: 0.947343
Gradient discriminator: -0.985220
Gradient professor: -15.933089
Loss Generator D: 3.989673
Loss Generator P: 0.860874
Gradient discriminator: 26.430585
Gradient professor: -36.386807
Loss Generator D: 2.268110
Loss Generator P: 0.914364
Generator    : Epoch:      6, update:    1380, cost:   0.914364
Gradient discriminator: -0.226888
Gradient professor: 8.276636
Loss Generator D: 1.122083
Loss Generator P: 0.766703
Gradient discriminator: -1.368087
Gradient professor: -3.326673
Loss Generator D: 1.659505
Loss Generator P: 0.772954
Gradient discriminator: 7.495987
Gradient professor: 6.347671
Loss Generator D: 2.013915
Loss Generator P: 0.710680
Gradient discriminator: 0.909967
Gradient professor: 14.190042
Loss Generator D: 2.332895
Loss Generator P: 0.943930
Gradient discriminator: 7.652082
Gradient professor: 19.516687
Loss Generator D: 1.799970
Loss Generator P: 0.899494
Gradient discriminator: -6.581745
Gradient professor: -11.892780
Loss Generator D: 2.046234
Loss Generator P: 0.613505
Gradient discriminator: 4.704756
Gradient professor: -12.982431
Loss Generator D: 2.079895
Loss Generator P: 0.822415
Gradient discriminator: -1.320038
Gradient professor: 15.970029
Loss Generator D: 1.577600
Loss Generator P: 0.607837
Gradient discriminator: 9.995017
Gradient professor: -7.748258
Loss Generator D: 1.593374
Loss Generator P: 0.888397
Gradient discriminator: 1.918430
Gradient professor: -0.849435
Loss Generator D: 1.776302
Loss Generator P: 0.788011
Generator    : Epoch:      6, update:    1390, cost:   0.788011
Gradient discriminator: 2.259831
Gradient professor: -2.534595
Loss Generator D: 1.970535
Loss Generator P: 0.728794
Gradient discriminator: 6.228186
Gradient professor: 22.849811
Loss Generator D: 1.529642
Loss Generator P: 0.857581
Gradient discriminator: -1.096202
Gradient professor: -10.929747
Loss Generator D: 1.746128
Loss Generator P: 0.942022
Gradient discriminator: -8.099152
Gradient professor: -21.280863
Loss Generator D: 2.113134
Loss Generator P: 0.899230
Gradient discriminator: 12.598040
Gradient professor: 8.186819
Loss Generator D: 2.078171
Loss Generator P: 0.974995
Gradient discriminator: -11.037650
Gradient professor: 22.059456
Loss Generator D: 1.412446
Loss Generator P: 1.015070
Gradient discriminator: 0.159288
Gradient professor: 5.727956
Loss Generator D: 2.045795
Loss Generator P: 0.660191
Gradient discriminator: 4.579763
Gradient professor: -5.266606
Loss Generator D: 1.706980
Loss Generator P: 0.663233
Gradient discriminator: -7.744994
Gradient professor: -7.342626
Loss Generator D: 1.525416
Loss Generator P: 0.701287
Gradient discriminator: 6.945735
Gradient professor: -1.259890
Loss Generator D: 1.882162
Loss Generator P: 0.717398
Generator    : Epoch:      6, update:    1400, cost:   0.717398
Validation 14 - LOSS = 1.631 (PPL: 5.107)
Calling beam-search process
Beam-search ended, took 2.28508 minutes.
Validation 14 - BLEU = 6.80, 13.2/8.2/5.5/3.6 (BP=1.000, ratio=4.316, hyp_len=18212, ref_len=4220)
Early stopping patience: 999 validation left
--> Current BEST BLEU = 11.590 at validation 13
--> Current BEST LOSS = 1.621 (PPL: 5.060) at validation 11
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -6.388499
Gradient professor: 17.055277
Loss Generator D: 1.575102
Loss Generator P: 0.928036
Gradient discriminator: -2.519825
Gradient professor: 49.967672
Loss Generator D: 1.380853
Loss Generator P: 0.834457
Gradient discriminator: 1.036329
Gradient professor: 19.708901
Loss Generator D: 1.229285
Loss Generator P: 0.824941
Gradient discriminator: 11.761505
Gradient professor: -25.928495
Loss Generator D: 1.537442
Loss Generator P: 0.793435
Gradient discriminator: 7.490354
Gradient professor: 7.143478
Loss Generator D: 1.526875
Loss Generator P: 0.892783
Gradient discriminator: -5.148681
Gradient professor: -5.439934
Loss Generator D: 1.774541
Loss Generator P: 0.757971
Gradient discriminator: 20.884714
Gradient professor: -0.434367
Loss Generator D: 1.172290
Loss Generator P: 0.864036
Gradient discriminator: -4.901537
Gradient professor: -2.183592
Loss Generator D: 1.763213
Loss Generator P: 0.657194
Gradient discriminator: 5.885745
Gradient professor: 0.709185
Loss Generator D: 1.544157
Loss Generator P: 0.587685
Gradient discriminator: 0.372190
Gradient professor: 4.614260
Loss Generator D: 1.663951
Loss Generator P: 0.783373
Generator    : Epoch:      6, update:    1410, cost:   0.783373
Gradient discriminator: 2.762353
Gradient professor: 0.838072
Loss Generator D: 1.683521
Loss Generator P: 0.697695
Gradient discriminator: -5.949390
Gradient professor: 18.920096
Loss Generator D: 1.440413
Loss Generator P: 0.986356
Gradient discriminator: -0.904343
Gradient professor: 6.501768
Loss Generator D: 1.357263
Loss Generator P: 0.975108
Gradient discriminator: 0.847689
Gradient professor: 21.440702
Loss Generator D: 1.315988
Loss Generator P: 0.977968
Gradient discriminator: 3.281262
Gradient professor: 0.659361
Loss Generator D: 1.665061
Loss Generator P: 0.978076
Gradient discriminator: 6.780591
Gradient professor: -11.683187
Loss Generator D: 1.615769
Loss Generator P: 1.007841
Gradient discriminator: -2.398183
Gradient professor: 19.562241
Loss Generator D: 1.236251
Loss Generator P: 1.011399
Gradient discriminator: 10.447933
Gradient professor: -13.372559
Loss Generator D: 1.657648
Loss Generator P: 0.763508
Gradient discriminator: -1.010185
Gradient professor: -50.413475
Loss Generator D: 1.558211
Loss Generator P: 0.919600
Gradient discriminator: 10.022466
Gradient professor: -13.425201
Loss Generator D: 1.071810
Loss Generator P: 0.917973
Generator    : Epoch:      6, update:    1420, cost:   0.917973
Gradient discriminator: -5.205425
Gradient professor: 3.635719
Loss Generator D: 1.310601
Loss Generator P: 0.798306
Gradient discriminator: 5.860479
Gradient professor: -9.121199
Loss Generator D: 1.567816
Loss Generator P: 0.737236
Gradient discriminator: 4.874141
Gradient professor: 18.795052
Loss Generator D: 1.648725
Loss Generator P: 0.824719
Gradient discriminator: 1.596071
Gradient professor: -29.480662
Loss Generator D: 1.689146
Loss Generator P: 0.635417
Gradient discriminator: -1.211314
Gradient professor: -12.008620
Loss Generator D: 1.812694
Loss Generator P: 0.748461
Gradient discriminator: -0.638967
Gradient professor: 0.545788
Loss Generator D: 1.431099
Loss Generator P: 0.803656
Gradient discriminator: 14.221646
Gradient professor: -12.789505
Loss Generator D: 1.335148
Loss Generator P: 1.014744
Gradient discriminator: -8.485396
Gradient professor: 22.695932
Loss Generator D: 1.201312
Loss Generator P: 1.064657
Gradient discriminator: 4.806197
Gradient professor: -57.034129
Loss Generator D: 1.458126
Loss Generator P: 1.068343
Gradient discriminator: -8.126677
Gradient professor: -10.693129
Loss Generator D: 1.694397
Loss Generator P: 0.706515
Generator    : Epoch:      6, update:    1430, cost:   0.706515
Gradient discriminator: 7.285808
Gradient professor: 7.383458
Loss Generator D: 1.713338
Loss Generator P: 0.841201
Gradient discriminator: -13.706132
Gradient professor: -2.636971
Loss Generator D: 1.689139
Loss Generator P: 0.821934
Gradient discriminator: 13.687811
Gradient professor: 1.491130
Loss Generator D: 2.096634
Loss Generator P: 0.791881
Gradient discriminator: -0.387329
Gradient professor: 4.197221
Loss Generator D: 1.520180
Loss Generator P: 1.059221
Gradient discriminator: 12.722373
Gradient professor: -21.857225
Loss Generator D: 2.036341
Loss Generator P: 1.013756
Gradient discriminator: 16.948391
Gradient professor: 23.280043
Loss Generator D: 2.134728
Loss Generator P: 0.818607
Gradient discriminator: 22.339863
Gradient professor: -2.007216
Loss Generator D: 1.946174
Loss Generator P: 0.938266
Gradient discriminator: -5.767724
Gradient professor: -0.855791
Loss Generator D: 2.000690
Loss Generator P: 0.987669
Gradient discriminator: 3.204533
Gradient professor: 26.265253
Loss Generator D: 2.332382
Loss Generator P: 1.007492
Gradient discriminator: 4.916169
Gradient professor: -36.315757
Loss Generator D: 2.289767
Loss Generator P: 0.883140
Generator    : Epoch:      6, update:    1440, cost:   0.883140
Gradient discriminator: 2.393613
Gradient professor: 20.324542
Loss Generator D: 2.540667
Loss Generator P: 0.979929
Gradient discriminator: 9.267887
Gradient professor: -4.548409
Loss Generator D: 2.711622
Loss Generator P: 0.833766
Gradient discriminator: 12.216609
Gradient professor: -14.974921
Loss Generator D: 2.369070
Loss Generator P: 1.193022
Gradient discriminator: 14.004929
Gradient professor: 18.364643
Loss Generator D: 2.059436
Loss Generator P: 1.116979
Gradient discriminator: -6.615605
Gradient professor: -11.642228
Loss Generator D: 1.686656
Loss Generator P: 0.716125
Gradient discriminator: -14.976911
Gradient professor: 10.671808
Loss Generator D: 2.189361
Loss Generator P: 0.941212
Gradient discriminator: 17.885132
Gradient professor: -9.316024
Loss Generator D: 2.278470
Loss Generator P: 0.863163
Gradient discriminator: -16.831057
Gradient professor: -28.045306
Loss Generator D: 1.915117
Loss Generator P: 0.980876
Gradient discriminator: -15.214925
Gradient professor: -5.870444
Loss Generator D: 1.721768
Loss Generator P: 0.930184
Gradient discriminator: 11.986453
Gradient professor: -4.762548
Loss Generator D: 2.146786
Loss Generator P: 0.753653
Generator    : Epoch:      6, update:    1450, cost:   0.753653
Gradient discriminator: 7.377458
Gradient professor: 0.287198
Loss Generator D: 1.767459
Loss Generator P: 0.884301
Gradient discriminator: 0.956121
Gradient professor: -15.526101
Loss Generator D: 1.965305
Loss Generator P: 0.821908
Gradient discriminator: -13.602821
Gradient professor: 15.056778
Loss Generator D: 1.589803
Loss Generator P: 0.854133
Gradient discriminator: -5.951736
Gradient professor: -10.694877
Loss Generator D: 1.602410
Loss Generator P: 0.832347
Gradient discriminator: 17.794596
Gradient professor: -13.960150
Loss Generator D: 1.667300
Loss Generator P: 0.676463
Gradient discriminator: -13.146414
Gradient professor: -17.639756
Loss Generator D: 1.564114
Loss Generator P: 0.683022
Gradient discriminator: 8.599757
Gradient professor: -15.280263
Loss Generator D: 2.131667
Loss Generator P: 0.902960
Gradient discriminator: -17.629528
Gradient professor: 13.170460
Loss Generator D: 1.742938
Loss Generator P: 1.013355
Gradient discriminator: 5.536930
Gradient professor: -17.196005
Loss Generator D: 1.916909
Loss Generator P: 0.879852
Gradient discriminator: -7.793372
Gradient professor: -24.952183
Loss Generator D: 1.784026
Loss Generator P: 0.904926
Generator    : Epoch:      6, update:    1460, cost:   0.904926
Gradient discriminator: 4.209066
Gradient professor: 3.938147
Loss Generator D: 1.891081
Loss Generator P: 0.899533
Gradient discriminator: 10.251645
Gradient professor: 14.199958
Loss Generator D: 1.775278
Loss Generator P: 0.984870
Gradient discriminator: -4.205123
Gradient professor: -12.216353
Loss Generator D: 1.904438
Loss Generator P: 0.866478
Gradient discriminator: 0.938650
Gradient professor: 15.210029
Loss Generator D: 1.513368
Loss Generator P: 0.771685
Gradient discriminator: -3.236922
Gradient professor: 32.352695
Loss Generator D: 1.353576
Loss Generator P: 0.856881
Gradient discriminator: 7.015351
Gradient professor: 1.094256
Loss Generator D: 1.508365
Loss Generator P: 0.882876
Gradient discriminator: -1.050887
Gradient professor: -21.288542
Loss Generator D: 1.390590
Loss Generator P: 0.860974
Gradient discriminator: -7.566099
Gradient professor: 5.170664
Loss Generator D: 1.956218
Loss Generator P: 0.749051
Gradient discriminator: -15.615606
Gradient professor: 8.282140
Loss Generator D: 1.758307
Loss Generator P: 0.710265
Gradient discriminator: 6.515882
Gradient professor: -5.993521
Loss Generator D: 1.721558
Loss Generator P: 0.743524
Generator    : Epoch:      6, update:    1470, cost:   0.743524
Gradient discriminator: 0.865733
Gradient professor: -9.107234
Loss Generator D: 1.754301
Loss Generator P: 0.824364
Gradient discriminator: -10.314648
Gradient professor: -12.294553
Loss Generator D: 1.508325
Loss Generator P: 0.869710
Gradient discriminator: 5.744492
Gradient professor: -12.898258
Loss Generator D: 1.548258
Loss Generator P: 0.905677
Gradient discriminator: -9.587071
Gradient professor: -0.819593
Loss Generator D: 1.409205
Loss Generator P: 0.745976
Gradient discriminator: 2.745520
Gradient professor: 8.219350
Loss Generator D: 1.555234
Loss Generator P: 0.780399
Gradient discriminator: -54.381397
Gradient professor: -7.019241
Loss Generator D: 1.425550
Loss Generator P: 0.797406
Gradient discriminator: 11.929052
Gradient professor: 17.874153
Loss Generator D: 1.403990
Loss Generator P: 0.797202
Gradient discriminator: -15.512944
Gradient professor: 15.137229
Loss Generator D: 1.822450
Loss Generator P: 0.784316
Gradient discriminator: -14.981535
Gradient professor: -10.629202
Loss Generator D: 1.604269
Loss Generator P: 0.754862
Gradient discriminator: -19.400036
Gradient professor: -0.941097
Loss Generator D: 2.297847
Loss Generator P: 0.849025
Generator    : Epoch:      6, update:    1480, cost:   0.849025
Gradient discriminator: 7.031536
Gradient professor: -1.407915
Loss Generator D: 1.603163
Loss Generator P: 0.993907
Gradient discriminator: -1.649852
Gradient professor: 4.008642
Loss Generator D: 1.508953
Loss Generator P: 0.964130
Gradient discriminator: 23.732457
Gradient professor: 38.750402
Loss Generator D: 1.730099
Loss Generator P: 1.004901
Gradient discriminator: 21.423869
Gradient professor: 11.269107
Loss Generator D: 1.759688
Loss Generator P: 0.627368
Gradient discriminator: -20.876417
Gradient professor: -0.675053
Loss Generator D: 1.529950
Loss Generator P: 0.727228
Gradient discriminator: -1.317575
Gradient professor: -10.336901
Loss Generator D: 1.906987
Loss Generator P: 0.756184
Gradient discriminator: 2.831054
Gradient professor: 3.704514
Loss Generator D: 2.041318
Loss Generator P: 0.708085
Gradient discriminator: -0.080487
Gradient professor: -12.105700
Loss Generator D: 1.812508
Loss Generator P: 0.839829
Gradient discriminator: 13.551664
Gradient professor: 5.892085
Loss Generator D: 1.549477
Loss Generator P: 0.841059
Gradient discriminator: -3.915041
Gradient professor: 27.337253
Loss Generator D: 1.840532
Loss Generator P: 0.802768
Generator    : Epoch:      6, update:    1490, cost:   0.802768
Gradient discriminator: 17.072973
Gradient professor: -25.994936
Loss Generator D: 1.598700
Loss Generator P: 0.792931
Gradient discriminator: -10.082960
Gradient professor: 10.507014
Loss Generator D: 1.652108
Loss Generator P: 0.811831
Gradient discriminator: 3.360602
Gradient professor: 13.251926
Loss Generator D: 1.652753
Loss Generator P: 0.757803
Gradient discriminator: 0.491960
Gradient professor: -10.790538
Loss Generator D: 1.685141
Loss Generator P: 0.795219
Gradient discriminator: -3.431754
Gradient professor: 34.671571
Loss Generator D: 1.813784
Loss Generator P: 0.931474
Gradient discriminator: -1.222004
Gradient professor: -5.315017
Loss Generator D: 1.820751
Loss Generator P: 0.693602
Gradient discriminator: 2.236177
Gradient professor: -7.508584
Loss Generator D: 1.634430
Loss Generator P: 0.869254
Gradient discriminator: 15.035564
Gradient professor: -13.301805
Loss Generator D: 1.788269
Loss Generator P: 0.763511
Gradient discriminator: 0.916820
Gradient professor: -6.040220
Loss Generator D: 1.185381
Loss Generator P: 0.816223
Gradient discriminator: -20.035133
Gradient professor: 0.299020
Loss Generator D: 1.997355
Loss Generator P: 0.602642
Generator    : Epoch:      6, update:    1500, cost:   0.602642
Validation 15 - LOSS = 1.610 (PPL: 5.001)
Calling beam-search process
Beam-search ended, took 2.66540 minutes.
Validation 15 - BLEU = 6.05, 11.6/7.2/4.9/3.3 (BP=1.000, ratio=4.969, hyp_len=20969, ref_len=4220)
Early stopping patience: 998 validation left
--> Current BEST BLEU = 11.590 at validation 13
--> Current BEST LOSS = 1.610 (PPL: 5.001) at validation 15
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 6 finished with mean loss 1.55558 (PPL: 4.73786)
--> Epoch took 495.346 minutes, 118.883 sec/update
Epoch summary of Discriminator:
--> Epoch 6 finished with mean loss nan (PPL:  nan)
--> Epoch took 495.346 minutes, 118.883 sec/update
---------------------------------------------------------
Starting Epoch 7
----------------
Gradient discriminator: -4.850554
Gradient professor: 16.202151
Loss Generator D: 1.732618
Loss Generator P: 1.020298
Gradient discriminator: -0.330888
Gradient professor: 21.925298
Loss Generator D: 1.479427
Loss Generator P: 0.846379
Gradient discriminator: 30.497236
Gradient professor: 58.458294
Loss Generator D: 1.881850
Loss Generator P: 0.831782
Gradient discriminator: -0.988111
Gradient professor: -3.021894
Loss Generator D: 1.555263
Loss Generator P: 0.964338
Gradient discriminator: 1.773251
Gradient professor: -14.642239
Loss Generator D: 1.343783
Loss Generator P: 0.738517
Gradient discriminator: -14.167116
Gradient professor: -7.185973
Loss Generator D: 1.505984
Loss Generator P: 0.784637
Gradient discriminator: -5.581593
Gradient professor: 19.105247
Loss Generator D: 1.667108
Loss Generator P: 0.917953
Gradient discriminator: -10.384610
Gradient professor: 25.955734
Loss Generator D: 1.425809
Loss Generator P: 0.799967
Gradient discriminator: -14.086093
Gradient professor: -1.406361
Loss Generator D: 1.632093
Loss Generator P: 0.953764
Gradient discriminator: 5.801001
Gradient professor: 3.636510
Loss Generator D: 1.516538
Loss Generator P: 1.061587
Generator    : Epoch:      7, update:    1510, cost:   1.061587
Gradient discriminator: 1.080102
Gradient professor: -5.609267
Loss Generator D: 1.365355
Loss Generator P: 1.096306
Gradient discriminator: -5.096915
Gradient professor: -26.579573
Loss Generator D: 1.793660
Loss Generator P: 0.867201
Gradient discriminator: -27.544888
Gradient professor: 27.094040
Loss Generator D: 1.570280
Loss Generator P: 1.018771
Gradient discriminator: 4.016207
Gradient professor: -8.791209
Loss Generator D: 1.586205
Loss Generator P: 0.923851
Gradient discriminator: 7.264692
Gradient professor: 4.661531
Loss Generator D: 1.624408
Loss Generator P: 0.684363
Gradient discriminator: -1.421718
Gradient professor: -20.951073
Loss Generator D: 1.414892
Loss Generator P: 0.618300
Gradient discriminator: -0.867537
Gradient professor: 24.639838
Loss Generator D: 1.521349
Loss Generator P: 0.820069
Gradient discriminator: 2.508838
Gradient professor: -6.443700
Loss Generator D: 1.684812
Loss Generator P: 0.802127
Gradient discriminator: -1.191174
Gradient professor: 2.864128
Loss Generator D: 1.735906
Loss Generator P: 0.859726
Gradient discriminator: 7.112563
Gradient professor: 39.280807
Loss Generator D: 1.468619
Loss Generator P: 0.982642
Generator    : Epoch:      7, update:    1520, cost:   0.982642
Gradient discriminator: 2.577214
Gradient professor: -40.659200
Loss Generator D: 1.672871
Loss Generator P: 0.835771
Gradient discriminator: -2.718183
Gradient professor: -3.769779
Loss Generator D: 1.812642
Loss Generator P: 0.800417
Gradient discriminator: 7.667424
Gradient professor: 6.208603
Loss Generator D: 1.720984
Loss Generator P: 0.769400
Gradient discriminator: -1.699793
Gradient professor: 5.580303
Loss Generator D: 1.812968
Loss Generator P: 0.991450
Gradient discriminator: 5.170735
Gradient professor: 5.964585
Loss Generator D: 1.866200
Loss Generator P: 0.964277
Gradient discriminator: -15.398314
Gradient professor: 19.351511
Loss Generator D: 1.938717
Loss Generator P: 0.801205
Gradient discriminator: 5.137294
Gradient professor: -4.937408
Loss Generator D: 1.617564
Loss Generator P: 0.711268
Gradient discriminator: -2.819955
Gradient professor: 20.978674
Loss Generator D: 2.086881
Loss Generator P: 0.825541
Gradient discriminator: 2.742470
Gradient professor: -17.110574
Loss Generator D: 1.879074
Loss Generator P: 0.750071
Gradient discriminator: -10.992127
Gradient professor: 1.244796
Loss Generator D: 1.708657
Loss Generator P: 0.815475
Generator    : Epoch:      7, update:    1530, cost:   0.815475
Gradient discriminator: -9.963204
Gradient professor: 1.992188
Loss Generator D: 2.071629
Loss Generator P: 0.703878
Gradient discriminator: -27.129343
Gradient professor: -2.704496
Loss Generator D: 2.158564
Loss Generator P: 0.643618
Gradient discriminator: 13.512337
Gradient professor: -10.359384
Loss Generator D: 2.217347
Loss Generator P: 0.978759
Gradient discriminator: -10.495732
Gradient professor: -11.307059
Loss Generator D: 2.108997
Loss Generator P: 1.008233
Gradient discriminator: -3.022575
Gradient professor: -7.403808
Loss Generator D: 2.392241
Loss Generator P: 0.795334
Gradient discriminator: -0.452127
Gradient professor: -10.591622
Loss Generator D: 2.431916
Loss Generator P: 0.739527
Gradient discriminator: -6.114514
Gradient professor: 4.441697
Loss Generator D: 1.980974
Loss Generator P: 0.682292
Gradient discriminator: 5.067715
Gradient professor: 12.137014
Loss Generator D: 1.883474
Loss Generator P: 0.865902
Gradient discriminator: -2.816582
Gradient professor: -0.085348
Loss Generator D: 1.994265
Loss Generator P: 0.755492
Gradient discriminator: 15.171371
Gradient professor: 19.932255
Loss Generator D: 2.267392
Loss Generator P: 0.983183
Generator    : Epoch:      7, update:    1540, cost:   0.983183
Gradient discriminator: 14.273660
Gradient professor: -19.230424
Loss Generator D: 1.718752
Loss Generator P: 0.926893
Gradient discriminator: 5.500400
Gradient professor: 18.519292
Loss Generator D: 2.021030
Loss Generator P: 0.809197
Gradient discriminator: 5.090070
Gradient professor: -39.793731
Loss Generator D: 2.425047
Loss Generator P: 0.809926
Gradient discriminator: -3.661720
Gradient professor: -17.668250
Loss Generator D: 2.258368
Loss Generator P: 0.711276
Gradient discriminator: 12.102451
Gradient professor: 13.328435
Loss Generator D: 2.157888
Loss Generator P: 1.028806
Gradient discriminator: 3.017147
Gradient professor: 16.018229
Loss Generator D: 1.612890
Loss Generator P: 0.965858
Gradient discriminator: 0.194838
Gradient professor: -8.459127
Loss Generator D: 1.806052
Loss Generator P: 0.774299
Gradient discriminator: 0.716503
Gradient professor: 11.061371
Loss Generator D: 2.121832
Loss Generator P: 0.969688
Gradient discriminator: -24.819026
Gradient professor: -18.883156
Loss Generator D: 2.416791
Loss Generator P: 1.142252
Gradient discriminator: 0.174800
Gradient professor: -31.390993
Loss Generator D: 1.934829
Loss Generator P: 0.952492
Generator    : Epoch:      7, update:    1550, cost:   0.952492
Gradient discriminator: -8.603634
Gradient professor: 22.453984
Loss Generator D: 1.805180
Loss Generator P: 0.916835
Gradient discriminator: 17.101811
Gradient professor: 3.470121
Loss Generator D: 1.986089
Loss Generator P: 0.824599
Gradient discriminator: 1.733155
Gradient professor: 0.136731
Loss Generator D: 1.570021
Loss Generator P: 0.830564
Gradient discriminator: -5.374138
Gradient professor: -0.429591
Loss Generator D: 1.787822
Loss Generator P: 1.011182
Gradient discriminator: -13.823706
Gradient professor: -45.177436
Loss Generator D: 1.916656
Loss Generator P: 0.860305
Gradient discriminator: -29.213808
Gradient professor: 24.591392
Loss Generator D: 1.684279
Loss Generator P: 0.771647
Gradient discriminator: 11.287591
Gradient professor: 13.115076
Loss Generator D: 1.634619
Loss Generator P: 0.739287
Gradient discriminator: 8.144811
Gradient professor: 13.038226
Loss Generator D: 1.534026
Loss Generator P: 0.709122
Gradient discriminator: -2.783656
Gradient professor: 6.422490
Loss Generator D: 1.312043
Loss Generator P: 0.819537
Gradient discriminator: 13.966533
Gradient professor: 3.890306
Loss Generator D: 1.530365
Loss Generator P: 0.861698
Generator    : Epoch:      7, update:    1560, cost:   0.861698
Gradient discriminator: -9.593343
Gradient professor: 8.743255
Loss Generator D: 1.566504
Loss Generator P: 0.775511
Gradient discriminator: 1.696613
Gradient professor: 2.165125
Loss Generator D: 1.323403
Loss Generator P: 1.031444
Gradient discriminator: 3.797606
Gradient professor: 10.396712
Loss Generator D: 1.154030
Loss Generator P: 0.790868
Gradient discriminator: -21.964948
Gradient professor: -6.726783
Loss Generator D: 1.209234
Loss Generator P: 0.822575
Gradient discriminator: 35.146895
Gradient professor: -17.447915
Loss Generator D: 1.388066
Loss Generator P: 0.955894
Gradient discriminator: 7.382827
Gradient professor: -14.437982
Loss Generator D: 1.282052
Loss Generator P: 0.860869
Gradient discriminator: 6.780078
Gradient professor: 8.884728
Loss Generator D: 1.398574
Loss Generator P: 0.808736
Gradient discriminator: -1.433151
Gradient professor: 7.956823
Loss Generator D: 1.573778
Loss Generator P: 0.805048
Gradient discriminator: -5.752606
Gradient professor: -14.632584
Loss Generator D: 1.464618
Loss Generator P: 1.012656
Gradient discriminator: 19.127490
Gradient professor: 8.165912
Loss Generator D: 1.313111
Loss Generator P: 0.856421
Generator    : Epoch:      7, update:    1570, cost:   0.856421
Gradient discriminator: 1.469627
Gradient professor: -17.153877
Loss Generator D: 1.438580
Loss Generator P: 0.729000
Gradient discriminator: 10.949253
Gradient professor: -4.777587
Loss Generator D: 1.275356
Loss Generator P: 0.650709
Gradient discriminator: 0.748480
Gradient professor: 1.420783
Loss Generator D: 1.218234
Loss Generator P: 0.883689
Gradient discriminator: -11.061361
Gradient professor: -1.173566
Loss Generator D: 1.203901
Loss Generator P: 0.930887
Gradient discriminator: -3.776827
Gradient professor: 20.920691
Loss Generator D: 1.201686
Loss Generator P: 0.919789
Gradient discriminator: 4.010526
Gradient professor: -3.708944
Loss Generator D: 1.391241
Loss Generator P: 0.716134
Gradient discriminator: -2.608547
Gradient professor: 8.966169
Loss Generator D: 1.363376
Loss Generator P: 0.807242
Gradient discriminator: -8.550190
Gradient professor: -1.456105
Loss Generator D: 1.493649
Loss Generator P: 0.958645
Gradient discriminator: -8.647404
Gradient professor: -6.606385
Loss Generator D: 1.515083
Loss Generator P: 0.648945
Gradient discriminator: 2.086062
Gradient professor: -4.975746
Loss Generator D: 1.669173
Loss Generator P: 0.664012
Generator    : Epoch:      7, update:    1580, cost:   0.664012
Gradient discriminator: -5.046860
Gradient professor: 11.924304
Loss Generator D: 1.883842
Loss Generator P: 0.674516
Gradient discriminator: -9.419718
Gradient professor: 1.350859
Loss Generator D: 2.052757
Loss Generator P: 0.754117
Gradient discriminator: 8.207860
Gradient professor: 2.067019
Loss Generator D: 1.855850
Loss Generator P: 0.730058
Gradient discriminator: 7.311329
Gradient professor: -3.690442
Loss Generator D: 1.901110
Loss Generator P: 0.521899
Gradient discriminator: 8.031621
Gradient professor: 12.636420
Loss Generator D: 2.423322
Loss Generator P: 0.639575
Gradient discriminator: 1.544820
Gradient professor: -4.997174
Loss Generator D: 1.933549
Loss Generator P: 0.649695
Gradient discriminator: -5.268547
Gradient professor: -14.758186
Loss Generator D: 2.092358
Loss Generator P: 0.686792
Gradient discriminator: 9.724866
Gradient professor: -0.340885
Loss Generator D: 2.292893
Loss Generator P: 0.895416
Gradient discriminator: -5.763905
Gradient professor: -12.606139
Loss Generator D: 2.377842
Loss Generator P: 0.782092
Gradient discriminator: -9.856656
Gradient professor: 14.474189
Loss Generator D: 2.210647
Loss Generator P: 0.891035
Generator    : Epoch:      7, update:    1590, cost:   0.891035
Gradient discriminator: 14.985780
Gradient professor: 8.384221
Loss Generator D: 2.420678
Loss Generator P: 0.739948
Gradient discriminator: 3.217032
Gradient professor: 16.835085
Loss Generator D: 2.481460
Loss Generator P: 1.041051
Gradient discriminator: -5.473931
Gradient professor: -3.121263
Loss Generator D: 2.457190
Loss Generator P: 0.680804
Gradient discriminator: 4.409354
Gradient professor: 10.207001
Loss Generator D: 2.473573
Loss Generator P: 0.577167
Gradient discriminator: -5.916684
Gradient professor: 6.487867
Loss Generator D: 2.335512
Loss Generator P: 0.737053
Gradient discriminator: -1.507820
Gradient professor: -15.544723
Loss Generator D: 2.451000
Loss Generator P: 0.759844
Gradient discriminator: -7.366685
Gradient professor: -14.815563
Loss Generator D: 2.971286
Loss Generator P: 0.656676
Gradient discriminator: -3.767890
Gradient professor: -7.288528
Loss Generator D: 2.472762
Loss Generator P: 0.652820
Gradient discriminator: -6.201172
Gradient professor: -0.253553
Loss Generator D: 2.454125
Loss Generator P: 0.727069
Gradient discriminator: -10.586517
Gradient professor: -3.693731
Loss Generator D: 2.480812
Loss Generator P: 0.764412
Generator    : Epoch:      7, update:    1600, cost:   0.764412
Validation 16 - LOSS = 1.608 (PPL: 4.991)
Calling beam-search process
Beam-search ended, took 1.46575 minutes.
Validation 16 - BLEU = 18.27, 31.8/21.4/15.3/10.7 (BP=1.000, ratio=2.037, hyp_len=8597, ref_len=4220)
Saving model with best validation BLEU
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.608 (PPL: 4.991) at validation 16
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 8.923498
Gradient professor: -12.381362
Loss Generator D: 3.136455
Loss Generator P: 0.855953
Gradient discriminator: -12.887815
Gradient professor: -7.795326
Loss Generator D: 2.729446
Loss Generator P: 0.863570
Gradient discriminator: 1.051865
Gradient professor: 7.052463
Loss Generator D: 2.983268
Loss Generator P: 0.670356
Gradient discriminator: 1.074890
Gradient professor: -8.870642
Loss Generator D: 2.671214
Loss Generator P: 0.767069
Gradient discriminator: 5.571679
Gradient professor: -1.455497
Loss Generator D: 2.562267
Loss Generator P: 0.590617
Gradient discriminator: 3.787005
Gradient professor: 9.142982
Loss Generator D: 1.989702
Loss Generator P: 0.828052
Gradient discriminator: 3.546602
Gradient professor: -8.635765
Loss Generator D: 2.489694
Loss Generator P: 0.672365
Gradient discriminator: -3.884022
Gradient professor: -3.626824
Loss Generator D: 2.929874
Loss Generator P: 0.750455
Gradient discriminator: 2.531583
Gradient professor: 11.258796
Loss Generator D: 2.971340
Loss Generator P: 0.835819
Gradient discriminator: -0.972238
Gradient professor: -14.283549
Loss Generator D: 2.864317
Loss Generator P: 0.699461
Generator    : Epoch:      7, update:    1610, cost:   0.699461
Gradient discriminator: 0.026354
Gradient professor: 2.423433
Loss Generator D: 3.013672
Loss Generator P: 0.865557
Gradient discriminator: 5.123781
Gradient professor: -25.995868
Loss Generator D: 2.644933
Loss Generator P: 0.806058
Gradient discriminator: 1.694044
Gradient professor: 7.508379
Loss Generator D: 2.719208
Loss Generator P: 0.715738
Gradient discriminator: -0.452353
Gradient professor: -4.970048
Loss Generator D: 1.852752
Loss Generator P: 0.573730
Gradient discriminator: 6.460013
Gradient professor: -19.220338
Loss Generator D: 2.522727
Loss Generator P: 0.850577
Gradient discriminator: -4.620395
Gradient professor: -23.376786
Loss Generator D: 2.166071
Loss Generator P: 0.908052
Gradient discriminator: 3.229996
Gradient professor: 19.434470
Loss Generator D: 2.434298
Loss Generator P: 0.620500
Gradient discriminator: 12.744472
Gradient professor: 0.353442
Loss Generator D: 2.338243
Loss Generator P: 0.935604
Gradient discriminator: 6.340546
Gradient professor: -23.918212
Loss Generator D: 2.161630
Loss Generator P: 0.731881
Gradient discriminator: -3.196419
Gradient professor: -19.219750
Loss Generator D: 2.332632
Loss Generator P: 0.739563
Generator    : Epoch:      7, update:    1620, cost:   0.739563
Gradient discriminator: -8.220849
Gradient professor: 1.763868
Loss Generator D: 2.531440
Loss Generator P: 0.834358
Gradient discriminator: 8.614805
Gradient professor: -11.358569
Loss Generator D: 2.093508
Loss Generator P: 0.839777
Gradient discriminator: 6.468514
Gradient professor: -13.899356
Loss Generator D: 2.653590
Loss Generator P: 0.873181
Gradient discriminator: 7.185916
Gradient professor: 10.155685
Loss Generator D: 2.751753
Loss Generator P: 0.889586
Gradient discriminator: -13.123405
Gradient professor: -15.386676
Loss Generator D: 2.264847
Loss Generator P: 0.900971
Gradient discriminator: 21.411523
Gradient professor: 1.447906
Loss Generator D: 2.424984
Loss Generator P: 0.820800
Gradient discriminator: -3.650637
Gradient professor: 26.779268
Loss Generator D: 1.929688
Loss Generator P: 0.883464
Gradient discriminator: -9.719341
Gradient professor: -1.445030
Loss Generator D: 2.588471
Loss Generator P: 0.895012
Gradient discriminator: -4.920529
Gradient professor: -11.941338
Loss Generator D: 2.672150
Loss Generator P: 0.830777
Gradient discriminator: -16.075564
Gradient professor: -19.956765
Loss Generator D: 2.493251
Loss Generator P: 0.845316
Generator    : Epoch:      7, update:    1630, cost:   0.845316
Gradient discriminator: -4.986707
Gradient professor: -10.133674
Loss Generator D: 2.247103
Loss Generator P: 0.728337
Gradient discriminator: -9.431447
Gradient professor: 3.255488
Loss Generator D: 2.269150
Loss Generator P: 0.709612
Gradient discriminator: 4.811946
Gradient professor: 15.792393
Loss Generator D: 1.937286
Loss Generator P: 0.628159
Gradient discriminator: -6.954970
Gradient professor: -16.414757
Loss Generator D: 2.436307
Loss Generator P: 0.943325
Gradient discriminator: 20.398372
Gradient professor: 8.915052
Loss Generator D: 1.939817
Loss Generator P: 0.822990
Gradient discriminator: 0.167957
Gradient professor: -10.435707
Loss Generator D: 2.642798
Loss Generator P: 0.619093
Gradient discriminator: 9.383436
Gradient professor: -19.039742
Loss Generator D: 2.742856
Loss Generator P: 0.818081
Gradient discriminator: 6.853692
Gradient professor: -7.337143
Loss Generator D: 2.751947
Loss Generator P: 0.589267
Gradient discriminator: 12.476951
Gradient professor: 15.253399
Loss Generator D: 2.724963
Loss Generator P: 0.918712
Gradient discriminator: -3.633660
Gradient professor: 18.600366
Loss Generator D: 2.450901
Loss Generator P: 0.848175
Generator    : Epoch:      7, update:    1640, cost:   0.848175
Gradient discriminator: -15.384760
Gradient professor: -22.779871
Loss Generator D: 2.618969
Loss Generator P: 0.657116
Gradient discriminator: -11.362815
Gradient professor: 11.512496
Loss Generator D: 2.349164
Loss Generator P: 0.866987
Gradient discriminator: 3.703773
Gradient professor: -22.204895
Loss Generator D: 2.186213
Loss Generator P: 0.944661
Gradient discriminator: 21.583928
Gradient professor: -49.131008
Loss Generator D: 2.012301
Loss Generator P: 0.932845
Gradient discriminator: 4.774919
Gradient professor: -40.637034
Loss Generator D: 1.781643
Loss Generator P: 1.000928
Gradient discriminator: -9.519394
Gradient professor: 11.917442
Loss Generator D: 1.878021
Loss Generator P: 1.002855
Gradient discriminator: -1.215253
Gradient professor: 19.896157
Loss Generator D: 1.992543
Loss Generator P: 0.616830
Gradient discriminator: 14.589418
Gradient professor: -2.392848
Loss Generator D: 2.076732
Loss Generator P: 0.686379
Gradient discriminator: -21.102746
Gradient professor: 2.837223
Loss Generator D: 2.036648
Loss Generator P: 0.670973
Gradient discriminator: -3.273165
Gradient professor: 1.323929
Loss Generator D: 2.220485
Loss Generator P: 0.676563
Generator    : Epoch:      7, update:    1650, cost:   0.676563
Gradient discriminator: 15.042573
Gradient professor: 3.691762
Loss Generator D: 2.210559
Loss Generator P: 0.962063
Gradient discriminator: -2.036289
Gradient professor: 14.424378
Loss Generator D: 1.773853
Loss Generator P: 0.791171
Gradient discriminator: 5.253124
Gradient professor: 26.692029
Loss Generator D: 2.308394
Loss Generator P: 0.795892
Gradient discriminator: 12.404136
Gradient professor: -19.361527
Loss Generator D: 2.181936
Loss Generator P: 0.772763
Gradient discriminator: -1.321173
Gradient professor: 14.457917
Loss Generator D: 1.514996
Loss Generator P: 0.861121
Gradient discriminator: 15.548197
Gradient professor: -18.382001
Loss Generator D: 1.986992
Loss Generator P: 0.676369
Gradient discriminator: -0.349258
Gradient professor: 27.326071
Loss Generator D: 1.801204
Loss Generator P: 0.761392
Gradient discriminator: -0.506710
Gradient professor: -9.240290
Loss Generator D: 1.935651
Loss Generator P: 0.649586
Gradient discriminator: 3.474463
Gradient professor: -2.722613
Loss Generator D: 1.419789
Loss Generator P: 0.612196
Gradient discriminator: 11.234646
Gradient professor: -13.640681
Loss Generator D: 2.061024
Loss Generator P: 0.682902
Generator    : Epoch:      7, update:    1660, cost:   0.682902
Gradient discriminator: 19.919283
Gradient professor: -1.196820
Loss Generator D: 2.225914
Loss Generator P: 0.783177
Gradient discriminator: 9.562033
Gradient professor: 10.027107
Loss Generator D: 2.322922
Loss Generator P: 0.950393
Gradient discriminator: 18.475923
Gradient professor: 10.887031
Loss Generator D: 2.520889
Loss Generator P: 0.947682
Gradient discriminator: 23.175389
Gradient professor: -11.439705
Loss Generator D: 2.722921
Loss Generator P: 0.937576
Gradient discriminator: 13.368231
Gradient professor: 7.349619
Loss Generator D: 1.960778
Loss Generator P: 0.957145
Gradient discriminator: -8.335451
Gradient professor: 2.421014
Loss Generator D: 1.868022
Loss Generator P: 0.903385
Gradient discriminator: -11.562009
Gradient professor: -14.121936
Loss Generator D: 2.573914
Loss Generator P: 0.914190
Gradient discriminator: -1.990628
Gradient professor: -2.542060
Loss Generator D: 2.696117
Loss Generator P: 0.675912
Gradient discriminator: 3.465128
Gradient professor: 6.835853
Loss Generator D: 2.339813
Loss Generator P: 0.859797
Gradient discriminator: -6.686396
Gradient professor: -12.526835
Loss Generator D: 2.668604
Loss Generator P: 0.880223
Generator    : Epoch:      7, update:    1670, cost:   0.880223
Gradient discriminator: 1.693617
Gradient professor: -14.256648
Loss Generator D: 2.597331
Loss Generator P: 0.715013
Gradient discriminator: 2.623912
Gradient professor: -1.266471
Loss Generator D: 2.131494
Loss Generator P: 0.661256
Gradient discriminator: 4.120165
Gradient professor: 6.474566
Loss Generator D: 2.388876
Loss Generator P: 0.761746
Gradient discriminator: -14.634932
Gradient professor: -13.619690
Loss Generator D: 2.469682
Loss Generator P: 0.550943
Gradient discriminator: -0.602825
Gradient professor: -14.905457
Loss Generator D: 2.732057
Loss Generator P: 0.685880
Gradient discriminator: 7.051094
Gradient professor: -16.825989
Loss Generator D: 2.452859
Loss Generator P: 0.728914
Gradient discriminator: 0.841400
Gradient professor: 8.018122
Loss Generator D: 2.202885
Loss Generator P: 0.914448
Gradient discriminator: 4.114935
Gradient professor: -6.190911
Loss Generator D: 1.993940
Loss Generator P: 0.981845
Gradient discriminator: 13.550019
Gradient professor: 14.223537
Loss Generator D: 2.447678
Loss Generator P: 0.924034
Gradient discriminator: 20.379756
Gradient professor: -6.123243
Loss Generator D: 2.471404
Loss Generator P: 0.660715
Generator    : Epoch:      7, update:    1680, cost:   0.660715
Gradient discriminator: 26.763377
Gradient professor: 4.434347
Loss Generator D: 2.372839
Loss Generator P: 0.738619
Gradient discriminator: -5.195592
Gradient professor: -4.115915
Loss Generator D: 2.149067
Loss Generator P: 0.843541
Gradient discriminator: -16.366392
Gradient professor: 0.030932
Loss Generator D: 2.337173
Loss Generator P: 0.762253
Gradient discriminator: -5.255635
Gradient professor: -11.578816
Loss Generator D: 2.220005
Loss Generator P: 1.004840
Gradient discriminator: 10.016056
Gradient professor: -12.733031
Loss Generator D: 2.425471
Loss Generator P: 0.955073
Gradient discriminator: 32.942580
Gradient professor: 2.690578
Loss Generator D: 2.528871
Loss Generator P: 0.786127
Gradient discriminator: 4.659109
Gradient professor: -9.725896
Loss Generator D: 2.026789
Loss Generator P: 0.885171
Gradient discriminator: -4.727015
Gradient professor: 4.520425
Loss Generator D: 2.115727
Loss Generator P: 0.969315
Gradient discriminator: 11.699473
Gradient professor: 8.503114
Loss Generator D: 2.696719
Loss Generator P: 0.978530
Gradient discriminator: -5.210008
Gradient professor: -28.931399
Loss Generator D: 2.117891
Loss Generator P: 0.810925
Generator    : Epoch:      7, update:    1690, cost:   0.810925
Gradient discriminator: 10.510531
Gradient professor: 22.456213
Loss Generator D: 2.414143
Loss Generator P: 0.941557
Gradient discriminator: 9.092480
Gradient professor: -11.431449
Loss Generator D: 2.438356
Loss Generator P: 0.817505
Gradient discriminator: -19.768448
Gradient professor: -8.440471
Loss Generator D: 2.212907
Loss Generator P: 1.154641
Gradient discriminator: 9.016287
Gradient professor: 27.909361
Loss Generator D: 2.056311
Loss Generator P: 1.067749
Gradient discriminator: -1.250403
Gradient professor: -34.338184
Loss Generator D: 2.032318
Loss Generator P: 0.703674
Gradient discriminator: 5.789984
Gradient professor: -9.018159
Loss Generator D: 2.333869
Loss Generator P: 0.905420
Gradient discriminator: 18.615017
Gradient professor: -1.379392
Loss Generator D: 2.171768
Loss Generator P: 0.827202
Gradient discriminator: -7.732854
Gradient professor: -24.719663
Loss Generator D: 1.833126
Loss Generator P: 0.968207
Gradient discriminator: -4.158330
Gradient professor: -15.536742
Loss Generator D: 1.978510
Loss Generator P: 0.922636
Gradient discriminator: 21.213603
Gradient professor: -0.669600
Loss Generator D: 2.065651
Loss Generator P: 0.728274
Generator    : Epoch:      7, update:    1700, cost:   0.728274
Validation 17 - LOSS = 1.605 (PPL: 4.978)
Calling beam-search process
Beam-search ended, took 2.61668 minutes.
Validation 17 - BLEU = 6.42, 12.3/7.7/5.2/3.4 (BP=1.000, ratio=4.762, hyp_len=20097, ref_len=4220)
Early stopping patience: 999 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.605 (PPL: 4.978) at validation 17
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 12.985534
Gradient professor: -3.954528
Loss Generator D: 2.111490
Loss Generator P: 0.856899
Gradient discriminator: -4.643338
Gradient professor: -16.977600
Loss Generator D: 1.800312
Loss Generator P: 0.805651
Gradient discriminator: 15.075876
Gradient professor: 19.805296
Loss Generator D: 1.847440
Loss Generator P: 0.827033
Gradient discriminator: 7.409529
Gradient professor: -31.395926
Loss Generator D: 2.593192
Loss Generator P: 0.778583
Gradient discriminator: -6.507826
Gradient professor: 2.058057
Loss Generator D: 2.423328
Loss Generator P: 0.651383
Gradient discriminator: 15.889741
Gradient professor: -21.782012
Loss Generator D: 2.661251
Loss Generator P: 0.680344
Gradient discriminator: -3.179971
Gradient professor: -1.230463
Loss Generator D: 3.034252
Loss Generator P: 0.870094
Gradient discriminator: 10.856155
Gradient professor: 11.209558
Loss Generator D: 2.631950
Loss Generator P: 0.905459
Gradient discriminator: -10.854643
Gradient professor: 46.716080
Loss Generator D: 2.137411
Loss Generator P: 0.771557
Gradient discriminator: 4.224177
Gradient professor: -48.501016
Loss Generator D: 2.838949
Loss Generator P: 0.909032
Generator    : Epoch:      7, update:    1710, cost:   0.909032
Gradient discriminator: 17.027268
Gradient professor: -4.899490
Loss Generator D: 2.465003
Loss Generator P: 0.905955
Gradient discriminator: 8.350119
Gradient professor: 26.196177
Loss Generator D: 2.190393
Loss Generator P: 0.909177
Gradient discriminator: 0.753043
Gradient professor: 0.681839
Loss Generator D: 2.952019
Loss Generator P: 0.864251
Gradient discriminator: -21.384247
Gradient professor: 6.338666
Loss Generator D: 1.953752
Loss Generator P: 0.737954
Gradient discriminator: 18.005155
Gradient professor: -9.877954
Loss Generator D: 2.786292
Loss Generator P: 0.855385
Gradient discriminator: -2.902833
Gradient professor: 4.641445
Loss Generator D: 2.076075
Loss Generator P: 0.850052
Gradient discriminator: 15.557690
Gradient professor: 15.198831
Loss Generator D: 2.060460
Loss Generator P: 0.793619
Gradient discriminator: 6.233674
Gradient professor: -20.298922
Loss Generator D: 1.738663
Loss Generator P: 0.694958
Gradient discriminator: -9.827309
Gradient professor: 8.011065
Loss Generator D: 2.136809
Loss Generator P: 0.668086
Gradient discriminator: 18.477056
Gradient professor: -9.826305
Loss Generator D: 1.800200
Loss Generator P: 0.738955
Generator    : Epoch:      7, update:    1720, cost:   0.738955
Gradient discriminator: 0.038074
Gradient professor: -18.411076
Loss Generator D: 2.214601
Loss Generator P: 0.826598
Gradient discriminator: -8.249977
Gradient professor: -17.748721
Loss Generator D: 1.842281
Loss Generator P: 0.805546
Gradient discriminator: 7.405808
Gradient professor: -17.484627
Loss Generator D: 2.037551
Loss Generator P: 0.825563
Gradient discriminator: 7.914415
Gradient professor: -4.787865
Loss Generator D: 1.755853
Loss Generator P: 0.687608
Gradient discriminator: -1.827271
Gradient professor: 13.952232
Loss Generator D: 2.321185
Loss Generator P: 0.700675
Gradient discriminator: -4.915692
Gradient professor: -11.795464
Loss Generator D: 1.826794
Loss Generator P: 0.750530
Gradient discriminator: 17.279041
Gradient professor: 9.732068
Loss Generator D: 2.168903
Loss Generator P: 0.741457
Gradient discriminator: -3.310577
Gradient professor: 17.862084
Loss Generator D: 2.548962
Loss Generator P: 0.691096
Gradient discriminator: -10.033156
Gradient professor: -19.632346
Loss Generator D: 2.528137
Loss Generator P: 0.743767
Gradient discriminator: -4.397212
Gradient professor: -18.482020
Loss Generator D: 2.302518
Loss Generator P: 0.783926
Generator    : Epoch:      7, update:    1730, cost:   0.783926
Gradient discriminator: 15.911876
Gradient professor: -0.802009
Loss Generator D: 2.358284
Loss Generator P: 0.916349
Gradient discriminator: 10.965345
Gradient professor: -1.979455
Loss Generator D: 2.285165
Loss Generator P: 0.846620
Gradient discriminator: 27.550518
Gradient professor: -2.778606
Loss Generator D: 2.302125
Loss Generator P: 0.928649
Gradient discriminator: -15.160788
Gradient professor: 23.182637
Loss Generator D: 2.255175
Loss Generator P: 0.568226
Gradient discriminator: -11.829519
Gradient professor: -19.360258
Loss Generator D: 2.177312
Loss Generator P: 0.666670
Gradient discriminator: 13.300074
Gradient professor: -3.418315
Loss Generator D: 2.165514
Loss Generator P: 0.765793
Gradient discriminator: -0.383780
Gradient professor: 4.211680
Loss Generator D: 2.918261
Loss Generator P: 0.632459
Gradient discriminator: 2.833690
Gradient professor: -19.061286
Loss Generator D: 2.177167
Loss Generator P: 0.792385
Gradient discriminator: -36.164037
Gradient professor: 2.428547
Loss Generator D: 2.084785
Loss Generator P: 0.740726
Gradient discriminator: 39.130830
Gradient professor: -2.148290
Loss Generator D: 2.536055
Loss Generator P: 0.763308
Generator    : Epoch:      7, update:    1740, cost:   0.763308
Gradient discriminator: 9.277732
Gradient professor: -6.612551
Loss Generator D: 1.794515
Loss Generator P: 0.747458
Gradient discriminator: -36.310482
Gradient professor: 3.503482
Loss Generator D: 1.810122
Loss Generator P: 0.709027
Gradient discriminator: -5.513940
Gradient professor: 5.446539
Loss Generator D: 2.076595
Loss Generator P: 0.676623
Gradient discriminator: -6.312405
Gradient professor: -26.572249
Loss Generator D: 1.989553
Loss Generator P: 0.724958
Gradient discriminator: 1.217428
Gradient professor: 39.240062
Loss Generator D: 2.354246
Loss Generator P: 0.807803
Gradient discriminator: 22.045937
Gradient professor: -12.766840
Loss Generator D: 2.121995
Loss Generator P: 0.683439
Gradient discriminator: 14.272262
Gradient professor: -8.757828
Loss Generator D: 2.076292
Loss Generator P: 0.722696
Gradient discriminator: 1.955640
Gradient professor: 6.402472
Loss Generator D: 2.409906
Loss Generator P: 0.693164
Gradient discriminator: 13.356717
Gradient professor: -0.117099
Loss Generator D: 1.863756
Loss Generator P: 0.759034
Gradient discriminator: 7.641104
Gradient professor: 5.242641
Loss Generator D: 1.959127
Loss Generator P: 0.584034
Generator    : Epoch:      7, update:    1750, cost:   0.584034
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 7 finished with mean loss 1.45673 (PPL: 4.29189)
--> Epoch took 392.100 minutes, 94.104 sec/update
Epoch summary of Discriminator:
--> Epoch 7 finished with mean loss nan (PPL:  nan)
--> Epoch took 392.100 minutes, 94.104 sec/update
---------------------------------------------------------
Starting Epoch 8
----------------
Gradient discriminator: -24.391128
Gradient professor: 18.013517
Loss Generator D: 1.809730
Loss Generator P: 0.925278
Gradient discriminator: 2.911854
Gradient professor: 4.481249
Loss Generator D: 1.801454
Loss Generator P: 0.796840
Gradient discriminator: 10.914448
Gradient professor: -3.869904
Loss Generator D: 2.222840
Loss Generator P: 0.774587
Gradient discriminator: 10.155762
Gradient professor: 7.987371
Loss Generator D: 2.138506
Loss Generator P: 0.929009
Gradient discriminator: -2.011605
Gradient professor: -3.414702
Loss Generator D: 2.017900
Loss Generator P: 0.707384
Gradient discriminator: 3.631153
Gradient professor: -1.249641
Loss Generator D: 2.244858
Loss Generator P: 0.778753
Gradient discriminator: 7.376147
Gradient professor: 9.487530
Loss Generator D: 2.461326
Loss Generator P: 0.878734
Gradient discriminator: 5.347708
Gradient professor: 18.030468
Loss Generator D: 2.374818
Loss Generator P: 0.747345
Gradient discriminator: 47.068230
Gradient professor: -8.246808
Loss Generator D: 2.502968
Loss Generator P: 0.937875
Gradient discriminator: 10.785416
Gradient professor: -21.569648
Loss Generator D: 2.412022
Loss Generator P: 1.029298
Generator    : Epoch:      8, update:    1760, cost:   1.029298
Gradient discriminator: 20.875719
Gradient professor: 19.034881
Loss Generator D: 2.753428
Loss Generator P: 1.066107
Gradient discriminator: -17.914253
Gradient professor: -3.708277
Loss Generator D: 2.368582
Loss Generator P: 0.799210
Gradient discriminator: -6.307304
Gradient professor: -0.613198
Loss Generator D: 2.819975
Loss Generator P: 0.989146
Gradient discriminator: 18.008881
Gradient professor: -17.891399
Loss Generator D: 2.562863
Loss Generator P: 0.881722
Gradient discriminator: -9.586544
Gradient professor: 15.533764
Loss Generator D: 2.081545
Loss Generator P: 0.629002
Gradient discriminator: -3.567243
Gradient professor: -12.640366
Loss Generator D: 2.555548
Loss Generator P: 0.531610
Gradient discriminator: -1.244936
Gradient professor: -6.421535
Loss Generator D: 2.892226
Loss Generator P: 0.792611
Gradient discriminator: 8.752057
Gradient professor: -2.716617
Loss Generator D: 3.043829
Loss Generator P: 0.748938
Gradient discriminator: -18.925633
Gradient professor: -5.033319
Loss Generator D: 2.845206
Loss Generator P: 0.809066
Gradient discriminator: 6.904168
Gradient professor: 27.407268
Loss Generator D: 2.549513
Loss Generator P: 0.913960
Generator    : Epoch:      8, update:    1770, cost:   0.913960
Gradient discriminator: 10.734882
Gradient professor: -12.480618
Loss Generator D: 2.586983
Loss Generator P: 0.771272
Gradient discriminator: 6.194024
Gradient professor: 8.534610
Loss Generator D: 2.594478
Loss Generator P: 0.748270
Gradient discriminator: 10.699507
Gradient professor: -12.206744
Loss Generator D: 2.493565
Loss Generator P: 0.740033
Gradient discriminator: -5.257031
Gradient professor: -26.469544
Loss Generator D: 2.447012
Loss Generator P: 1.014364
Gradient discriminator: 19.195992
Gradient professor: -24.431113
Loss Generator D: 2.902602
Loss Generator P: 0.894749
Gradient discriminator: -13.728567
Gradient professor: 15.828418
Loss Generator D: 2.458069
Loss Generator P: 0.858516
Gradient discriminator: 2.283383
Gradient professor: -11.063087
Loss Generator D: 2.446824
Loss Generator P: 0.662684
Gradient discriminator: 9.488501
Gradient professor: 13.947610
Loss Generator D: 2.544937
Loss Generator P: 0.741296
Gradient discriminator: -13.098410
Gradient professor: -21.076891
Loss Generator D: 2.850996
Loss Generator P: 0.683254
Gradient discriminator: -7.747183
Gradient professor: 15.274901
Loss Generator D: 2.385518
Loss Generator P: 0.783590
Generator    : Epoch:      8, update:    1780, cost:   0.783590
Gradient discriminator: -4.745007
Gradient professor: -8.141863
Loss Generator D: 2.920187
Loss Generator P: 0.740196
Gradient discriminator: 2.988297
Gradient professor: 0.845517
Loss Generator D: 2.724499
Loss Generator P: 0.648356
Gradient discriminator: 7.781370
Gradient professor: -0.445415
Loss Generator D: 3.123131
Loss Generator P: 0.932199
Gradient discriminator: 0.621887
Gradient professor: -0.586523
Loss Generator D: 2.684434
Loss Generator P: 0.951568
Gradient discriminator: 1.214388
Gradient professor: -20.359310
Loss Generator D: 3.026536
Loss Generator P: 0.723601
Gradient discriminator: 2.506587
Gradient professor: 17.001588
Loss Generator D: 3.120627
Loss Generator P: 0.705162
Gradient discriminator: -8.733790
Gradient professor: -1.336643
Loss Generator D: 2.721858
Loss Generator P: 0.627406
Gradient discriminator: 0.209184
Gradient professor: -4.230515
Loss Generator D: 2.520683
Loss Generator P: 0.725990
Gradient discriminator: -0.518236
Gradient professor: 14.368341
Loss Generator D: 2.386315
Loss Generator P: 0.748519
Gradient discriminator: -2.081899
Gradient professor: -1.436023
Loss Generator D: 2.615505
Loss Generator P: 0.937033
Generator    : Epoch:      8, update:    1790, cost:   0.937033
Gradient discriminator: -9.039116
Gradient professor: 5.269104
Loss Generator D: 2.572054
Loss Generator P: 0.777707
Gradient discriminator: 0.137190
Gradient professor: -16.100975
Loss Generator D: 2.871439
Loss Generator P: 0.685432
Gradient discriminator: 11.995234
Gradient professor: -6.968098
Loss Generator D: 2.917625
Loss Generator P: 0.780345
Gradient discriminator: 16.474170
Gradient professor: 5.097569
Loss Generator D: 2.772489
Loss Generator P: 0.732206
Gradient discriminator: 1.910295
Gradient professor: 6.554140
Loss Generator D: 3.613029
Loss Generator P: 0.906930
Gradient discriminator: 1.491461
Gradient professor: 30.791102
Loss Generator D: 2.727780
Loss Generator P: 0.836644
Gradient discriminator: -3.136755
Gradient professor: 12.722106
Loss Generator D: 3.476980
Loss Generator P: 0.705404
Gradient discriminator: -11.686602
Gradient professor: 13.059089
Loss Generator D: 3.037029
Loss Generator P: 0.832935
Gradient discriminator: -15.963923
Gradient professor: -39.371596
Loss Generator D: 3.945025
Loss Generator P: 1.081492
Gradient discriminator: -54.194426
Gradient professor: 37.189028
Loss Generator D: 2.372235
Loss Generator P: 0.760869
Generator    : Epoch:      8, update:    1800, cost:   0.760869
Validation 18 - LOSS = 1.627 (PPL: 5.087)
Calling beam-search process
Beam-search ended, took 1.99587 minutes.
Validation 18 - BLEU = 10.39, 19.5/12.3/8.5/5.7 (BP=1.000, ratio=3.171, hyp_len=13380, ref_len=4220)
Early stopping patience: 998 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.605 (PPL: 4.978) at validation 17
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 54.928787
Gradient professor: 14.441966
Loss Generator D: 2.333310
Loss Generator P: 0.865082
Gradient discriminator: -36.129266
Gradient professor: -9.226238
Loss Generator D: 2.017340
Loss Generator P: 0.812195
Gradient discriminator: 11.033613
Gradient professor: 12.434162
Loss Generator D: 1.873598
Loss Generator P: 0.759371
Gradient discriminator: -80.271795
Gradient professor: -6.591848
Loss Generator D: 2.192225
Loss Generator P: 0.880203
Gradient discriminator: 10.694634
Gradient professor: -35.514921
Loss Generator D: 1.674424
Loss Generator P: 0.816462
Gradient discriminator: 9.968354
Gradient professor: -4.024189
Loss Generator D: 1.821492
Loss Generator P: 0.686364
Gradient discriminator: 4.943987
Gradient professor: 22.949011
Loss Generator D: 2.008148
Loss Generator P: 0.695909
Gradient discriminator: 21.264417
Gradient professor: -3.661213
Loss Generator D: 2.521670
Loss Generator P: 0.654335
Gradient discriminator: -7.146892
Gradient professor: 11.752514
Loss Generator D: 2.065301
Loss Generator P: 0.740584
Gradient discriminator: 16.557525
Gradient professor: -6.648145
Loss Generator D: 1.593950
Loss Generator P: 0.804038
Generator    : Epoch:      8, update:    1810, cost:   0.804038
Gradient discriminator: 0.596458
Gradient professor: 14.525292
Loss Generator D: 1.422550
Loss Generator P: 0.750570
Gradient discriminator: 3.668716
Gradient professor: 13.503424
Loss Generator D: 1.190516
Loss Generator P: 0.960850
Gradient discriminator: 14.160667
Gradient professor: -4.272465
Loss Generator D: 1.510212
Loss Generator P: 0.804976
Gradient discriminator: 4.983155
Gradient professor: 26.440090
Loss Generator D: 1.757379
Loss Generator P: 0.705495
Gradient discriminator: 22.230246
Gradient professor: -13.163634
Loss Generator D: 1.746435
Loss Generator P: 0.852732
Gradient discriminator: 0.242385
Gradient professor: -8.024451
Loss Generator D: 1.766600
Loss Generator P: 0.808628
Gradient discriminator: 5.909020
Gradient professor: 8.576092
Loss Generator D: 1.910033
Loss Generator P: 0.749203
Gradient discriminator: -12.159775
Gradient professor: 19.251043
Loss Generator D: 2.276128
Loss Generator P: 0.756521
Gradient discriminator: 21.054435
Gradient professor: -27.981262
Loss Generator D: 2.507116
Loss Generator P: 0.903775
Gradient discriminator: 20.497616
Gradient professor: -3.370608
Loss Generator D: 2.055090
Loss Generator P: 0.840940
Discriminator: Epoch:      8, update:    1820, cost:   0.404384
Generator    : Epoch:      8, update:    1820, cost:   0.840940
Gradient discriminator: -3.267832
Gradient professor: -0.213031
Loss Generator D: 2.366207
Loss Generator P: 0.596108
Gradient discriminator: -2.081457
Gradient professor: -2.588336
Loss Generator D: 1.884176
Loss Generator P: 0.588689
Gradient discriminator: 0.116950
Gradient professor: -2.080643
Loss Generator D: 1.639414
Loss Generator P: 0.782771
Gradient discriminator: -0.163231
Gradient professor: -13.650566
Loss Generator D: 2.028435
Loss Generator P: 0.848595
Gradient discriminator: -0.194769
Gradient professor: -0.760833
Loss Generator D: 1.958631
Loss Generator P: 0.783686
Gradient discriminator: -9.367404
Gradient professor: 2.059954
Loss Generator D: 1.861157
Loss Generator P: 0.711964
Gradient discriminator: 3.207266
Gradient professor: -19.834648
Loss Generator D: 2.670297
Loss Generator P: 0.759003
Gradient discriminator: -3.483920
Gradient professor: 13.924187
Loss Generator D: 2.227324
Loss Generator P: 0.890614
Gradient discriminator: -4.432416
Gradient professor: 6.342617
Loss Generator D: 2.028158
Loss Generator P: 0.533090
Gradient discriminator: -1.756755
Gradient professor: -2.404442
Loss Generator D: 2.149840
Loss Generator P: 0.555605
Generator    : Epoch:      8, update:    1830, cost:   0.555605
Gradient discriminator: 12.004663
Gradient professor: 11.080401
Loss Generator D: 2.846013
Loss Generator P: 0.598690
Gradient discriminator: -8.360022
Gradient professor: 15.928478
Loss Generator D: 3.072007
Loss Generator P: 0.627007
Gradient discriminator: 8.987803
Gradient professor: -12.627010
Loss Generator D: 2.749883
Loss Generator P: 0.660185
Gradient discriminator: 2.514465
Gradient professor: -2.364653
Loss Generator D: 2.437117
Loss Generator P: 0.501672
Gradient discriminator: -0.583638
Gradient professor: -11.211395
Loss Generator D: 3.154180
Loss Generator P: 0.555398
Gradient discriminator: 4.241552
Gradient professor: -2.194762
Loss Generator D: 2.354645
Loss Generator P: 0.549728
Gradient discriminator: 1.560632
Gradient professor: -16.810197
Loss Generator D: 2.838431
Loss Generator P: 0.619304
Gradient discriminator: 12.534718
Gradient professor: 24.884793
Loss Generator D: 2.550356
Loss Generator P: 0.846966
Gradient discriminator: -4.095719
Gradient professor: -19.379632
Loss Generator D: 2.604735
Loss Generator P: 0.642420
Gradient discriminator: -9.492570
Gradient professor: 4.000762
Loss Generator D: 2.693907
Loss Generator P: 0.804010
Generator    : Epoch:      8, update:    1840, cost:   0.804010
Gradient discriminator: 11.041295
Gradient professor: 16.265789
Loss Generator D: 2.544622
Loss Generator P: 0.620825
Gradient discriminator: 2.366836
Gradient professor: 12.645425
Loss Generator D: 2.257617
Loss Generator P: 0.969271
Gradient discriminator: -2.892987
Gradient professor: -17.812805
Loss Generator D: 2.371496
Loss Generator P: 0.661042
Gradient discriminator: 4.218793
Gradient professor: 0.830268
Loss Generator D: 2.417538
Loss Generator P: 0.556337
Gradient discriminator: -9.317630
Gradient professor: -14.238899
Loss Generator D: 2.632266
Loss Generator P: 0.684116
Gradient discriminator: -5.418794
Gradient professor: -1.026004
Loss Generator D: 2.750640
Loss Generator P: 0.683470
Gradient discriminator: -5.743945
Gradient professor: -22.228418
Loss Generator D: 2.610987
Loss Generator P: 0.648726
Gradient discriminator: 1.852425
Gradient professor: -10.287926
Loss Generator D: 2.426707
Loss Generator P: 0.630508
Gradient discriminator: -0.303327
Gradient professor: -1.521103
Loss Generator D: 3.088742
Loss Generator P: 0.657685
Gradient discriminator: -7.376269
Gradient professor: -4.288961
Loss Generator D: 2.959294
Loss Generator P: 0.734528
Generator    : Epoch:      8, update:    1850, cost:   0.734528
Gradient discriminator: 6.932903
Gradient professor: 6.614040
Loss Generator D: 2.913265
Loss Generator P: 0.834939
Gradient discriminator: 15.900598
Gradient professor: -22.883982
Loss Generator D: 2.075074
Loss Generator P: 0.804363
Gradient discriminator: 8.245484
Gradient professor: -19.201233
Loss Generator D: 2.793334
Loss Generator P: 0.611239
Gradient discriminator: 12.518180
Gradient professor: 1.636566
Loss Generator D: 2.038319
Loss Generator P: 0.747012
Gradient discriminator: -13.505661
Gradient professor: 10.503554
Loss Generator D: 2.162415
Loss Generator P: 0.551763
Gradient discriminator: 8.581581
Gradient professor: 2.378206
Loss Generator D: 2.593665
Loss Generator P: 0.769692
Gradient discriminator: 0.025466
Gradient professor: -29.655418
Loss Generator D: 2.628042
Loss Generator P: 0.653638
Gradient discriminator: -12.528904
Gradient professor: -0.358730
Loss Generator D: 2.733481
Loss Generator P: 0.636491
Gradient discriminator: -7.738187
Gradient professor: 0.359440
Loss Generator D: 2.468508
Loss Generator P: 0.705442
Gradient discriminator: -1.741979
Gradient professor: 1.245193
Loss Generator D: 1.910189
Loss Generator P: 0.658195
Generator    : Epoch:      8, update:    1860, cost:   0.658195
Gradient discriminator: -6.143009
Gradient professor: 0.720803
Loss Generator D: 2.741012
Loss Generator P: 0.777817
Gradient discriminator: 7.302667
Gradient professor: 20.546044
Loss Generator D: 2.141954
Loss Generator P: 0.729066
Gradient discriminator: 3.730178
Gradient professor: -6.502673
Loss Generator D: 3.066985
Loss Generator P: 0.621253
Gradient discriminator: -7.614878
Gradient professor: -15.586255
Loss Generator D: 2.298865
Loss Generator P: 0.549790
Gradient discriminator: 7.549955
Gradient professor: -1.139886
Loss Generator D: 2.928714
Loss Generator P: 0.811156
Gradient discriminator: 2.412755
Gradient professor: -12.243512
Loss Generator D: 2.374228
Loss Generator P: 0.840637
Gradient discriminator: -5.453139
Gradient professor: 10.752148
Loss Generator D: 2.682225
Loss Generator P: 0.597346
Gradient discriminator: 8.531774
Gradient professor: 6.840644
Loss Generator D: 2.487687
Loss Generator P: 0.890911
Gradient discriminator: 1.574131
Gradient professor: -5.599772
Loss Generator D: 2.300261
Loss Generator P: 0.702469
Gradient discriminator: 3.341828
Gradient professor: 16.429290
Loss Generator D: 1.493014
Loss Generator P: 0.730914
Generator    : Epoch:      8, update:    1870, cost:   0.730914
Gradient discriminator: -4.498557
Gradient professor: -8.946187
Loss Generator D: 1.888910
Loss Generator P: 0.750148
Gradient discriminator: 0.642613
Gradient professor: 6.133449
Loss Generator D: 1.669074
Loss Generator P: 0.705062
Gradient discriminator: 4.987911
Gradient professor: 0.972515
Loss Generator D: 1.619273
Loss Generator P: 0.793654
Gradient discriminator: -6.687926
Gradient professor: 20.697794
Loss Generator D: 1.837645
Loss Generator P: 0.827494
Gradient discriminator: 0.320372
Gradient professor: -5.585957
Loss Generator D: 1.970232
Loss Generator P: 0.820789
Gradient discriminator: 9.102074
Gradient professor: 25.579308
Loss Generator D: 1.938803
Loss Generator P: 0.771766
Gradient discriminator: 3.809396
Gradient professor: -12.620069
Loss Generator D: 2.547527
Loss Generator P: 0.726004
Gradient discriminator: 6.012053
Gradient professor: 19.630984
Loss Generator D: 3.237767
Loss Generator P: 0.883395
Gradient discriminator: -2.233235
Gradient professor: 3.621725
Loss Generator D: 2.304390
Loss Generator P: 0.795083
Gradient discriminator: 2.348816
Gradient professor: -72.669454
Loss Generator D: 2.743977
Loss Generator P: 0.800877
Generator    : Epoch:      8, update:    1880, cost:   0.800877
Gradient discriminator: -1.752748
Gradient professor: -10.523147
Loss Generator D: 2.466590
Loss Generator P: 0.684582
Gradient discriminator: -1.510389
Gradient professor: -16.927294
Loss Generator D: 2.583683
Loss Generator P: 0.681874
Gradient discriminator: -2.436261
Gradient professor: 28.100247
Loss Generator D: 1.966703
Loss Generator P: 0.597520
Gradient discriminator: 5.891892
Gradient professor: -21.856542
Loss Generator D: 2.453763
Loss Generator P: 0.837519
Gradient discriminator: 13.109934
Gradient professor: -7.444255
Loss Generator D: 2.094892
Loss Generator P: 0.761716
Gradient discriminator: 6.354211
Gradient professor: 3.071849
Loss Generator D: 2.569996
Loss Generator P: 0.512511
Gradient discriminator: 2.371584
Gradient professor: 0.210967
Loss Generator D: 2.408160
Loss Generator P: 0.741692
Gradient discriminator: 0.547429
Gradient professor: 12.874105
Loss Generator D: 3.092097
Loss Generator P: 0.531767
Gradient discriminator: -7.169091
Gradient professor: -8.265745
Loss Generator D: 2.647393
Loss Generator P: 0.851767
Gradient discriminator: 3.509042
Gradient professor: -9.295898
Loss Generator D: 2.670050
Loss Generator P: 0.741349
Generator    : Epoch:      8, update:    1890, cost:   0.741349
Gradient discriminator: -9.458591
Gradient professor: 0.671445
Loss Generator D: 2.344658
Loss Generator P: 0.651704
Gradient discriminator: 7.043757
Gradient professor: 3.677944
Loss Generator D: 2.927382
Loss Generator P: 0.847402
Gradient discriminator: 3.049903
Gradient professor: 15.272819
Loss Generator D: 2.954352
Loss Generator P: 0.907964
Gradient discriminator: -2.049557
Gradient professor: -19.368710
Loss Generator D: 3.113898
Loss Generator P: 0.805027
Gradient discriminator: 4.350093
Gradient professor: -21.218235
Loss Generator D: 2.866678
Loss Generator P: 0.904893
Gradient discriminator: 2.579496
Gradient professor: -10.223973
Loss Generator D: 2.942716
Loss Generator P: 0.961762
Gradient discriminator: 2.050789
Gradient professor: 17.029441
Loss Generator D: 2.877964
Loss Generator P: 0.565171
Gradient discriminator: -4.596381
Gradient professor: 24.179170
Loss Generator D: 2.985715
Loss Generator P: 0.619222
Gradient discriminator: 4.685891
Gradient professor: -5.784346
Loss Generator D: 2.866714
Loss Generator P: 0.648876
Gradient discriminator: 8.466705
Gradient professor: -13.491507
Loss Generator D: 3.092474
Loss Generator P: 0.591295
Generator    : Epoch:      8, update:    1900, cost:   0.591295
Validation 19 - LOSS = 1.660 (PPL: 5.258)
Calling beam-search process
Beam-search ended, took 1.71989 minutes.
Validation 19 - BLEU = 12.48, 23.3/14.8/10.2/7.0 (BP=1.000, ratio=2.601, hyp_len=10977, ref_len=4220)
Early stopping patience: 997 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.605 (PPL: 4.978) at validation 17
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -0.272561
Gradient professor: 25.178905
Loss Generator D: 2.978027
Loss Generator P: 0.877184
Gradient discriminator: 8.122459
Gradient professor: 25.368043
Loss Generator D: 2.813015
Loss Generator P: 0.791900
Gradient discriminator: 3.146455
Gradient professor: 0.338197
Loss Generator D: 2.688418
Loss Generator P: 0.801347
Gradient discriminator: -3.841510
Gradient professor: 5.751177
Loss Generator D: 2.569175
Loss Generator P: 0.679727
Gradient discriminator: 4.211273
Gradient professor: 5.401325
Loss Generator D: 2.787531
Loss Generator P: 0.825311
Gradient discriminator: 0.744482
Gradient professor: -6.909897
Loss Generator D: 2.498055
Loss Generator P: 0.668939
Gradient discriminator: 10.815793
Gradient professor: -14.173335
Loss Generator D: 2.718801
Loss Generator P: 0.779936
Gradient discriminator: 23.093065
Gradient professor: -6.375638
Loss Generator D: 2.196141
Loss Generator P: 0.584461
Gradient discriminator: 2.397588
Gradient professor: 29.875262
Loss Generator D: 2.669368
Loss Generator P: 0.581484
Gradient discriminator: 0.182185
Gradient professor: 12.064596
Loss Generator D: 2.728051
Loss Generator P: 0.659081
Generator    : Epoch:      8, update:    1910, cost:   0.659081
Gradient discriminator: 6.778531
Gradient professor: 2.303636
Loss Generator D: 2.707734
Loss Generator P: 0.654056
Gradient discriminator: 0.195386
Gradient professor: -11.692953
Loss Generator D: 2.451231
Loss Generator P: 0.916878
Gradient discriminator: 4.796229
Gradient professor: 20.433645
Loss Generator D: 2.578889
Loss Generator P: 0.856288
Gradient discriminator: 9.690212
Gradient professor: 5.173874
Loss Generator D: 2.412678
Loss Generator P: 0.860010
Gradient discriminator: 1.517747
Gradient professor: 13.684440
Loss Generator D: 2.709550
Loss Generator P: 0.949312
Gradient discriminator: 1.171212
Gradient professor: 12.401229
Loss Generator D: 2.553380
Loss Generator P: 0.885485
Gradient discriminator: -0.438232
Gradient professor: 18.078075
Loss Generator D: 2.537607
Loss Generator P: 0.896269
Gradient discriminator: -5.794799
Gradient professor: -17.959613
Loss Generator D: 2.492015
Loss Generator P: 0.676242
Gradient discriminator: 3.292977
Gradient professor: 10.363852
Loss Generator D: 2.190956
Loss Generator P: 0.821093
Gradient discriminator: 24.282353
Gradient professor: -23.316200
Loss Generator D: 2.638728
Loss Generator P: 0.813046
Generator    : Epoch:      8, update:    1920, cost:   0.813046
Gradient discriminator: -2.812754
Gradient professor: 6.434327
Loss Generator D: 2.474629
Loss Generator P: 0.700180
Gradient discriminator: -1.563201
Gradient professor: 2.088810
Loss Generator D: 2.557708
Loss Generator P: 0.660808
Gradient discriminator: -10.716419
Gradient professor: 10.893781
Loss Generator D: 2.423179
Loss Generator P: 0.709893
Gradient discriminator: -2.645768
Gradient professor: -15.197228
Loss Generator D: 2.466249
Loss Generator P: 0.521088
Gradient discriminator: -0.011651
Gradient professor: -4.856302
Loss Generator D: 2.835537
Loss Generator P: 0.707584
Gradient discriminator: 11.042689
Gradient professor: -5.166992
Loss Generator D: 2.720747
Loss Generator P: 0.710543
Gradient discriminator: 8.914682
Gradient professor: -8.920289
Loss Generator D: 2.047372
Loss Generator P: 0.901139
Gradient discriminator: -3.373345
Gradient professor: 34.151782
Loss Generator D: 2.125855
Loss Generator P: 0.960031
Gradient discriminator: -0.862107
Gradient professor: -18.738072
Loss Generator D: 2.490503
Loss Generator P: 0.903986
Discriminator: Epoch:      8, update:    1929, cost:   0.244158
Gradient discriminator: -8.758017
Gradient professor: 18.275965
Loss Generator D: 2.627469
Loss Generator P: 0.696936
Generator    : Epoch:      8, update:    1930, cost:   0.696936
Gradient discriminator: 19.545685
Gradient professor: -4.302872
Loss Generator D: 2.841545
Loss Generator P: 0.736819
Gradient discriminator: 0.120626
Gradient professor: 13.961308
Loss Generator D: 2.400314
Loss Generator P: 0.788969
Gradient discriminator: 11.146998
Gradient professor: 15.513164
Loss Generator D: 2.514397
Loss Generator P: 0.787732
Gradient discriminator: 13.756534
Gradient professor: 8.265136
Loss Generator D: 2.343356
Loss Generator P: 0.951573
Gradient discriminator: 10.983710
Gradient professor: -3.516973
Loss Generator D: 2.506810
Loss Generator P: 0.863301
Gradient discriminator: 23.213292
Gradient professor: -7.398740
Loss Generator D: 2.160056
Loss Generator P: 0.712054
Gradient discriminator: -50.293596
Gradient professor: 24.571803
Loss Generator D: 2.105851
Loss Generator P: 0.755068
Gradient discriminator: -3.845089
Gradient professor: 15.979137
Loss Generator D: 2.474768
Loss Generator P: 0.876648
Gradient discriminator: 11.946666
Gradient professor: 14.803810
Loss Generator D: 2.131103
Loss Generator P: 0.876089
Gradient discriminator: 12.646703
Gradient professor: -14.793297
Loss Generator D: 2.154602
Loss Generator P: 0.770708
Generator    : Epoch:      8, update:    1940, cost:   0.770708
Gradient discriminator: 7.011513
Gradient professor: -1.708776
Loss Generator D: 2.523992
Loss Generator P: 0.933727
Gradient discriminator: 35.300138
Gradient professor: 7.384919
Loss Generator D: 2.425152
Loss Generator P: 0.703086
Gradient discriminator: 3.951733
Gradient professor: -15.109677
Loss Generator D: 2.169566
Loss Generator P: 1.100631
Gradient discriminator: -74.460906
Gradient professor: 20.230766
Loss Generator D: 1.789757
Loss Generator P: 0.986050
Gradient discriminator: -8.621801
Gradient professor: -5.501681
Loss Generator D: 2.335356
Loss Generator P: 0.655034
Gradient discriminator: 36.063154
Gradient professor: -12.341060
Loss Generator D: 1.961315
Loss Generator P: 0.834028
Gradient discriminator: 23.223015
Gradient professor: 21.873355
Loss Generator D: 1.706248
Loss Generator P: 0.844314
Gradient discriminator: 23.293216
Gradient professor: -18.385856
Loss Generator D: 1.632568
Loss Generator P: 0.925958
Gradient discriminator: 8.722456
Gradient professor: -7.038964
Loss Generator D: 1.568966
Loss Generator P: 0.893909
Gradient discriminator: -13.278805
Gradient professor: 2.393280
Loss Generator D: 2.167972
Loss Generator P: 0.687691
Generator    : Epoch:      8, update:    1950, cost:   0.687691
Gradient discriminator: -30.490846
Gradient professor: -4.655836
Loss Generator D: 2.301454
Loss Generator P: 0.732125
Gradient discriminator: 8.010440
Gradient professor: -18.143699
Loss Generator D: 2.512934
Loss Generator P: 0.750510
Gradient discriminator: -19.324906
Gradient professor: 18.530211
Loss Generator D: 2.348180
Loss Generator P: 0.690771
Gradient discriminator: 2.773447
Gradient professor: -20.134716
Loss Generator D: 2.562452
Loss Generator P: 0.713947
Gradient discriminator: -2.445961
Gradient professor: -8.821802
Loss Generator D: 2.458877
Loss Generator P: 0.618890
Gradient discriminator: -2.002467
Gradient professor: 4.119727
Loss Generator D: 2.206956
Loss Generator P: 0.591528
Gradient discriminator: 12.269005
Gradient professor: -13.454440
Loss Generator D: 2.980711
Loss Generator P: 0.827354
Gradient discriminator: 11.237972
Gradient professor: 8.510919
Loss Generator D: 2.453878
Loss Generator P: 0.864792
Gradient discriminator: -0.815367
Gradient professor: -15.702760
Loss Generator D: 2.155755
Loss Generator P: 0.731028
Gradient discriminator: 69.581090
Gradient professor: -28.326487
Loss Generator D: 2.508259
Loss Generator P: 0.792537
Generator    : Epoch:      8, update:    1960, cost:   0.792537
Gradient discriminator: 3.265064
Gradient professor: 7.602295
Loss Generator D: 2.449320
Loss Generator P: 0.909834
Gradient discriminator: 12.114810
Gradient professor: 5.230318
Loss Generator D: 2.509534
Loss Generator P: 0.943307
Gradient discriminator: 7.482870
Gradient professor: 21.590471
Loss Generator D: 2.433851
Loss Generator P: 0.799177
Gradient discriminator: -4.474899
Gradient professor: 1.384841
Loss Generator D: 2.238149
Loss Generator P: 0.624039
Gradient discriminator: 7.513281
Gradient professor: 5.093618
Loss Generator D: 2.754167
Loss Generator P: 0.822923
Gradient discriminator: 1.018745
Gradient professor: -10.629146
Loss Generator D: 2.873446
Loss Generator P: 0.790964
Gradient discriminator: 18.928740
Gradient professor: -28.792467
Loss Generator D: 2.692003
Loss Generator P: 0.826165
Gradient discriminator: 45.831201
Gradient professor: -1.116960
Loss Generator D: 2.417990
Loss Generator P: 0.703856
Gradient discriminator: 20.492461
Gradient professor: 11.834446
Loss Generator D: 2.691279
Loss Generator P: 0.687547
Gradient discriminator: 39.650402
Gradient professor: 2.899736
Loss Generator D: 2.078056
Loss Generator P: 0.705733
Generator    : Epoch:      8, update:    1970, cost:   0.705733
Gradient discriminator: 24.556369
Gradient professor: -24.964593
Loss Generator D: 2.414966
Loss Generator P: 0.770413
Gradient discriminator: -31.103845
Gradient professor: -17.133324
Loss Generator D: 2.434663
Loss Generator P: 0.773275
Gradient discriminator: -40.820756
Gradient professor: 2.986037
Loss Generator D: 2.374426
Loss Generator P: 0.783279
Gradient discriminator: 12.698904
Gradient professor: -5.558115
Loss Generator D: 2.293175
Loss Generator P: 0.703373
Gradient discriminator: -14.802176
Gradient professor: 3.254985
Loss Generator D: 2.208879
Loss Generator P: 0.670211
Gradient discriminator: -0.664741
Gradient professor: -11.361468
Loss Generator D: 2.581203
Loss Generator P: 0.711991
Gradient discriminator: 33.482634
Gradient professor: 34.459282
Loss Generator D: 2.766082
Loss Generator P: 0.693555
Gradient discriminator: -6.015262
Gradient professor: -16.115330
Loss Generator D: 2.753560
Loss Generator P: 0.686287
Gradient discriminator: -20.447460
Gradient professor: -15.565612
Loss Generator D: 2.934654
Loss Generator P: 0.729555
Gradient discriminator: -4.690137
Gradient professor: -23.464341
Loss Generator D: 3.018150
Loss Generator P: 0.766295
Generator    : Epoch:      8, update:    1980, cost:   0.766295
Gradient discriminator: -11.145061
Gradient professor: 4.815863
Loss Generator D: 2.814702
Loss Generator P: 0.845290
Gradient discriminator: -19.895029
Gradient professor: 0.450219
Loss Generator D: 2.810588
Loss Generator P: 0.828259
Gradient discriminator: 43.796146
Gradient professor: 49.870410
Loss Generator D: 2.774674
Loss Generator P: 0.875154
Gradient discriminator: -7.373987
Gradient professor: 7.016752
Loss Generator D: 2.441671
Loss Generator P: 0.520501
Gradient discriminator: 8.506022
Gradient professor: 12.679548
Loss Generator D: 2.498508
Loss Generator P: 0.678131
Gradient discriminator: 22.918717
Gradient professor: -8.458551
Loss Generator D: 2.628361
Loss Generator P: 0.665379
Gradient discriminator: 0.941581
Gradient professor: 6.736867
Loss Generator D: 2.590347
Loss Generator P: 0.613163
Gradient discriminator: 15.235393
Gradient professor: -8.154809
Loss Generator D: 2.519762
Loss Generator P: 0.728288
Gradient discriminator: 42.749226
Gradient professor: -11.768776
Loss Generator D: 2.191407
Loss Generator P: 0.723065
Gradient discriminator: 10.629488
Gradient professor: 25.125318
Loss Generator D: 2.306715
Loss Generator P: 0.678524
Generator    : Epoch:      8, update:    1990, cost:   0.678524
Gradient discriminator: 12.656049
Gradient professor: -14.632569
Loss Generator D: 1.927673
Loss Generator P: 0.693998
Gradient discriminator: -30.615669
Gradient professor: -0.032379
Loss Generator D: 2.192513
Loss Generator P: 0.664861
Gradient discriminator: -12.011234
Gradient professor: 6.143835
Loss Generator D: 2.606867
Loss Generator P: 0.592857
Gradient discriminator: 57.600374
Gradient professor: -7.324675
Loss Generator D: 2.158149
Loss Generator P: 0.735356
Gradient discriminator: 111.624859
Gradient professor: -72.381471
Loss Generator D: 2.681229
Loss Generator P: 0.843367
Gradient discriminator: 24.763402
Gradient professor: 9.240992
Loss Generator D: 2.306021
Loss Generator P: 0.724786
Gradient discriminator: -33.597169
Gradient professor: -17.619870
Loss Generator D: 2.382916
Loss Generator P: 0.688228
Gradient discriminator: 16.120014
Gradient professor: 3.573164
Loss Generator D: 2.365759
Loss Generator P: 0.635417
Gradient discriminator: 23.990475
Gradient professor: -17.317046
Loss Generator D: 2.098363
Loss Generator P: 0.756816
Gradient discriminator: -2.396133
Gradient professor: -5.762543
Loss Generator D: 2.004936
Loss Generator P: 0.472928
Generator    : Epoch:      8, update:    2000, cost:   0.472928
Validation 20 - LOSS = 1.615 (PPL: 5.028)
Calling beam-search process
Beam-search ended, took 1.87144 minutes.
Validation 20 - BLEU = 11.07, 20.4/13.0/9.1/6.2 (BP=1.000, ratio=2.991, hyp_len=12621, ref_len=4220)
Early stopping patience: 996 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.605 (PPL: 4.978) at validation 17
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 8 finished with mean loss 1.60555 (PPL: 4.98060)
--> Epoch took 365.917 minutes, 87.820 sec/update
Epoch summary of Discriminator:
--> Epoch 8 finished with mean loss 0.32427 (PPL: 1.38302)
--> Epoch took 365.917 minutes, 87.820 sec/update
---------------------------------------------------------
Starting Epoch 9
----------------
Gradient discriminator: 1.783052
Gradient professor: 26.669087
Loss Generator D: 2.424313
Loss Generator P: 0.924640
Gradient discriminator: 17.248683
Gradient professor: 15.668600
Loss Generator D: 2.227950
Loss Generator P: 0.817769
Gradient discriminator: 5.207721
Gradient professor: 41.586956
Loss Generator D: 2.767908
Loss Generator P: 0.775740
Gradient discriminator: 38.828823
Gradient professor: -18.456364
Loss Generator D: 2.102498
Loss Generator P: 0.859968
Gradient discriminator: 10.911212
Gradient professor: -39.914364
Loss Generator D: 2.537435
Loss Generator P: 0.705437
Gradient discriminator: 25.480715
Gradient professor: -5.255884
Loss Generator D: 2.513972
Loss Generator P: 0.779903
Gradient discriminator: -2.452638
Gradient professor: -1.644383
Loss Generator D: 3.085772
Loss Generator P: 0.850428
Gradient discriminator: -1.493710
Gradient professor: 19.688739
Loss Generator D: 2.656434
Loss Generator P: 0.663617
Gradient discriminator: 5.197331
Gradient professor: -9.215472
Loss Generator D: 2.071740
Loss Generator P: 0.862249
Gradient discriminator: 1.552402
Gradient professor: 2.524138
Loss Generator D: 2.272344
Loss Generator P: 0.951480
Generator    : Epoch:      9, update:    2010, cost:   0.951480
Gradient discriminator: 14.135006
Gradient professor: -16.372426
Loss Generator D: 2.743443
Loss Generator P: 1.043180
Gradient discriminator: -2.963657
Gradient professor: 6.754244
Loss Generator D: 2.436635
Loss Generator P: 0.796282
Gradient discriminator: 20.009566
Gradient professor: 4.083030
Loss Generator D: 2.870770
Loss Generator P: 0.936215
Gradient discriminator: 14.375237
Gradient professor: -10.766649
Loss Generator D: 2.467399
Loss Generator P: 0.833369
Gradient discriminator: 6.128147
Gradient professor: 30.979459
Loss Generator D: 2.785783
Loss Generator P: 0.644017
Gradient discriminator: 16.235609
Gradient professor: -17.155119
Loss Generator D: 2.625318
Loss Generator P: 0.496914
Gradient discriminator: -1.699751
Gradient professor: -14.711680
Loss Generator D: 2.792145
Loss Generator P: 0.758493
Gradient discriminator: 7.864775
Gradient professor: -5.408806
Loss Generator D: 3.358437
Loss Generator P: 0.674833
Gradient discriminator: -0.255969
Gradient professor: 3.396681
Loss Generator D: 3.168039
Loss Generator P: 0.797835
Gradient discriminator: -8.264533
Gradient professor: 34.771842
Loss Generator D: 2.401371
Loss Generator P: 0.899001
Generator    : Epoch:      9, update:    2020, cost:   0.899001
Gradient discriminator: 9.501377
Gradient professor: -4.122565
Loss Generator D: 2.922064
Loss Generator P: 0.813217
Gradient discriminator: -5.566469
Gradient professor: 7.063733
Loss Generator D: 3.086486
Loss Generator P: 0.694825
Gradient discriminator: -1.232923
Gradient professor: -4.087300
Loss Generator D: 2.381455
Loss Generator P: 0.639040
Gradient discriminator: 8.860111
Gradient professor: 1.475566
Loss Generator D: 2.598386
Loss Generator P: 0.942651
Gradient discriminator: 2.153664
Gradient professor: 12.426317
Loss Generator D: 3.309582
Loss Generator P: 0.861137
Gradient discriminator: -7.052964
Gradient professor: -9.826743
Loss Generator D: 2.861805
Loss Generator P: 0.831989
Gradient discriminator: -5.571049
Gradient professor: 6.187936
Loss Generator D: 2.677247
Loss Generator P: 0.589466
Gradient discriminator: -0.162083
Gradient professor: -0.974869
Loss Generator D: 2.577630
Loss Generator P: 0.719317
Gradient discriminator: 2.979034
Gradient professor: 11.701662
Loss Generator D: 3.222261
Loss Generator P: 0.661302
Gradient discriminator: -4.241009
Gradient professor: -9.244418
Loss Generator D: 2.797446
Loss Generator P: 0.736101
Generator    : Epoch:      9, update:    2030, cost:   0.736101
Gradient discriminator: 2.440761
Gradient professor: 27.033503
Loss Generator D: 3.252160
Loss Generator P: 0.658752
Gradient discriminator: -16.083277
Gradient professor: 29.445778
Loss Generator D: 3.155758
Loss Generator P: 0.619728
Gradient discriminator: 12.525798
Gradient professor: -7.959169
Loss Generator D: 3.610061
Loss Generator P: 0.920334
Gradient discriminator: 2.695429
Gradient professor: 7.770075
Loss Generator D: 2.755773
Loss Generator P: 0.878986
Gradient discriminator: -3.538513
Gradient professor: -11.250283
Loss Generator D: 3.245997
Loss Generator P: 0.702791
Gradient discriminator: 5.199905
Gradient professor: -16.044552
Loss Generator D: 3.300565
Loss Generator P: 0.655560
Gradient discriminator: 3.810345
Gradient professor: 7.116699
Loss Generator D: 2.977961
Loss Generator P: 0.637911
Gradient discriminator: 0.260367
Gradient professor: -13.790361
Loss Generator D: 3.107708
Loss Generator P: 0.758180
Gradient discriminator: 3.721905
Gradient professor: 17.585650
Loss Generator D: 3.007745
Loss Generator P: 0.709503
Gradient discriminator: 5.069330
Gradient professor: -9.079301
Loss Generator D: 3.377930
Loss Generator P: 0.896784
Generator    : Epoch:      9, update:    2040, cost:   0.896784
Gradient discriminator: 4.397453
Gradient professor: 6.305273
Loss Generator D: 2.978379
Loss Generator P: 0.717481
Gradient discriminator: 0.977202
Gradient professor: 24.687403
Loss Generator D: 3.306839
Loss Generator P: 0.671059
Gradient discriminator: 1.900116
Gradient professor: 0.743464
Loss Generator D: 3.261329
Loss Generator P: 0.712010
Gradient discriminator: -1.642489
Gradient professor: -15.822147
Loss Generator D: 3.268653
Loss Generator P: 0.722405
Gradient discriminator: -12.169085
Gradient professor: 10.377350
Loss Generator D: 3.288872
Loss Generator P: 0.844352
Gradient discriminator: -18.066598
Gradient professor: 21.305775
Loss Generator D: 3.398764
Loss Generator P: 0.785055
Gradient discriminator: -8.437154
Gradient professor: -3.578496
Loss Generator D: 2.878122
Loss Generator P: 0.640736
Gradient discriminator: -11.986616
Gradient professor: 1.374735
Loss Generator D: 2.894492
Loss Generator P: 0.844642
Gradient discriminator: 8.137791
Gradient professor: 11.229302
Loss Generator D: 3.169957
Loss Generator P: 1.021451
Gradient discriminator: -27.815458
Gradient professor: -20.094477
Loss Generator D: 3.000031
Loss Generator P: 0.753320
Generator    : Epoch:      9, update:    2050, cost:   0.753320
Gradient discriminator: 9.087990
Gradient professor: 0.293909
Loss Generator D: 3.241007
Loss Generator P: 0.843559
Gradient discriminator: -10.011668
Gradient professor: 16.778776
Loss Generator D: 2.740693
Loss Generator P: 0.824894
Gradient discriminator: -30.104022
Gradient professor: -2.837735
Loss Generator D: 2.108853
Loss Generator P: 0.675960
Gradient discriminator: -0.194054
Gradient professor: -13.504747
Loss Generator D: 2.597669
Loss Generator P: 0.864393
Gradient discriminator: -0.923326
Gradient professor: -50.372960
Loss Generator D: 2.710268
Loss Generator P: 0.818762
Gradient discriminator: -1.514580
Gradient professor: 12.543259
Loss Generator D: 2.603847
Loss Generator P: 0.654014
Gradient discriminator: 5.902001
Gradient professor: 19.258677
Loss Generator D: 2.408587
Loss Generator P: 0.660927
Gradient discriminator: 6.039907
Gradient professor: -17.168515
Loss Generator D: 3.726791
Loss Generator P: 0.615050
Gradient discriminator: 0.167792
Gradient professor: 1.015120
Loss Generator D: 3.922820
Loss Generator P: 0.701104
Gradient discriminator: -3.775619
Gradient professor: 17.420211
Loss Generator D: 3.817628
Loss Generator P: 0.771377
Generator    : Epoch:      9, update:    2060, cost:   0.771377
Gradient discriminator: -0.326802
Gradient professor: -19.080206
Loss Generator D: 4.021163
Loss Generator P: 0.734820
Gradient discriminator: -6.389484
Gradient professor: 30.504264
Loss Generator D: 3.622873
Loss Generator P: 0.988274
Gradient discriminator: 1.128691
Gradient professor: -7.422889
Loss Generator D: 3.254466
Loss Generator P: 0.721107
Gradient discriminator: 2.107195
Gradient professor: -9.265318
Loss Generator D: 4.086842
Loss Generator P: 0.699106
Gradient discriminator: 30.143181
Gradient professor: -38.190897
Loss Generator D: 2.854731
Loss Generator P: 0.894229
Gradient discriminator: -6.492009
Gradient professor: -1.961821
Loss Generator D: 3.031224
Loss Generator P: 0.797147
Gradient discriminator: -1.091038
Gradient professor: -16.097453
Loss Generator D: 3.606898
Loss Generator P: 0.711341
Gradient discriminator: -6.039403
Gradient professor: -3.713031
Loss Generator D: 3.482038
Loss Generator P: 0.688423
Gradient discriminator: -1.108307
Gradient professor: 11.553305
Loss Generator D: 3.365181
Loss Generator P: 0.905969
Gradient discriminator: 3.503762
Gradient professor: 1.948413
Loss Generator D: 3.999315
Loss Generator P: 0.798429
Generator    : Epoch:      9, update:    2070, cost:   0.798429
Gradient discriminator: 3.959937
Gradient professor: -11.198232
Loss Generator D: 3.807095
Loss Generator P: 0.655516
Gradient discriminator: 12.746338
Gradient professor: 3.241609
Loss Generator D: 3.060297
Loss Generator P: 0.586463
Gradient discriminator: -3.507904
Gradient professor: -4.584844
Loss Generator D: 3.500816
Loss Generator P: 0.737387
Gradient discriminator: 0.515342
Gradient professor: -6.640522
Loss Generator D: 2.543247
Loss Generator P: 0.826457
Gradient discriminator: -13.728703
Gradient professor: -1.973645
Loss Generator D: 2.779631
Loss Generator P: 0.716974
Gradient discriminator: 1.058880
Gradient professor: 8.922634
Loss Generator D: 2.167371
Loss Generator P: 0.664608
Gradient discriminator: -2.442485
Gradient professor: 18.907418
Loss Generator D: 3.436219
Loss Generator P: 0.704701
Gradient discriminator: 11.877839
Gradient professor: -0.293121
Loss Generator D: 3.015284
Loss Generator P: 0.858921
Gradient discriminator: -1.213067
Gradient professor: -10.272109
Loss Generator D: 2.314466
Loss Generator P: 0.538035
Gradient discriminator: 0.402814
Gradient professor: -19.333001
Loss Generator D: 2.626968
Loss Generator P: 0.503747
Generator    : Epoch:      9, update:    2080, cost:   0.503747
Gradient discriminator: 4.751398
Gradient professor: 21.975011
Loss Generator D: 3.255771
Loss Generator P: 0.603069
Gradient discriminator: 4.103677
Gradient professor: -2.550626
Loss Generator D: 3.045030
Loss Generator P: 0.658690
Gradient discriminator: 4.387639
Gradient professor: -13.005690
Loss Generator D: 2.183312
Loss Generator P: 0.633301
Gradient discriminator: 7.484093
Gradient professor: -7.752166
Loss Generator D: 3.243755
Loss Generator P: 0.501721
Gradient discriminator: -2.785586
Gradient professor: 0.721993
Loss Generator D: 3.646309
Loss Generator P: 0.535167
Gradient discriminator: 1.062403
Gradient professor: -1.688699
Loss Generator D: 2.406998
Loss Generator P: 0.541176
Gradient discriminator: 11.905013
Gradient professor: -6.196928
Loss Generator D: 2.854186
Loss Generator P: 0.555239
Gradient discriminator: -15.931675
Gradient professor: -13.890360
Loss Generator D: 2.716892
Loss Generator P: 0.768106
Gradient discriminator: -5.822832
Gradient professor: -1.936549
Loss Generator D: 2.706486
Loss Generator P: 0.635747
Gradient discriminator: 6.113284
Gradient professor: 1.596738
Loss Generator D: 3.218653
Loss Generator P: 0.770560
Generator    : Epoch:      9, update:    2090, cost:   0.770560
Gradient discriminator: -7.847230
Gradient professor: 3.133888
Loss Generator D: 3.048278
Loss Generator P: 0.588602
Gradient discriminator: -17.968698
Gradient professor: 34.241870
Loss Generator D: 2.803190
Loss Generator P: 0.997427
Gradient discriminator: -5.904648
Gradient professor: -27.763333
Loss Generator D: 3.205745
Loss Generator P: 0.692375
Gradient discriminator: 7.197210
Gradient professor: -8.841526
Loss Generator D: 2.772432
Loss Generator P: 0.516433
Gradient discriminator: -19.713175
Gradient professor: -1.113172
Loss Generator D: 2.164745
Loss Generator P: 0.615692
Gradient discriminator: -16.996450
Gradient professor: -23.431436
Loss Generator D: 2.370995
Loss Generator P: 0.649191
Gradient discriminator: -9.281615
Gradient professor: -19.891248
Loss Generator D: 2.898534
Loss Generator P: 0.629977
Gradient discriminator: -4.437345
Gradient professor: 3.588524
Loss Generator D: 2.510408
Loss Generator P: 0.591532
Gradient discriminator: -9.537376
Gradient professor: 5.148123
Loss Generator D: 2.717697
Loss Generator P: 0.634271
Gradient discriminator: 2.974295
Gradient professor: -15.925690
Loss Generator D: 3.171445
Loss Generator P: 0.710496
Generator    : Epoch:      9, update:    2100, cost:   0.710496
Validation 21 - LOSS = 1.602 (PPL: 4.965)
Calling beam-search process
Beam-search ended, took 2.49077 minutes.
Validation 21 - BLEU = 7.34, 13.2/8.7/6.1/4.2 (BP=1.000, ratio=4.729, hyp_len=19957, ref_len=4220)
Early stopping patience: 995 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 9.028943
Gradient professor: 7.746433
Loss Generator D: 2.497763
Loss Generator P: 0.779284
Gradient discriminator: 9.526222
Gradient professor: -12.383116
Loss Generator D: 2.476390
Loss Generator P: 0.761059
Gradient discriminator: -0.595742
Gradient professor: 2.261211
Loss Generator D: 2.888516
Loss Generator P: 0.561895
Gradient discriminator: 12.805989
Gradient professor: 6.149938
Loss Generator D: 2.165981
Loss Generator P: 0.681470
Gradient discriminator: -7.084704
Gradient professor: -0.414885
Loss Generator D: 2.553427
Loss Generator P: 0.490110
Gradient discriminator: -6.194346
Gradient professor: -15.325732
Loss Generator D: 3.129524
Loss Generator P: 0.782534
Gradient discriminator: -4.556762
Gradient professor: 1.495793
Loss Generator D: 2.779765
Loss Generator P: 0.551130
Gradient discriminator: 15.326029
Gradient professor: -10.233636
Loss Generator D: 2.798630
Loss Generator P: 0.591171
Gradient discriminator: 24.116395
Gradient professor: -8.886701
Loss Generator D: 3.420153
Loss Generator P: 0.698402
Gradient discriminator: -0.586613
Gradient professor: -5.257411
Loss Generator D: 2.904575
Loss Generator P: 0.572081
Generator    : Epoch:      9, update:    2110, cost:   0.572081
Gradient discriminator: -2.542839
Gradient professor: -18.723297
Loss Generator D: 3.165867
Loss Generator P: 0.734965
Gradient discriminator: -0.239256
Gradient professor: 22.613129
Loss Generator D: 2.651761
Loss Generator P: 0.695457
Gradient discriminator: -0.830366
Gradient professor: -17.580053
Loss Generator D: 3.677771
Loss Generator P: 0.599253
Gradient discriminator: -2.591378
Gradient professor: -4.487726
Loss Generator D: 2.991637
Loss Generator P: 0.539329
Gradient discriminator: -3.100724
Gradient professor: 16.011961
Loss Generator D: 3.337545
Loss Generator P: 0.761048
Gradient discriminator: -8.187367
Gradient professor: -19.617037
Loss Generator D: 3.154656
Loss Generator P: 0.783982
Gradient discriminator: -5.962852
Gradient professor: 25.139432
Loss Generator D: 2.912352
Loss Generator P: 0.589701
Gradient discriminator: -12.229757
Gradient professor: -22.732516
Loss Generator D: 3.442860
Loss Generator P: 0.782298
Gradient discriminator: -5.414785
Gradient professor: 19.645051
Loss Generator D: 3.176119
Loss Generator P: 0.610846
Gradient discriminator: -0.074247
Gradient professor: 15.656709
Loss Generator D: 2.721556
Loss Generator P: 0.676937
Generator    : Epoch:      9, update:    2120, cost:   0.676937
Gradient discriminator: -5.161587
Gradient professor: -0.183541
Loss Generator D: 2.749457
Loss Generator P: 0.687514
Gradient discriminator: -11.236693
Gradient professor: -1.168131
Loss Generator D: 2.440785
Loss Generator P: 0.688267
Gradient discriminator: -25.083565
Gradient professor: -7.185714
Loss Generator D: 2.418722
Loss Generator P: 0.735032
Gradient discriminator: 18.191883
Gradient professor: -8.783667
Loss Generator D: 2.272829
Loss Generator P: 0.776594
Gradient discriminator: 4.539118
Gradient professor: 18.674548
Loss Generator D: 1.845765
Loss Generator P: 0.788573
Gradient discriminator: -70.152116
Gradient professor: -16.173131
Loss Generator D: 2.745865
Loss Generator P: 0.664755
Gradient discriminator: -22.839955
Gradient professor: 11.149415
Loss Generator D: 2.375186
Loss Generator P: 0.702073
Gradient discriminator: -5.537260
Gradient professor: 11.010010
Loss Generator D: 3.146033
Loss Generator P: 0.784445
Gradient discriminator: 55.937689
Gradient professor: -5.071339
Loss Generator D: 2.412906
Loss Generator P: 0.757985
Gradient discriminator: -29.327969
Gradient professor: -7.988248
Loss Generator D: 2.716618
Loss Generator P: 0.780965
Generator    : Epoch:      9, update:    2130, cost:   0.780965
Gradient discriminator: 9.426368
Gradient professor: -16.568974
Loss Generator D: 2.247145
Loss Generator P: 0.630136
Gradient discriminator: -18.208160
Gradient professor: 0.187622
Loss Generator D: 2.533486
Loss Generator P: 0.589650
Gradient discriminator: 2.611068
Gradient professor: 11.323781
Loss Generator D: 2.086437
Loss Generator P: 0.579055
Gradient discriminator: -14.748215
Gradient professor: -14.989371
Loss Generator D: 2.497653
Loss Generator P: 0.794800
Gradient discriminator: -7.227981
Gradient professor: 4.317492
Loss Generator D: 2.165744
Loss Generator P: 0.705631
Gradient discriminator: 0.797973
Gradient professor: -20.215825
Loss Generator D: 2.854807
Loss Generator P: 0.543882
Gradient discriminator: -0.408751
Gradient professor: 15.414267
Loss Generator D: 2.602835
Loss Generator P: 0.692092
Gradient discriminator: 8.914623
Gradient professor: 4.296761
Loss Generator D: 3.251669
Loss Generator P: 0.454454
Gradient discriminator: 4.524400
Gradient professor: 10.487876
Loss Generator D: 3.004237
Loss Generator P: 0.757935
Gradient discriminator: -1.024303
Gradient professor: 3.165385
Loss Generator D: 2.940555
Loss Generator P: 0.692210
Generator    : Epoch:      9, update:    2140, cost:   0.692210
Gradient discriminator: -13.944864
Gradient professor: 11.028354
Loss Generator D: 2.501871
Loss Generator P: 0.676568
Gradient discriminator: -1.297009
Gradient professor: 6.036034
Loss Generator D: 2.753337
Loss Generator P: 0.765632
Gradient discriminator: -0.889887
Gradient professor: 35.433941
Loss Generator D: 2.912716
Loss Generator P: 0.891459
Gradient discriminator: 11.519903
Gradient professor: -10.190160
Loss Generator D: 3.272577
Loss Generator P: 0.722755
Gradient discriminator: 39.976841
Gradient professor: -29.112796
Loss Generator D: 2.812447
Loss Generator P: 0.839505
Gradient discriminator: -23.513044
Gradient professor: 2.419329
Loss Generator D: 2.752464
Loss Generator P: 0.886114
Gradient discriminator: 3.033071
Gradient professor: -1.275071
Loss Generator D: 2.873698
Loss Generator P: 0.551237
Gradient discriminator: -5.043387
Gradient professor: 16.678610
Loss Generator D: 2.661476
Loss Generator P: 0.655383
Gradient discriminator: 0.765628
Gradient professor: -16.568820
Loss Generator D: 2.683741
Loss Generator P: 0.591463
Gradient discriminator: -12.867028
Gradient professor: -5.242133
Loss Generator D: 2.811589
Loss Generator P: 0.544422
Generator    : Epoch:      9, update:    2150, cost:   0.544422
Gradient discriminator: 5.257267
Gradient professor: -28.846187
Loss Generator D: 2.822320
Loss Generator P: 0.810713
Gradient discriminator: -17.732936
Gradient professor: 37.776451
Loss Generator D: 2.654650
Loss Generator P: 0.689897
Gradient discriminator: -19.696253
Gradient professor: -7.238621
Loss Generator D: 2.331903
Loss Generator P: 0.716198
Gradient discriminator: 22.670404
Gradient professor: -1.519586
Loss Generator D: 2.668688
Loss Generator P: 0.624435
Gradient discriminator: -4.806319
Gradient professor: 20.887031
Loss Generator D: 2.186775
Loss Generator P: 0.779210
Gradient discriminator: 10.844605
Gradient professor: -25.515787
Loss Generator D: 2.597619
Loss Generator P: 0.711643
Gradient discriminator: -2.877851
Gradient professor: 18.153747
Loss Generator D: 2.471861
Loss Generator P: 0.737426
Gradient discriminator: -4.716188
Gradient professor: 20.250275
Loss Generator D: 2.142205
Loss Generator P: 0.541532
Gradient discriminator: -3.843745
Gradient professor: -13.362665
Loss Generator D: 2.486216
Loss Generator P: 0.527473
Gradient discriminator: 10.503747
Gradient professor: -4.290520
Loss Generator D: 2.374021
Loss Generator P: 0.714444
Generator    : Epoch:      9, update:    2160, cost:   0.714444
Gradient discriminator: 9.963221
Gradient professor: -10.494918
Loss Generator D: 2.502795
Loss Generator P: 0.705997
Gradient discriminator: 2.534595
Gradient professor: 8.835610
Loss Generator D: 2.529303
Loss Generator P: 0.851777
Gradient discriminator: -4.208400
Gradient professor: 0.001784
Loss Generator D: 2.121605
Loss Generator P: 0.855140
Gradient discriminator: 12.575743
Gradient professor: 9.695931
Loss Generator D: 2.427152
Loss Generator P: 0.813036
Gradient discriminator: 5.208677
Gradient professor: 34.728672
Loss Generator D: 2.347783
Loss Generator P: 0.861078
Gradient discriminator: 25.579015
Gradient professor: -30.777320
Loss Generator D: 2.118438
Loss Generator P: 0.804891
Gradient discriminator: -5.404433
Gradient professor: 11.814993
Loss Generator D: 2.119809
Loss Generator P: 0.840614
Gradient discriminator: -2.723809
Gradient professor: -5.171460
Loss Generator D: 2.670193
Loss Generator P: 0.714569
Gradient discriminator: -4.717135
Gradient professor: 2.917796
Loss Generator D: 2.195296
Loss Generator P: 0.745193
Gradient discriminator: -13.959713
Gradient professor: -20.228136
Loss Generator D: 2.569170
Loss Generator P: 0.831841
Generator    : Epoch:      9, update:    2170, cost:   0.831841
Gradient discriminator: -1.132008
Gradient professor: 0.397570
Loss Generator D: 2.461957
Loss Generator P: 0.692519
Gradient discriminator: -4.818270
Gradient professor: 14.034443
Loss Generator D: 1.908644
Loss Generator P: 0.610372
Gradient discriminator: -5.926754
Gradient professor: -11.118615
Loss Generator D: 2.325172
Loss Generator P: 0.713564
Gradient discriminator: 9.724084
Gradient professor: -10.632258
Loss Generator D: 2.101364
Loss Generator P: 0.500173
Gradient discriminator: -6.770776
Gradient professor: -3.093095
Loss Generator D: 2.001946
Loss Generator P: 0.614379
Gradient discriminator: 3.902140
Gradient professor: 9.419023
Loss Generator D: 2.000261
Loss Generator P: 0.693465
Gradient discriminator: 9.084087
Gradient professor: -2.277588
Loss Generator D: 1.945052
Loss Generator P: 0.912317
Gradient discriminator: 2.466440
Gradient professor: 5.532109
Loss Generator D: 2.315684
Loss Generator P: 1.008336
Gradient discriminator: 3.493934
Gradient professor: 2.795090
Loss Generator D: 2.583517
Loss Generator P: 0.893592
Gradient discriminator: -5.127313
Gradient professor: 28.768554
Loss Generator D: 2.502161
Loss Generator P: 0.575811
Generator    : Epoch:      9, update:    2180, cost:   0.575811
Gradient discriminator: 11.408168
Gradient professor: 11.679271
Loss Generator D: 2.784992
Loss Generator P: 0.691993
Gradient discriminator: 8.211600
Gradient professor: -4.148357
Loss Generator D: 2.009487
Loss Generator P: 0.747259
Gradient discriminator: -0.558384
Gradient professor: 6.329131
Loss Generator D: 2.485720
Loss Generator P: 0.689127
Gradient discriminator: 3.804813
Gradient professor: -16.132754
Loss Generator D: 2.468403
Loss Generator P: 0.863453
Gradient discriminator: 8.618460
Gradient professor: -28.268139
Loss Generator D: 2.416543
Loss Generator P: 0.889035
Gradient discriminator: 3.989540
Gradient professor: 12.078957
Loss Generator D: 2.402351
Loss Generator P: 0.718174
Gradient discriminator: -10.335667
Gradient professor: 33.199812
Loss Generator D: 2.183063
Loss Generator P: 0.791915
Gradient discriminator: 12.871715
Gradient professor: -5.218445
Loss Generator D: 2.207788
Loss Generator P: 0.848702
Gradient discriminator: -3.583454
Gradient professor: 0.879361
Loss Generator D: 2.645674
Loss Generator P: 0.841839
Gradient discriminator: 29.713795
Gradient professor: -56.679893
Loss Generator D: 2.278006
Loss Generator P: 0.870908
Generator    : Epoch:      9, update:    2190, cost:   0.870908
Gradient discriminator: 2.951293
Gradient professor: 5.832979
Loss Generator D: 2.579890
Loss Generator P: 0.840347
Gradient discriminator: -8.753946
Gradient professor: -9.747941
Loss Generator D: 2.546320
Loss Generator P: 0.684591
Gradient discriminator: -6.346934
Gradient professor: -28.391807
Loss Generator D: 2.329592
Loss Generator P: 1.041078
Gradient discriminator: -6.402966
Gradient professor: 2.480407
Loss Generator D: 2.022187
Loss Generator P: 1.005445
Gradient discriminator: -8.665457
Gradient professor: 2.086946
Loss Generator D: 2.156838
Loss Generator P: 0.637393
Gradient discriminator: 8.978579
Gradient professor: -16.670310
Loss Generator D: 2.343317
Loss Generator P: 0.834815
Gradient discriminator: -9.088552
Gradient professor: -2.482243
Loss Generator D: 1.942727
Loss Generator P: 0.811887
Gradient discriminator: -37.477184
Gradient professor: -46.968656
Loss Generator D: 2.031826
Loss Generator P: 0.831150
Gradient discriminator: -15.168074
Gradient professor: -11.146335
Loss Generator D: 1.931859
Loss Generator P: 0.841398
Gradient discriminator: -5.010577
Gradient professor: 1.335782
Loss Generator D: 2.159931
Loss Generator P: 0.685118
Generator    : Epoch:      9, update:    2200, cost:   0.685118
Validation 22 - LOSS = 1.624 (PPL: 5.073)
Calling beam-search process
Beam-search ended, took 1.81986 minutes.
Validation 22 - BLEU = 11.64, 21.9/13.9/9.5/6.4 (BP=1.000, ratio=2.759, hyp_len=11644, ref_len=4220)
Early stopping patience: 994 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -6.057785
Gradient professor: -7.046502
Loss Generator D: 2.698636
Loss Generator P: 0.725601
Gradient discriminator: 7.581392
Gradient professor: -20.063728
Loss Generator D: 2.130828
Loss Generator P: 0.756663
Gradient discriminator: 6.750873
Gradient professor: 12.807485
Loss Generator D: 2.099357
Loss Generator P: 0.657554
Gradient discriminator: -5.845252
Gradient professor: -14.654240
Loss Generator D: 2.156536
Loss Generator P: 0.719599
Gradient discriminator: 6.111776
Gradient professor: -4.818380
Loss Generator D: 1.838481
Loss Generator P: 0.593818
Gradient discriminator: -13.938645
Gradient professor: -24.360283
Loss Generator D: 2.061187
Loss Generator P: 0.547321
Gradient discriminator: -17.488302
Gradient professor: 7.086818
Loss Generator D: 2.520037
Loss Generator P: 0.787460
Gradient discriminator: -7.769658
Gradient professor: -13.688812
Loss Generator D: 2.312263
Loss Generator P: 0.860141
Gradient discriminator: 4.097537
Gradient professor: -0.667954
Loss Generator D: 1.845708
Loss Generator P: 0.671902
Gradient discriminator: 3.767528
Gradient professor: -9.357806
Loss Generator D: 2.151043
Loss Generator P: 0.846779
Generator    : Epoch:      9, update:    2210, cost:   0.846779
Gradient discriminator: -2.225973
Gradient professor: -22.229323
Loss Generator D: 2.282188
Loss Generator P: 0.832071
Gradient discriminator: 127.809180
Gradient professor: 27.226641
Loss Generator D: 1.817664
Loss Generator P: 0.872411
Gradient discriminator: 5.344048
Gradient professor: -8.211412
Loss Generator D: 2.520093
Loss Generator P: 0.754328
Gradient discriminator: -2.919231
Gradient professor: -11.782610
Loss Generator D: 1.980620
Loss Generator P: 0.645429
Gradient discriminator: 11.927381
Gradient professor: 5.677964
Loss Generator D: 2.287529
Loss Generator P: 0.750314
Gradient discriminator: 2.126224
Gradient professor: -0.306008
Loss Generator D: 2.299060
Loss Generator P: 0.736164
Gradient discriminator: 11.853925
Gradient professor: -11.751731
Loss Generator D: 2.209374
Loss Generator P: 0.787479
Gradient discriminator: 12.214096
Gradient professor: -12.239791
Loss Generator D: 1.983423
Loss Generator P: 0.699973
Gradient discriminator: -8.632888
Gradient professor: 13.314410
Loss Generator D: 2.034751
Loss Generator P: 0.600043
Gradient discriminator: 9.158871
Gradient professor: -8.751956
Loss Generator D: 2.255637
Loss Generator P: 0.638158
Generator    : Epoch:      9, update:    2220, cost:   0.638158
Gradient discriminator: 3.922527
Gradient professor: -0.099115
Loss Generator D: 1.901085
Loss Generator P: 0.742849
Gradient discriminator: 2.892341
Gradient professor: -17.436425
Loss Generator D: 1.858700
Loss Generator P: 0.780998
Gradient discriminator: 11.732761
Gradient professor: -6.434472
Loss Generator D: 2.030756
Loss Generator P: 0.739586
Gradient discriminator: -19.837496
Gradient professor: 3.407490
Loss Generator D: 2.178874
Loss Generator P: 0.621888
Gradient discriminator: 14.003162
Gradient professor: 14.894489
Loss Generator D: 2.048621
Loss Generator P: 0.640569
Gradient discriminator: -14.304118
Gradient professor: -74.914443
Loss Generator D: 1.842838
Loss Generator P: 0.652645
Gradient discriminator: 9.806972
Gradient professor: 6.531833
Loss Generator D: 1.911765
Loss Generator P: 0.686605
Gradient discriminator: -4.326012
Gradient professor: -1.445421
Loss Generator D: 2.637409
Loss Generator P: 0.640447
Gradient discriminator: -4.531932
Gradient professor: 13.327751
Loss Generator D: 2.526696
Loss Generator P: 0.692502
Gradient discriminator: -3.979701
Gradient professor: -22.078692
Loss Generator D: 2.358376
Loss Generator P: 0.710441
Generator    : Epoch:      9, update:    2230, cost:   0.710441
Gradient discriminator: -33.002448
Gradient professor: -2.342547
Loss Generator D: 2.278915
Loss Generator P: 0.756557
Gradient discriminator: -8.782579
Gradient professor: -32.329934
Loss Generator D: 2.341062
Loss Generator P: 0.850314
Gradient discriminator: -9.039625
Gradient professor: 12.781629
Loss Generator D: 2.704995
Loss Generator P: 0.889764
Gradient discriminator: 10.135891
Gradient professor: 1.953262
Loss Generator D: 2.546277
Loss Generator P: 0.515379
Gradient discriminator: -15.357905
Gradient professor: -1.688979
Loss Generator D: 2.154433
Loss Generator P: 0.682831
Gradient discriminator: -25.259623
Gradient professor: 17.373393
Loss Generator D: 2.450198
Loss Generator P: 0.682999
Gradient discriminator: 13.934619
Gradient professor: 18.491014
Loss Generator D: 3.133679
Loss Generator P: 0.551317
Gradient discriminator: -3.595434
Gradient professor: -25.894721
Loss Generator D: 2.469814
Loss Generator P: 0.723332
Gradient discriminator: 13.466382
Gradient professor: -4.342814
Loss Generator D: 2.555316
Loss Generator P: 0.682513
Gradient discriminator: 5.181454
Gradient professor: 4.187140
Loss Generator D: 2.552114
Loss Generator P: 0.632316
Generator    : Epoch:      9, update:    2240, cost:   0.632316
Gradient discriminator: 9.093503
Gradient professor: 3.631176
Loss Generator D: 2.506625
Loss Generator P: 0.662986
Gradient discriminator: -12.163474
Gradient professor: 5.741620
Loss Generator D: 2.575299
Loss Generator P: 0.647162
Gradient discriminator: -0.733665
Gradient professor: 13.796949
Loss Generator D: 2.584025
Loss Generator P: 0.590730
Gradient discriminator: 19.662714
Gradient professor: -14.886481
Loss Generator D: 2.501576
Loss Generator P: 0.699669
Gradient discriminator: 7.225223
Gradient professor: -1.438983
Loss Generator D: 2.924595
Loss Generator P: 0.819559
Gradient discriminator: 18.609063
Gradient professor: -0.728273
Loss Generator D: 3.020705
Loss Generator P: 0.641683
Gradient discriminator: 1.282304
Gradient professor: -28.950581
Loss Generator D: 3.260973
Loss Generator P: 0.667219
Gradient discriminator: -8.519827
Gradient professor: -7.950721
Loss Generator D: 2.932477
Loss Generator P: 0.560696
Gradient discriminator: 8.662494
Gradient professor: -8.676849
Loss Generator D: 2.793423
Loss Generator P: 0.687749
Gradient discriminator: 13.798548
Gradient professor: -3.235161
Loss Generator D: 2.557583
Loss Generator P: 0.476064
Generator    : Epoch:      9, update:    2250, cost:   0.476064
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 9 finished with mean loss 1.69709 (PPL: 5.45806)
--> Epoch took 280.133 minutes, 67.232 sec/update
Epoch summary of Discriminator:
--> Epoch 9 finished with mean loss nan (PPL:  nan)
--> Epoch took 280.133 minutes, 67.232 sec/update
---------------------------------------------------------
Starting Epoch 10
-----------------
Gradient discriminator: 18.982475
Gradient professor: 10.847562
Loss Generator D: 2.399894
Loss Generator P: 0.923019
Gradient discriminator: -9.780731
Gradient professor: 10.909120
Loss Generator D: 2.291858
Loss Generator P: 0.713219
Gradient discriminator: 6.677288
Gradient professor: -5.254676
Loss Generator D: 2.486425
Loss Generator P: 0.713260
Gradient discriminator: 1.436897
Gradient professor: -16.979260
Loss Generator D: 2.272911
Loss Generator P: 0.921802
Gradient discriminator: 15.789284
Gradient professor: -3.397573
Loss Generator D: 2.668215
Loss Generator P: 0.656484
Gradient discriminator: 13.688434
Gradient professor: 4.164045
Loss Generator D: 2.333688
Loss Generator P: 0.677192
Gradient discriminator: 16.177831
Gradient professor: 25.708547
Loss Generator D: 2.639459
Loss Generator P: 0.772433
Gradient discriminator: 13.802235
Gradient professor: 22.759893
Loss Generator D: 2.147329
Loss Generator P: 0.654259
Gradient discriminator: -2.305151
Gradient professor: 19.125011
Loss Generator D: 2.377176
Loss Generator P: 0.801004
Gradient discriminator: 0.236204
Gradient professor: 4.737278
Loss Generator D: 2.370962
Loss Generator P: 0.928243
Generator    : Epoch:     10, update:    2260, cost:   0.928243
Gradient discriminator: 6.834642
Gradient professor: 0.071303
Loss Generator D: 2.810815
Loss Generator P: 1.000656
Gradient discriminator: -4.944657
Gradient professor: -18.170712
Loss Generator D: 2.336008
Loss Generator P: 0.675982
Gradient discriminator: 12.364051
Gradient professor: 12.343850
Loss Generator D: 2.596153
Loss Generator P: 0.871852
Gradient discriminator: -22.741035
Gradient professor: 10.221546
Loss Generator D: 2.276778
Loss Generator P: 0.808101
Gradient discriminator: -5.693487
Gradient professor: -12.292510
Loss Generator D: 2.178184
Loss Generator P: 0.551882
Gradient discriminator: -3.111303
Gradient professor: -8.394506
Loss Generator D: 2.554923
Loss Generator P: 0.500857
Gradient discriminator: 0.877834
Gradient professor: -19.288281
Loss Generator D: 3.015098
Loss Generator P: 0.644571
Gradient discriminator: -2.364221
Gradient professor: 11.123210
Loss Generator D: 2.676431
Loss Generator P: 0.678183
Gradient discriminator: -4.030961
Gradient professor: -19.754894
Loss Generator D: 2.796085
Loss Generator P: 0.745639
Gradient discriminator: -10.854002
Gradient professor: 33.410538
Loss Generator D: 2.613224
Loss Generator P: 0.782973
Generator    : Epoch:     10, update:    2270, cost:   0.782973
Gradient discriminator: 18.736809
Gradient professor: -6.215562
Loss Generator D: 2.557137
Loss Generator P: 0.667269
Gradient discriminator: 5.644638
Gradient professor: -1.946280
Loss Generator D: 2.526459
Loss Generator P: 0.629001
Gradient discriminator: 1.483231
Gradient professor: 8.898162
Loss Generator D: 2.444805
Loss Generator P: 0.624996
Gradient discriminator: 38.514096
Gradient professor: 0.725137
Loss Generator D: 1.853822
Loss Generator P: 0.875233
Gradient discriminator: -2.671498
Gradient professor: 22.798038
Loss Generator D: 1.026054
Loss Generator P: 0.788254
Gradient discriminator: -10.366606
Gradient professor: -9.099412
Loss Generator D: 1.538162
Loss Generator P: 0.666518
Gradient discriminator: 10.533087
Gradient professor: 1.509407
Loss Generator D: 2.084502
Loss Generator P: 0.575091
Gradient discriminator: -6.167965
Gradient professor: 25.752183
Loss Generator D: 2.337278
Loss Generator P: 0.675306
Gradient discriminator: 4.420087
Gradient professor: -1.848706
Loss Generator D: 2.158898
Loss Generator P: 0.644787
Gradient discriminator: -22.257453
Gradient professor: -11.405843
Loss Generator D: 2.838427
Loss Generator P: 0.667155
Generator    : Epoch:     10, update:    2280, cost:   0.667155
Gradient discriminator: 15.998138
Gradient professor: 18.371352
Loss Generator D: 2.333440
Loss Generator P: 0.690915
Gradient discriminator: -8.943395
Gradient professor: 0.772806
Loss Generator D: 2.758919
Loss Generator P: 0.567640
Gradient discriminator: -46.802840
Gradient professor: 0.134816
Loss Generator D: 2.835197
Loss Generator P: 0.847997
Gradient discriminator: -6.686651
Gradient professor: -5.246138
Loss Generator D: 2.939210
Loss Generator P: 0.933232
Gradient discriminator: -2.409270
Gradient professor: 19.569811
Loss Generator D: 2.706848
Loss Generator P: 0.644201
Gradient discriminator: -0.491647
Gradient professor: -13.666907
Loss Generator D: 2.836490
Loss Generator P: 0.625911
Gradient discriminator: 4.230192
Gradient professor: -0.724033
Loss Generator D: 2.962491
Loss Generator P: 0.556907
Gradient discriminator: 7.159984
Gradient professor: -12.082957
Loss Generator D: 2.779909
Loss Generator P: 0.672101
Gradient discriminator: -6.070523
Gradient professor: 9.534206
Loss Generator D: 2.809444
Loss Generator P: 0.624442
Gradient discriminator: -2.066689
Gradient professor: 11.812435
Loss Generator D: 3.298688
Loss Generator P: 0.843483
Generator    : Epoch:     10, update:    2290, cost:   0.843483
Gradient discriminator: 40.652594
Gradient professor: 7.433474
Loss Generator D: 3.138545
Loss Generator P: 0.633952
Gradient discriminator: 10.839306
Gradient professor: -0.106214
Loss Generator D: 3.437434
Loss Generator P: 0.662222
Gradient discriminator: 7.138990
Gradient professor: -16.294282
Loss Generator D: 3.539878
Loss Generator P: 0.646037
Gradient discriminator: -0.602918
Gradient professor: 2.998000
Loss Generator D: 3.182861
Loss Generator P: 0.641359
Gradient discriminator: 2.755604
Gradient professor: -64.761854
Loss Generator D: 3.742858
Loss Generator P: 0.903409
Gradient discriminator: 7.082756
Gradient professor: 28.547542
Loss Generator D: 3.148485
Loss Generator P: 0.754802
Gradient discriminator: -1.377592
Gradient professor: 11.328811
Loss Generator D: 2.932506
Loss Generator P: 0.660520
Gradient discriminator: 7.662601
Gradient professor: 5.782476
Loss Generator D: 3.172212
Loss Generator P: 0.798961
Gradient discriminator: -0.698535
Gradient professor: 14.512323
Loss Generator D: 3.329107
Loss Generator P: 1.007601
Gradient discriminator: 4.219004
Gradient professor: 33.545285
Loss Generator D: 2.976355
Loss Generator P: 0.708017
Generator    : Epoch:     10, update:    2300, cost:   0.708017
Validation 23 - LOSS = 1.688 (PPL: 5.407)
Calling beam-search process
Beam-search ended, took 1.62895 minutes.
Validation 23 - BLEU = 14.88, 27.0/17.3/12.2/8.6 (BP=1.000, ratio=2.191, hyp_len=9247, ref_len=4220)
Early stopping patience: 993 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -0.279719
Gradient professor: 26.418927
Loss Generator D: 3.070844
Loss Generator P: 0.781177
Gradient discriminator: -10.670146
Gradient professor: -15.895180
Loss Generator D: 3.289978
Loss Generator P: 0.753266
Gradient discriminator: 13.324274
Gradient professor: 0.700593
Loss Generator D: 2.434854
Loss Generator P: 0.657774
Gradient discriminator: -1.985232
Gradient professor: 5.339160
Loss Generator D: 2.873936
Loss Generator P: 0.805316
Gradient discriminator: 3.329856
Gradient professor: -51.690292
Loss Generator D: 2.735274
Loss Generator P: 0.772896
Gradient discriminator: -11.516228
Gradient professor: 5.770930
Loss Generator D: 2.643980
Loss Generator P: 0.624060
Gradient discriminator: 10.516518
Gradient professor: 29.313428
Loss Generator D: 2.374587
Loss Generator P: 0.626086
Gradient discriminator: -6.278846
Gradient professor: 9.621331
Loss Generator D: 3.312488
Loss Generator P: 0.578975
Gradient discriminator: -9.915330
Gradient professor: 17.380415
Loss Generator D: 3.210783
Loss Generator P: 0.630953
Gradient discriminator: -10.762977
Gradient professor: -20.732580
Loss Generator D: 3.179681
Loss Generator P: 0.755556
Generator    : Epoch:     10, update:    2310, cost:   0.755556
Gradient discriminator: 7.601929
Gradient professor: 10.673888
Loss Generator D: 3.162160
Loss Generator P: 0.706617
Gradient discriminator: 2.334561
Gradient professor: 9.100374
Loss Generator D: 3.098820
Loss Generator P: 0.863001
Gradient discriminator: 8.458660
Gradient professor: 17.406159
Loss Generator D: 2.799240
Loss Generator P: 0.685987
Gradient discriminator: -0.307002
Gradient professor: 12.494657
Loss Generator D: 3.062123
Loss Generator P: 0.633758
Gradient discriminator: 2.391653
Gradient professor: -21.526790
Loss Generator D: 2.601012
Loss Generator P: 0.818854
Gradient discriminator: 2.139578
Gradient professor: -5.068612
Loss Generator D: 2.584363
Loss Generator P: 0.729374
Gradient discriminator: 4.024472
Gradient professor: -21.469746
Loss Generator D: 3.540745
Loss Generator P: 0.697457
Gradient discriminator: 4.929924
Gradient professor: 5.652712
Loss Generator D: 3.495504
Loss Generator P: 0.687785
Gradient discriminator: 5.853365
Gradient professor: 0.546260
Loss Generator D: 3.719555
Loss Generator P: 0.862366
Gradient discriminator: 0.561834
Gradient professor: -11.731488
Loss Generator D: 3.121916
Loss Generator P: 0.756416
Generator    : Epoch:     10, update:    2320, cost:   0.756416
Gradient discriminator: 4.023080
Gradient professor: -6.675538
Loss Generator D: 3.576246
Loss Generator P: 0.626508
Gradient discriminator: 10.306574
Gradient professor: -13.642706
Loss Generator D: 3.456244
Loss Generator P: 0.601897
Gradient discriminator: 7.162310
Gradient professor: 12.332180
Loss Generator D: 2.789114
Loss Generator P: 0.743005
Gradient discriminator: -6.725993
Gradient professor: -12.775518
Loss Generator D: 3.187933
Loss Generator P: 0.738711
Gradient discriminator: -5.663103
Gradient professor: 3.513408
Loss Generator D: 2.805675
Loss Generator P: 0.656588
Gradient discriminator: -4.839724
Gradient professor: -8.921287
Loss Generator D: 2.240863
Loss Generator P: 0.641514
Gradient discriminator: 3.550092
Gradient professor: 7.116139
Loss Generator D: 3.415514
Loss Generator P: 0.709451
Gradient discriminator: 6.359907
Gradient professor: 9.160795
Loss Generator D: 2.980483
Loss Generator P: 0.796466
Gradient discriminator: 4.859453
Gradient professor: -4.184247
Loss Generator D: 2.562539
Loss Generator P: 0.495465
Gradient discriminator: 3.435447
Gradient professor: -8.036247
Loss Generator D: 2.835338
Loss Generator P: 0.519144
Generator    : Epoch:     10, update:    2330, cost:   0.519144
Gradient discriminator: -0.629229
Gradient professor: -4.729679
Loss Generator D: 3.371308
Loss Generator P: 0.557351
Gradient discriminator: 0.855865
Gradient professor: -10.762647
Loss Generator D: 3.242085
Loss Generator P: 0.597527
Gradient discriminator: -8.522423
Gradient professor: -29.537207
Loss Generator D: 2.774909
Loss Generator P: 0.571704
Gradient discriminator: 12.756059
Gradient professor: -3.730600
Loss Generator D: 2.677977
Loss Generator P: 0.409649
Gradient discriminator: 3.642596
Gradient professor: 1.514390
Loss Generator D: 3.344841
Loss Generator P: 0.473367
Gradient discriminator: -16.138891
Gradient professor: -15.360166
Loss Generator D: 2.768794
Loss Generator P: 0.484699
Gradient discriminator: -3.485871
Gradient professor: -0.344993
Loss Generator D: 3.037671
Loss Generator P: 0.537050
Gradient discriminator: 2.940180
Gradient professor: 6.606075
Loss Generator D: 3.076649
Loss Generator P: 0.724452
Gradient discriminator: 1.353575
Gradient professor: -14.793063
Loss Generator D: 2.935054
Loss Generator P: 0.597337
Gradient discriminator: 1.575347
Gradient professor: 2.055688
Loss Generator D: 2.904926
Loss Generator P: 0.808737
Generator    : Epoch:     10, update:    2340, cost:   0.808737
Gradient discriminator: -7.820374
Gradient professor: 18.163415
Loss Generator D: 3.052435
Loss Generator P: 0.575026
Gradient discriminator: 2.253765
Gradient professor: 5.714494
Loss Generator D: 2.736049
Loss Generator P: 0.879947
Gradient discriminator: 13.952016
Gradient professor: -3.583543
Loss Generator D: 2.794549
Loss Generator P: 0.601244
Gradient discriminator: 7.730843
Gradient professor: 4.963894
Loss Generator D: 2.956263
Loss Generator P: 0.508285
Gradient discriminator: 18.692648
Gradient professor: -7.727978
Loss Generator D: 3.123727
Loss Generator P: 0.622538
Gradient discriminator: 6.575702
Gradient professor: 8.194282
Loss Generator D: 3.120873
Loss Generator P: 0.587054
Gradient discriminator: 2.799246
Gradient professor: -17.822080
Loss Generator D: 3.549262
Loss Generator P: 0.606066
Gradient discriminator: -11.359053
Gradient professor: 17.649902
Loss Generator D: 2.761230
Loss Generator P: 0.576265
Gradient discriminator: -17.752866
Gradient professor: 2.066217
Loss Generator D: 3.185487
Loss Generator P: 0.546778
Gradient discriminator: -8.159359
Gradient professor: 1.929129
Loss Generator D: 3.424204
Loss Generator P: 0.632141
Generator    : Epoch:     10, update:    2350, cost:   0.632141
Gradient discriminator: -13.669933
Gradient professor: 9.251544
Loss Generator D: 3.329022
Loss Generator P: 0.741584
Gradient discriminator: -0.571385
Gradient professor: -15.499488
Loss Generator D: 2.771197
Loss Generator P: 0.673557
Gradient discriminator: 2.178548
Gradient professor: -19.857728
Loss Generator D: 2.912629
Loss Generator P: 0.581201
Gradient discriminator: -25.494518
Gradient professor: 12.268106
Loss Generator D: 2.480025
Loss Generator P: 0.609273
Gradient discriminator: 1.013949
Gradient professor: -19.815525
Loss Generator D: 2.709690
Loss Generator P: 0.455254
Gradient discriminator: 18.178114
Gradient professor: 7.768299
Loss Generator D: 3.133710
Loss Generator P: 0.677251
Gradient discriminator: -4.137346
Gradient professor: -32.439921
Loss Generator D: 2.592040
Loss Generator P: 0.502988
Gradient discriminator: 1.607302
Gradient professor: -7.910069
Loss Generator D: 2.784986
Loss Generator P: 0.562449
Gradient discriminator: -8.596231
Gradient professor: 15.596297
Loss Generator D: 3.209571
Loss Generator P: 0.666049
Gradient discriminator: -14.762830
Gradient professor: -17.732643
Loss Generator D: 2.659915
Loss Generator P: 0.540978
Generator    : Epoch:     10, update:    2360, cost:   0.540978
Gradient discriminator: 9.780328
Gradient professor: -1.054750
Loss Generator D: 2.685039
Loss Generator P: 0.688891
Gradient discriminator: 18.415502
Gradient professor: 19.119359
Loss Generator D: 2.777251
Loss Generator P: 0.609964
Gradient discriminator: 5.551481
Gradient professor: 0.670838
Loss Generator D: 3.030615
Loss Generator P: 0.530909
Gradient discriminator: -3.471591
Gradient professor: -3.107399
Loss Generator D: 2.687443
Loss Generator P: 0.497727
Gradient discriminator: 4.611471
Gradient professor: -2.831320
Loss Generator D: 2.849652
Loss Generator P: 0.660551
Gradient discriminator: 8.140387
Gradient professor: -10.550772
Loss Generator D: 2.490282
Loss Generator P: 0.718323
Gradient discriminator: -16.254539
Gradient professor: -3.364983
Loss Generator D: 2.818105
Loss Generator P: 0.500306
Gradient discriminator: -1.504940
Gradient professor: 7.067187
Loss Generator D: 2.752473
Loss Generator P: 0.739819
Gradient discriminator: 2.332578
Gradient professor: 10.415415
Loss Generator D: 2.912055
Loss Generator P: 0.575464
Gradient discriminator: 5.687108
Gradient professor: 9.936930
Loss Generator D: 2.819787
Loss Generator P: 0.624642
Generator    : Epoch:     10, update:    2370, cost:   0.624642
Gradient discriminator: 20.104256
Gradient professor: 14.527835
Loss Generator D: 2.311725
Loss Generator P: 0.590750
Gradient discriminator: -27.794966
Gradient professor: -5.734917
Loss Generator D: 2.326113
Loss Generator P: 0.691420
Gradient discriminator: 32.880301
Gradient professor: -21.902421
Loss Generator D: 2.610771
Loss Generator P: 0.647034
Gradient discriminator: -9.387859
Gradient professor: 26.249970
Loss Generator D: 2.757682
Loss Generator P: 0.748397
Gradient discriminator: -12.305680
Gradient professor: 59.983774
Loss Generator D: 2.315644
Loss Generator P: 0.737056
Gradient discriminator: 17.450032
Gradient professor: -14.910135
Loss Generator D: 2.556300
Loss Generator P: 0.684115
Gradient discriminator: 8.030615
Gradient professor: -6.338626
Loss Generator D: 2.594159
Loss Generator P: 0.686274
Gradient discriminator: 7.153017
Gradient professor: 33.245319
Loss Generator D: 3.065719
Loss Generator P: 0.816062
Gradient discriminator: 2.586739
Gradient professor: -22.504289
Loss Generator D: 2.768106
Loss Generator P: 0.727967
Gradient discriminator: -2.535240
Gradient professor: -36.753433
Loss Generator D: 2.802846
Loss Generator P: 0.739947
Generator    : Epoch:     10, update:    2380, cost:   0.739947
Gradient discriminator: -7.597225
Gradient professor: -11.296195
Loss Generator D: 2.493423
Loss Generator P: 0.573078
Gradient discriminator: -4.011738
Gradient professor: -30.194712
Loss Generator D: 2.473752
Loss Generator P: 0.615108
Gradient discriminator: -21.099196
Gradient professor: 27.404028
Loss Generator D: 1.973714
Loss Generator P: 0.515772
Gradient discriminator: -3.059167
Gradient professor: -28.151832
Loss Generator D: 2.774060
Loss Generator P: 0.854902
Gradient discriminator: -3.764136
Gradient professor: 9.901438
Loss Generator D: 2.256820
Loss Generator P: 0.654303
Gradient discriminator: 0.367000
Gradient professor: 7.914561
Loss Generator D: 2.675273
Loss Generator P: 0.488691
Gradient discriminator: 4.284774
Gradient professor: -12.702070
Loss Generator D: 2.780397
Loss Generator P: 0.661882
Gradient discriminator: -14.957944
Gradient professor: 9.117057
Loss Generator D: 2.585096
Loss Generator P: 0.476647
Gradient discriminator: 8.098617
Gradient professor: 20.661546
Loss Generator D: 2.610609
Loss Generator P: 0.700845
Gradient discriminator: 5.327293
Gradient professor: -0.434360
Loss Generator D: 2.635272
Loss Generator P: 0.643663
Generator    : Epoch:     10, update:    2390, cost:   0.643663
Gradient discriminator: -4.300185
Gradient professor: -6.644751
Loss Generator D: 2.518252
Loss Generator P: 0.562288
Gradient discriminator: 22.565794
Gradient professor: -3.148245
Loss Generator D: 2.386815
Loss Generator P: 0.691332
Gradient discriminator: 3.265987
Gradient professor: 14.510184
Loss Generator D: 2.206223
Loss Generator P: 0.834182
Gradient discriminator: 6.210425
Gradient professor: -35.907840
Loss Generator D: 1.820269
Loss Generator P: 0.721190
Gradient discriminator: 6.569678
Gradient professor: -43.851079
Loss Generator D: 1.914364
Loss Generator P: 0.794254
Gradient discriminator: 11.253237
Gradient professor: -12.447186
Loss Generator D: 2.168663
Loss Generator P: 0.817958
Gradient discriminator: -2.357647
Gradient professor: 3.767928
Loss Generator D: 1.901303
Loss Generator P: 0.505168
Gradient discriminator: 7.436785
Gradient professor: 3.933473
Loss Generator D: 2.366121
Loss Generator P: 0.557011
Gradient discriminator: -0.641855
Gradient professor: -24.961432
Loss Generator D: 2.536671
Loss Generator P: 0.573316
Gradient discriminator: 2.915919
Gradient professor: -1.072585
Loss Generator D: 2.509783
Loss Generator P: 0.523528
Generator    : Epoch:     10, update:    2400, cost:   0.523528
Validation 24 - LOSS = 1.672 (PPL: 5.323)
Calling beam-search process
Beam-search ended, took 2.09724 minutes.
Validation 24 - BLEU = 7.81, 15.3/9.4/6.3/4.1 (BP=1.000, ratio=3.868, hyp_len=16321, ref_len=4220)
Early stopping patience: 992 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -3.541848
Gradient professor: -15.414639
Loss Generator D: 2.443440
Loss Generator P: 0.709079
Gradient discriminator: -5.319098
Gradient professor: 19.905228
Loss Generator D: 2.099114
Loss Generator P: 0.680473
Gradient discriminator: 3.688591
Gradient professor: -1.782539
Loss Generator D: 2.225437
Loss Generator P: 0.692092
Gradient discriminator: -1.991583
Gradient professor: -20.143328
Loss Generator D: 1.896598
Loss Generator P: 0.559796
Gradient discriminator: 27.604078
Gradient professor: -4.220568
Loss Generator D: 2.034723
Loss Generator P: 0.696891
Gradient discriminator: 11.291182
Gradient professor: -3.518005
Loss Generator D: 2.337327
Loss Generator P: 0.599592
Gradient discriminator: 14.101613
Gradient professor: -7.524240
Loss Generator D: 2.550020
Loss Generator P: 0.668184
Gradient discriminator: 12.581030
Gradient professor: 14.816896
Loss Generator D: 2.252696
Loss Generator P: 0.515016
Gradient discriminator: 13.948077
Gradient professor: -2.702747
Loss Generator D: 2.665175
Loss Generator P: 0.511977
Gradient discriminator: -11.470696
Gradient professor: 2.004693
Loss Generator D: 2.355475
Loss Generator P: 0.644518
Generator    : Epoch:     10, update:    2410, cost:   0.644518
Gradient discriminator: 6.838951
Gradient professor: -1.334997
Loss Generator D: 2.557420
Loss Generator P: 0.641208
Gradient discriminator: 7.528537
Gradient professor: -1.017446
Loss Generator D: 2.316427
Loss Generator P: 0.795015
Gradient discriminator: 4.621062
Gradient professor: 13.174568
Loss Generator D: 2.605859
Loss Generator P: 0.776680
Gradient discriminator: 5.962906
Gradient professor: -14.900110
Loss Generator D: 2.920883
Loss Generator P: 0.775778
Gradient discriminator: -9.594142
Gradient professor: 26.684453
Loss Generator D: 2.525912
Loss Generator P: 0.860303
Gradient discriminator: 4.489608
Gradient professor: 11.339077
Loss Generator D: 2.404196
Loss Generator P: 0.735490
Gradient discriminator: 9.842401
Gradient professor: 27.401013
Loss Generator D: 2.394488
Loss Generator P: 0.831509
Gradient discriminator: 7.372283
Gradient professor: 2.091569
Loss Generator D: 2.792686
Loss Generator P: 0.577528
Gradient discriminator: 16.803973
Gradient professor: -21.141373
Loss Generator D: 2.377582
Loss Generator P: 0.736184
Gradient discriminator: -0.545590
Gradient professor: -16.942349
Loss Generator D: 2.346290
Loss Generator P: 0.751359
Generator    : Epoch:     10, update:    2420, cost:   0.751359
Gradient discriminator: 8.304812
Gradient professor: -23.389061
Loss Generator D: 2.190516
Loss Generator P: 0.597033
Gradient discriminator: 21.633726
Gradient professor: 9.132653
Loss Generator D: 1.988263
Loss Generator P: 0.565921
Gradient discriminator: -1.196901
Gradient professor: 11.007227
Loss Generator D: 2.522300
Loss Generator P: 0.632031
Gradient discriminator: 4.881398
Gradient professor: -5.291179
Loss Generator D: 2.452608
Loss Generator P: 0.489283
Gradient discriminator: 3.314090
Gradient professor: -9.121583
Loss Generator D: 2.675798
Loss Generator P: 0.590968
Gradient discriminator: 6.009956
Gradient professor: 17.104966
Loss Generator D: 2.450902
Loss Generator P: 0.623419
Gradient discriminator: 14.595301
Gradient professor: 9.158362
Loss Generator D: 2.342775
Loss Generator P: 0.813977
Gradient discriminator: -8.824376
Gradient professor: -16.924416
Loss Generator D: 2.098490
Loss Generator P: 0.895517
Gradient discriminator: 22.792753
Gradient professor: 12.086343
Loss Generator D: 2.197257
Loss Generator P: 0.833583
Gradient discriminator: 2.852087
Gradient professor: -3.594617
Loss Generator D: 2.353708
Loss Generator P: 0.562667
Generator    : Epoch:     10, update:    2430, cost:   0.562667
Gradient discriminator: 12.993035
Gradient professor: -2.848614
Loss Generator D: 1.947451
Loss Generator P: 0.709062
Gradient discriminator: -13.765710
Gradient professor: 0.676030
Loss Generator D: 1.482665
Loss Generator P: 0.674695
Gradient discriminator: -3.992077
Gradient professor: 2.887524
Loss Generator D: 1.744159
Loss Generator P: 0.654072
Gradient discriminator: 4.029973
Gradient professor: 4.055377
Loss Generator D: 2.288513
Loss Generator P: 0.821161
Gradient discriminator: 12.229744
Gradient professor: -16.728385
Loss Generator D: 2.126226
Loss Generator P: 0.797654
Gradient discriminator: -0.877481
Gradient professor: 6.075848
Loss Generator D: 2.052812
Loss Generator P: 0.655229
Gradient discriminator: 9.888959
Gradient professor: 3.397159
Loss Generator D: 1.956901
Loss Generator P: 0.745593
Gradient discriminator: -5.247516
Gradient professor: -5.740921
Loss Generator D: 1.701906
Loss Generator P: 0.812491
Gradient discriminator: -6.789251
Gradient professor: 12.841399
Loss Generator D: 2.332796
Loss Generator P: 0.811194
Gradient discriminator: 15.475022
Gradient professor: -16.270420
Loss Generator D: 2.269836
Loss Generator P: 0.793305
Generator    : Epoch:     10, update:    2440, cost:   0.793305
Gradient discriminator: -1.039789
Gradient professor: 6.237640
Loss Generator D: 2.344041
Loss Generator P: 0.817996
Gradient discriminator: 15.866855
Gradient professor: 2.592772
Loss Generator D: 2.622310
Loss Generator P: 0.602433
Gradient discriminator: -3.175736
Gradient professor: -14.765643
Loss Generator D: 2.501934
Loss Generator P: 1.013152
Gradient discriminator: -5.836369
Gradient professor: 38.085126
Loss Generator D: 1.933146
Loss Generator P: 0.907514
Gradient discriminator: 0.798169
Gradient professor: -3.503639
Loss Generator D: 2.044693
Loss Generator P: 0.540853
Gradient discriminator: 13.387770
Gradient professor: 11.067560
Loss Generator D: 2.356916
Loss Generator P: 0.759168
Gradient discriminator: 5.173885
Gradient professor: -4.422228
Loss Generator D: 2.595253
Loss Generator P: 0.744282
Gradient discriminator: 7.862534
Gradient professor: -14.493999
Loss Generator D: 2.013109
Loss Generator P: 0.839011
Gradient discriminator: -3.613454
Gradient professor: -27.740564
Loss Generator D: 2.432688
Loss Generator P: 0.766796
Gradient discriminator: 0.925711
Gradient professor: -3.361904
Loss Generator D: 2.733643
Loss Generator P: 0.666736
Generator    : Epoch:     10, update:    2450, cost:   0.666736
Gradient discriminator: 13.308541
Gradient professor: 8.785406
Loss Generator D: 2.629613
Loss Generator P: 0.697372
Gradient discriminator: 10.847842
Gradient professor: -19.849733
Loss Generator D: 2.212167
Loss Generator P: 0.722501
Gradient discriminator: -12.205774
Gradient professor: -2.446590
Loss Generator D: 2.556612
Loss Generator P: 0.618666
Gradient discriminator: 5.513939
Gradient professor: -1.352943
Loss Generator D: 2.785553
Loss Generator P: 0.651618
Gradient discriminator: 2.919742
Gradient professor: -14.732892
Loss Generator D: 2.382630
Loss Generator P: 0.559414
Gradient discriminator: -4.279238
Gradient professor: -1.077692
Loss Generator D: 2.567780
Loss Generator P: 0.515828
Gradient discriminator: 7.316894
Gradient professor: -3.957011
Loss Generator D: 2.850582
Loss Generator P: 0.711177
Gradient discriminator: 5.026369
Gradient professor: 7.466796
Loss Generator D: 2.627734
Loss Generator P: 0.773989
Gradient discriminator: 2.832819
Gradient professor: 5.517607
Loss Generator D: 2.162475
Loss Generator P: 0.628978
Gradient discriminator: 8.981105
Gradient professor: -30.029087
Loss Generator D: 2.597938
Loss Generator P: 0.707257
Generator    : Epoch:     10, update:    2460, cost:   0.707257
Gradient discriminator: 12.489297
Gradient professor: 11.511214
Loss Generator D: 2.629937
Loss Generator P: 0.785031
Gradient discriminator: -4.378080
Gradient professor: -9.088850
Loss Generator D: 2.448973
Loss Generator P: 0.777973
Gradient discriminator: -0.738099
Gradient professor: 17.326208
Loss Generator D: 2.711972
Loss Generator P: 0.689063
Gradient discriminator: 23.843891
Gradient professor: -1.672427
Loss Generator D: 2.394307
Loss Generator P: 0.577089
Gradient discriminator: 10.396998
Gradient professor: 23.582387
Loss Generator D: 2.256852
Loss Generator P: 0.715383
Gradient discriminator: -2.939802
Gradient professor: -11.924368
Loss Generator D: 2.605027
Loss Generator P: 0.744158
Gradient discriminator: 6.019201
Gradient professor: -2.351090
Loss Generator D: 2.268055
Loss Generator P: 0.740035
Gradient discriminator: 0.306172
Gradient professor: -5.969746
Loss Generator D: 1.938122
Loss Generator P: 0.605580
Gradient discriminator: -26.056818
Gradient professor: -11.821869
Loss Generator D: 2.014921
Loss Generator P: 0.563061
Gradient discriminator: -10.784990
Gradient professor: -7.430555
Loss Generator D: 1.805758
Loss Generator P: 0.518618
Generator    : Epoch:     10, update:    2470, cost:   0.518618
Gradient discriminator: -19.108895
Gradient professor: -8.894137
Loss Generator D: 1.591345
Loss Generator P: 0.600716
Gradient discriminator: -6.875194
Gradient professor: -7.211372
Loss Generator D: 1.888098
Loss Generator P: 0.641342
Gradient discriminator: 0.341659
Gradient professor: 1.557737
Loss Generator D: 1.658687
Loss Generator P: 0.676006
Gradient discriminator: 3.219093
Gradient professor: -13.235415
Loss Generator D: 1.696533
Loss Generator P: 0.529572
Gradient discriminator: -3.700124
Gradient professor: 5.635707
Loss Generator D: 1.687727
Loss Generator P: 0.549086
Gradient discriminator: 9.287089
Gradient professor: -19.991300
Loss Generator D: 1.471531
Loss Generator P: 0.648023
Gradient discriminator: 7.283242
Gradient professor: 24.679899
Loss Generator D: 2.109518
Loss Generator P: 0.572527
Gradient discriminator: -22.388647
Gradient professor: -7.510372
Loss Generator D: 1.764963
Loss Generator P: 0.570220
Gradient discriminator: 4.256991
Gradient professor: 22.565231
Loss Generator D: 1.688991
Loss Generator P: 0.602704
Gradient discriminator: -8.679122
Gradient professor: -8.786004
Loss Generator D: 1.766599
Loss Generator P: 0.617992
Generator    : Epoch:     10, update:    2480, cost:   0.617992
Gradient discriminator: -6.537081
Gradient professor: -20.390940
Loss Generator D: 1.786155
Loss Generator P: 0.720827
Gradient discriminator: 12.276691
Gradient professor: 8.804743
Loss Generator D: 2.043468
Loss Generator P: 0.745659
Gradient discriminator: -33.103679
Gradient professor: -0.770188
Loss Generator D: 2.068201
Loss Generator P: 0.790397
Gradient discriminator: -4.946057
Gradient professor: 4.703137
Loss Generator D: 2.364216
Loss Generator P: 0.469408
Gradient discriminator: 5.580648
Gradient professor: -44.496795
Loss Generator D: 2.216774
Loss Generator P: 0.616562
Gradient discriminator: 13.064838
Gradient professor: -2.470083
Loss Generator D: 2.186361
Loss Generator P: 0.611445
Gradient discriminator: -2.667574
Gradient professor: 4.189156
Loss Generator D: 2.836890
Loss Generator P: 0.496140
Gradient discriminator: -23.367742
Gradient professor: 6.103163
Loss Generator D: 2.246147
Loss Generator P: 0.642175
Gradient discriminator: -14.167127
Gradient professor: 8.514289
Loss Generator D: 2.292407
Loss Generator P: 0.628652
Gradient discriminator: -16.792574
Gradient professor: 22.501821
Loss Generator D: 1.898207
Loss Generator P: 0.564269
Generator    : Epoch:     10, update:    2490, cost:   0.564269
Gradient discriminator: -11.186740
Gradient professor: -13.533942
Loss Generator D: 2.297090
Loss Generator P: 0.635751
Gradient discriminator: -13.952141
Gradient professor: 20.568313
Loss Generator D: 2.038515
Loss Generator P: 0.662969
Gradient discriminator: -22.716427
Gradient professor: -0.743522
Loss Generator D: 2.431786
Loss Generator P: 0.605353
Gradient discriminator: -11.957232
Gradient professor: 5.912734
Loss Generator D: 2.123275
Loss Generator P: 0.620434
Gradient discriminator: -121.609681
Gradient professor: 3.934000
Loss Generator D: 3.128138
Loss Generator P: 0.738768
Gradient discriminator: 5.972496
Gradient professor: -6.743252
Loss Generator D: 2.626142
Loss Generator P: 0.595006
Gradient discriminator: 13.162396
Gradient professor: 9.414859
Loss Generator D: 3.316354
Loss Generator P: 0.664737
Gradient discriminator: -6.194321
Gradient professor: -1.174280
Loss Generator D: 2.723977
Loss Generator P: 0.589195
Gradient discriminator: 6.061727
Gradient professor: 5.635110
Loss Generator D: 2.629004
Loss Generator P: 0.625142
Gradient discriminator: -8.899917
Gradient professor: -10.544785
Loss Generator D: 2.645287
Loss Generator P: 0.439926
Generator    : Epoch:     10, update:    2500, cost:   0.439926
Validation 25 - LOSS = 1.611 (PPL: 5.010)
Calling beam-search process
Beam-search ended, took 2.56087 minutes.
Validation 25 - BLEU = 6.65, 12.3/8.0/5.5/3.7 (BP=1.000, ratio=4.857, hyp_len=20497, ref_len=4220)
Early stopping patience: 991 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 10 finished with mean loss 1.62013 (PPL: 5.05377)
--> Epoch took 286.181 minutes, 68.683 sec/update
Epoch summary of Discriminator:
--> Epoch 10 finished with mean loss nan (PPL:  nan)
--> Epoch took 286.181 minutes, 68.683 sec/update
---------------------------------------------------------
Starting Epoch 11
-----------------
Gradient discriminator: 18.602034
Gradient professor: 12.998283
Loss Generator D: 1.965855
Loss Generator P: 0.822712
Gradient discriminator: -3.957089
Gradient professor: -8.637735
Loss Generator D: 2.910386
Loss Generator P: 0.635144
Gradient discriminator: -1.418106
Gradient professor: 14.831455
Loss Generator D: 3.119064
Loss Generator P: 0.630157
Gradient discriminator: -0.053209
Gradient professor: 0.014829
Loss Generator D: 2.419213
Loss Generator P: 0.813046
Gradient discriminator: 0.398512
Gradient professor: -25.200724
Loss Generator D: 2.611693
Loss Generator P: 0.600949
Gradient discriminator: -5.167074
Gradient professor: -10.383801
Loss Generator D: 2.346219
Loss Generator P: 0.741267
Gradient discriminator: -3.692421
Gradient professor: 13.237413
Loss Generator D: 2.911748
Loss Generator P: 0.725778
Gradient discriminator: 12.720792
Gradient professor: 36.540404
Loss Generator D: 2.089173
Loss Generator P: 0.613387
Gradient discriminator: -8.536157
Gradient professor: -50.737373
Loss Generator D: 2.328354
Loss Generator P: 0.816996
Gradient discriminator: 1.862036
Gradient professor: 7.300573
Loss Generator D: 2.142479
Loss Generator P: 0.853323
Generator    : Epoch:     11, update:    2510, cost:   0.853323
Gradient discriminator: 7.130868
Gradient professor: 17.049163
Loss Generator D: 2.463525
Loss Generator P: 0.920794
Gradient discriminator: 6.383206
Gradient professor: -15.210474
Loss Generator D: 2.255701
Loss Generator P: 0.658428
Gradient discriminator: -5.504646
Gradient professor: 17.583975
Loss Generator D: 2.084844
Loss Generator P: 0.833976
Gradient discriminator: -5.955024
Gradient professor: 0.806528
Loss Generator D: 2.306951
Loss Generator P: 0.719864
Gradient discriminator: 3.467310
Gradient professor: 8.591341
Loss Generator D: 2.995452
Loss Generator P: 0.542261
Gradient discriminator: -26.043348
Gradient professor: 20.183088
Loss Generator D: 2.843066
Loss Generator P: 0.452051
Gradient discriminator: 1.901372
Gradient professor: -70.343316
Loss Generator D: 2.859771
Loss Generator P: 0.731075
Gradient discriminator: -1.942791
Gradient professor: 4.919885
Loss Generator D: 2.553134
Loss Generator P: 0.628069
Gradient discriminator: 8.485748
Gradient professor: 2.788841
Loss Generator D: 2.536094
Loss Generator P: 0.740368
Gradient discriminator: -0.390977
Gradient professor: 10.714232
Loss Generator D: 2.380110
Loss Generator P: 0.741257
Generator    : Epoch:     11, update:    2520, cost:   0.741257
Gradient discriminator: -2.511997
Gradient professor: -4.996819
Loss Generator D: 2.482756
Loss Generator P: 0.649438
Gradient discriminator: 16.955069
Gradient professor: 10.919961
Loss Generator D: 2.384876
Loss Generator P: 0.573887
Gradient discriminator: 4.925490
Gradient professor: -16.491962
Loss Generator D: 2.563807
Loss Generator P: 0.627256
Gradient discriminator: -7.817300
Gradient professor: -6.851673
Loss Generator D: 2.685793
Loss Generator P: 0.861459
Gradient discriminator: 8.424242
Gradient professor: -12.341634
Loss Generator D: 2.808184
Loss Generator P: 0.839565
Gradient discriminator: 5.345055
Gradient professor: -3.727838
Loss Generator D: 2.451571
Loss Generator P: 0.646483
Gradient discriminator: 10.109259
Gradient professor: -4.761881
Loss Generator D: 2.364080
Loss Generator P: 0.518271
Gradient discriminator: -3.658015
Gradient professor: 30.544804
Loss Generator D: 2.191060
Loss Generator P: 0.612128
Gradient discriminator: 6.921493
Gradient professor: 4.732062
Loss Generator D: 2.211780
Loss Generator P: 0.564270
Gradient discriminator: 14.297313
Gradient professor: -0.545749
Loss Generator D: 2.409336
Loss Generator P: 0.613018
Generator    : Epoch:     11, update:    2530, cost:   0.613018
Gradient discriminator: -3.121791
Gradient professor: 13.599194
Loss Generator D: 2.637024
Loss Generator P: 0.537947
Gradient discriminator: 16.606155
Gradient professor: 4.008179
Loss Generator D: 2.680603
Loss Generator P: 0.548140
Gradient discriminator: 17.483185
Gradient professor: -9.656732
Loss Generator D: 3.002861
Loss Generator P: 0.785217
Gradient discriminator: -23.482655
Gradient professor: -3.933834
Loss Generator D: 2.499101
Loss Generator P: 0.827224
Gradient discriminator: 3.016653
Gradient professor: 18.794928
Loss Generator D: 2.693226
Loss Generator P: 0.610007
Gradient discriminator: 7.120564
Gradient professor: 0.018040
Loss Generator D: 2.729787
Loss Generator P: 0.561599
Gradient discriminator: 9.739570
Gradient professor: 3.715964
Loss Generator D: 2.611281
Loss Generator P: 0.528127
Gradient discriminator: 7.659376
Gradient professor: 14.697487
Loss Generator D: 3.009621
Loss Generator P: 0.620881
Gradient discriminator: 0.958898
Gradient professor: 5.787482
Loss Generator D: 2.728698
Loss Generator P: 0.583952
Gradient discriminator: 9.089128
Gradient professor: 4.326384
Loss Generator D: 3.133832
Loss Generator P: 0.779113
Generator    : Epoch:     11, update:    2540, cost:   0.779113
Gradient discriminator: 13.812147
Gradient professor: 13.156920
Loss Generator D: 2.362381
Loss Generator P: 0.605650
Gradient discriminator: -6.251305
Gradient professor: 20.249911
Loss Generator D: 2.631631
Loss Generator P: 0.627771
Gradient discriminator: -1.270911
Gradient professor: -7.346737
Loss Generator D: 2.432598
Loss Generator P: 0.678140
Gradient discriminator: 1.983218
Gradient professor: 4.306220
Loss Generator D: 1.981990
Loss Generator P: 0.580691
Gradient discriminator: 10.605912
Gradient professor: -12.705599
Loss Generator D: 1.410387
Loss Generator P: 0.766395
Gradient discriminator: -0.647879
Gradient professor: 5.389165
Loss Generator D: 1.678442
Loss Generator P: 0.671550
Gradient discriminator: 29.368992
Gradient professor: 20.223231
Loss Generator D: 1.776925
Loss Generator P: 0.557369
Gradient discriminator: -4.455400
Gradient professor: -5.571558
Loss Generator D: 2.354095
Loss Generator P: 0.690958
Gradient discriminator: -5.451401
Gradient professor: 4.464104
Loss Generator D: 2.104478
Loss Generator P: 0.867683
Gradient discriminator: 4.993054
Gradient professor: -14.263233
Loss Generator D: 2.434135
Loss Generator P: 0.678764
Generator    : Epoch:     11, update:    2550, cost:   0.678764
Gradient discriminator: -5.086939
Gradient professor: 1.799826
Loss Generator D: 2.676257
Loss Generator P: 0.742460
Gradient discriminator: 1.274044
Gradient professor: 5.536724
Loss Generator D: 2.967322
Loss Generator P: 0.681095
Gradient discriminator: 10.832602
Gradient professor: -9.475533
Loss Generator D: 2.290800
Loss Generator P: 0.576521
Gradient discriminator: -8.498592
Gradient professor: -32.134077
Loss Generator D: 2.152147
Loss Generator P: 0.767004
Gradient discriminator: 0.692569
Gradient professor: -13.946628
Loss Generator D: 2.608315
Loss Generator P: 0.716460
Gradient discriminator: -0.038685
Gradient professor: -11.119221
Loss Generator D: 2.801550
Loss Generator P: 0.594256
Gradient discriminator: -0.104237
Gradient professor: 7.396643
Loss Generator D: 2.366636
Loss Generator P: 0.588266
Gradient discriminator: 11.043258
Gradient professor: 11.912088
Loss Generator D: 3.324792
Loss Generator P: 0.559688
Gradient discriminator: -0.396964
Gradient professor: 5.015695
Loss Generator D: 3.012111
Loss Generator P: 0.585571
Gradient discriminator: -1.259474
Gradient professor: -6.359487
Loss Generator D: 2.830762
Loss Generator P: 0.670521
Generator    : Epoch:     11, update:    2560, cost:   0.670521
Gradient discriminator: 2.406931
Gradient professor: 1.622500
Loss Generator D: 3.009848
Loss Generator P: 0.621052
Gradient discriminator: 8.229666
Gradient professor: 12.267396
Loss Generator D: 2.761264
Loss Generator P: 0.816932
Gradient discriminator: -11.642189
Gradient professor: 6.029644
Loss Generator D: 2.679450
Loss Generator P: 0.635045
Gradient discriminator: 6.104258
Gradient professor: -4.245346
Loss Generator D: 2.894509
Loss Generator P: 0.605111
Gradient discriminator: 21.260290
Gradient professor: -19.686929
Loss Generator D: 2.661035
Loss Generator P: 0.753308
Gradient discriminator: 11.973540
Gradient professor: -11.644451
Loss Generator D: 2.242413
Loss Generator P: 0.672749
Gradient discriminator: -3.142547
Gradient professor: -13.078572
Loss Generator D: 2.895882
Loss Generator P: 0.652252
Gradient discriminator: 25.624115
Gradient professor: 13.066512
Loss Generator D: 3.184597
Loss Generator P: 0.595665
Gradient discriminator: 42.884361
Gradient professor: 12.057835
Loss Generator D: 3.080326
Loss Generator P: 0.787767
Gradient discriminator: 16.823321
Gradient professor: -16.763522
Loss Generator D: 2.830131
Loss Generator P: 0.716249
Generator    : Epoch:     11, update:    2570, cost:   0.716249
Gradient discriminator: -10.223898
Gradient professor: -1.029409
Loss Generator D: 2.985842
Loss Generator P: 0.591717
Gradient discriminator: 14.445584
Gradient professor: 3.252361
Loss Generator D: 3.082712
Loss Generator P: 0.486050
Gradient discriminator: 25.138053
Gradient professor: 7.737045
Loss Generator D: 2.373806
Loss Generator P: 0.654500
Gradient discriminator: 2.630822
Gradient professor: -21.726354
Loss Generator D: 2.992033
Loss Generator P: 0.740058
Gradient discriminator: 1.561160
Gradient professor: -1.221737
Loss Generator D: 2.506858
Loss Generator P: 0.590340
Gradient discriminator: 11.179540
Gradient professor: 10.442896
Loss Generator D: 2.373064
Loss Generator P: 0.536189
Gradient discriminator: -4.047200
Gradient professor: -2.633529
Loss Generator D: 3.010628
Loss Generator P: 0.646020
Gradient discriminator: 25.534814
Gradient professor: -12.477761
Loss Generator D: 2.854852
Loss Generator P: 0.764284
Gradient discriminator: -2.951898
Gradient professor: -9.750140
Loss Generator D: 2.215548
Loss Generator P: 0.439086
Gradient discriminator: -6.493070
Gradient professor: 0.471611
Loss Generator D: 2.358617
Loss Generator P: 0.475132
Generator    : Epoch:     11, update:    2580, cost:   0.475132
Gradient discriminator: 13.227906
Gradient professor: 23.113250
Loss Generator D: 2.916151
Loss Generator P: 0.517374
Gradient discriminator: -0.818733
Gradient professor: 3.031787
Loss Generator D: 2.781770
Loss Generator P: 0.593455
Gradient discriminator: 5.161115
Gradient professor: 1.585492
Loss Generator D: 2.570858
Loss Generator P: 0.525556
Gradient discriminator: -3.411104
Gradient professor: -5.605418
Loss Generator D: 2.825273
Loss Generator P: 0.395438
Gradient discriminator: -1.754794
Gradient professor: -9.229196
Loss Generator D: 3.371423
Loss Generator P: 0.441004
Gradient discriminator: 1.422503
Gradient professor: 23.481042
Loss Generator D: 2.557541
Loss Generator P: 0.473840
Gradient discriminator: 1.636484
Gradient professor: 21.596577
Loss Generator D: 3.142938
Loss Generator P: 0.550083
Gradient discriminator: -1.298675
Gradient professor: -13.413590
Loss Generator D: 3.054376
Loss Generator P: 0.697443
Gradient discriminator: -4.720318
Gradient professor: 14.437837
Loss Generator D: 2.869166
Loss Generator P: 0.567808
Gradient discriminator: 2.953111
Gradient professor: 11.835090
Loss Generator D: 2.797065
Loss Generator P: 0.787796
Generator    : Epoch:     11, update:    2590, cost:   0.787796
Gradient discriminator: -13.061721
Gradient professor: 11.787614
Loss Generator D: 2.955317
Loss Generator P: 0.514544
Gradient discriminator: -7.379715
Gradient professor: -6.273646
Loss Generator D: 2.707231
Loss Generator P: 0.785854
Gradient discriminator: -5.632546
Gradient professor: -10.427675
Loss Generator D: 2.479613
Loss Generator P: 0.563717
Gradient discriminator: 3.046271
Gradient professor: -5.247977
Loss Generator D: 2.379251
Loss Generator P: 0.473921
Gradient discriminator: -10.750499
Gradient professor: -7.284169
Loss Generator D: 2.752282
Loss Generator P: 0.556851
Gradient discriminator: 2.522931
Gradient professor: -4.745331
Loss Generator D: 2.695220
Loss Generator P: 0.559639
Gradient discriminator: 14.603694
Gradient professor: 1.397338
Loss Generator D: 3.136966
Loss Generator P: 0.542658
Gradient discriminator: -1.662075
Gradient professor: -16.261035
Loss Generator D: 2.543455
Loss Generator P: 0.498318
Gradient discriminator: 1.495495
Gradient professor: -9.671428
Loss Generator D: 2.869722
Loss Generator P: 0.512436
Gradient discriminator: 0.080671
Gradient professor: -5.932957
Loss Generator D: 3.303198
Loss Generator P: 0.592157
Generator    : Epoch:     11, update:    2600, cost:   0.592157
Validation 26 - LOSS = 1.609 (PPL: 4.999)
Calling beam-search process
Beam-search ended, took 1.89143 minutes.
Validation 26 - BLEU = 11.64, 21.1/13.8/9.6/6.6 (BP=1.000, ratio=3.059, hyp_len=12911, ref_len=4220)
Early stopping patience: 990 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 6.587448
Gradient professor: 0.437771
Loss Generator D: 2.914909
Loss Generator P: 0.648400
Gradient discriminator: 18.499105
Gradient professor: -18.170256
Loss Generator D: 2.487470
Loss Generator P: 0.594136
Gradient discriminator: 9.081391
Gradient professor: -32.864025
Loss Generator D: 3.044358
Loss Generator P: 0.503285
Gradient discriminator: -2.393137
Gradient professor: 16.340063
Loss Generator D: 2.188531
Loss Generator P: 0.551324
Gradient discriminator: 11.119378
Gradient professor: -8.997274
Loss Generator D: 2.776886
Loss Generator P: 0.434288
Gradient discriminator: 68.450402
Gradient professor: 13.269935
Loss Generator D: 2.480494
Loss Generator P: 0.652462
Gradient discriminator: 5.584165
Gradient professor: -28.635301
Loss Generator D: 2.336886
Loss Generator P: 0.495326
Gradient discriminator: 4.540047
Gradient professor: 6.256705
Loss Generator D: 2.693691
Loss Generator P: 0.541340
Gradient discriminator: 14.174172
Gradient professor: -26.423567
Loss Generator D: 3.066923
Loss Generator P: 0.603428
Gradient discriminator: -10.129442
Gradient professor: 10.450448
Loss Generator D: 2.347490
Loss Generator P: 0.515658
Generator    : Epoch:     11, update:    2610, cost:   0.515658
Gradient discriminator: -4.723016
Gradient professor: -1.501381
Loss Generator D: 2.349343
Loss Generator P: 0.677070
Gradient discriminator: -7.081286
Gradient professor: 0.002428
Loss Generator D: 2.321884
Loss Generator P: 0.580748
Gradient discriminator: -3.887053
Gradient professor: 16.498350
Loss Generator D: 2.942725
Loss Generator P: 0.510913
Gradient discriminator: 1.677155
Gradient professor: -6.955908
Loss Generator D: 2.621824
Loss Generator P: 0.482859
Gradient discriminator: 7.496337
Gradient professor: -3.587233
Loss Generator D: 2.680150
Loss Generator P: 0.622684
Gradient discriminator: 10.498553
Gradient professor: -18.052647
Loss Generator D: 2.459976
Loss Generator P: 0.683021
Gradient discriminator: -22.185271
Gradient professor: 13.223537
Loss Generator D: 2.609908
Loss Generator P: 0.420958
Gradient discriminator: 0.020208
Gradient professor: -6.035613
Loss Generator D: 2.601756
Loss Generator P: 0.701792
Gradient discriminator: 3.724871
Gradient professor: 6.906425
Loss Generator D: 2.598814
Loss Generator P: 0.512032
Gradient discriminator: 11.919285
Gradient professor: -9.375466
Loss Generator D: 2.574525
Loss Generator P: 0.564295
Generator    : Epoch:     11, update:    2620, cost:   0.564295
Gradient discriminator: -31.262673
Gradient professor: 5.940286
Loss Generator D: 2.473692
Loss Generator P: 0.582775
Gradient discriminator: 12.694405
Gradient professor: -11.739761
Loss Generator D: 2.502918
Loss Generator P: 0.611326
Gradient discriminator: 10.779410
Gradient professor: 10.422139
Loss Generator D: 2.954963
Loss Generator P: 0.611369
Gradient discriminator: 21.649956
Gradient professor: 20.588584
Loss Generator D: 3.278550
Loss Generator P: 0.694531
Gradient discriminator: 0.341719
Gradient professor: -7.309781
Loss Generator D: 2.399424
Loss Generator P: 0.702333
Gradient discriminator: 11.684703
Gradient professor: 12.392361
Loss Generator D: 3.134497
Loss Generator P: 0.589990
Gradient discriminator: 6.890761
Gradient professor: -17.529534
Loss Generator D: 3.133742
Loss Generator P: 0.668942
Gradient discriminator: 0.157361
Gradient professor: 10.057536
Loss Generator D: 3.619959
Loss Generator P: 0.702178
Gradient discriminator: 2.554362
Gradient professor: -19.963366
Loss Generator D: 2.959997
Loss Generator P: 0.652625
Gradient discriminator: -0.757685
Gradient professor: -18.163269
Loss Generator D: 3.629148
Loss Generator P: 0.792059
Generator    : Epoch:     11, update:    2630, cost:   0.792059
Gradient discriminator: 0.306439
Gradient professor: -9.586398
Loss Generator D: 2.968879
Loss Generator P: 0.553448
Gradient discriminator: 11.061267
Gradient professor: -11.934625
Loss Generator D: 3.409570
Loss Generator P: 0.585401
Gradient discriminator: -3.651121
Gradient professor: 5.190708
Loss Generator D: 2.480544
Loss Generator P: 0.490410
Gradient discriminator: 19.193371
Gradient professor: -5.747549
Loss Generator D: 3.502063
Loss Generator P: 0.829448
Gradient discriminator: 13.969738
Gradient professor: 6.732200
Loss Generator D: 2.589350
Loss Generator P: 0.632301
Gradient discriminator: -4.032057
Gradient professor: -1.264822
Loss Generator D: 3.300251
Loss Generator P: 0.461262
Gradient discriminator: -4.402696
Gradient professor: 2.019377
Loss Generator D: 2.901516
Loss Generator P: 0.547950
Gradient discriminator: -1.165744
Gradient professor: 2.456822
Loss Generator D: 3.446898
Loss Generator P: 0.411985
Gradient discriminator: 2.859178
Gradient professor: 13.234204
Loss Generator D: 2.864713
Loss Generator P: 0.721042
Gradient discriminator: 7.361496
Gradient professor: -5.371650
Loss Generator D: 2.880840
Loss Generator P: 0.587426
Generator    : Epoch:     11, update:    2640, cost:   0.587426
Gradient discriminator: -0.043738
Gradient professor: -8.612674
Loss Generator D: 2.936372
Loss Generator P: 0.555019
Gradient discriminator: 10.211036
Gradient professor: 30.104119
Loss Generator D: 2.737826
Loss Generator P: 0.678891
Gradient discriminator: -1.044984
Gradient professor: 24.353554
Loss Generator D: 2.796793
Loss Generator P: 0.809127
Gradient discriminator: 20.480636
Gradient professor: -11.820724
Loss Generator D: 3.372295
Loss Generator P: 0.651822
Gradient discriminator: 12.439562
Gradient professor: -28.533260
Loss Generator D: 2.423705
Loss Generator P: 0.735147
Gradient discriminator: -0.902811
Gradient professor: -5.913059
Loss Generator D: 3.030702
Loss Generator P: 0.811265
Gradient discriminator: -8.668116
Gradient professor: -1.967943
Loss Generator D: 2.657060
Loss Generator P: 0.474921
Gradient discriminator: 7.743746
Gradient professor: -2.423703
Loss Generator D: 2.745528
Loss Generator P: 0.492232
Gradient discriminator: -6.227395
Gradient professor: -11.419096
Loss Generator D: 3.058894
Loss Generator P: 0.510408
Gradient discriminator: -3.953572
Gradient professor: -7.911666
Loss Generator D: 2.868104
Loss Generator P: 0.445743
Generator    : Epoch:     11, update:    2650, cost:   0.445743
Gradient discriminator: 7.365339
Gradient professor: 3.940020
Loss Generator D: 3.123537
Loss Generator P: 0.691215
Gradient discriminator: 6.536047
Gradient professor: -4.009070
Loss Generator D: 3.028765
Loss Generator P: 0.590113
Gradient discriminator: 8.994680
Gradient professor: 4.408693
Loss Generator D: 2.508991
Loss Generator P: 0.619900
Gradient discriminator: 8.619114
Gradient professor: 0.432015
Loss Generator D: 2.831475
Loss Generator P: 0.544737
Gradient discriminator: 15.846369
Gradient professor: 28.541562
Loss Generator D: 2.140923
Loss Generator P: 0.701082
Gradient discriminator: 4.864112
Gradient professor: -21.254538
Loss Generator D: 2.535560
Loss Generator P: 0.515896
Gradient discriminator: 0.271924
Gradient professor: 2.947826
Loss Generator D: 2.342118
Loss Generator P: 0.649735
Gradient discriminator: -1.723806
Gradient professor: 1.008973
Loss Generator D: 2.642139
Loss Generator P: 0.467903
Gradient discriminator: 10.670974
Gradient professor: -15.063887
Loss Generator D: 2.330473
Loss Generator P: 0.480199
Gradient discriminator: -11.821573
Gradient professor: 9.701430
Loss Generator D: 2.267494
Loss Generator P: 0.545993
Generator    : Epoch:     11, update:    2660, cost:   0.545993
Gradient discriminator: 14.309072
Gradient professor: -4.779613
Loss Generator D: 2.350997
Loss Generator P: 0.565830
Gradient discriminator: 12.515228
Gradient professor: 10.816187
Loss Generator D: 2.137187
Loss Generator P: 0.746518
Gradient discriminator: 8.973186
Gradient professor: 7.826633
Loss Generator D: 2.270398
Loss Generator P: 0.707703
Gradient discriminator: 1.454590
Gradient professor: 9.455890
Loss Generator D: 2.693911
Loss Generator P: 0.717344
Gradient discriminator: 13.221213
Gradient professor: -1.378172
Loss Generator D: 2.320408
Loss Generator P: 0.742730
Gradient discriminator: -1.489836
Gradient professor: -3.045077
Loss Generator D: 2.463211
Loss Generator P: 0.698832
Gradient discriminator: 2.146193
Gradient professor: 30.240569
Loss Generator D: 2.549084
Loss Generator P: 0.771745
Gradient discriminator: -0.691340
Gradient professor: -22.968678
Loss Generator D: 2.533430
Loss Generator P: 0.515675
Gradient discriminator: 4.477599
Gradient professor: -10.098236
Loss Generator D: 2.151960
Loss Generator P: 0.641289
Gradient discriminator: 5.971023
Gradient professor: 4.237411
Loss Generator D: 2.670498
Loss Generator P: 0.680466
Generator    : Epoch:     11, update:    2670, cost:   0.680466
Gradient discriminator: 7.583254
Gradient professor: 5.060751
Loss Generator D: 2.382261
Loss Generator P: 0.536595
Gradient discriminator: 17.928325
Gradient professor: 1.573001
Loss Generator D: 1.984692
Loss Generator P: 0.514111
Gradient discriminator: 18.033560
Gradient professor: 28.019337
Loss Generator D: 2.556927
Loss Generator P: 0.575524
Gradient discriminator: -5.501141
Gradient professor: -22.495920
Loss Generator D: 2.440226
Loss Generator P: 0.435322
Gradient discriminator: 1.040450
Gradient professor: -15.505093
Loss Generator D: 2.553755
Loss Generator P: 0.553356
Gradient discriminator: 15.717688
Gradient professor: 2.668076
Loss Generator D: 2.435047
Loss Generator P: 0.616017
Gradient discriminator: -8.124945
Gradient professor: 7.982305
Loss Generator D: 2.047875
Loss Generator P: 0.790590
Gradient discriminator: 3.961509
Gradient professor: 12.967206
Loss Generator D: 2.047089
Loss Generator P: 0.874737
Gradient discriminator: -2.669267
Gradient professor: 4.819483
Loss Generator D: 2.095940
Loss Generator P: 0.808284
Gradient discriminator: -1.487709
Gradient professor: -14.455648
Loss Generator D: 2.847970
Loss Generator P: 0.493250
Generator    : Epoch:     11, update:    2680, cost:   0.493250
Gradient discriminator: 16.120471
Gradient professor: 22.090450
Loss Generator D: 2.696522
Loss Generator P: 0.620638
Gradient discriminator: 4.587745
Gradient professor: -7.322270
Loss Generator D: 1.867484
Loss Generator P: 0.654428
Gradient discriminator: -6.821979
Gradient professor: 32.186553
Loss Generator D: 2.544118
Loss Generator P: 0.619833
Gradient discriminator: 1.565218
Gradient professor: -23.579482
Loss Generator D: 2.316464
Loss Generator P: 0.748753
Gradient discriminator: 14.258659
Gradient professor: -6.671475
Loss Generator D: 2.359812
Loss Generator P: 0.759291
Gradient discriminator: -8.367902
Gradient professor: 6.526437
Loss Generator D: 2.436708
Loss Generator P: 0.596233
Gradient discriminator: 26.369163
Gradient professor: 10.058414
Loss Generator D: 2.129607
Loss Generator P: 0.708808
Gradient discriminator: -8.367350
Gradient professor: -8.370782
Loss Generator D: 2.266980
Loss Generator P: 0.759791
Gradient discriminator: 10.720615
Gradient professor: 12.515561
Loss Generator D: 2.676674
Loss Generator P: 0.740276
Gradient discriminator: 10.673061
Gradient professor: -50.108478
Loss Generator D: 2.438560
Loss Generator P: 0.741694
Generator    : Epoch:     11, update:    2690, cost:   0.741694
Gradient discriminator: -2.792347
Gradient professor: -7.309051
Loss Generator D: 2.313172
Loss Generator P: 0.753013
Gradient discriminator: 11.796948
Gradient professor: -1.211261
Loss Generator D: 2.532289
Loss Generator P: 0.588971
Gradient discriminator: -0.130309
Gradient professor: -33.180710
Loss Generator D: 2.519022
Loss Generator P: 0.941398
Gradient discriminator: 11.849115
Gradient professor: 25.924313
Loss Generator D: 2.163289
Loss Generator P: 0.841712
Gradient discriminator: 4.839802
Gradient professor: 17.074115
Loss Generator D: 1.760985
Loss Generator P: 0.559077
Gradient discriminator: 10.704404
Gradient professor: -10.567818
Loss Generator D: 2.340540
Loss Generator P: 0.712001
Gradient discriminator: -10.409561
Gradient professor: 17.366471
Loss Generator D: 2.299830
Loss Generator P: 0.684300
Gradient discriminator: 15.862212
Gradient professor: -6.678955
Loss Generator D: 2.098366
Loss Generator P: 0.743665
Gradient discriminator: -6.669328
Gradient professor: -9.974144
Loss Generator D: 2.350667
Loss Generator P: 0.722890
Gradient discriminator: 22.826293
Gradient professor: 8.495700
Loss Generator D: 2.415132
Loss Generator P: 0.576475
Generator    : Epoch:     11, update:    2700, cost:   0.576475
Validation 27 - LOSS = 1.618 (PPL: 5.043)
Calling beam-search process
Beam-search ended, took 2.42597 minutes.
Validation 27 - BLEU = 7.38, 13.9/8.9/6.0/4.0 (BP=1.000, ratio=4.309, hyp_len=18186, ref_len=4220)
Early stopping patience: 989 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -2.539504
Gradient professor: 11.513445
Loss Generator D: 2.822096
Loss Generator P: 0.671407
Gradient discriminator: 4.525734
Gradient professor: -13.532409
Loss Generator D: 2.511389
Loss Generator P: 0.628462
Gradient discriminator: 0.227351
Gradient professor: -0.297669
Loss Generator D: 2.602125
Loss Generator P: 0.556512
Gradient discriminator: -2.138164
Gradient professor: -11.587074
Loss Generator D: 2.530517
Loss Generator P: 0.592194
Gradient discriminator: -4.428126
Gradient professor: -15.640142
Loss Generator D: 2.807864
Loss Generator P: 0.511031
Gradient discriminator: 16.147594
Gradient professor: 10.723506
Loss Generator D: 2.436416
Loss Generator P: 0.460189
Gradient discriminator: -1.702404
Gradient professor: -7.017722
Loss Generator D: 3.025676
Loss Generator P: 0.692129
Gradient discriminator: -12.188631
Gradient professor: 1.545111
Loss Generator D: 2.667533
Loss Generator P: 0.747380
Gradient discriminator: -4.327247
Gradient professor: -11.774588
Loss Generator D: 2.374673
Loss Generator P: 0.577484
Gradient discriminator: 5.464475
Gradient professor: -21.888794
Loss Generator D: 2.521572
Loss Generator P: 0.659818
Generator    : Epoch:     11, update:    2710, cost:   0.659818
Gradient discriminator: -17.975352
Gradient professor: 3.655767
Loss Generator D: 2.485690
Loss Generator P: 0.694812
Gradient discriminator: -17.375759
Gradient professor: -4.849175
Loss Generator D: 2.723900
Loss Generator P: 0.776329
Gradient discriminator: -12.961402
Gradient professor: 19.043979
Loss Generator D: 2.747748
Loss Generator P: 0.623508
Gradient discriminator: 5.481994
Gradient professor: 14.364879
Loss Generator D: 2.035237
Loss Generator P: 0.516973
Gradient discriminator: -14.867058
Gradient professor: 9.755984
Loss Generator D: 2.571112
Loss Generator P: 0.644886
Gradient discriminator: 14.756711
Gradient professor: 18.876572
Loss Generator D: 2.450083
Loss Generator P: 0.686054
Gradient discriminator: 8.018865
Gradient professor: 32.587385
Loss Generator D: 2.369859
Loss Generator P: 0.672707
Gradient discriminator: -4.353179
Gradient professor: -32.261484
Loss Generator D: 2.324827
Loss Generator P: 0.594840
Gradient discriminator: 17.032192
Gradient professor: 1.381923
Loss Generator D: 2.529958
Loss Generator P: 0.525715
Gradient discriminator: -2.327091
Gradient professor: 6.046629
Loss Generator D: 2.583078
Loss Generator P: 0.514730
Generator    : Epoch:     11, update:    2720, cost:   0.514730
Gradient discriminator: -5.181420
Gradient professor: -8.435635
Loss Generator D: 2.803233
Loss Generator P: 0.601543
Gradient discriminator: 15.678186
Gradient professor: -2.912786
Loss Generator D: 2.714453
Loss Generator P: 0.610608
Gradient discriminator: 4.225826
Gradient professor: 12.051552
Loss Generator D: 2.920738
Loss Generator P: 0.639151
Gradient discriminator: 6.266921
Gradient professor: 12.637752
Loss Generator D: 2.983892
Loss Generator P: 0.545608
Gradient discriminator: 9.300659
Gradient professor: 22.592644
Loss Generator D: 2.928238
Loss Generator P: 0.584949
Gradient discriminator: 0.895162
Gradient professor: -11.385472
Loss Generator D: 2.885965
Loss Generator P: 0.554325
Gradient discriminator: -0.516021
Gradient professor: 5.249909
Loss Generator D: 3.021720
Loss Generator P: 0.576156
Gradient discriminator: 6.804351
Gradient professor: 15.784518
Loss Generator D: 3.496436
Loss Generator P: 0.560031
Gradient discriminator: 5.953046
Gradient professor: -9.818444
Loss Generator D: 3.050590
Loss Generator P: 0.613866
Gradient discriminator: 1.334135
Gradient professor: -11.966147
Loss Generator D: 3.035924
Loss Generator P: 0.634123
Generator    : Epoch:     11, update:    2730, cost:   0.634123
Gradient discriminator: -1.658391
Gradient professor: -2.754675
Loss Generator D: 3.088693
Loss Generator P: 0.707458
Gradient discriminator: -1.391314
Gradient professor: -18.105791
Loss Generator D: 2.874390
Loss Generator P: 0.747173
Gradient discriminator: 5.939627
Gradient professor: -10.503666
Loss Generator D: 3.242463
Loss Generator P: 0.868025
Gradient discriminator: -7.624481
Gradient professor: -3.756802
Loss Generator D: 2.755127
Loss Generator P: 0.478536
Gradient discriminator: -6.858803
Gradient professor: -2.398673
Loss Generator D: 2.400414
Loss Generator P: 0.616978
Gradient discriminator: 1.617457
Gradient professor: -4.052018
Loss Generator D: 2.628476
Loss Generator P: 0.588872
Gradient discriminator: 5.678206
Gradient professor: 35.666277
Loss Generator D: 2.583011
Loss Generator P: 0.494236
Gradient discriminator: -3.003489
Gradient professor: -20.962536
Loss Generator D: 2.985501
Loss Generator P: 0.591416
Gradient discriminator: -7.352535
Gradient professor: 14.319425
Loss Generator D: 3.061965
Loss Generator P: 0.595929
Gradient discriminator: -2.794478
Gradient professor: 15.699503
Loss Generator D: 3.008435
Loss Generator P: 0.516148
Generator    : Epoch:     11, update:    2740, cost:   0.516148
Gradient discriminator: -7.552750
Gradient professor: -5.256116
Loss Generator D: 3.089420
Loss Generator P: 0.546294
Gradient discriminator: -3.788447
Gradient professor: 16.391188
Loss Generator D: 2.778548
Loss Generator P: 0.535748
Gradient discriminator: 3.146061
Gradient professor: -0.135122
Loss Generator D: 2.910666
Loss Generator P: 0.490200
Gradient discriminator: -8.131036
Gradient professor: 9.241993
Loss Generator D: 2.650692
Loss Generator P: 0.570205
Gradient discriminator: 5.994847
Gradient professor: -7.030688
Loss Generator D: 3.199330
Loss Generator P: 0.690484
Gradient discriminator: 3.448219
Gradient professor: -14.492120
Loss Generator D: 2.727641
Loss Generator P: 0.536443
Gradient discriminator: 8.861900
Gradient professor: -9.725838
Loss Generator D: 2.742047
Loss Generator P: 0.558548
Gradient discriminator: 0.391738
Gradient professor: 3.858326
Loss Generator D: 3.224876
Loss Generator P: 0.495067
Gradient discriminator: -7.679999
Gradient professor: -0.505388
Loss Generator D: 2.535073
Loss Generator P: 0.610584
Gradient discriminator: 16.137448
Gradient professor: 8.724104
Loss Generator D: 2.402360
Loss Generator P: 0.359661
Generator    : Epoch:     11, update:    2750, cost:   0.359661
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 11 finished with mean loss 1.63598 (PPL: 5.13446)
--> Epoch took 276.829 minutes, 66.439 sec/update
Epoch summary of Discriminator:
--> Epoch 11 finished with mean loss nan (PPL:  nan)
--> Epoch took 276.829 minutes, 66.439 sec/update
---------------------------------------------------------
Starting Epoch 12
-----------------
Gradient discriminator: 14.299443
Gradient professor: 15.176711
Loss Generator D: 2.118263
Loss Generator P: 0.763090
Gradient discriminator: 4.777755
Gradient professor: -4.089841
Loss Generator D: 2.346853
Loss Generator P: 0.595255
Gradient discriminator: 52.288898
Gradient professor: -4.557219
Loss Generator D: 2.685827
Loss Generator P: 0.579231
Gradient discriminator: -3.900353
Gradient professor: -24.431154
Loss Generator D: 2.133538
Loss Generator P: 0.699092
Gradient discriminator: 2.261465
Gradient professor: -25.026180
Loss Generator D: 2.496686
Loss Generator P: 0.522633
Gradient discriminator: -5.179103
Gradient professor: 20.478932
Loss Generator D: 2.419629
Loss Generator P: 0.615249
Gradient discriminator: -29.226823
Gradient professor: -2.856909
Loss Generator D: 2.502263
Loss Generator P: 0.688574
Gradient discriminator: -6.410117
Gradient professor: 11.586591
Loss Generator D: 2.199002
Loss Generator P: 0.558238
Gradient discriminator: 5.136686
Gradient professor: 22.671850
Loss Generator D: 2.794705
Loss Generator P: 0.742321
Gradient discriminator: 1.409352
Gradient professor: -13.814003
Loss Generator D: 2.176124
Loss Generator P: 0.833362
Generator    : Epoch:     12, update:    2760, cost:   0.833362
Gradient discriminator: -9.403203
Gradient professor: 17.026076
Loss Generator D: 2.207449
Loss Generator P: 0.866574
Gradient discriminator: 6.828912
Gradient professor: -9.708522
Loss Generator D: 2.648839
Loss Generator P: 0.617160
Gradient discriminator: 6.811152
Gradient professor: 18.107713
Loss Generator D: 2.661976
Loss Generator P: 0.723072
Gradient discriminator: -34.211588
Gradient professor: -7.099945
Loss Generator D: 2.910362
Loss Generator P: 0.681740
Gradient discriminator: 0.732752
Gradient professor: -6.078415
Loss Generator D: 2.839933
Loss Generator P: 0.489997
Gradient discriminator: -5.498646
Gradient professor: -5.819023
Loss Generator D: 2.881438
Loss Generator P: 0.409366
Gradient discriminator: 4.879617
Gradient professor: -16.575476
Loss Generator D: 2.916536
Loss Generator P: 0.562834
Gradient discriminator: 85.085244
Gradient professor: 10.711885
Loss Generator D: 3.312818
Loss Generator P: 0.559341
Gradient discriminator: 2.922318
Gradient professor: 2.776049
Loss Generator D: 3.188208
Loss Generator P: 0.650626
Gradient discriminator: 10.851746
Gradient professor: 9.391688
Loss Generator D: 2.518100
Loss Generator P: 0.683114
Generator    : Epoch:     12, update:    2770, cost:   0.683114
Gradient discriminator: -5.199262
Gradient professor: -31.499852
Loss Generator D: 2.863814
Loss Generator P: 0.591689
Gradient discriminator: -2.354474
Gradient professor: 17.231844
Loss Generator D: 3.229837
Loss Generator P: 0.552497
Gradient discriminator: 2.996836
Gradient professor: 2.134837
Loss Generator D: 2.591159
Loss Generator P: 0.552683
Gradient discriminator: 14.173346
Gradient professor: -10.524667
Loss Generator D: 2.776638
Loss Generator P: 0.842479
Gradient discriminator: 15.840398
Gradient professor: 4.720797
Loss Generator D: 3.166875
Loss Generator P: 0.757240
Gradient discriminator: 10.826792
Gradient professor: -0.572174
Loss Generator D: 3.084686
Loss Generator P: 0.589806
Gradient discriminator: 8.350504
Gradient professor: 0.044016
Loss Generator D: 2.831174
Loss Generator P: 0.503495
Gradient discriminator: 10.825062
Gradient professor: 6.990006
Loss Generator D: 2.409209
Loss Generator P: 0.574803
Gradient discriminator: 10.815162
Gradient professor: 2.073275
Loss Generator D: 2.843269
Loss Generator P: 0.516220
Gradient discriminator: -5.355321
Gradient professor: -16.318815
Loss Generator D: 2.972509
Loss Generator P: 0.566114
Generator    : Epoch:     12, update:    2780, cost:   0.566114
Gradient discriminator: -18.099613
Gradient professor: 9.205508
Loss Generator D: 2.941511
Loss Generator P: 0.546084
Gradient discriminator: 0.294592
Gradient professor: 6.549141
Loss Generator D: 3.279313
Loss Generator P: 0.470042
Gradient discriminator: -7.234312
Gradient professor: -2.262576
Loss Generator D: 3.452154
Loss Generator P: 0.739822
Gradient discriminator: -16.872920
Gradient professor: 0.690043
Loss Generator D: 2.909907
Loss Generator P: 0.757454
Gradient discriminator: -20.049768
Gradient professor: -5.828654
Loss Generator D: 2.919338
Loss Generator P: 0.613748
Gradient discriminator: -2.732459
Gradient professor: 4.732837
Loss Generator D: 2.890941
Loss Generator P: 0.532549
Gradient discriminator: -4.922278
Gradient professor: 14.836610
Loss Generator D: 2.955369
Loss Generator P: 0.477809
Gradient discriminator: -5.818280
Gradient professor: 7.497687
Loss Generator D: 3.063394
Loss Generator P: 0.623888
Gradient discriminator: -12.052708
Gradient professor: -7.601589
Loss Generator D: 2.851382
Loss Generator P: 0.620222
Gradient discriminator: 2.178522
Gradient professor: 24.527457
Loss Generator D: 3.201733
Loss Generator P: 0.720138
Generator    : Epoch:     12, update:    2790, cost:   0.720138
Gradient discriminator: 12.252737
Gradient professor: 9.082338
Loss Generator D: 2.652154
Loss Generator P: 0.603741
Gradient discriminator: 10.305301
Gradient professor: 7.986338
Loss Generator D: 2.826056
Loss Generator P: 0.567351
Gradient discriminator: -10.025982
Gradient professor: 3.961803
Loss Generator D: 3.207613
Loss Generator P: 0.605984
Gradient discriminator: 24.179118
Gradient professor: 1.807838
Loss Generator D: 2.875189
Loss Generator P: 0.550019
Gradient discriminator: 128.208924
Gradient professor: -23.582388
Loss Generator D: 3.187592
Loss Generator P: 0.706368
Gradient discriminator: 5.810783
Gradient professor: 20.215218
Loss Generator D: 2.557312
Loss Generator P: 0.648111
Gradient discriminator: 20.830798
Gradient professor: 16.347593
Loss Generator D: 2.807339
Loss Generator P: 0.552436
Gradient discriminator: -1.061487
Gradient professor: 7.220235
Loss Generator D: 2.627144
Loss Generator P: 0.703719
Gradient discriminator: 9.914685
Gradient professor: -22.301008
Loss Generator D: 2.597095
Loss Generator P: 0.928121
Gradient discriminator: -0.076991
Gradient professor: 3.630519
Loss Generator D: 2.616024
Loss Generator P: 0.650922
Generator    : Epoch:     12, update:    2800, cost:   0.650922
Validation 28 - LOSS = 1.693 (PPL: 5.437)
Calling beam-search process
Beam-search ended, took 1.96586 minutes.
Validation 28 - BLEU = 9.65, 18.1/11.4/7.8/5.4 (BP=1.000, ratio=3.332, hyp_len=14061, ref_len=4220)
Early stopping patience: 988 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -6.614402
Gradient professor: 23.327633
Loss Generator D: 3.074857
Loss Generator P: 0.679380
Gradient discriminator: -0.671314
Gradient professor: -1.564686
Loss Generator D: 2.800004
Loss Generator P: 0.626910
Gradient discriminator: 2.008863
Gradient professor: 3.405848
Loss Generator D: 2.520816
Loss Generator P: 0.604772
Gradient discriminator: 4.054902
Gradient professor: 16.931055
Loss Generator D: 3.156629
Loss Generator P: 0.711528
Gradient discriminator: 4.673968
Gradient professor: -28.193067
Loss Generator D: 2.939564
Loss Generator P: 0.637725
Gradient discriminator: 1.925963
Gradient professor: 13.082686
Loss Generator D: 3.395508
Loss Generator P: 0.492671
Gradient discriminator: 4.335439
Gradient professor: 17.474712
Loss Generator D: 2.658069
Loss Generator P: 0.511349
Gradient discriminator: 11.524389
Gradient professor: 11.466290
Loss Generator D: 3.211703
Loss Generator P: 0.506908
Gradient discriminator: 0.512964
Gradient professor: 4.743128
Loss Generator D: 3.097311
Loss Generator P: 0.538669
Gradient discriminator: 6.090670
Gradient professor: 0.820701
Loss Generator D: 2.989271
Loss Generator P: 0.624451
Generator    : Epoch:     12, update:    2810, cost:   0.624451
Gradient discriminator: -0.581824
Gradient professor: 2.903221
Loss Generator D: 3.038451
Loss Generator P: 0.626860
Gradient discriminator: 12.502077
Gradient professor: 2.002671
Loss Generator D: 2.660880
Loss Generator P: 0.806138
Gradient discriminator: 26.860552
Gradient professor: 4.177947
Loss Generator D: 2.322128
Loss Generator P: 0.598799
Gradient discriminator: -16.303941
Gradient professor: -14.063790
Loss Generator D: 2.801820
Loss Generator P: 0.600064
Gradient discriminator: 12.637856
Gradient professor: -27.519672
Loss Generator D: 2.459247
Loss Generator P: 0.687057
Gradient discriminator: 5.686949
Gradient professor: -1.296487
Loss Generator D: 2.355420
Loss Generator P: 0.602761
Gradient discriminator: -17.455663
Gradient professor: 10.671496
Loss Generator D: 2.537415
Loss Generator P: 0.587489
Gradient discriminator: 2.186055
Gradient professor: -21.431134
Loss Generator D: 2.942518
Loss Generator P: 0.550924
Gradient discriminator: 0.506793
Gradient professor: 3.509939
Loss Generator D: 2.941622
Loss Generator P: 0.722796
Gradient discriminator: -9.523395
Gradient professor: -5.977521
Loss Generator D: 2.822451
Loss Generator P: 0.611778
Generator    : Epoch:     12, update:    2820, cost:   0.611778
Gradient discriminator: -10.043744
Gradient professor: -23.813804
Loss Generator D: 2.707869
Loss Generator P: 0.545403
Gradient discriminator: 29.000641
Gradient professor: -2.488527
Loss Generator D: 3.003413
Loss Generator P: 0.437463
Gradient discriminator: 5.433826
Gradient professor: 13.695676
Loss Generator D: 2.716137
Loss Generator P: 0.604730
Gradient discriminator: 40.988676
Gradient professor: 1.147056
Loss Generator D: 3.158778
Loss Generator P: 0.633674
Gradient discriminator: -4.248874
Gradient professor: -6.023035
Loss Generator D: 2.724766
Loss Generator P: 0.585907
Gradient discriminator: -8.651237
Gradient professor: 5.607332
Loss Generator D: 2.333050
Loss Generator P: 0.534658
Gradient discriminator: 10.362043
Gradient professor: 4.538639
Loss Generator D: 3.209521
Loss Generator P: 0.615469
Gradient discriminator: 5.221805
Gradient professor: 22.859238
Loss Generator D: 3.218868
Loss Generator P: 0.688977
Gradient discriminator: 15.637337
Gradient professor: -16.122775
Loss Generator D: 2.263339
Loss Generator P: 0.412295
Gradient discriminator: -5.642359
Gradient professor: 2.952889
Loss Generator D: 2.451970
Loss Generator P: 0.448923
Generator    : Epoch:     12, update:    2830, cost:   0.448923
Gradient discriminator: 6.965756
Gradient professor: 12.290298
Loss Generator D: 3.441135
Loss Generator P: 0.479811
Gradient discriminator: -3.455553
Gradient professor: 12.435063
Loss Generator D: 2.952293
Loss Generator P: 0.525348
Gradient discriminator: 5.324728
Gradient professor: -26.409012
Loss Generator D: 2.973626
Loss Generator P: 0.505252
Gradient discriminator: 0.871177
Gradient professor: 7.082622
Loss Generator D: 2.841957
Loss Generator P: 0.374557
Gradient discriminator: -7.344654
Gradient professor: 10.945802
Loss Generator D: 3.088106
Loss Generator P: 0.434715
Gradient discriminator: 2.051632
Gradient professor: 9.375198
Loss Generator D: 2.836573
Loss Generator P: 0.435510
Gradient discriminator: -0.815500
Gradient professor: -24.009092
Loss Generator D: 3.110611
Loss Generator P: 0.461838
Gradient discriminator: 1.940944
Gradient professor: -7.789009
Loss Generator D: 3.042570
Loss Generator P: 0.643988
Gradient discriminator: 3.674781
Gradient professor: -7.881793
Loss Generator D: 3.082602
Loss Generator P: 0.544859
Gradient discriminator: -1.355233
Gradient professor: 17.998731
Loss Generator D: 3.029881
Loss Generator P: 0.714523
Generator    : Epoch:     12, update:    2840, cost:   0.714523
Gradient discriminator: 2.922160
Gradient professor: 17.558835
Loss Generator D: 3.221517
Loss Generator P: 0.480615
Gradient discriminator: -6.133039
Gradient professor: 18.283448
Loss Generator D: 2.816055
Loss Generator P: 0.709774
Gradient discriminator: 4.525138
Gradient professor: -24.755791
Loss Generator D: 3.225170
Loss Generator P: 0.542055
Gradient discriminator: 0.625482
Gradient professor: -6.050225
Loss Generator D: 2.837102
Loss Generator P: 0.428547
Gradient discriminator: -0.670785
Gradient professor: -9.863211
Loss Generator D: 2.676095
Loss Generator P: 0.505112
Gradient discriminator: 11.941361
Gradient professor: -5.410055
Loss Generator D: 3.022529
Loss Generator P: 0.534901
Gradient discriminator: 4.316586
Gradient professor: -43.238444
Loss Generator D: 3.708282
Loss Generator P: 0.554639
Gradient discriminator: -7.463158
Gradient professor: -9.441347
Loss Generator D: 2.896394
Loss Generator P: 0.448403
Gradient discriminator: 5.179124
Gradient professor: -17.258330
Loss Generator D: 3.571252
Loss Generator P: 0.478610
Gradient discriminator: 2.449414
Gradient professor: 2.795580
Loss Generator D: 3.094929
Loss Generator P: 0.577665
Generator    : Epoch:     12, update:    2850, cost:   0.577665
Gradient discriminator: 3.319644
Gradient professor: -22.475307
Loss Generator D: 3.035131
Loss Generator P: 0.645652
Gradient discriminator: 3.523454
Gradient professor: -4.142069
Loss Generator D: 2.400499
Loss Generator P: 0.615216
Gradient discriminator: 1.144271
Gradient professor: -15.120284
Loss Generator D: 3.247173
Loss Generator P: 0.455728
Gradient discriminator: 3.248613
Gradient professor: 12.914007
Loss Generator D: 2.625238
Loss Generator P: 0.557065
Gradient discriminator: 8.720938
Gradient professor: -23.324193
Loss Generator D: 2.903638
Loss Generator P: 0.415112
Gradient discriminator: 8.014445
Gradient professor: 9.815922
Loss Generator D: 2.818565
Loss Generator P: 0.585161
Gradient discriminator: 17.408666
Gradient professor: -19.066243
Loss Generator D: 2.564138
Loss Generator P: 0.471743
Gradient discriminator: 5.491528
Gradient professor: 17.705193
Loss Generator D: 2.889438
Loss Generator P: 0.480996
Gradient discriminator: 11.479471
Gradient professor: 3.031581
Loss Generator D: 3.484753
Loss Generator P: 0.629278
Gradient discriminator: -2.143610
Gradient professor: 18.560459
Loss Generator D: 3.136817
Loss Generator P: 0.536401
Generator    : Epoch:     12, update:    2860, cost:   0.536401
Gradient discriminator: 19.415815
Gradient professor: -2.775779
Loss Generator D: 2.773036
Loss Generator P: 0.599059
Gradient discriminator: 16.469573
Gradient professor: 21.497952
Loss Generator D: 2.288689
Loss Generator P: 0.560204
Gradient discriminator: -3.207554
Gradient professor: 1.198608
Loss Generator D: 2.960761
Loss Generator P: 0.443108
Gradient discriminator: -0.603958
Gradient professor: -9.792437
Loss Generator D: 2.781920
Loss Generator P: 0.419779
Gradient discriminator: -0.570561
Gradient professor: 30.495665
Loss Generator D: 3.175564
Loss Generator P: 0.580786
Gradient discriminator: 4.555978
Gradient professor: -12.452856
Loss Generator D: 2.541070
Loss Generator P: 0.686669
Gradient discriminator: 0.265203
Gradient professor: -11.831547
Loss Generator D: 2.644754
Loss Generator P: 0.412249
Gradient discriminator: 7.866660
Gradient professor: -16.308911
Loss Generator D: 2.661892
Loss Generator P: 0.634415
Gradient discriminator: 7.738925
Gradient professor: -12.761294
Loss Generator D: 2.757259
Loss Generator P: 0.488765
Gradient discriminator: 3.847127
Gradient professor: 8.496392
Loss Generator D: 2.600672
Loss Generator P: 0.564445
Generator    : Epoch:     12, update:    2870, cost:   0.564445
Gradient discriminator: -2.094753
Gradient professor: -17.405458
Loss Generator D: 2.360167
Loss Generator P: 0.589671
Gradient discriminator: -13.212393
Gradient professor: -7.565536
Loss Generator D: 2.317096
Loss Generator P: 0.536881
Gradient discriminator: 4.140375
Gradient professor: -14.453982
Loss Generator D: 2.695594
Loss Generator P: 0.634788
Gradient discriminator: -10.190507
Gradient professor: 7.696698
Loss Generator D: 2.667554
Loss Generator P: 0.668628
Gradient discriminator: 1.012636
Gradient professor: -6.817981
Loss Generator D: 2.610141
Loss Generator P: 0.644907
Gradient discriminator: 5.242237
Gradient professor: 22.580075
Loss Generator D: 2.433315
Loss Generator P: 0.638565
Gradient discriminator: -8.183890
Gradient professor: 5.915709
Loss Generator D: 2.461020
Loss Generator P: 0.581767
Gradient discriminator: -0.834123
Gradient professor: -9.694187
Loss Generator D: 3.426707
Loss Generator P: 0.680277
Gradient discriminator: 0.925665
Gradient professor: 37.976961
Loss Generator D: 2.919847
Loss Generator P: 0.604191
Gradient discriminator: -4.151680
Gradient professor: -17.393635
Loss Generator D: 3.406776
Loss Generator P: 0.675190
Generator    : Epoch:     12, update:    2880, cost:   0.675190
Gradient discriminator: -6.883284
Gradient professor: -11.334115
Loss Generator D: 3.195939
Loss Generator P: 0.544828
Gradient discriminator: -26.642919
Gradient professor: -31.210105
Loss Generator D: 2.950085
Loss Generator P: 0.587699
Gradient discriminator: 3.453723
Gradient professor: 18.915547
Loss Generator D: 2.491226
Loss Generator P: 0.453285
Gradient discriminator: -10.771479
Gradient professor: 8.677925
Loss Generator D: 2.823945
Loss Generator P: 0.793565
Gradient discriminator: 12.053052
Gradient professor: -9.748853
Loss Generator D: 2.364862
Loss Generator P: 0.636311
Gradient discriminator: -7.703254
Gradient professor: 5.434626
Loss Generator D: 2.839132
Loss Generator P: 0.437448
Gradient discriminator: -0.472128
Gradient professor: -22.779673
Loss Generator D: 2.651693
Loss Generator P: 0.549381
Gradient discriminator: 8.977076
Gradient professor: 11.182771
Loss Generator D: 2.995762
Loss Generator P: 0.396503
Gradient discriminator: 2.252660
Gradient professor: 4.486938
Loss Generator D: 2.637722
Loss Generator P: 0.673039
Gradient discriminator: -13.641538
Gradient professor: 22.914263
Loss Generator D: 2.489569
Loss Generator P: 0.623547
Generator    : Epoch:     12, update:    2890, cost:   0.623547
Gradient discriminator: -9.103751
Gradient professor: -7.910136
Loss Generator D: 2.516071
Loss Generator P: 0.520769
Gradient discriminator: 0.732541
Gradient professor: -2.479605
Loss Generator D: 2.874250
Loss Generator P: 0.594663
Gradient discriminator: -16.699594
Gradient professor: 25.538361
Loss Generator D: 2.875568
Loss Generator P: 0.757876
Gradient discriminator: 3.577647
Gradient professor: -0.012264
Loss Generator D: 2.970749
Loss Generator P: 0.626688
Gradient discriminator: 0.513060
Gradient professor: -11.656211
Loss Generator D: 2.920210
Loss Generator P: 0.714226
Gradient discriminator: 17.169833
Gradient professor: 4.864548
Loss Generator D: 2.776270
Loss Generator P: 0.725203
Gradient discriminator: 1.186440
Gradient professor: -5.055718
Loss Generator D: 2.553669
Loss Generator P: 0.434332
Gradient discriminator: -3.394048
Gradient professor: 14.597620
Loss Generator D: 2.345827
Loss Generator P: 0.495655
Gradient discriminator: -4.157817
Gradient professor: 4.147841
Loss Generator D: 2.892720
Loss Generator P: 0.495107
Gradient discriminator: -3.404241
Gradient professor: -11.652951
Loss Generator D: 2.966315
Loss Generator P: 0.444868
Generator    : Epoch:     12, update:    2900, cost:   0.444868
Validation 29 - LOSS = 1.679 (PPL: 5.360)
Calling beam-search process
Beam-search ended, took 2.47155 minutes.
Validation 29 - BLEU = 5.85, 11.5/7.0/4.7/3.1 (BP=1.000, ratio=5.028, hyp_len=21217, ref_len=4220)
Early stopping patience: 987 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 6.630238
Gradient professor: 0.582370
Loss Generator D: 2.752297
Loss Generator P: 0.650580
Gradient discriminator: -1.810400
Gradient professor: 1.804230
Loss Generator D: 2.520575
Loss Generator P: 0.600794
Gradient discriminator: 0.549322
Gradient professor: 6.973299
Loss Generator D: 2.547234
Loss Generator P: 0.608778
Gradient discriminator: -1.067410
Gradient professor: -10.076033
Loss Generator D: 2.368552
Loss Generator P: 0.519497
Gradient discriminator: -1.513131
Gradient professor: -12.390243
Loss Generator D: 2.536165
Loss Generator P: 0.671157
Gradient discriminator: -0.657222
Gradient professor: -8.759394
Loss Generator D: 2.335744
Loss Generator P: 0.559917
Gradient discriminator: 3.228058
Gradient professor: -4.996022
Loss Generator D: 3.001143
Loss Generator P: 0.596498
Gradient discriminator: -3.103800
Gradient professor: 3.374986
Loss Generator D: 2.646322
Loss Generator P: 0.432381
Gradient discriminator: 5.301950
Gradient professor: -4.064493
Loss Generator D: 2.744228
Loss Generator P: 0.457528
Gradient discriminator: -3.365271
Gradient professor: 2.643089
Loss Generator D: 2.211780
Loss Generator P: 0.556409
Generator    : Epoch:     12, update:    2910, cost:   0.556409
Gradient discriminator: -8.755146
Gradient professor: 2.412564
Loss Generator D: 2.658093
Loss Generator P: 0.539582
Gradient discriminator: -3.050951
Gradient professor: 23.694124
Loss Generator D: 2.538970
Loss Generator P: 0.685855
Gradient discriminator: -7.796828
Gradient professor: -4.266141
Loss Generator D: 2.355450
Loss Generator P: 0.699841
Gradient discriminator: -0.137356
Gradient professor: -6.696677
Loss Generator D: 2.860078
Loss Generator P: 0.701580
Gradient discriminator: -22.687230
Gradient professor: 12.103569
Loss Generator D: 2.381085
Loss Generator P: 0.716594
Gradient discriminator: -13.372323
Gradient professor: -23.012125
Loss Generator D: 2.442806
Loss Generator P: 0.665793
Gradient discriminator: 5.688374
Gradient professor: 4.685350
Loss Generator D: 2.699473
Loss Generator P: 0.701341
Gradient discriminator: -11.109268
Gradient professor: -0.782097
Loss Generator D: 2.594737
Loss Generator P: 0.515660
Gradient discriminator: 19.303448
Gradient professor: -11.273642
Loss Generator D: 2.016215
Loss Generator P: 0.642703
Gradient discriminator: 12.482909
Gradient professor: 6.586558
Loss Generator D: 2.507481
Loss Generator P: 0.665806
Generator    : Epoch:     12, update:    2920, cost:   0.665806
Gradient discriminator: -3.445722
Gradient professor: -4.895997
Loss Generator D: 2.601992
Loss Generator P: 0.494264
Gradient discriminator: -5.450654
Gradient professor: 12.874265
Loss Generator D: 1.906105
Loss Generator P: 0.444610
Gradient discriminator: -5.573623
Gradient professor: 4.315440
Loss Generator D: 2.343425
Loss Generator P: 0.530174
Gradient discriminator: 5.013906
Gradient professor: -23.284991
Loss Generator D: 2.815145
Loss Generator P: 0.381757
Gradient discriminator: 8.672841
Gradient professor: -6.876935
Loss Generator D: 2.539463
Loss Generator P: 0.497153
Gradient discriminator: 17.485398
Gradient professor: 21.159100
Loss Generator D: 2.473760
Loss Generator P: 0.595065
Gradient discriminator: -8.358210
Gradient professor: 22.425919
Loss Generator D: 2.205001
Loss Generator P: 0.724894
Gradient discriminator: -2.678892
Gradient professor: 4.055451
Loss Generator D: 2.255912
Loss Generator P: 0.744577
Gradient discriminator: 2.550490
Gradient professor: -14.634765
Loss Generator D: 2.483830
Loss Generator P: 0.784524
Gradient discriminator: -1.768363
Gradient professor: -1.626713
Loss Generator D: 2.948036
Loss Generator P: 0.472717
Generator    : Epoch:     12, update:    2930, cost:   0.472717
Gradient discriminator: -3.804584
Gradient professor: -13.600010
Loss Generator D: 2.315196
Loss Generator P: 0.583288
Gradient discriminator: -4.095578
Gradient professor: 1.775826
Loss Generator D: 2.423509
Loss Generator P: 0.581181
Gradient discriminator: -1.150131
Gradient professor: 8.892858
Loss Generator D: 2.543508
Loss Generator P: 0.607496
Gradient discriminator: 10.027005
Gradient professor: -23.688763
Loss Generator D: 2.864480
Loss Generator P: 0.713554
Gradient discriminator: 2.742629
Gradient professor: 3.584966
Loss Generator D: 2.785239
Loss Generator P: 0.729973
Gradient discriminator: 7.362769
Gradient professor: -17.746895
Loss Generator D: 2.599431
Loss Generator P: 0.561340
Gradient discriminator: 13.835672
Gradient professor: 38.696414
Loss Generator D: 2.247613
Loss Generator P: 0.634330
Gradient discriminator: 5.859749
Gradient professor: -8.927909
Loss Generator D: 2.309473
Loss Generator P: 0.781908
Gradient discriminator: -0.305017
Gradient professor: 0.194070
Loss Generator D: 2.423664
Loss Generator P: 0.697093
Gradient discriminator: 4.668209
Gradient professor: -5.057123
Loss Generator D: 2.402319
Loss Generator P: 0.648241
Generator    : Epoch:     12, update:    2940, cost:   0.648241
Gradient discriminator: 5.613715
Gradient professor: 22.865323
Loss Generator D: 2.575883
Loss Generator P: 0.700158
Gradient discriminator: 6.704720
Gradient professor: -4.268984
Loss Generator D: 2.818301
Loss Generator P: 0.526899
Gradient discriminator: 5.820816
Gradient professor: -48.361037
Loss Generator D: 2.727972
Loss Generator P: 0.886351
Gradient discriminator: 3.987254
Gradient professor: 29.306592
Loss Generator D: 2.531046
Loss Generator P: 0.792083
Gradient discriminator: -5.464191
Gradient professor: 3.732526
Loss Generator D: 2.195117
Loss Generator P: 0.523489
Gradient discriminator: 8.450974
Gradient professor: 18.064672
Loss Generator D: 2.459938
Loss Generator P: 0.663101
Gradient discriminator: 12.268374
Gradient professor: -16.894909
Loss Generator D: 2.636585
Loss Generator P: 0.646143
Gradient discriminator: -4.037647
Gradient professor: -0.368564
Loss Generator D: 1.928727
Loss Generator P: 0.703622
Gradient discriminator: -17.691748
Gradient professor: -2.507863
Loss Generator D: 2.211030
Loss Generator P: 0.671234
Gradient discriminator: 9.426451
Gradient professor: 11.384345
Loss Generator D: 2.560210
Loss Generator P: 0.538221
Generator    : Epoch:     12, update:    2950, cost:   0.538221
Gradient discriminator: 6.001043
Gradient professor: 18.597113
Loss Generator D: 2.614943
Loss Generator P: 0.616501
Gradient discriminator: -9.118199
Gradient professor: -7.791180
Loss Generator D: 2.390962
Loss Generator P: 0.631810
Gradient discriminator: 8.994036
Gradient professor: 5.426817
Loss Generator D: 2.858507
Loss Generator P: 0.549554
Gradient discriminator: 5.571266
Gradient professor: -30.737904
Loss Generator D: 2.880997
Loss Generator P: 0.586283
Gradient discriminator: 1.805889
Gradient professor: 20.882178
Loss Generator D: 2.769907
Loss Generator P: 0.511102
Gradient discriminator: 0.443363
Gradient professor: -10.077610
Loss Generator D: 2.827418
Loss Generator P: 0.438618
Gradient discriminator: 1.979926
Gradient professor: -14.282181
Loss Generator D: 3.141057
Loss Generator P: 0.666239
Gradient discriminator: 1.472367
Gradient professor: 9.466722
Loss Generator D: 2.586810
Loss Generator P: 0.675403
Gradient discriminator: 6.773313
Gradient professor: -2.357118
Loss Generator D: 2.652255
Loss Generator P: 0.588084
Gradient discriminator: 2.024602
Gradient professor: -27.376522
Loss Generator D: 2.756511
Loss Generator P: 0.665521
Generator    : Epoch:     12, update:    2960, cost:   0.665521
Gradient discriminator: -5.105886
Gradient professor: -10.715281
Loss Generator D: 2.788827
Loss Generator P: 0.686717
Gradient discriminator: -4.500846
Gradient professor: -3.818801
Loss Generator D: 2.626651
Loss Generator P: 0.752956
Gradient discriminator: -5.399067
Gradient professor: 6.685969
Loss Generator D: 3.013305
Loss Generator P: 0.563456
Gradient discriminator: -2.577988
Gradient professor: -0.112443
Loss Generator D: 2.180955
Loss Generator P: 0.474049
Gradient discriminator: -3.216616
Gradient professor: 32.817801
Loss Generator D: 2.940750
Loss Generator P: 0.616985
Gradient discriminator: -2.490817
Gradient professor: 21.826723
Loss Generator D: 2.940791
Loss Generator P: 0.678108
Gradient discriminator: 9.065809
Gradient professor: 3.182907
Loss Generator D: 2.888132
Loss Generator P: 0.630756
Gradient discriminator: -2.079931
Gradient professor: -4.670421
Loss Generator D: 2.552764
Loss Generator P: 0.613201
Gradient discriminator: 0.675098
Gradient professor: 11.639481
Loss Generator D: 2.593126
Loss Generator P: 0.505062
Gradient discriminator: -4.885225
Gradient professor: -25.551436
Loss Generator D: 2.678336
Loss Generator P: 0.473476
Generator    : Epoch:     12, update:    2970, cost:   0.473476
Gradient discriminator: -4.124294
Gradient professor: 1.734440
Loss Generator D: 2.797057
Loss Generator P: 0.669151
Gradient discriminator: -3.062301
Gradient professor: -13.320753
Loss Generator D: 2.650795
Loss Generator P: 0.548001
Gradient discriminator: 0.908137
Gradient professor: 11.988058
Loss Generator D: 2.921695
Loss Generator P: 0.610728
Gradient discriminator: 7.377316
Gradient professor: 6.576910
Loss Generator D: 3.176377
Loss Generator P: 0.554589
Gradient discriminator: 3.637470
Gradient professor: 25.532981
Loss Generator D: 3.204937
Loss Generator P: 0.504600
Gradient discriminator: -22.183070
Gradient professor: 44.560972
Loss Generator D: 2.686122
Loss Generator P: 0.602365
Gradient discriminator: 4.509123
Gradient professor: -7.556548
Loss Generator D: 2.922613
Loss Generator P: 0.520235
Gradient discriminator: 7.828937
Gradient professor: 9.213751
Loss Generator D: 3.098307
Loss Generator P: 0.554705
Gradient discriminator: -5.637863
Gradient professor: -2.865815
Loss Generator D: 2.878668
Loss Generator P: 0.567820
Gradient discriminator: 0.959765
Gradient professor: 1.896247
Loss Generator D: 2.661323
Loss Generator P: 0.581075
Generator    : Epoch:     12, update:    2980, cost:   0.581075
Gradient discriminator: 6.653209
Gradient professor: -4.745461
Loss Generator D: 2.639816
Loss Generator P: 0.652109
Gradient discriminator: 0.623566
Gradient professor: 9.843391
Loss Generator D: 2.859579
Loss Generator P: 0.715386
Gradient discriminator: 2.363913
Gradient professor: -0.582844
Loss Generator D: 2.784010
Loss Generator P: 0.819387
Gradient discriminator: 6.533930
Gradient professor: 3.612541
Loss Generator D: 2.765518
Loss Generator P: 0.488079
Gradient discriminator: -3.904321
Gradient professor: 21.750366
Loss Generator D: 2.611060
Loss Generator P: 0.546489
Gradient discriminator: -0.880250
Gradient professor: -0.496329
Loss Generator D: 2.738852
Loss Generator P: 0.540852
Gradient discriminator: 9.695821
Gradient professor: 2.953964
Loss Generator D: 2.967351
Loss Generator P: 0.442798
Gradient discriminator: -2.350903
Gradient professor: 5.625694
Loss Generator D: 2.618195
Loss Generator P: 0.572532
Gradient discriminator: -18.429019
Gradient professor: -2.396896
Loss Generator D: 2.795520
Loss Generator P: 0.541626
Gradient discriminator: 6.028474
Gradient professor: -13.543208
Loss Generator D: 2.585012
Loss Generator P: 0.517059
Generator    : Epoch:     12, update:    2990, cost:   0.517059
Gradient discriminator: -0.855464
Gradient professor: 30.244411
Loss Generator D: 2.582677
Loss Generator P: 0.549368
Gradient discriminator: 12.824633
Gradient professor: 1.463928
Loss Generator D: 2.572218
Loss Generator P: 0.516194
Gradient discriminator: -8.272908
Gradient professor: 4.087963
Loss Generator D: 2.711258
Loss Generator P: 0.468918
Gradient discriminator: 4.713706
Gradient professor: -3.040919
Loss Generator D: 2.613053
Loss Generator P: 0.573664
Gradient discriminator: 7.526911
Gradient professor: 5.424422
Loss Generator D: 3.412071
Loss Generator P: 0.675125
Gradient discriminator: 17.199567
Gradient professor: 1.337412
Loss Generator D: 3.049334
Loss Generator P: 0.541173
Gradient discriminator: 1.529922
Gradient professor: -1.488811
Loss Generator D: 3.119932
Loss Generator P: 0.520123
Gradient discriminator: 6.068434
Gradient professor: -8.622427
Loss Generator D: 3.364049
Loss Generator P: 0.486973
Gradient discriminator: 1.656836
Gradient professor: 6.293661
Loss Generator D: 3.045305
Loss Generator P: 0.555436
Gradient discriminator: 5.080737
Gradient professor: 10.001617
Loss Generator D: 2.714888
Loss Generator P: 0.277274
Generator    : Epoch:     12, update:    3000, cost:   0.277274
Validation 30 - LOSS = 1.658 (PPL: 5.247)
Calling beam-search process
Beam-search ended, took 2.27493 minutes.
Validation 30 - BLEU = 7.45, 13.9/8.9/6.1/4.1 (BP=1.000, ratio=4.299, hyp_len=18140, ref_len=4220)
Early stopping patience: 986 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 12 finished with mean loss 1.67376 (PPL: 5.33219)
--> Epoch took 271.286 minutes, 65.109 sec/update
Epoch summary of Discriminator:
--> Epoch 12 finished with mean loss nan (PPL:  nan)
--> Epoch took 271.286 minutes, 65.109 sec/update
---------------------------------------------------------
Starting Epoch 13
-----------------
Gradient discriminator: 4.779905
Gradient professor: -1.690200
Loss Generator D: 2.632020
Loss Generator P: 0.739902
Gradient discriminator: -3.013441
Gradient professor: 11.560704
Loss Generator D: 2.491163
Loss Generator P: 0.598410
Gradient discriminator: 2.519334
Gradient professor: 10.166247
Loss Generator D: 2.928866
Loss Generator P: 0.557529
Gradient discriminator: 6.386800
Gradient professor: -10.373068
Loss Generator D: 2.622395
Loss Generator P: 0.755662
Gradient discriminator: 13.020087
Gradient professor: -16.813053
Loss Generator D: 3.262872
Loss Generator P: 0.547936
Gradient discriminator: 20.603250
Gradient professor: 5.143398
Loss Generator D: 2.747776
Loss Generator P: 0.581215
Gradient discriminator: 1.826461
Gradient professor: -0.757587
Loss Generator D: 2.819239
Loss Generator P: 0.628888
Gradient discriminator: 25.302754
Gradient professor: 16.747816
Loss Generator D: 2.242627
Loss Generator P: 0.571795
Gradient discriminator: -15.414070
Gradient professor: 26.424918
Loss Generator D: 3.040596
Loss Generator P: 0.794350
Gradient discriminator: 1.841208
Gradient professor: 14.376879
Loss Generator D: 2.530224
Loss Generator P: 0.790335
Generator    : Epoch:     13, update:    3010, cost:   0.790335
Gradient discriminator: 3.784884
Gradient professor: 3.598547
Loss Generator D: 2.979069
Loss Generator P: 0.812452
Gradient discriminator: -16.559533
Gradient professor: 13.046893
Loss Generator D: 3.105395
Loss Generator P: 0.557868
Gradient discriminator: 1.918115
Gradient professor: 13.393958
Loss Generator D: 2.888550
Loss Generator P: 0.681865
Gradient discriminator: -13.012014
Gradient professor: -6.970336
Loss Generator D: 3.016656
Loss Generator P: 0.652093
Gradient discriminator: 0.654231
Gradient professor: 17.250549
Loss Generator D: 3.021371
Loss Generator P: 0.470840
Gradient discriminator: 6.336716
Gradient professor: 3.129891
Loss Generator D: 3.072679
Loss Generator P: 0.381618
Gradient discriminator: 6.559206
Gradient professor: -4.641884
Loss Generator D: 3.557700
Loss Generator P: 0.571369
Gradient discriminator: -5.785332
Gradient professor: -7.737224
Loss Generator D: 3.612958
Loss Generator P: 0.497572
Gradient discriminator: 1.646782
Gradient professor: 4.711872
Loss Generator D: 3.701735
Loss Generator P: 0.612894
Gradient discriminator: -7.377666
Gradient professor: 20.112948
Loss Generator D: 2.933167
Loss Generator P: 0.683553
Generator    : Epoch:     13, update:    3020, cost:   0.683553
Gradient discriminator: 3.937810
Gradient professor: -7.671898
Loss Generator D: 2.917330
Loss Generator P: 0.576215
Gradient discriminator: -6.353269
Gradient professor: 12.632951
Loss Generator D: 3.261523
Loss Generator P: 0.564235
Gradient discriminator: 2.368007
Gradient professor: 16.045372
Loss Generator D: 3.132196
Loss Generator P: 0.500623
Gradient discriminator: 1.059447
Gradient professor: 10.996026
Loss Generator D: 2.795535
Loss Generator P: 0.786854
Gradient discriminator: -10.421175
Gradient professor: -2.574925
Loss Generator D: 3.445011
Loss Generator P: 0.718371
Gradient discriminator: -7.101625
Gradient professor: -1.471760
Loss Generator D: 2.874628
Loss Generator P: 0.581452
Gradient discriminator: 0.317092
Gradient professor: 9.330042
Loss Generator D: 2.731416
Loss Generator P: 0.430878
Gradient discriminator: -7.888929
Gradient professor: 17.993821
Loss Generator D: 2.606452
Loss Generator P: 0.545158
Gradient discriminator: 2.483201
Gradient professor: 22.060640
Loss Generator D: 2.864058
Loss Generator P: 0.467953
Gradient discriminator: -21.106791
Gradient professor: 15.091529
Loss Generator D: 3.185510
Loss Generator P: 0.532441
Generator    : Epoch:     13, update:    3030, cost:   0.532441
Gradient discriminator: 0.245686
Gradient professor: -9.298011
Loss Generator D: 3.156751
Loss Generator P: 0.526632
Gradient discriminator: -3.987811
Gradient professor: -11.718002
Loss Generator D: 3.022015
Loss Generator P: 0.461622
Gradient discriminator: 1.685820
Gradient professor: 20.786207
Loss Generator D: 3.877413
Loss Generator P: 0.778025
Gradient discriminator: 1.451755
Gradient professor: -10.193508
Loss Generator D: 2.912154
Loss Generator P: 0.793150
Gradient discriminator: -12.900361
Gradient professor: 9.224216
Loss Generator D: 2.851864
Loss Generator P: 0.544461
Gradient discriminator: 1.939288
Gradient professor: -9.628606
Loss Generator D: 2.900036
Loss Generator P: 0.481376
Gradient discriminator: 3.573410
Gradient professor: 0.496471
Loss Generator D: 2.715967
Loss Generator P: 0.484643
Gradient discriminator: 1.384056
Gradient professor: 8.642717
Loss Generator D: 3.020010
Loss Generator P: 0.558205
Gradient discriminator: 3.403121
Gradient professor: -12.059098
Loss Generator D: 2.622913
Loss Generator P: 0.581339
Gradient discriminator: 1.123939
Gradient professor: 27.125619
Loss Generator D: 3.014054
Loss Generator P: 0.685816
Generator    : Epoch:     13, update:    3040, cost:   0.685816
Gradient discriminator: 8.763958
Gradient professor: -3.181725
Loss Generator D: 3.120350
Loss Generator P: 0.620151
Gradient discriminator: -12.624499
Gradient professor: -0.502199
Loss Generator D: 3.312995
Loss Generator P: 0.597888
Gradient discriminator: 4.378142
Gradient professor: -11.924358
Loss Generator D: 3.488245
Loss Generator P: 0.559574
Gradient discriminator: 8.944882
Gradient professor: 11.167564
Loss Generator D: 3.116922
Loss Generator P: 0.525479
Gradient discriminator: 3.757678
Gradient professor: -3.110660
Loss Generator D: 3.502144
Loss Generator P: 0.704909
Gradient discriminator: -0.116340
Gradient professor: -18.181333
Loss Generator D: 3.215523
Loss Generator P: 0.609680
Gradient discriminator: 5.328783
Gradient professor: 29.175129
Loss Generator D: 3.143251
Loss Generator P: 0.473713
Gradient discriminator: -3.250633
Gradient professor: 3.474252
Loss Generator D: 3.050458
Loss Generator P: 0.647122
Gradient discriminator: -0.255403
Gradient professor: -3.321107
Loss Generator D: 3.635963
Loss Generator P: 0.810496
Gradient discriminator: -4.932117
Gradient professor: -13.607724
Loss Generator D: 3.048645
Loss Generator P: 0.647876
Generator    : Epoch:     13, update:    3050, cost:   0.647876
Gradient discriminator: 10.595381
Gradient professor: 25.145010
Loss Generator D: 3.063906
Loss Generator P: 0.633065
Gradient discriminator: -3.576643
Gradient professor: -25.544205
Loss Generator D: 2.946694
Loss Generator P: 0.593550
Gradient discriminator: 6.820858
Gradient professor: 11.616895
Loss Generator D: 2.418070
Loss Generator P: 0.560870
Gradient discriminator: 10.904119
Gradient professor: -22.985340
Loss Generator D: 2.720637
Loss Generator P: 0.645396
Gradient discriminator: 9.535008
Gradient professor: -17.829953
Loss Generator D: 2.886620
Loss Generator P: 0.606254
Gradient discriminator: -3.350566
Gradient professor: 8.125005
Loss Generator D: 3.380843
Loss Generator P: 0.514415
Gradient discriminator: -4.868463
Gradient professor: 3.207320
Loss Generator D: 2.218359
Loss Generator P: 0.473320
Gradient discriminator: 3.957821
Gradient professor: -1.133388
Loss Generator D: 3.309611
Loss Generator P: 0.450800
Gradient discriminator: -1.725510
Gradient professor: 19.504122
Loss Generator D: 2.945294
Loss Generator P: 0.499004
Gradient discriminator: -6.724988
Gradient professor: -13.436686
Loss Generator D: 3.069814
Loss Generator P: 0.561165
Generator    : Epoch:     13, update:    3060, cost:   0.561165
Gradient discriminator: 2.226633
Gradient professor: 0.565069
Loss Generator D: 3.050402
Loss Generator P: 0.548222
Gradient discriminator: -10.443257
Gradient professor: 16.341050
Loss Generator D: 2.724033
Loss Generator P: 0.713596
Gradient discriminator: 9.853378
Gradient professor: 10.416981
Loss Generator D: 2.599388
Loss Generator P: 0.588508
Gradient discriminator: -11.770180
Gradient professor: 29.816349
Loss Generator D: 2.807552
Loss Generator P: 0.552251
Gradient discriminator: 17.970413
Gradient professor: -18.691026
Loss Generator D: 2.469832
Loss Generator P: 0.640389
Gradient discriminator: -12.380015
Gradient professor: -26.068405
Loss Generator D: 2.267399
Loss Generator P: 0.648609
Gradient discriminator: -27.882557
Gradient professor: -8.043438
Loss Generator D: 2.785383
Loss Generator P: 0.609350
Gradient discriminator: 10.794349
Gradient professor: 15.348965
Loss Generator D: 2.813397
Loss Generator P: 0.513751
Gradient discriminator: 7.108030
Gradient professor: 26.382381
Loss Generator D: 2.873090
Loss Generator P: 0.701787
Gradient discriminator: 1.949442
Gradient professor: 17.995810
Loss Generator D: 2.700696
Loss Generator P: 0.570190
Generator    : Epoch:     13, update:    3070, cost:   0.570190
Gradient discriminator: 0.542793
Gradient professor: 15.422920
Loss Generator D: 3.103033
Loss Generator P: 0.488401
Gradient discriminator: 3.552649
Gradient professor: -0.758598
Loss Generator D: 2.875967
Loss Generator P: 0.441174
Gradient discriminator: 7.255869
Gradient professor: 8.148385
Loss Generator D: 2.489852
Loss Generator P: 0.564839
Gradient discriminator: 6.110279
Gradient professor: 2.091659
Loss Generator D: 2.791012
Loss Generator P: 0.578717
Gradient discriminator: -4.873322
Gradient professor: -0.980652
Loss Generator D: 2.730821
Loss Generator P: 0.563725
Gradient discriminator: 0.869913
Gradient professor: 13.556065
Loss Generator D: 2.215238
Loss Generator P: 0.488932
Gradient discriminator: -5.973880
Gradient professor: -17.314505
Loss Generator D: 2.976734
Loss Generator P: 0.582308
Gradient discriminator: 3.899324
Gradient professor: -4.701928
Loss Generator D: 2.811328
Loss Generator P: 0.709188
Gradient discriminator: 9.186211
Gradient professor: -3.427972
Loss Generator D: 2.546334
Loss Generator P: 0.377344
Gradient discriminator: 2.790091
Gradient professor: -22.217783
Loss Generator D: 2.810093
Loss Generator P: 0.395247
Generator    : Epoch:     13, update:    3080, cost:   0.395247
Gradient discriminator: 1.063149
Gradient professor: -16.216930
Loss Generator D: 3.303722
Loss Generator P: 0.435844
Gradient discriminator: -0.751702
Gradient professor: 13.473983
Loss Generator D: 3.412041
Loss Generator P: 0.441042
Gradient discriminator: -17.400745
Gradient professor: 9.427385
Loss Generator D: 2.828075
Loss Generator P: 0.422995
Gradient discriminator: 4.263023
Gradient professor: -9.653776
Loss Generator D: 2.806531
Loss Generator P: 0.328135
Gradient discriminator: -9.649461
Gradient professor: 14.758979
Loss Generator D: 3.497930
Loss Generator P: 0.380931
Gradient discriminator: 4.064497
Gradient professor: -19.221377
Loss Generator D: 3.194273
Loss Generator P: 0.391806
Gradient discriminator: 2.494446
Gradient professor: -3.780843
Loss Generator D: 3.483978
Loss Generator P: 0.404858
Gradient discriminator: 15.447724
Gradient professor: -8.591159
Loss Generator D: 3.372719
Loss Generator P: 0.555937
Gradient discriminator: -2.644666
Gradient professor: -29.363619
Loss Generator D: 3.338356
Loss Generator P: 0.451011
Gradient discriminator: 12.721736
Gradient professor: 31.735592
Loss Generator D: 3.260721
Loss Generator P: 0.690203
Generator    : Epoch:     13, update:    3090, cost:   0.690203
Gradient discriminator: 1.020541
Gradient professor: 18.593517
Loss Generator D: 2.979385
Loss Generator P: 0.423063
Gradient discriminator: -8.579395
Gradient professor: 6.554546
Loss Generator D: 2.971032
Loss Generator P: 0.681884
Gradient discriminator: 4.682106
Gradient professor: -19.460990
Loss Generator D: 2.832557
Loss Generator P: 0.500079
Gradient discriminator: -13.754675
Gradient professor: 2.093555
Loss Generator D: 2.813423
Loss Generator P: 0.398414
Gradient discriminator: 22.914433
Gradient professor: 8.815384
Loss Generator D: 2.785458
Loss Generator P: 0.463400
Gradient discriminator: -6.622495
Gradient professor: -9.428571
Loss Generator D: 2.782376
Loss Generator P: 0.514485
Gradient discriminator: -1.703278
Gradient professor: 3.779734
Loss Generator D: 3.592188
Loss Generator P: 0.471493
Gradient discriminator: -2.736355
Gradient professor: -39.039251
Loss Generator D: 3.119823
Loss Generator P: 0.430332
Gradient discriminator: 2.552980
Gradient professor: 16.990157
Loss Generator D: 3.622966
Loss Generator P: 0.439590
Gradient discriminator: 0.871360
Gradient professor: -15.248317
Loss Generator D: 3.728024
Loss Generator P: 0.561689
Generator    : Epoch:     13, update:    3100, cost:   0.561689
Validation 31 - LOSS = 1.604 (PPL: 4.972)
Calling beam-search process
Beam-search ended, took 1.76475 minutes.
Validation 31 - BLEU = 13.76, 24.5/16.2/11.4/7.9 (BP=1.000, ratio=2.696, hyp_len=11377, ref_len=4220)
Early stopping patience: 985 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 6.928234
Gradient professor: -14.265249
Loss Generator D: 3.542364
Loss Generator P: 0.639069
Gradient discriminator: -3.041804
Gradient professor: -20.292919
Loss Generator D: 2.506707
Loss Generator P: 0.537773
Gradient discriminator: 0.836709
Gradient professor: 2.488040
Loss Generator D: 3.340982
Loss Generator P: 0.477506
Gradient discriminator: -10.369620
Gradient professor: 3.147519
Loss Generator D: 2.923690
Loss Generator P: 0.491915
Gradient discriminator: 5.719688
Gradient professor: 23.333718
Loss Generator D: 3.234476
Loss Generator P: 0.380749
Gradient discriminator: -2.622762
Gradient professor: -3.369571
Loss Generator D: 3.228306
Loss Generator P: 0.590589
Gradient discriminator: 17.645009
Gradient professor: -20.389283
Loss Generator D: 2.718412
Loss Generator P: 0.427149
Gradient discriminator: 3.178732
Gradient professor: -11.992205
Loss Generator D: 2.997892
Loss Generator P: 0.409889
Gradient discriminator: 4.515331
Gradient professor: 21.953689
Loss Generator D: 3.446082
Loss Generator P: 0.576656
Gradient discriminator: -9.453876
Gradient professor: 2.846528
Loss Generator D: 2.821105
Loss Generator P: 0.473528
Generator    : Epoch:     13, update:    3110, cost:   0.473528
Gradient discriminator: 5.435240
Gradient professor: 28.683801
Loss Generator D: 3.160782
Loss Generator P: 0.533367
Gradient discriminator: 7.872790
Gradient professor: 13.933738
Loss Generator D: 2.782689
Loss Generator P: 0.533404
Gradient discriminator: 5.943377
Gradient professor: 2.390056
Loss Generator D: 3.600125
Loss Generator P: 0.416476
Gradient discriminator: -0.922593
Gradient professor: 0.331881
Loss Generator D: 3.063803
Loss Generator P: 0.382823
Gradient discriminator: 1.010818
Gradient professor: 9.149966
Loss Generator D: 3.524536
Loss Generator P: 0.563394
Gradient discriminator: -0.873637
Gradient professor: 0.231137
Loss Generator D: 2.808184
Loss Generator P: 0.617064
Gradient discriminator: 5.147145
Gradient professor: 7.432488
Loss Generator D: 3.066912
Loss Generator P: 0.353746
Gradient discriminator: 5.877744
Gradient professor: -33.831595
Loss Generator D: 3.747890
Loss Generator P: 0.609709
Gradient discriminator: 4.923298
Gradient professor: -4.308697
Loss Generator D: 3.528207
Loss Generator P: 0.414408
Gradient discriminator: 2.325808
Gradient professor: 1.525016
Loss Generator D: 3.128996
Loss Generator P: 0.488253
Generator    : Epoch:     13, update:    3120, cost:   0.488253
Gradient discriminator: -6.896064
Gradient professor: -17.584402
Loss Generator D: 3.623188
Loss Generator P: 0.546190
Gradient discriminator: 5.254642
Gradient professor: -11.313694
Loss Generator D: 2.832770
Loss Generator P: 0.528614
Gradient discriminator: 2.524700
Gradient professor: 21.630079
Loss Generator D: 3.480691
Loss Generator P: 0.562773
Gradient discriminator: -5.510681
Gradient professor: 49.486849
Loss Generator D: 3.045991
Loss Generator P: 0.613888
Gradient discriminator: 7.686170
Gradient professor: 19.578028
Loss Generator D: 2.806198
Loss Generator P: 0.598440
Gradient discriminator: -16.969656
Gradient professor: 17.275303
Loss Generator D: 3.085676
Loss Generator P: 0.601132
Gradient discriminator: 2.063530
Gradient professor: -6.782219
Loss Generator D: 2.645491
Loss Generator P: 0.543595
Gradient discriminator: 8.448314
Gradient professor: 5.273220
Loss Generator D: 3.524210
Loss Generator P: 0.622978
Gradient discriminator: -1.385719
Gradient professor: 24.304715
Loss Generator D: 2.850215
Loss Generator P: 0.602050
Gradient discriminator: 2.006146
Gradient professor: -33.940796
Loss Generator D: 3.310212
Loss Generator P: 0.640578
Generator    : Epoch:     13, update:    3130, cost:   0.640578
Gradient discriminator: 1.009770
Gradient professor: 6.381187
Loss Generator D: 2.990523
Loss Generator P: 0.534611
Gradient discriminator: 0.573453
Gradient professor: -12.669799
Loss Generator D: 3.174887
Loss Generator P: 0.507262
Gradient discriminator: -2.924682
Gradient professor: 23.138522
Loss Generator D: 2.302499
Loss Generator P: 0.425913
Gradient discriminator: -2.697434
Gradient professor: -42.429110
Loss Generator D: 3.060424
Loss Generator P: 0.734514
Gradient discriminator: 2.319231
Gradient professor: 44.004759
Loss Generator D: 2.342876
Loss Generator P: 0.583727
Gradient discriminator: 1.544004
Gradient professor: -18.225910
Loss Generator D: 3.287977
Loss Generator P: 0.422345
Gradient discriminator: 3.155020
Gradient professor: 12.538516
Loss Generator D: 2.791630
Loss Generator P: 0.485242
Gradient discriminator: 2.421594
Gradient professor: -1.367479
Loss Generator D: 3.505477
Loss Generator P: 0.390820
Gradient discriminator: 10.213663
Gradient professor: 19.327317
Loss Generator D: 3.104666
Loss Generator P: 0.634653
Gradient discriminator: 1.181511
Gradient professor: 16.097564
Loss Generator D: 2.843426
Loss Generator P: 0.525872
Generator    : Epoch:     13, update:    3140, cost:   0.525872
Gradient discriminator: 1.927315
Gradient professor: -19.089388
Loss Generator D: 3.002799
Loss Generator P: 0.448012
Gradient discriminator: 3.341252
Gradient professor: 0.906358
Loss Generator D: 3.300438
Loss Generator P: 0.576928
Gradient discriminator: 3.685249
Gradient professor: -8.154316
Loss Generator D: 3.105453
Loss Generator P: 0.695803
Gradient discriminator: 3.639231
Gradient professor: -9.994718
Loss Generator D: 3.340142
Loss Generator P: 0.589349
Gradient discriminator: -1.277293
Gradient professor: 1.954082
Loss Generator D: 3.093709
Loss Generator P: 0.644130
Gradient discriminator: -6.321533
Gradient professor: -3.478437
Loss Generator D: 2.930606
Loss Generator P: 0.680209
Gradient discriminator: -6.046768
Gradient professor: 10.724225
Loss Generator D: 3.221156
Loss Generator P: 0.379746
Gradient discriminator: -4.742660
Gradient professor: 3.576149
Loss Generator D: 3.129864
Loss Generator P: 0.466965
Gradient discriminator: -5.258188
Gradient professor: 12.286964
Loss Generator D: 3.504249
Loss Generator P: 0.432308
Gradient discriminator: 4.850220
Gradient professor: -11.485810
Loss Generator D: 3.523952
Loss Generator P: 0.404382
Generator    : Epoch:     13, update:    3150, cost:   0.404382
Gradient discriminator: 7.266315
Gradient professor: 10.382587
Loss Generator D: 3.190045
Loss Generator P: 0.619335
Gradient discriminator: 4.162145
Gradient professor: 5.750258
Loss Generator D: 3.185037
Loss Generator P: 0.613662
Gradient discriminator: 1.958731
Gradient professor: 15.258273
Loss Generator D: 3.279992
Loss Generator P: 0.588379
Gradient discriminator: 5.697972
Gradient professor: -14.653976
Loss Generator D: 3.208059
Loss Generator P: 0.472851
Gradient discriminator: 2.174789
Gradient professor: 15.130423
Loss Generator D: 3.209759
Loss Generator P: 0.612515
Gradient discriminator: -0.550368
Gradient professor: -12.278553
Loss Generator D: 3.536874
Loss Generator P: 0.470493
Gradient discriminator: 12.062527
Gradient professor: 17.900071
Loss Generator D: 3.542743
Loss Generator P: 0.543094
Gradient discriminator: -3.571906
Gradient professor: 0.994402
Loss Generator D: 2.766475
Loss Generator P: 0.387923
Gradient discriminator: 0.735753
Gradient professor: -3.581101
Loss Generator D: 3.205484
Loss Generator P: 0.446316
Gradient discriminator: -6.288795
Gradient professor: 7.341235
Loss Generator D: 2.841065
Loss Generator P: 0.490102
Generator    : Epoch:     13, update:    3160, cost:   0.490102
Gradient discriminator: 0.427305
Gradient professor: -9.564095
Loss Generator D: 3.056316
Loss Generator P: 0.531352
Gradient discriminator: 12.256350
Gradient professor: 22.354318
Loss Generator D: 2.981465
Loss Generator P: 0.681466
Gradient discriminator: 2.882596
Gradient professor: 14.335903
Loss Generator D: 3.160569
Loss Generator P: 0.641591
Gradient discriminator: 0.727141
Gradient professor: 9.105573
Loss Generator D: 3.126233
Loss Generator P: 0.617639
Gradient discriminator: 14.247120
Gradient professor: 1.649497
Loss Generator D: 2.702140
Loss Generator P: 0.749795
Gradient discriminator: 0.126350
Gradient professor: 3.367990
Loss Generator D: 2.748381
Loss Generator P: 0.697431
Gradient discriminator: -11.470085
Gradient professor: 28.294442
Loss Generator D: 2.768795
Loss Generator P: 0.659204
Gradient discriminator: -2.700235
Gradient professor: 8.746188
Loss Generator D: 3.179702
Loss Generator P: 0.468186
Gradient discriminator: 2.007979
Gradient professor: -7.300022
Loss Generator D: 2.639279
Loss Generator P: 0.585948
Gradient discriminator: -2.224875
Gradient professor: 6.885411
Loss Generator D: 3.126386
Loss Generator P: 0.618460
Generator    : Epoch:     13, update:    3170, cost:   0.618460
Gradient discriminator: 0.715508
Gradient professor: -3.553731
Loss Generator D: 2.774958
Loss Generator P: 0.470193
Gradient discriminator: -31.366267
Gradient professor: -1.173649
Loss Generator D: 2.319903
Loss Generator P: 0.461110
Gradient discriminator: 6.089362
Gradient professor: 20.323086
Loss Generator D: 2.996989
Loss Generator P: 0.531271
Gradient discriminator: 1.666118
Gradient professor: -7.661259
Loss Generator D: 2.828932
Loss Generator P: 0.359505
Gradient discriminator: 0.863345
Gradient professor: -15.372982
Loss Generator D: 2.899577
Loss Generator P: 0.444075
Gradient discriminator: -9.445636
Gradient professor: -8.609940
Loss Generator D: 3.091073
Loss Generator P: 0.569759
Gradient discriminator: -11.532381
Gradient professor: -17.671602
Loss Generator D: 2.366493
Loss Generator P: 0.662274
Gradient discriminator: -1.219731
Gradient professor: 14.506831
Loss Generator D: 2.710784
Loss Generator P: 0.714481
Gradient discriminator: 3.102221
Gradient professor: -13.689190
Loss Generator D: 2.856201
Loss Generator P: 0.746399
Gradient discriminator: 5.524280
Gradient professor: 21.472757
Loss Generator D: 2.980593
Loss Generator P: 0.472742
Generator    : Epoch:     13, update:    3180, cost:   0.472742
Gradient discriminator: 3.979748
Gradient professor: 9.474599
Loss Generator D: 2.730354
Loss Generator P: 0.543677
Gradient discriminator: -2.169257
Gradient professor: -13.164832
Loss Generator D: 2.747024
Loss Generator P: 0.528936
Gradient discriminator: -6.130231
Gradient professor: -36.298458
Loss Generator D: 2.954069
Loss Generator P: 0.566191
Gradient discriminator: 8.171504
Gradient professor: 6.080724
Loss Generator D: 2.797485
Loss Generator P: 0.703595
Gradient discriminator: 0.790867
Gradient professor: -21.738641
Loss Generator D: 2.685727
Loss Generator P: 0.668004
Gradient discriminator: 5.842497
Gradient professor: 2.559097
Loss Generator D: 2.820270
Loss Generator P: 0.498573
Gradient discriminator: -17.319036
Gradient professor: 1.099755
Loss Generator D: 2.171047
Loss Generator P: 0.593116
Gradient discriminator: 26.087184
Gradient professor: -0.200660
Loss Generator D: 2.398172
Loss Generator P: 0.685038
Gradient discriminator: -6.511285
Gradient professor: 20.475509
Loss Generator D: 2.358249
Loss Generator P: 0.650101
Gradient discriminator: 11.340609
Gradient professor: -18.537416
Loss Generator D: 2.389086
Loss Generator P: 0.612941
Generator    : Epoch:     13, update:    3190, cost:   0.612941
Gradient discriminator: -2.197252
Gradient professor: -1.239380
Loss Generator D: 2.806419
Loss Generator P: 0.624411
Gradient discriminator: 1.747372
Gradient professor: -0.954877
Loss Generator D: 2.793684
Loss Generator P: 0.505732
Gradient discriminator: 6.043861
Gradient professor: 4.938207
Loss Generator D: 2.461306
Loss Generator P: 0.841420
Gradient discriminator: -1.990469
Gradient professor: 7.978694
Loss Generator D: 2.794276
Loss Generator P: 0.773352
Gradient discriminator: -1.399250
Gradient professor: 3.602888
Loss Generator D: 2.031391
Loss Generator P: 0.501852
Gradient discriminator: -2.901753
Gradient professor: -11.579105
Loss Generator D: 2.465493
Loss Generator P: 0.613530
Gradient discriminator: 14.149366
Gradient professor: 4.211054
Loss Generator D: 2.640413
Loss Generator P: 0.608873
Gradient discriminator: 1.841788
Gradient professor: -20.656675
Loss Generator D: 2.207502
Loss Generator P: 0.732498
Gradient discriminator: -2.294425
Gradient professor: 1.927147
Loss Generator D: 2.164355
Loss Generator P: 0.626282
Gradient discriminator: 4.708533
Gradient professor: -5.411405
Loss Generator D: 2.470070
Loss Generator P: 0.480150
Generator    : Epoch:     13, update:    3200, cost:   0.480150
Validation 32 - LOSS = 1.621 (PPL: 5.057)
Calling beam-search process
Beam-search ended, took 2.60917 minutes.
Validation 32 - BLEU = 5.84, 11.2/7.0/4.7/3.1 (BP=1.000, ratio=5.213, hyp_len=21999, ref_len=4220)
Early stopping patience: 984 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -1.182800
Gradient professor: 7.770891
Loss Generator D: 2.302833
Loss Generator P: 0.563350
Gradient discriminator: 2.819344
Gradient professor: -19.754044
Loss Generator D: 2.452985
Loss Generator P: 0.537050
Gradient discriminator: -5.787091
Gradient professor: -3.482526
Loss Generator D: 2.466085
Loss Generator P: 0.494173
Gradient discriminator: -1.821834
Gradient professor: 7.294351
Loss Generator D: 2.169756
Loss Generator P: 0.537356
Gradient discriminator: 10.735298
Gradient professor: -29.802575
Loss Generator D: 2.255397
Loss Generator P: 0.447379
Gradient discriminator: 16.465759
Gradient professor: 3.191498
Loss Generator D: 2.236225
Loss Generator P: 0.417511
Gradient discriminator: 22.565918
Gradient professor: 8.094455
Loss Generator D: 2.811268
Loss Generator P: 0.620289
Gradient discriminator: 3.918420
Gradient professor: 8.706763
Loss Generator D: 2.432978
Loss Generator P: 0.623338
Gradient discriminator: 7.751269
Gradient professor: -16.844173
Loss Generator D: 2.079140
Loss Generator P: 0.468242
Gradient discriminator: 14.189183
Gradient professor: -13.207899
Loss Generator D: 2.555228
Loss Generator P: 0.609894
Generator    : Epoch:     13, update:    3210, cost:   0.609894
Gradient discriminator: 5.272448
Gradient professor: 3.459446
Loss Generator D: 2.740738
Loss Generator P: 0.583282
Gradient discriminator: 6.637024
Gradient professor: 6.935127
Loss Generator D: 2.408177
Loss Generator P: 0.663199
Gradient discriminator: 2.545927
Gradient professor: -1.768941
Loss Generator D: 2.870038
Loss Generator P: 0.517453
Gradient discriminator: 22.236758
Gradient professor: -19.489882
Loss Generator D: 2.306105
Loss Generator P: 0.624280
Gradient discriminator: 4.986227
Gradient professor: 10.524774
Loss Generator D: 2.705309
Loss Generator P: 0.656486
Gradient discriminator: 4.807866
Gradient professor: -0.506921
Loss Generator D: 2.824759
Loss Generator P: 0.660682
Gradient discriminator: -8.828941
Gradient professor: -14.198563
Loss Generator D: 2.444929
Loss Generator P: 0.549920
Gradient discriminator: -31.557403
Gradient professor: -7.303362
Loss Generator D: 2.515641
Loss Generator P: 0.554316
Gradient discriminator: -1.299476
Gradient professor: 9.775525
Loss Generator D: 2.611086
Loss Generator P: 0.485373
Gradient discriminator: 9.249003
Gradient professor: -2.482387
Loss Generator D: 2.494942
Loss Generator P: 0.473830
Generator    : Epoch:     13, update:    3220, cost:   0.473830
Gradient discriminator: -3.238788
Gradient professor: -16.465526
Loss Generator D: 2.593942
Loss Generator P: 0.536062
Gradient discriminator: 0.542667
Gradient professor: -2.835816
Loss Generator D: 2.583627
Loss Generator P: 0.584526
Gradient discriminator: 3.673554
Gradient professor: 11.346427
Loss Generator D: 2.336174
Loss Generator P: 0.667420
Gradient discriminator: 9.845630
Gradient professor: -9.125532
Loss Generator D: 2.632334
Loss Generator P: 0.555611
Gradient discriminator: 3.797217
Gradient professor: 12.775371
Loss Generator D: 2.784001
Loss Generator P: 0.456571
Gradient discriminator: -8.368628
Gradient professor: -3.124043
Loss Generator D: 2.647792
Loss Generator P: 0.574437
Gradient discriminator: 3.133411
Gradient professor: 14.133921
Loss Generator D: 2.563592
Loss Generator P: 0.475223
Gradient discriminator: 0.418094
Gradient professor: 21.547645
Loss Generator D: 3.195041
Loss Generator P: 0.503728
Gradient discriminator: 2.671836
Gradient professor: -0.818099
Loss Generator D: 2.912738
Loss Generator P: 0.564059
Gradient discriminator: 7.196164
Gradient professor: -18.766083
Loss Generator D: 3.236960
Loss Generator P: 0.509751
Generator    : Epoch:     13, update:    3230, cost:   0.509751
Gradient discriminator: 5.971206
Gradient professor: -0.336691
Loss Generator D: 2.931799
Loss Generator P: 0.640030
Gradient discriminator: 37.048876
Gradient professor: 0.646565
Loss Generator D: 2.895045
Loss Generator P: 0.626005
Gradient discriminator: 7.015695
Gradient professor: 13.374941
Loss Generator D: 3.196009
Loss Generator P: 0.719770
Gradient discriminator: 16.754849
Gradient professor: 1.925513
Loss Generator D: 2.787193
Loss Generator P: 0.406977
Gradient discriminator: -6.437869
Gradient professor: -13.745942
Loss Generator D: 2.011245
Loss Generator P: 0.525198
Gradient discriminator: -5.048043
Gradient professor: 13.317869
Loss Generator D: 2.772755
Loss Generator P: 0.520151
Gradient discriminator: -3.454107
Gradient professor: 11.980438
Loss Generator D: 2.638654
Loss Generator P: 0.404708
Gradient discriminator: -0.187416
Gradient professor: -5.564966
Loss Generator D: 2.604978
Loss Generator P: 0.569126
Gradient discriminator: 0.512462
Gradient professor: -4.752418
Loss Generator D: 2.527331
Loss Generator P: 0.489038
Gradient discriminator: 1.994010
Gradient professor: 25.579877
Loss Generator D: 2.756704
Loss Generator P: 0.476944
Generator    : Epoch:     13, update:    3240, cost:   0.476944
Gradient discriminator: -7.103773
Gradient professor: -15.613925
Loss Generator D: 2.720238
Loss Generator P: 0.502568
Gradient discriminator: 5.999403
Gradient professor: 1.774197
Loss Generator D: 2.496776
Loss Generator P: 0.507278
Gradient discriminator: -0.241383
Gradient professor: 26.000551
Loss Generator D: 2.506134
Loss Generator P: 0.480218
Gradient discriminator: 1.615643
Gradient professor: -18.186081
Loss Generator D: 2.266505
Loss Generator P: 0.492665
Gradient discriminator: 2.963863
Gradient professor: -2.241392
Loss Generator D: 3.325363
Loss Generator P: 0.610203
Gradient discriminator: 9.847758
Gradient professor: -6.616736
Loss Generator D: 2.920045
Loss Generator P: 0.426386
Gradient discriminator: 11.146421
Gradient professor: -10.481776
Loss Generator D: 3.265523
Loss Generator P: 0.453391
Gradient discriminator: 7.704959
Gradient professor: 22.773502
Loss Generator D: 3.226606
Loss Generator P: 0.401270
Gradient discriminator: 1.168824
Gradient professor: -10.765850
Loss Generator D: 2.728038
Loss Generator P: 0.503298
Gradient discriminator: 8.418650
Gradient professor: -6.316936
Loss Generator D: 3.011267
Loss Generator P: 0.273429
Generator    : Epoch:     13, update:    3250, cost:   0.273429
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 13 finished with mean loss 1.73278 (PPL: 5.65635)
--> Epoch took 227.804 minutes, 54.673 sec/update
Epoch summary of Discriminator:
--> Epoch 13 finished with mean loss nan (PPL:  nan)
--> Epoch took 227.804 minutes, 54.673 sec/update
---------------------------------------------------------
Starting Epoch 14
-----------------
Gradient discriminator: 3.250656
Gradient professor: 3.366637
Loss Generator D: 2.465316
Loss Generator P: 0.656035
Gradient discriminator: 5.618567
Gradient professor: 9.679558
Loss Generator D: 2.608308
Loss Generator P: 0.524187
Gradient discriminator: 8.314281
Gradient professor: 11.178562
Loss Generator D: 3.019618
Loss Generator P: 0.527919
Gradient discriminator: 8.956802
Gradient professor: -14.265520
Loss Generator D: 1.835179
Loss Generator P: 0.682604
Gradient discriminator: 0.455626
Gradient professor: -33.786380
Loss Generator D: 2.874312
Loss Generator P: 0.476812
Gradient discriminator: 4.608412
Gradient professor: 3.107479
Loss Generator D: 2.340770
Loss Generator P: 0.539147
Gradient discriminator: 2.170320
Gradient professor: 11.968205
Loss Generator D: 2.501689
Loss Generator P: 0.580952
Gradient discriminator: 4.491862
Gradient professor: 19.083748
Loss Generator D: 2.007240
Loss Generator P: 0.484345
Gradient discriminator: 7.146670
Gradient professor: -28.201625
Loss Generator D: 2.494396
Loss Generator P: 0.658103
Gradient discriminator: 7.393330
Gradient professor: 7.094534
Loss Generator D: 2.079522
Loss Generator P: 0.713246
Generator    : Epoch:     14, update:    3260, cost:   0.713246
Gradient discriminator: -3.495794
Gradient professor: -7.623607
Loss Generator D: 2.439254
Loss Generator P: 0.755596
Gradient discriminator: -4.292447
Gradient professor: -7.462272
Loss Generator D: 2.974533
Loss Generator P: 0.551923
Gradient discriminator: -0.002042
Gradient professor: 21.401770
Loss Generator D: 3.064022
Loss Generator P: 0.681838
Gradient discriminator: -11.293285
Gradient professor: 15.544011
Loss Generator D: 3.070261
Loss Generator P: 0.601932
Gradient discriminator: 0.013722
Gradient professor: 9.815071
Loss Generator D: 3.355976
Loss Generator P: 0.444806
Gradient discriminator: 6.136832
Gradient professor: 5.980800
Loss Generator D: 3.207463
Loss Generator P: 0.367475
Gradient discriminator: 8.482761
Gradient professor: 1.777955
Loss Generator D: 3.357418
Loss Generator P: 0.489716
Gradient discriminator: 0.894738
Gradient professor: 4.121289
Loss Generator D: 3.747705
Loss Generator P: 0.494104
Gradient discriminator: 1.243679
Gradient professor: -13.324346
Loss Generator D: 3.175902
Loss Generator P: 0.577200
Gradient discriminator: -18.993739
Gradient professor: 18.666249
Loss Generator D: 2.907504
Loss Generator P: 0.586380
Generator    : Epoch:     14, update:    3270, cost:   0.586380
Gradient discriminator: -0.533329
Gradient professor: -1.912628
Loss Generator D: 2.867206
Loss Generator P: 0.544353
Gradient discriminator: -6.167599
Gradient professor: -5.132846
Loss Generator D: 3.195559
Loss Generator P: 0.558090
Gradient discriminator: 4.456333
Gradient professor: -0.280569
Loss Generator D: 3.194727
Loss Generator P: 0.501300
Gradient discriminator: 2.257546
Gradient professor: -22.402127
Loss Generator D: 3.085397
Loss Generator P: 0.796822
Gradient discriminator: 7.790475
Gradient professor: -2.414310
Loss Generator D: 3.387100
Loss Generator P: 0.667008
Gradient discriminator: -0.551196
Gradient professor: 10.414285
Loss Generator D: 3.278357
Loss Generator P: 0.542099
Gradient discriminator: 3.476617
Gradient professor: -10.676664
Loss Generator D: 2.640355
Loss Generator P: 0.391746
Gradient discriminator: 0.787640
Gradient professor: -9.326264
Loss Generator D: 2.536062
Loss Generator P: 0.500544
Gradient discriminator: 2.555185
Gradient professor: 27.773801
Loss Generator D: 2.988982
Loss Generator P: 0.460826
Gradient discriminator: -11.159294
Gradient professor: -0.740594
Loss Generator D: 3.125967
Loss Generator P: 0.461052
Generator    : Epoch:     14, update:    3280, cost:   0.461052
Gradient discriminator: 2.219575
Gradient professor: -22.045913
Loss Generator D: 3.119959
Loss Generator P: 0.488122
Gradient discriminator: 0.524995
Gradient professor: 4.384634
Loss Generator D: 3.178008
Loss Generator P: 0.419007
Gradient discriminator: -0.324067
Gradient professor: 18.574118
Loss Generator D: 3.448700
Loss Generator P: 0.646104
Gradient discriminator: 2.716522
Gradient professor: -30.248725
Loss Generator D: 3.165807
Loss Generator P: 0.761503
Gradient discriminator: 0.809783
Gradient professor: -1.156554
Loss Generator D: 2.998076
Loss Generator P: 0.482002
Gradient discriminator: -0.360727
Gradient professor: 17.878254
Loss Generator D: 3.007023
Loss Generator P: 0.456970
Gradient discriminator: -8.530418
Gradient professor: -19.418957
Loss Generator D: 2.773669
Loss Generator P: 0.438955
Gradient discriminator: -6.107609
Gradient professor: -6.625899
Loss Generator D: 3.019718
Loss Generator P: 0.510213
Gradient discriminator: -7.189641
Gradient professor: 2.034469
Loss Generator D: 2.859272
Loss Generator P: 0.502647
Gradient discriminator: -2.628157
Gradient professor: -25.831373
Loss Generator D: 3.407233
Loss Generator P: 0.704958
Generator    : Epoch:     14, update:    3290, cost:   0.704958
Gradient discriminator: 28.117161
Gradient professor: 10.877216
Loss Generator D: 2.685059
Loss Generator P: 0.512352
Gradient discriminator: -3.626419
Gradient professor: 26.569378
Loss Generator D: 2.837330
Loss Generator P: 0.550421
Gradient discriminator: -2.873672
Gradient professor: 10.302025
Loss Generator D: 3.502600
Loss Generator P: 0.500731
Gradient discriminator: -6.854077
Gradient professor: 1.642540
Loss Generator D: 3.228370
Loss Generator P: 0.484386
Gradient discriminator: -2.919431
Gradient professor: -30.445381
Loss Generator D: 3.545541
Loss Generator P: 0.679369
Gradient discriminator: 10.826562
Gradient professor: 10.199626
Loss Generator D: 3.139021
Loss Generator P: 0.575137
Gradient discriminator: 7.870661
Gradient professor: 9.050643
Loss Generator D: 2.864529
Loss Generator P: 0.443879
Gradient discriminator: 1.478001
Gradient professor: 17.710640
Loss Generator D: 3.137866
Loss Generator P: 0.598873
Gradient discriminator: 2.737321
Gradient professor: -19.592121
Loss Generator D: 3.611896
Loss Generator P: 0.720576
Gradient discriminator: -9.839665
Gradient professor: 10.235287
Loss Generator D: 3.172899
Loss Generator P: 0.563591
Generator    : Epoch:     14, update:    3300, cost:   0.563591
Validation 33 - LOSS = 1.690 (PPL: 5.422)
Calling beam-search process
Beam-search ended, took 2.51460 minutes.
Validation 33 - BLEU = 5.95, 11.4/7.1/4.8/3.2 (BP=1.000, ratio=4.926, hyp_len=20789, ref_len=4220)
Early stopping patience: 983 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 1.545737
Gradient professor: -7.518695
Loss Generator D: 3.002795
Loss Generator P: 0.581827
Gradient discriminator: 13.328501
Gradient professor: 20.719707
Loss Generator D: 2.967568
Loss Generator P: 0.534560
Gradient discriminator: -0.369771
Gradient professor: -3.685267
Loss Generator D: 2.368319
Loss Generator P: 0.528116
Gradient discriminator: 13.586705
Gradient professor: 5.661599
Loss Generator D: 3.081025
Loss Generator P: 0.628939
Gradient discriminator: -13.967285
Gradient professor: 4.156701
Loss Generator D: 2.988170
Loss Generator P: 0.633903
Gradient discriminator: 9.471980
Gradient professor: 8.884344
Loss Generator D: 2.992431
Loss Generator P: 0.478878
Gradient discriminator: -2.662586
Gradient professor: -3.581751
Loss Generator D: 2.320124
Loss Generator P: 0.483047
Gradient discriminator: -8.252095
Gradient professor: 5.326189
Loss Generator D: 2.875768
Loss Generator P: 0.455235
Gradient discriminator: 8.855622
Gradient professor: -18.063473
Loss Generator D: 3.002223
Loss Generator P: 0.462706
Gradient discriminator: 0.790417
Gradient professor: 23.625691
Loss Generator D: 3.130320
Loss Generator P: 0.516200
Generator    : Epoch:     14, update:    3310, cost:   0.516200
Gradient discriminator: -2.887531
Gradient professor: -2.279436
Loss Generator D: 2.803106
Loss Generator P: 0.529736
Gradient discriminator: 16.313485
Gradient professor: -2.029156
Loss Generator D: 2.545334
Loss Generator P: 0.712656
Gradient discriminator: 13.866868
Gradient professor: 5.378014
Loss Generator D: 2.579914
Loss Generator P: 0.528137
Gradient discriminator: 3.037100
Gradient professor: -10.830485
Loss Generator D: 2.689510
Loss Generator P: 0.596235
Gradient discriminator: -18.968001
Gradient professor: -5.699579
Loss Generator D: 2.132030
Loss Generator P: 0.681028
Gradient discriminator: -7.563452
Gradient professor: 0.199484
Loss Generator D: 2.006029
Loss Generator P: 0.606556
Gradient discriminator: 4.857485
Gradient professor: 14.923527
Loss Generator D: 2.570236
Loss Generator P: 0.595409
Gradient discriminator: 15.966832
Gradient professor: -4.505632
Loss Generator D: 2.793205
Loss Generator P: 0.490757
Gradient discriminator: 4.158172
Gradient professor: 2.484418
Loss Generator D: 2.922036
Loss Generator P: 0.661971
Gradient discriminator: -4.081422
Gradient professor: -25.130018
Loss Generator D: 2.827555
Loss Generator P: 0.597719
Generator    : Epoch:     14, update:    3320, cost:   0.597719
Gradient discriminator: -9.006251
Gradient professor: 3.380764
Loss Generator D: 2.684524
Loss Generator P: 0.493248
Gradient discriminator: 2.059281
Gradient professor: -6.734926
Loss Generator D: 2.997880
Loss Generator P: 0.427629
Gradient discriminator: 9.438716
Gradient professor: -0.550959
Loss Generator D: 2.791021
Loss Generator P: 0.570092
Gradient discriminator: 5.173720
Gradient professor: -11.121726
Loss Generator D: 2.317452
Loss Generator P: 0.582250
Gradient discriminator: -0.914455
Gradient professor: 0.341941
Loss Generator D: 2.663061
Loss Generator P: 0.491973
Gradient discriminator: 6.730428
Gradient professor: 17.840562
Loss Generator D: 1.845314
Loss Generator P: 0.504569
Gradient discriminator: 3.234672
Gradient professor: 5.351872
Loss Generator D: 2.707001
Loss Generator P: 0.516481
Gradient discriminator: 2.516926
Gradient professor: 11.891301
Loss Generator D: 2.648297
Loss Generator P: 0.643618
Gradient discriminator: 3.907139
Gradient professor: 4.531471
Loss Generator D: 2.120806
Loss Generator P: 0.379123
Gradient discriminator: -3.452356
Gradient professor: -8.544560
Loss Generator D: 2.120621
Loss Generator P: 0.348538
Generator    : Epoch:     14, update:    3330, cost:   0.348538
Gradient discriminator: 12.012253
Gradient professor: 20.798677
Loss Generator D: 2.872214
Loss Generator P: 0.429395
Gradient discriminator: -2.856549
Gradient professor: -7.222005
Loss Generator D: 2.637361
Loss Generator P: 0.470221
Gradient discriminator: -4.704059
Gradient professor: 12.809539
Loss Generator D: 2.244103
Loss Generator P: 0.428499
Gradient discriminator: 7.993050
Gradient professor: -5.161267
Loss Generator D: 2.523563
Loss Generator P: 0.340434
Gradient discriminator: -0.840364
Gradient professor: 2.904280
Loss Generator D: 2.896926
Loss Generator P: 0.351350
Gradient discriminator: -3.265210
Gradient professor: -9.450043
Loss Generator D: 2.266544
Loss Generator P: 0.378539
Gradient discriminator: 1.266462
Gradient professor: -16.545949
Loss Generator D: 3.000170
Loss Generator P: 0.370453
Gradient discriminator: -2.140098
Gradient professor: -9.058654
Loss Generator D: 2.622613
Loss Generator P: 0.526068
Gradient discriminator: 9.081917
Gradient professor: 0.589966
Loss Generator D: 2.561391
Loss Generator P: 0.438465
Gradient discriminator: -6.516771
Gradient professor: 15.062895
Loss Generator D: 2.955080
Loss Generator P: 0.612797
Generator    : Epoch:     14, update:    3340, cost:   0.612797
Gradient discriminator: -2.065091
Gradient professor: 1.651200
Loss Generator D: 2.697304
Loss Generator P: 0.438602
Gradient discriminator: 12.953217
Gradient professor: 20.210748
Loss Generator D: 2.671409
Loss Generator P: 0.644624
Gradient discriminator: -0.368652
Gradient professor: 19.985985
Loss Generator D: 2.608296
Loss Generator P: 0.456826
Gradient discriminator: -7.737197
Gradient professor: -3.125628
Loss Generator D: 2.656857
Loss Generator P: 0.372651
Gradient discriminator: -10.012074
Gradient professor: 9.837729
Loss Generator D: 2.689193
Loss Generator P: 0.482105
Gradient discriminator: 0.003674
Gradient professor: 5.603139
Loss Generator D: 2.619915
Loss Generator P: 0.470009
Gradient discriminator: -4.738878
Gradient professor: -16.813042
Loss Generator D: 2.975544
Loss Generator P: 0.434678
Gradient discriminator: -2.213111
Gradient professor: 5.175635
Loss Generator D: 2.550509
Loss Generator P: 0.407082
Gradient discriminator: -7.071660
Gradient professor: -2.160278
Loss Generator D: 2.615316
Loss Generator P: 0.394822
Gradient discriminator: 4.314279
Gradient professor: -17.933117
Loss Generator D: 3.103062
Loss Generator P: 0.486911
Generator    : Epoch:     14, update:    3350, cost:   0.486911
Gradient discriminator: 9.173618
Gradient professor: 1.723777
Loss Generator D: 2.699371
Loss Generator P: 0.601992
Gradient discriminator: 11.570454
Gradient professor: -13.596804
Loss Generator D: 2.184969
Loss Generator P: 0.527984
Gradient discriminator: 0.602994
Gradient professor: -0.016213
Loss Generator D: 3.038469
Loss Generator P: 0.386370
Gradient discriminator: 3.408337
Gradient professor: -8.798338
Loss Generator D: 2.077817
Loss Generator P: 0.495375
Gradient discriminator: -2.713462
Gradient professor: 12.851550
Loss Generator D: 2.558883
Loss Generator P: 0.352459
Gradient discriminator: 11.262649
Gradient professor: -8.035514
Loss Generator D: 2.815848
Loss Generator P: 0.529817
Gradient discriminator: 5.892255
Gradient professor: -16.925215
Loss Generator D: 2.264600
Loss Generator P: 0.400371
Gradient discriminator: 20.858242
Gradient professor: -8.064537
Loss Generator D: 2.460019
Loss Generator P: 0.378917
Gradient discriminator: 2.805400
Gradient professor: 7.795244
Loss Generator D: 2.648585
Loss Generator P: 0.494776
Gradient discriminator: -5.415677
Gradient professor: 1.605710
Loss Generator D: 3.009259
Loss Generator P: 0.412538
Generator    : Epoch:     14, update:    3360, cost:   0.412538
Gradient discriminator: -7.082573
Gradient professor: 9.898446
Loss Generator D: 2.676329
Loss Generator P: 0.547939
Gradient discriminator: 6.256705
Gradient professor: 8.883452
Loss Generator D: 2.291190
Loss Generator P: 0.472927
Gradient discriminator: 14.760073
Gradient professor: -3.967597
Loss Generator D: 3.182590
Loss Generator P: 0.383413
Gradient discriminator: 4.333414
Gradient professor: -9.742102
Loss Generator D: 2.735098
Loss Generator P: 0.369337
Gradient discriminator: 2.368965
Gradient professor: 22.692288
Loss Generator D: 3.180509
Loss Generator P: 0.502800
Gradient discriminator: 8.057579
Gradient professor: -11.080661
Loss Generator D: 2.721772
Loss Generator P: 0.611828
Gradient discriminator: 7.202429
Gradient professor: 18.272286
Loss Generator D: 2.652377
Loss Generator P: 0.346678
Gradient discriminator: 3.164035
Gradient professor: -14.300949
Loss Generator D: 3.084151
Loss Generator P: 0.582570
Gradient discriminator: 3.733851
Gradient professor: -17.132315
Loss Generator D: 3.337427
Loss Generator P: 0.427741
Gradient discriminator: 9.526644
Gradient professor: 15.244346
Loss Generator D: 3.010482
Loss Generator P: 0.439525
Generator    : Epoch:     14, update:    3370, cost:   0.439525
Gradient discriminator: 1.880325
Gradient professor: 10.098216
Loss Generator D: 2.804081
Loss Generator P: 0.510120
Gradient discriminator: -9.789222
Gradient professor: -2.109094
Loss Generator D: 2.197092
Loss Generator P: 0.512082
Gradient discriminator: 6.214250
Gradient professor: 15.264609
Loss Generator D: 2.372161
Loss Generator P: 0.503605
Gradient discriminator: -2.506817
Gradient professor: 10.375902
Loss Generator D: 2.591199
Loss Generator P: 0.552064
Gradient discriminator: 5.577836
Gradient professor: 3.075713
Loss Generator D: 2.139845
Loss Generator P: 0.566946
Gradient discriminator: 10.574950
Gradient professor: 10.949279
Loss Generator D: 2.264767
Loss Generator P: 0.531595
Gradient discriminator: -0.086992
Gradient professor: -1.156051
Loss Generator D: 2.292318
Loss Generator P: 0.505469
Gradient discriminator: 1.561153
Gradient professor: 7.078488
Loss Generator D: 3.002562
Loss Generator P: 0.535929
Gradient discriminator: 6.281057
Gradient professor: -8.803847
Loss Generator D: 2.460089
Loss Generator P: 0.558331
Gradient discriminator: 2.724983
Gradient professor: -18.295754
Loss Generator D: 2.446131
Loss Generator P: 0.548604
Generator    : Epoch:     14, update:    3380, cost:   0.548604
Gradient discriminator: -5.190017
Gradient professor: -6.798329
Loss Generator D: 2.344162
Loss Generator P: 0.465779
Gradient discriminator: -5.478519
Gradient professor: -21.221477
Loss Generator D: 2.207474
Loss Generator P: 0.464346
Gradient discriminator: 1.345789
Gradient professor: 25.088840
Loss Generator D: 1.987980
Loss Generator P: 0.405621
Gradient discriminator: -4.661063
Gradient professor: -10.888266
Loss Generator D: 2.204964
Loss Generator P: 0.703563
Gradient discriminator: 12.675193
Gradient professor: 0.077089
Loss Generator D: 1.703350
Loss Generator P: 0.493466
Gradient discriminator: 6.988290
Gradient professor: -8.922047
Loss Generator D: 2.356959
Loss Generator P: 0.344566
Gradient discriminator: 3.368634
Gradient professor: 9.122664
Loss Generator D: 2.571410
Loss Generator P: 0.433702
Gradient discriminator: 6.722721
Gradient professor: 0.950073
Loss Generator D: 2.479985
Loss Generator P: 0.339997
Gradient discriminator: -1.991380
Gradient professor: 12.726205
Loss Generator D: 2.361995
Loss Generator P: 0.585336
Gradient discriminator: 4.860653
Gradient professor: 21.130280
Loss Generator D: 2.153031
Loss Generator P: 0.501890
Generator    : Epoch:     14, update:    3390, cost:   0.501890
Gradient discriminator: 7.450070
Gradient professor: -6.546055
Loss Generator D: 1.943431
Loss Generator P: 0.457855
Gradient discriminator: 1.016151
Gradient professor: 7.909521
Loss Generator D: 2.310870
Loss Generator P: 0.528017
Gradient discriminator: -11.893237
Gradient professor: 6.811542
Loss Generator D: 2.029637
Loss Generator P: 0.641033
Gradient discriminator: 2.095660
Gradient professor: -1.527309
Loss Generator D: 2.702056
Loss Generator P: 0.537029
Gradient discriminator: 5.029764
Gradient professor: -31.428739
Loss Generator D: 2.333203
Loss Generator P: 0.664248
Gradient discriminator: 14.753590
Gradient professor: 6.883216
Loss Generator D: 2.411650
Loss Generator P: 0.626832
Gradient discriminator: -3.986621
Gradient professor: 8.273706
Loss Generator D: 2.155441
Loss Generator P: 0.349014
Gradient discriminator: 0.654096
Gradient professor: 11.003363
Loss Generator D: 2.198165
Loss Generator P: 0.408713
Gradient discriminator: -3.784481
Gradient professor: -17.823138
Loss Generator D: 2.818450
Loss Generator P: 0.412122
Gradient discriminator: 8.008841
Gradient professor: -3.391103
Loss Generator D: 2.502086
Loss Generator P: 0.374273
Generator    : Epoch:     14, update:    3400, cost:   0.374273
Validation 34 - LOSS = 1.713 (PPL: 5.543)
Calling beam-search process
Beam-search ended, took 2.95468 minutes.
Validation 34 - BLEU = 4.38, 8.3/5.2/3.6/2.4 (BP=1.000, ratio=6.518, hyp_len=27506, ref_len=4220)
Early stopping patience: 982 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 7.883315
Gradient professor: -8.742837
Loss Generator D: 2.724374
Loss Generator P: 0.605985
Gradient discriminator: -4.465534
Gradient professor: 12.564424
Loss Generator D: 2.401990
Loss Generator P: 0.554949
Gradient discriminator: 11.715710
Gradient professor: 8.661049
Loss Generator D: 2.491949
Loss Generator P: 0.488401
Gradient discriminator: 2.495328
Gradient professor: -6.466960
Loss Generator D: 2.491790
Loss Generator P: 0.476169
Gradient discriminator: 11.282043
Gradient professor: 26.018383
Loss Generator D: 2.167168
Loss Generator P: 0.580749
Gradient discriminator: 15.130933
Gradient professor: -17.801476
Loss Generator D: 2.075164
Loss Generator P: 0.460482
Gradient discriminator: -3.732021
Gradient professor: -24.491023
Loss Generator D: 2.793893
Loss Generator P: 0.529161
Gradient discriminator: 0.225242
Gradient professor: -3.004366
Loss Generator D: 2.257986
Loss Generator P: 0.381462
Gradient discriminator: 5.185520
Gradient professor: 7.629119
Loss Generator D: 2.608881
Loss Generator P: 0.360841
Gradient discriminator: -2.129423
Gradient professor: 2.245343
Loss Generator D: 1.969412
Loss Generator P: 0.452601
Generator    : Epoch:     14, update:    3410, cost:   0.452601
Gradient discriminator: 3.838402
Gradient professor: -14.810396
Loss Generator D: 2.427541
Loss Generator P: 0.447202
Gradient discriminator: 3.973546
Gradient professor: 17.853451
Loss Generator D: 2.584260
Loss Generator P: 0.635713
Gradient discriminator: 14.102505
Gradient professor: 6.699063
Loss Generator D: 2.599796
Loss Generator P: 0.619962
Gradient discriminator: 7.938619
Gradient professor: 2.882039
Loss Generator D: 2.579787
Loss Generator P: 0.586164
Gradient discriminator: 0.375168
Gradient professor: 3.726600
Loss Generator D: 2.080969
Loss Generator P: 0.699058
Gradient discriminator: 3.865640
Gradient professor: 3.464682
Loss Generator D: 2.134933
Loss Generator P: 0.581059
Gradient discriminator: -2.194628
Gradient professor: 22.044313
Loss Generator D: 2.034445
Loss Generator P: 0.604071
Gradient discriminator: 24.203606
Gradient professor: -0.808605
Loss Generator D: 2.236903
Loss Generator P: 0.426742
Gradient discriminator: -7.745227
Gradient professor: 4.649421
Loss Generator D: 1.992178
Loss Generator P: 0.577034
Gradient discriminator: 234.616319
Gradient professor: -9.607021
Loss Generator D: 2.581575
Loss Generator P: 0.563686
Generator    : Epoch:     14, update:    3420, cost:   0.563686
Gradient discriminator: 7.477073
Gradient professor: 2.274755
Loss Generator D: 2.124416
Loss Generator P: 0.442284
Gradient discriminator: 16.388801
Gradient professor: 13.095247
Loss Generator D: 1.763012
Loss Generator P: 0.442099
Gradient discriminator: 9.503541
Gradient professor: 4.369503
Loss Generator D: 2.354832
Loss Generator P: 0.460165
Gradient discriminator: -2.108760
Gradient professor: -17.640664
Loss Generator D: 2.332876
Loss Generator P: 0.360058
Gradient discriminator: 3.566583
Gradient professor: -14.399086
Loss Generator D: 2.575000
Loss Generator P: 0.411989
Gradient discriminator: -2.083290
Gradient professor: -5.137916
Loss Generator D: 2.275424
Loss Generator P: 0.483366
Gradient discriminator: -11.577192
Gradient professor: -20.662205
Loss Generator D: 2.082088
Loss Generator P: 0.667216
Gradient discriminator: 2.622749
Gradient professor: 23.363448
Loss Generator D: 2.078056
Loss Generator P: 0.715408
Gradient discriminator: 21.011032
Gradient professor: -17.210979
Loss Generator D: 2.324836
Loss Generator P: 0.724231
Gradient discriminator: 12.296603
Gradient professor: 4.221769
Loss Generator D: 2.533769
Loss Generator P: 0.423891
Generator    : Epoch:     14, update:    3430, cost:   0.423891
Gradient discriminator: 22.783617
Gradient professor: -4.075926
Loss Generator D: 2.122958
Loss Generator P: 0.519643
Gradient discriminator: -13.842271
Gradient professor: -9.123371
Loss Generator D: 2.276475
Loss Generator P: 0.522979
Gradient discriminator: 6.602930
Gradient professor: 4.669674
Loss Generator D: 2.243252
Loss Generator P: 0.579296
Gradient discriminator: -1.928405
Gradient professor: -11.329765
Loss Generator D: 3.050576
Loss Generator P: 0.662212
Gradient discriminator: -2.677038
Gradient professor: 12.214354
Loss Generator D: 2.733601
Loss Generator P: 0.616967
Gradient discriminator: 2.133399
Gradient professor: -25.119055
Loss Generator D: 2.784947
Loss Generator P: 0.492049
Gradient discriminator: 15.477438
Gradient professor: 13.521913
Loss Generator D: 2.131795
Loss Generator P: 0.570876
Gradient discriminator: -1.999361
Gradient professor: -10.775051
Loss Generator D: 2.537070
Loss Generator P: 0.640178
Gradient discriminator: 1.903033
Gradient professor: 2.708415
Loss Generator D: 2.650414
Loss Generator P: 0.589052
Gradient discriminator: 20.144527
Gradient professor: -19.127413
Loss Generator D: 2.187519
Loss Generator P: 0.587083
Generator    : Epoch:     14, update:    3440, cost:   0.587083
Gradient discriminator: -2.882669
Gradient professor: -2.006801
Loss Generator D: 2.519886
Loss Generator P: 0.566183
Gradient discriminator: -0.376126
Gradient professor: 1.343169
Loss Generator D: 2.441330
Loss Generator P: 0.453346
Gradient discriminator: 11.728703
Gradient professor: -33.899397
Loss Generator D: 2.644987
Loss Generator P: 0.810567
Gradient discriminator: -0.206176
Gradient professor: 32.099763
Loss Generator D: 2.308033
Loss Generator P: 0.694518
Gradient discriminator: 8.606485
Gradient professor: 16.207792
Loss Generator D: 2.175896
Loss Generator P: 0.423293
Gradient discriminator: -11.259892
Gradient professor: -5.788378
Loss Generator D: 2.568192
Loss Generator P: 0.560954
Gradient discriminator: 15.615449
Gradient professor: 23.751850
Loss Generator D: 2.881103
Loss Generator P: 0.546868
Gradient discriminator: -2.143422
Gradient professor: -5.135345
Loss Generator D: 2.422623
Loss Generator P: 0.628141
Gradient discriminator: 0.925188
Gradient professor: -4.908866
Loss Generator D: 2.399464
Loss Generator P: 0.553875
Gradient discriminator: -7.364588
Gradient professor: -3.740935
Loss Generator D: 2.912087
Loss Generator P: 0.441670
Generator    : Epoch:     14, update:    3450, cost:   0.441670
Gradient discriminator: -2.235386
Gradient professor: 6.470149
Loss Generator D: 2.681886
Loss Generator P: 0.570902
Gradient discriminator: -8.155027
Gradient professor: -18.921993
Loss Generator D: 2.664707
Loss Generator P: 0.521076
Gradient discriminator: 4.198029
Gradient professor: 6.369129
Loss Generator D: 2.476369
Loss Generator P: 0.492415
Gradient discriminator: 10.713102
Gradient professor: -4.265494
Loss Generator D: 2.595912
Loss Generator P: 0.469436
Gradient discriminator: -1.317386
Gradient professor: -9.960385
Loss Generator D: 2.608581
Loss Generator P: 0.406924
Gradient discriminator: -3.246115
Gradient professor: -3.382793
Loss Generator D: 2.807678
Loss Generator P: 0.368342
Gradient discriminator: 5.521358
Gradient professor: 7.746960
Loss Generator D: 3.146223
Loss Generator P: 0.545768
Gradient discriminator: 2.584269
Gradient professor: -43.845866
Loss Generator D: 2.892524
Loss Generator P: 0.624288
Gradient discriminator: -5.571900
Gradient professor: 6.311146
Loss Generator D: 2.033070
Loss Generator P: 0.447618
Gradient discriminator: -1.444780
Gradient professor: -4.700041
Loss Generator D: 2.573180
Loss Generator P: 0.559216
Generator    : Epoch:     14, update:    3460, cost:   0.559216
Gradient discriminator: 1.136896
Gradient professor: -24.300840
Loss Generator D: 3.089235
Loss Generator P: 0.563069
Gradient discriminator: 5.081473
Gradient professor: 12.400534
Loss Generator D: 2.396141
Loss Generator P: 0.668879
Gradient discriminator: 6.491368
Gradient professor: -1.562219
Loss Generator D: 2.715233
Loss Generator P: 0.487511
Gradient discriminator: -10.676842
Gradient professor: 15.292543
Loss Generator D: 2.056290
Loss Generator P: 0.429326
Gradient discriminator: 6.155106
Gradient professor: 5.008195
Loss Generator D: 2.463994
Loss Generator P: 0.583530
Gradient discriminator: 13.663278
Gradient professor: 1.426298
Loss Generator D: 2.107828
Loss Generator P: 0.589395
Gradient discriminator: -0.475908
Gradient professor: -9.795279
Loss Generator D: 1.864290
Loss Generator P: 0.513969
Gradient discriminator: 2.848474
Gradient professor: -6.505440
Loss Generator D: 2.514727
Loss Generator P: 0.541605
Gradient discriminator: 5.445185
Gradient professor: 27.911411
Loss Generator D: 2.327755
Loss Generator P: 0.408916
Gradient discriminator: 1.309962
Gradient professor: 2.773944
Loss Generator D: 2.286609
Loss Generator P: 0.392464
Generator    : Epoch:     14, update:    3470, cost:   0.392464
Gradient discriminator: -6.752680
Gradient professor: 20.054779
Loss Generator D: 2.458308
Loss Generator P: 0.493818
Gradient discriminator: 1.780206
Gradient professor: -20.315815
Loss Generator D: 2.139771
Loss Generator P: 0.549948
Gradient discriminator: 4.652402
Gradient professor: 13.367266
Loss Generator D: 2.479150
Loss Generator P: 0.532368
Gradient discriminator: -4.811858
Gradient professor: 2.082216
Loss Generator D: 2.508118
Loss Generator P: 0.444944
Gradient discriminator: -5.982244
Gradient professor: -3.312314
Loss Generator D: 2.711703
Loss Generator P: 0.394545
Gradient discriminator: -0.368577
Gradient professor: 0.103916
Loss Generator D: 2.436336
Loss Generator P: 0.473752
Gradient discriminator: 5.671660
Gradient professor: 3.113327
Loss Generator D: 2.700323
Loss Generator P: 0.421351
Gradient discriminator: -15.767249
Gradient professor: 11.924884
Loss Generator D: 2.584023
Loss Generator P: 0.483260
Gradient discriminator: 21.463494
Gradient professor: 0.600878
Loss Generator D: 2.668240
Loss Generator P: 0.482877
Gradient discriminator: 1.761213
Gradient professor: -18.943119
Loss Generator D: 2.632905
Loss Generator P: 0.455173
Generator    : Epoch:     14, update:    3480, cost:   0.455173
Gradient discriminator: 9.327718
Gradient professor: -1.697521
Loss Generator D: 2.515686
Loss Generator P: 0.584677
Gradient discriminator: -2.996257
Gradient professor: 12.692535
Loss Generator D: 2.209433
Loss Generator P: 0.612941
Gradient discriminator: -2.082854
Gradient professor: 13.155430
Loss Generator D: 2.096968
Loss Generator P: 0.761013
Gradient discriminator: 4.045098
Gradient professor: 1.572258
Loss Generator D: 2.347701
Loss Generator P: 0.397956
Gradient discriminator: -11.103299
Gradient professor: 0.036295
Loss Generator D: 1.966312
Loss Generator P: 0.554821
Gradient discriminator: 4.701895
Gradient professor: -5.797994
Loss Generator D: 2.438951
Loss Generator P: 0.455265
Gradient discriminator: 13.154489
Gradient professor: 30.009749
Loss Generator D: 2.766306
Loss Generator P: 0.350302
Gradient discriminator: -6.794704
Gradient professor: -3.399970
Loss Generator D: 2.608895
Loss Generator P: 0.500326
Gradient discriminator: 8.702582
Gradient professor: -13.029548
Loss Generator D: 2.987233
Loss Generator P: 0.474926
Gradient discriminator: -2.304329
Gradient professor: 3.141095
Loss Generator D: 2.971766
Loss Generator P: 0.414761
Generator    : Epoch:     14, update:    3490, cost:   0.414761
Gradient discriminator: 6.358977
Gradient professor: 1.027453
Loss Generator D: 2.777046
Loss Generator P: 0.478054
Gradient discriminator: 8.674119
Gradient professor: 8.183818
Loss Generator D: 2.835553
Loss Generator P: 0.475757
Gradient discriminator: -5.400607
Gradient professor: 5.636581
Loss Generator D: 2.813447
Loss Generator P: 0.421562
Gradient discriminator: 7.127977
Gradient professor: -1.106382
Loss Generator D: 2.864516
Loss Generator P: 0.486398
Gradient discriminator: 0.278781
Gradient professor: -3.887572
Loss Generator D: 3.388409
Loss Generator P: 0.524838
Gradient discriminator: 34.609566
Gradient professor: 4.295398
Loss Generator D: 3.310908
Loss Generator P: 0.365344
Gradient discriminator: 7.250534
Gradient professor: -6.580548
Loss Generator D: 3.833544
Loss Generator P: 0.464020
Gradient discriminator: 11.747202
Gradient professor: 5.043112
Loss Generator D: 3.201743
Loss Generator P: 0.413873
Gradient discriminator: 1.410153
Gradient professor: -7.254079
Loss Generator D: 3.267982
Loss Generator P: 0.514725
Gradient discriminator: -7.526757
Gradient professor: 13.079561
Loss Generator D: 3.513025
Loss Generator P: 0.260481
Generator    : Epoch:     14, update:    3500, cost:   0.260481
Validation 35 - LOSS = 1.646 (PPL: 5.185)
Calling beam-search process
Beam-search ended, took 1.88132 minutes.
Validation 35 - BLEU = 9.87, 17.8/11.6/8.1/5.6 (BP=1.000, ratio=3.443, hyp_len=14530, ref_len=4220)
Early stopping patience: 981 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 14 finished with mean loss 1.57561 (PPL: 4.83370)
--> Epoch took 283.633 minutes, 68.072 sec/update
Epoch summary of Discriminator:
--> Epoch 14 finished with mean loss nan (PPL:  nan)
--> Epoch took 283.633 minutes, 68.072 sec/update
---------------------------------------------------------
Starting Epoch 15
-----------------
Gradient discriminator: 4.852802
Gradient professor: 3.756821
Loss Generator D: 2.342932
Loss Generator P: 0.626243
Gradient discriminator: -5.009218
Gradient professor: -10.741527
Loss Generator D: 2.960369
Loss Generator P: 0.478814
Gradient discriminator: -5.658951
Gradient professor: 1.235283
Loss Generator D: 3.320801
Loss Generator P: 0.559353
Gradient discriminator: 8.695163
Gradient professor: -15.149198
Loss Generator D: 2.512911
Loss Generator P: 0.618538
Gradient discriminator: -8.829696
Gradient professor: 1.996770
Loss Generator D: 2.973772
Loss Generator P: 0.471148
Gradient discriminator: -15.399741
Gradient professor: -28.982134
Loss Generator D: 2.641988
Loss Generator P: 0.524722
Gradient discriminator: 8.647314
Gradient professor: 1.002408
Loss Generator D: 2.959496
Loss Generator P: 0.528352
Gradient discriminator: -3.243218
Gradient professor: 2.991263
Loss Generator D: 2.433346
Loss Generator P: 0.410164
Gradient discriminator: -6.799862
Gradient professor: -6.372823
Loss Generator D: 2.606493
Loss Generator P: 0.645231
Gradient discriminator: 13.931828
Gradient professor: 11.605710
Loss Generator D: 2.921540
Loss Generator P: 0.621329
Generator    : Epoch:     15, update:    3510, cost:   0.621329
Gradient discriminator: 1.362342
Gradient professor: 34.827469
Loss Generator D: 3.138606
Loss Generator P: 0.731205
Gradient discriminator: -12.129555
Gradient professor: 18.121374
Loss Generator D: 3.046304
Loss Generator P: 0.513872
Gradient discriminator: 0.723544
Gradient professor: 15.811964
Loss Generator D: 2.745195
Loss Generator P: 0.615478
Gradient discriminator: 5.424260
Gradient professor: 2.957430
Loss Generator D: 3.192354
Loss Generator P: 0.572952
Gradient discriminator: -6.643488
Gradient professor: -14.809716
Loss Generator D: 2.907616
Loss Generator P: 0.368800
Gradient discriminator: 2.289491
Gradient professor: 9.123160
Loss Generator D: 2.852724
Loss Generator P: 0.336266
Gradient discriminator: -14.621217
Gradient professor: -3.057329
Loss Generator D: 2.818755
Loss Generator P: 0.471672
Gradient discriminator: -2.310102
Gradient professor: 2.771343
Loss Generator D: 3.022357
Loss Generator P: 0.512531
Gradient discriminator: -7.801401
Gradient professor: 2.944003
Loss Generator D: 3.067131
Loss Generator P: 0.544107
Gradient discriminator: 9.249229
Gradient professor: 16.548960
Loss Generator D: 2.831237
Loss Generator P: 0.599987
Generator    : Epoch:     15, update:    3520, cost:   0.599987
Gradient discriminator: -0.389581
Gradient professor: -6.459856
Loss Generator D: 3.019140
Loss Generator P: 0.512083
Gradient discriminator: 3.116875
Gradient professor: 2.938999
Loss Generator D: 3.247804
Loss Generator P: 0.475561
Gradient discriminator: -7.798994
Gradient professor: 21.180892
Loss Generator D: 3.102023
Loss Generator P: 0.441049
Gradient discriminator: -2.293967
Gradient professor: -7.018395
Loss Generator D: 3.262049
Loss Generator P: 0.736285
Gradient discriminator: 26.879182
Gradient professor: -35.186455
Loss Generator D: 3.484526
Loss Generator P: 0.710137
Gradient discriminator: -6.080562
Gradient professor: -1.466057
Loss Generator D: 3.157799
Loss Generator P: 0.484802
Gradient discriminator: 0.000100
Gradient professor: -7.476978
Loss Generator D: 2.735113
Loss Generator P: 0.381052
Gradient discriminator: -3.691523
Gradient professor: 15.947181
Loss Generator D: 2.587244
Loss Generator P: 0.513689
Gradient discriminator: 9.275947
Gradient professor: -5.204603
Loss Generator D: 2.995254
Loss Generator P: 0.452438
Gradient discriminator: -6.313960
Gradient professor: -25.237272
Loss Generator D: 3.113791
Loss Generator P: 0.476458
Generator    : Epoch:     15, update:    3530, cost:   0.476458
Gradient discriminator: -9.293791
Gradient professor: 21.912150
Loss Generator D: 3.148826
Loss Generator P: 0.428411
Gradient discriminator: 3.139664
Gradient professor: 3.408404
Loss Generator D: 2.943366
Loss Generator P: 0.409548
Gradient discriminator: 0.254736
Gradient professor: -0.388536
Loss Generator D: 3.240809
Loss Generator P: 0.657661
Gradient discriminator: -13.728746
Gradient professor: 2.460667
Loss Generator D: 2.990832
Loss Generator P: 0.676283
Gradient discriminator: 4.434008
Gradient professor: -12.568678
Loss Generator D: 2.833759
Loss Generator P: 0.439592
Gradient discriminator: -7.140131
Gradient professor: -6.203776
Loss Generator D: 2.811212
Loss Generator P: 0.418946
Gradient discriminator: 5.523783
Gradient professor: -3.526242
Loss Generator D: 2.716775
Loss Generator P: 0.368009
Gradient discriminator: 6.320445
Gradient professor: -1.247637
Loss Generator D: 2.907309
Loss Generator P: 0.500229
Gradient discriminator: 3.404822
Gradient professor: -7.744570
Loss Generator D: 2.675815
Loss Generator P: 0.463964
Gradient discriminator: 7.209171
Gradient professor: 6.159828
Loss Generator D: 2.727765
Loss Generator P: 0.646697
Generator    : Epoch:     15, update:    3540, cost:   0.646697
Gradient discriminator: 2.715983
Gradient professor: -2.866383
Loss Generator D: 2.595033
Loss Generator P: 0.455721
Gradient discriminator: 2.905229
Gradient professor: 30.428308
Loss Generator D: 3.037898
Loss Generator P: 0.461269
Gradient discriminator: 0.276690
Gradient professor: -28.683076
Loss Generator D: 3.105234
Loss Generator P: 0.465627
Gradient discriminator: -5.792916
Gradient professor: 13.570321
Loss Generator D: 2.906472
Loss Generator P: 0.476493
Gradient discriminator: 3.758501
Gradient professor: -17.026722
Loss Generator D: 3.230296
Loss Generator P: 0.633835
Gradient discriminator: 0.016307
Gradient professor: 25.447537
Loss Generator D: 2.976800
Loss Generator P: 0.533051
Gradient discriminator: 0.380832
Gradient professor: -9.524272
Loss Generator D: 2.850116
Loss Generator P: 0.465433
Gradient discriminator: -0.215358
Gradient professor: 3.389828
Loss Generator D: 2.619845
Loss Generator P: 0.521527
Gradient discriminator: -3.775086
Gradient professor: 2.590343
Loss Generator D: 3.190800
Loss Generator P: 0.735029
Gradient discriminator: -22.991421
Gradient professor: 26.585024
Loss Generator D: 2.783550
Loss Generator P: 0.510312
Generator    : Epoch:     15, update:    3550, cost:   0.510312
Gradient discriminator: 7.399359
Gradient professor: 11.730899
Loss Generator D: 2.773330
Loss Generator P: 0.566842
Gradient discriminator: 9.418548
Gradient professor: 7.786097
Loss Generator D: 2.599933
Loss Generator P: 0.495810
Gradient discriminator: 3.117848
Gradient professor: -10.355279
Loss Generator D: 2.097351
Loss Generator P: 0.526329
Gradient discriminator: -6.710954
Gradient professor: -15.588590
Loss Generator D: 2.811199
Loss Generator P: 0.603779
Gradient discriminator: 5.932050
Gradient professor: -6.485820
Loss Generator D: 2.451262
Loss Generator P: 0.561831
Gradient discriminator: -10.678968
Gradient professor: 7.836608
Loss Generator D: 2.614848
Loss Generator P: 0.444902
Gradient discriminator: -6.847277
Gradient professor: -3.450806
Loss Generator D: 2.379676
Loss Generator P: 0.422417
Gradient discriminator: 2.329006
Gradient professor: 19.224182
Loss Generator D: 2.658616
Loss Generator P: 0.421829
Gradient discriminator: -1.596349
Gradient professor: -4.339142
Loss Generator D: 3.123800
Loss Generator P: 0.438597
Gradient discriminator: 3.338285
Gradient professor: -8.854411
Loss Generator D: 2.116568
Loss Generator P: 0.459116
Generator    : Epoch:     15, update:    3560, cost:   0.459116
Gradient discriminator: 22.580556
Gradient professor: -0.713996
Loss Generator D: 1.860727
Loss Generator P: 0.512779
Gradient discriminator: 5.466259
Gradient professor: 18.981433
Loss Generator D: 1.730022
Loss Generator P: 0.677476
Gradient discriminator: 0.874390
Gradient professor: 5.071514
Loss Generator D: 1.979986
Loss Generator P: 0.500349
Gradient discriminator: -4.144842
Gradient professor: 3.908873
Loss Generator D: 1.915435
Loss Generator P: 0.538156
Gradient discriminator: 3.248116
Gradient professor: -15.660540
Loss Generator D: 2.114303
Loss Generator P: 0.587387
Gradient discriminator: -16.652249
Gradient professor: -6.981260
Loss Generator D: 2.201223
Loss Generator P: 0.498613
Gradient discriminator: -6.175148
Gradient professor: 10.552805
Loss Generator D: 1.937245
Loss Generator P: 0.498692
Gradient discriminator: -6.935797
Gradient professor: -6.036144
Loss Generator D: 2.062143
Loss Generator P: 0.417854
Gradient discriminator: 16.957544
Gradient professor: 1.127959
Loss Generator D: 2.231943
Loss Generator P: 0.591235
Gradient discriminator: 16.634282
Gradient professor: 7.932450
Loss Generator D: 1.770684
Loss Generator P: 0.505282
Generator    : Epoch:     15, update:    3570, cost:   0.505282
Gradient discriminator: 7.357295
Gradient professor: 3.064664
Loss Generator D: 1.634996
Loss Generator P: 0.397255
Gradient discriminator: 13.674062
Gradient professor: -17.091708
Loss Generator D: 1.965293
Loss Generator P: 0.351349
Gradient discriminator: -12.281483
Gradient professor: 8.859535
Loss Generator D: 1.499987
Loss Generator P: 0.453214
Gradient discriminator: 1.769891
Gradient professor: 2.693693
Loss Generator D: 1.814945
Loss Generator P: 0.511054
Gradient discriminator: 8.706594
Gradient professor: -15.508493
Loss Generator D: 1.791050
Loss Generator P: 0.473833
Gradient discriminator: 16.975541
Gradient professor: 2.678625
Loss Generator D: 1.539095
Loss Generator P: 0.432073
Gradient discriminator: 7.692988
Gradient professor: 22.418213
Loss Generator D: 2.142194
Loss Generator P: 0.448297
Gradient discriminator: 12.153901
Gradient professor: -0.322953
Loss Generator D: 1.956072
Loss Generator P: 0.602738
Gradient discriminator: 17.411525
Gradient professor: 1.461562
Loss Generator D: 1.644141
Loss Generator P: 0.329839
Gradient discriminator: -1.633907
Gradient professor: -3.680172
Loss Generator D: 2.144506
Loss Generator P: 0.306206
Generator    : Epoch:     15, update:    3580, cost:   0.306206
Gradient discriminator: 2.672637
Gradient professor: 14.529329
Loss Generator D: 2.667670
Loss Generator P: 0.395685
Gradient discriminator: 0.579697
Gradient professor: -12.710519
Loss Generator D: 2.448876
Loss Generator P: 0.406529
Gradient discriminator: 6.711358
Gradient professor: 4.425055
Loss Generator D: 2.154701
Loss Generator P: 0.366828
Gradient discriminator: 6.732163
Gradient professor: -2.075047
Loss Generator D: 2.551950
Loss Generator P: 0.303752
Gradient discriminator: 0.612119
Gradient professor: -4.269794
Loss Generator D: 2.949514
Loss Generator P: 0.311730
Gradient discriminator: -1.256161
Gradient professor: 8.291116
Loss Generator D: 2.199244
Loss Generator P: 0.339418
Gradient discriminator: 1.721037
Gradient professor: 21.616194
Loss Generator D: 2.299708
Loss Generator P: 0.369124
Gradient discriminator: 8.195169
Gradient professor: -9.027120
Loss Generator D: 2.016024
Loss Generator P: 0.551871
Gradient discriminator: 4.727205
Gradient professor: -11.615058
Loss Generator D: 2.431131
Loss Generator P: 0.414889
Gradient discriminator: 24.031858
Gradient professor: 14.003280
Loss Generator D: 2.317037
Loss Generator P: 0.592598
Generator    : Epoch:     15, update:    3590, cost:   0.592598
Gradient discriminator: 12.257240
Gradient professor: -4.265290
Loss Generator D: 2.584015
Loss Generator P: 0.411439
Gradient discriminator: 1.213220
Gradient professor: 4.216987
Loss Generator D: 2.688329
Loss Generator P: 0.569204
Gradient discriminator: 2.994782
Gradient professor: 12.501217
Loss Generator D: 2.409544
Loss Generator P: 0.425809
Gradient discriminator: -1.207492
Gradient professor: 2.859428
Loss Generator D: 2.578802
Loss Generator P: 0.339898
Gradient discriminator: -32.750399
Gradient professor: 6.497824
Loss Generator D: 2.532445
Loss Generator P: 0.371879
Gradient discriminator: -7.170928
Gradient professor: 7.520925
Loss Generator D: 2.412397
Loss Generator P: 0.423490
Gradient discriminator: 14.599075
Gradient professor: -19.291436
Loss Generator D: 3.061940
Loss Generator P: 0.421244
Gradient discriminator: -6.575353
Gradient professor: -22.115055
Loss Generator D: 2.408442
Loss Generator P: 0.325907
Gradient discriminator: 4.394391
Gradient professor: -15.747333
Loss Generator D: 3.199485
Loss Generator P: 0.402369
Gradient discriminator: -2.233336
Gradient professor: 26.809711
Loss Generator D: 3.012785
Loss Generator P: 0.434551
Generator    : Epoch:     15, update:    3600, cost:   0.434551
Validation 36 - LOSS = 1.634 (PPL: 5.122)
Calling beam-search process
Beam-search ended, took 2.82990 minutes.
Validation 36 - BLEU = 4.88, 8.7/5.8/4.0/2.8 (BP=1.000, ratio=6.745, hyp_len=28462, ref_len=4220)
Early stopping patience: 980 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 6.079271
Gradient professor: -3.230127
Loss Generator D: 2.526030
Loss Generator P: 0.538433
Gradient discriminator: 9.845149
Gradient professor: -35.464676
Loss Generator D: 1.728087
Loss Generator P: 0.477706
Gradient discriminator: 6.856165
Gradient professor: -14.268553
Loss Generator D: 2.180596
Loss Generator P: 0.411422
Gradient discriminator: 5.872012
Gradient professor: -15.118265
Loss Generator D: 2.007850
Loss Generator P: 0.424295
Gradient discriminator: 20.613216
Gradient professor: 4.935658
Loss Generator D: 2.509903
Loss Generator P: 0.295260
Gradient discriminator: 15.491943
Gradient professor: 13.445467
Loss Generator D: 1.771467
Loss Generator P: 0.492075
Gradient discriminator: 8.286156
Gradient professor: -29.255253
Loss Generator D: 1.818157
Loss Generator P: 0.341963
Gradient discriminator: -11.433808
Gradient professor: -4.183342
Loss Generator D: 2.231405
Loss Generator P: 0.394306
Gradient discriminator: 4.890008
Gradient professor: -30.230560
Loss Generator D: 2.330886
Loss Generator P: 0.476027
Gradient discriminator: -8.757177
Gradient professor: -12.820716
Loss Generator D: 2.730641
Loss Generator P: 0.412453
Generator    : Epoch:     15, update:    3610, cost:   0.412453
Gradient discriminator: -2.366964
Gradient professor: 15.431789
Loss Generator D: 2.865797
Loss Generator P: 0.487398
Gradient discriminator: 8.297282
Gradient professor: 13.197357
Loss Generator D: 2.844740
Loss Generator P: 0.437358
Gradient discriminator: -2.051873
Gradient professor: 8.251922
Loss Generator D: 3.103669
Loss Generator P: 0.349634
Gradient discriminator: 2.468116
Gradient professor: -1.446169
Loss Generator D: 3.040974
Loss Generator P: 0.337559
Gradient discriminator: -11.934312
Gradient professor: 0.565499
Loss Generator D: 3.267964
Loss Generator P: 0.449682
Gradient discriminator: -9.788858
Gradient professor: -5.719993
Loss Generator D: 2.466248
Loss Generator P: 0.561229
Gradient discriminator: 12.686957
Gradient professor: 6.818056
Loss Generator D: 2.970603
Loss Generator P: 0.262662
Gradient discriminator: -6.276460
Gradient professor: 15.663448
Loss Generator D: 3.052325
Loss Generator P: 0.513767
Gradient discriminator: -16.175154
Gradient professor: -6.151449
Loss Generator D: 3.274563
Loss Generator P: 0.342276
Gradient discriminator: -7.331393
Gradient professor: -1.680968
Loss Generator D: 2.301272
Loss Generator P: 0.408460
Generator    : Epoch:     15, update:    3620, cost:   0.408460
Gradient discriminator: -12.096319
Gradient professor: -28.601446
Loss Generator D: 2.019103
Loss Generator P: 0.455783
Gradient discriminator: -7.016777
Gradient professor: -13.265146
Loss Generator D: 2.298517
Loss Generator P: 0.439460
Gradient discriminator: 3.674531
Gradient professor: -8.648612
Loss Generator D: 2.181074
Loss Generator P: 0.434674
Gradient discriminator: 3.973415
Gradient professor: -6.574161
Loss Generator D: 2.498915
Loss Generator P: 0.510504
Gradient discriminator: 8.152424
Gradient professor: 10.988095
Loss Generator D: 2.490138
Loss Generator P: 0.513046
Gradient discriminator: 11.968681
Gradient professor: 0.188577
Loss Generator D: 3.025753
Loss Generator P: 0.465863
Gradient discriminator: 4.373123
Gradient professor: 2.250004
Loss Generator D: 2.928673
Loss Generator P: 0.443395
Gradient discriminator: -5.402441
Gradient professor: 21.896954
Loss Generator D: 3.581837
Loss Generator P: 0.489052
Gradient discriminator: 2.459463
Gradient professor: 22.554925
Loss Generator D: 3.248276
Loss Generator P: 0.529264
Gradient discriminator: -3.099424
Gradient professor: -19.602513
Loss Generator D: 3.134528
Loss Generator P: 0.496520
Generator    : Epoch:     15, update:    3630, cost:   0.496520
Gradient discriminator: 6.419614
Gradient professor: 12.654776
Loss Generator D: 3.024839
Loss Generator P: 0.408090
Gradient discriminator: 21.845931
Gradient professor: -18.903663
Loss Generator D: 3.322822
Loss Generator P: 0.413194
Gradient discriminator: -2.566005
Gradient professor: 21.724468
Loss Generator D: 2.223136
Loss Generator P: 0.344224
Gradient discriminator: 116.175656
Gradient professor: -21.078568
Loss Generator D: 2.912618
Loss Generator P: 0.581089
Gradient discriminator: -3.662368
Gradient professor: 11.269476
Loss Generator D: 2.342083
Loss Generator P: 0.429068
Gradient discriminator: 6.650656
Gradient professor: 6.258525
Loss Generator D: 3.200154
Loss Generator P: 0.370201
Gradient discriminator: 2.042552
Gradient professor: -10.135118
Loss Generator D: 3.106149
Loss Generator P: 0.366344
Gradient discriminator: -0.426636
Gradient professor: 10.728491
Loss Generator D: 3.569781
Loss Generator P: 0.283479
Gradient discriminator: -9.628742
Gradient professor: -0.256918
Loss Generator D: 3.484296
Loss Generator P: 0.500361
Gradient discriminator: 13.809375
Gradient professor: 15.035703
Loss Generator D: 2.919238
Loss Generator P: 0.432966
Generator    : Epoch:     15, update:    3640, cost:   0.432966
Gradient discriminator: -11.612925
Gradient professor: -21.828325
Loss Generator D: 3.090192
Loss Generator P: 0.369241
Gradient discriminator: 5.058460
Gradient professor: 15.135423
Loss Generator D: 3.134432
Loss Generator P: 0.488765
Gradient discriminator: -0.051188
Gradient professor: -2.353150
Loss Generator D: 2.962506
Loss Generator P: 0.629670
Gradient discriminator: 6.083479
Gradient professor: -0.160704
Loss Generator D: 3.302850
Loss Generator P: 0.533223
Gradient discriminator: -2.397364
Gradient professor: -20.021708
Loss Generator D: 2.942428
Loss Generator P: 0.572471
Gradient discriminator: -4.527145
Gradient professor: -3.776771
Loss Generator D: 3.068804
Loss Generator P: 0.586954
Gradient discriminator: -18.440552
Gradient professor: -18.436293
Loss Generator D: 3.039555
Loss Generator P: 0.303475
Gradient discriminator: -5.940725
Gradient professor: 7.861454
Loss Generator D: 3.389666
Loss Generator P: 0.369167
Gradient discriminator: -7.700239
Gradient professor: 0.707795
Loss Generator D: 3.312082
Loss Generator P: 0.380424
Gradient discriminator: 1.287870
Gradient professor: 8.330749
Loss Generator D: 3.361628
Loss Generator P: 0.340548
Generator    : Epoch:     15, update:    3650, cost:   0.340548
Gradient discriminator: 1.593591
Gradient professor: 8.875807
Loss Generator D: 3.478553
Loss Generator P: 0.536448
Gradient discriminator: 2.441787
Gradient professor: 9.032238
Loss Generator D: 2.956561
Loss Generator P: 0.490992
Gradient discriminator: 2.014648
Gradient professor: 8.501821
Loss Generator D: 2.949420
Loss Generator P: 0.442126
Gradient discriminator: 16.184524
Gradient professor: 3.730216
Loss Generator D: 2.741896
Loss Generator P: 0.407386
Gradient discriminator: 6.214147
Gradient professor: 12.588615
Loss Generator D: 2.400812
Loss Generator P: 0.499204
Gradient discriminator: 1.496309
Gradient professor: -13.580739
Loss Generator D: 2.881109
Loss Generator P: 0.461517
Gradient discriminator: -6.445217
Gradient professor: -22.998289
Loss Generator D: 2.908145
Loss Generator P: 0.447883
Gradient discriminator: -7.881003
Gradient professor: -5.249666
Loss Generator D: 2.475283
Loss Generator P: 0.319469
Gradient discriminator: -8.484241
Gradient professor: 5.372581
Loss Generator D: 2.460023
Loss Generator P: 0.318811
Gradient discriminator: 1.603624
Gradient professor: 5.520644
Loss Generator D: 2.486554
Loss Generator P: 0.450266
Generator    : Epoch:     15, update:    3660, cost:   0.450266
Gradient discriminator: 9.504809
Gradient professor: -5.936683
Loss Generator D: 3.110034
Loss Generator P: 0.449903
Gradient discriminator: -4.648327
Gradient professor: 31.527170
Loss Generator D: 2.925186
Loss Generator P: 0.581551
Gradient discriminator: -1.198210
Gradient professor: -1.938216
Loss Generator D: 3.016016
Loss Generator P: 0.565937
Gradient discriminator: 7.301597
Gradient professor: -0.782441
Loss Generator D: 2.922750
Loss Generator P: 0.535685
Gradient discriminator: 11.098895
Gradient professor: 25.338850
Loss Generator D: 2.519944
Loss Generator P: 0.637421
Gradient discriminator: 10.679204
Gradient professor: -9.370621
Loss Generator D: 2.671899
Loss Generator P: 0.535859
Gradient discriminator: -11.572973
Gradient professor: 8.658944
Loss Generator D: 2.340366
Loss Generator P: 0.545519
Gradient discriminator: 3.236806
Gradient professor: 3.745799
Loss Generator D: 2.891060
Loss Generator P: 0.360072
Gradient discriminator: 4.751652
Gradient professor: -23.558620
Loss Generator D: 2.316740
Loss Generator P: 0.487186
Gradient discriminator: -4.099348
Gradient professor: 6.888158
Loss Generator D: 3.057112
Loss Generator P: 0.518297
Generator    : Epoch:     15, update:    3670, cost:   0.518297
Gradient discriminator: 0.710159
Gradient professor: -2.352559
Loss Generator D: 2.856534
Loss Generator P: 0.385221
Gradient discriminator: -7.156177
Gradient professor: 5.351674
Loss Generator D: 2.147196
Loss Generator P: 0.393836
Gradient discriminator: 5.309157
Gradient professor: 9.647909
Loss Generator D: 2.860673
Loss Generator P: 0.435278
Gradient discriminator: -13.776569
Gradient professor: -3.670312
Loss Generator D: 2.824528
Loss Generator P: 0.286575
Gradient discriminator: 16.558316
Gradient professor: -14.025894
Loss Generator D: 2.747136
Loss Generator P: 0.407997
Gradient discriminator: 12.790663
Gradient professor: -7.968300
Loss Generator D: 3.070705
Loss Generator P: 0.486217
Gradient discriminator: -8.632234
Gradient professor: -5.454089
Loss Generator D: 2.401991
Loss Generator P: 0.635351
Gradient discriminator: 9.450834
Gradient professor: 25.338806
Loss Generator D: 2.694832
Loss Generator P: 0.726523
Gradient discriminator: 6.058849
Gradient professor: -1.266979
Loss Generator D: 2.881521
Loss Generator P: 0.638372
Gradient discriminator: -7.704578
Gradient professor: -2.804063
Loss Generator D: 3.179498
Loss Generator P: 0.378375
Generator    : Epoch:     15, update:    3680, cost:   0.378375
Gradient discriminator: -4.128349
Gradient professor: 2.321748
Loss Generator D: 2.800776
Loss Generator P: 0.492734
Gradient discriminator: 5.631547
Gradient professor: -2.933237
Loss Generator D: 2.745577
Loss Generator P: 0.462836
Gradient discriminator: -2.271861
Gradient professor: 19.230107
Loss Generator D: 2.896523
Loss Generator P: 0.566636
Gradient discriminator: 2.502641
Gradient professor: 0.159754
Loss Generator D: 2.885265
Loss Generator P: 0.659664
Gradient discriminator: 0.467173
Gradient professor: 13.412149
Loss Generator D: 3.102798
Loss Generator P: 0.575474
Gradient discriminator: 2.401940
Gradient professor: -0.446647
Loss Generator D: 2.895267
Loss Generator P: 0.414436
Gradient discriminator: 4.052996
Gradient professor: 9.650770
Loss Generator D: 2.352839
Loss Generator P: 0.502168
Gradient discriminator: 1.168867
Gradient professor: -0.445488
Loss Generator D: 2.469451
Loss Generator P: 0.563870
Gradient discriminator: -6.126894
Gradient professor: -14.032242
Loss Generator D: 2.970048
Loss Generator P: 0.531222
Gradient discriminator: -11.145963
Gradient professor: -24.512649
Loss Generator D: 2.495365
Loss Generator P: 0.542971
Generator    : Epoch:     15, update:    3690, cost:   0.542971
Gradient discriminator: 1.290059
Gradient professor: -7.064553
Loss Generator D: 2.725708
Loss Generator P: 0.575304
Gradient discriminator: 18.736501
Gradient professor: 8.488352
Loss Generator D: 2.812663
Loss Generator P: 0.399346
Gradient discriminator: -3.013231
Gradient professor: -76.068486
Loss Generator D: 2.736259
Loss Generator P: 0.762213
Gradient discriminator: 5.002837
Gradient professor: 38.548056
Loss Generator D: 2.434060
Loss Generator P: 0.693846
Gradient discriminator: 3.370462
Gradient professor: 6.011672
Loss Generator D: 2.271450
Loss Generator P: 0.367859
Gradient discriminator: 15.156394
Gradient professor: 7.255549
Loss Generator D: 2.870596
Loss Generator P: 0.536788
Gradient discriminator: 4.109566
Gradient professor: 0.049413
Loss Generator D: 2.923690
Loss Generator P: 0.502961
Gradient discriminator: 8.557758
Gradient professor: 7.799679
Loss Generator D: 2.170840
Loss Generator P: 0.579432
Gradient discriminator: 9.691893
Gradient professor: -13.410344
Loss Generator D: 2.358580
Loss Generator P: 0.537441
Gradient discriminator: 16.040988
Gradient professor: 21.321037
Loss Generator D: 2.705265
Loss Generator P: 0.406497
Generator    : Epoch:     15, update:    3700, cost:   0.406497
Validation 37 - LOSS = 1.662 (PPL: 5.270)
Calling beam-search process
Beam-search ended, took 2.69430 minutes.
Validation 37 - BLEU = 5.33, 10.2/6.4/4.3/2.9 (BP=1.000, ratio=5.555, hyp_len=23442, ref_len=4220)
Early stopping patience: 979 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 15.556431
Gradient professor: 16.248660
Loss Generator D: 3.111535
Loss Generator P: 0.499941
Gradient discriminator: 3.702263
Gradient professor: -0.819827
Loss Generator D: 2.249746
Loss Generator P: 0.441468
Gradient discriminator: 12.079492
Gradient professor: 0.286622
Loss Generator D: 2.901576
Loss Generator P: 0.432856
Gradient discriminator: -1.432345
Gradient professor: -7.695090
Loss Generator D: 2.917939
Loss Generator P: 0.426428
Gradient discriminator: -1.794320
Gradient professor: -8.580861
Loss Generator D: 2.760233
Loss Generator P: 0.343837
Gradient discriminator: -10.004791
Gradient professor: -6.912528
Loss Generator D: 3.037850
Loss Generator P: 0.349762
Gradient discriminator: -12.864791
Gradient professor: -3.526960
Loss Generator D: 3.310330
Loss Generator P: 0.494726
Gradient discriminator: -12.965265
Gradient professor: 10.492977
Loss Generator D: 3.085277
Loss Generator P: 0.546177
Gradient discriminator: 1.053646
Gradient professor: 5.163558
Loss Generator D: 2.361120
Loss Generator P: 0.397584
Gradient discriminator: 1.614472
Gradient professor: -24.216130
Loss Generator D: 2.673470
Loss Generator P: 0.518029
Generator    : Epoch:     15, update:    3710, cost:   0.518029
Gradient discriminator: -5.301333
Gradient professor: -2.873222
Loss Generator D: 2.983423
Loss Generator P: 0.554132
Gradient discriminator: -17.669960
Gradient professor: 17.723268
Loss Generator D: 2.744619
Loss Generator P: 0.552116
Gradient discriminator: -7.151533
Gradient professor: -10.002595
Loss Generator D: 3.262748
Loss Generator P: 0.426863
Gradient discriminator: -3.391731
Gradient professor: 9.191391
Loss Generator D: 2.586452
Loss Generator P: 0.401866
Gradient discriminator: -0.949192
Gradient professor: 33.241202
Loss Generator D: 3.217026
Loss Generator P: 0.500918
Gradient discriminator: -0.719301
Gradient professor: 19.786927
Loss Generator D: 3.257594
Loss Generator P: 0.536246
Gradient discriminator: 8.086569
Gradient professor: -5.070875
Loss Generator D: 2.922235
Loss Generator P: 0.481327
Gradient discriminator: 5.146383
Gradient professor: 7.166417
Loss Generator D: 2.952702
Loss Generator P: 0.473559
Gradient discriminator: 0.187968
Gradient professor: 12.936293
Loss Generator D: 2.842144
Loss Generator P: 0.394211
Gradient discriminator: 1.559974
Gradient professor: -21.637427
Loss Generator D: 2.711764
Loss Generator P: 0.382953
Generator    : Epoch:     15, update:    3720, cost:   0.382953
Gradient discriminator: -0.742162
Gradient professor: 10.664423
Loss Generator D: 3.215495
Loss Generator P: 0.455413
Gradient discriminator: -2.178169
Gradient professor: 0.531540
Loss Generator D: 2.967668
Loss Generator P: 0.493240
Gradient discriminator: -5.449169
Gradient professor: -5.126094
Loss Generator D: 2.519887
Loss Generator P: 0.495412
Gradient discriminator: -2.558977
Gradient professor: 16.009805
Loss Generator D: 2.746198
Loss Generator P: 0.374180
Gradient discriminator: 4.052780
Gradient professor: 1.414903
Loss Generator D: 2.692280
Loss Generator P: 0.400904
Gradient discriminator: 8.103037
Gradient professor: -14.075072
Loss Generator D: 2.626191
Loss Generator P: 0.544221
Gradient discriminator: -1.027385
Gradient professor: 17.476735
Loss Generator D: 3.152145
Loss Generator P: 0.369159
Gradient discriminator: 1.699480
Gradient professor: -17.764814
Loss Generator D: 3.105155
Loss Generator P: 0.452388
Gradient discriminator: -2.575646
Gradient professor: 5.538142
Loss Generator D: 2.669646
Loss Generator P: 0.506808
Gradient discriminator: 8.280024
Gradient professor: -7.018760
Loss Generator D: 2.794285
Loss Generator P: 0.482516
Generator    : Epoch:     15, update:    3730, cost:   0.482516
Gradient discriminator: -0.533964
Gradient professor: -33.190055
Loss Generator D: 2.641151
Loss Generator P: 0.558739
Gradient discriminator: -3.611271
Gradient professor: 1.868431
Loss Generator D: 2.503915
Loss Generator P: 0.654212
Gradient discriminator: 5.138331
Gradient professor: 17.705319
Loss Generator D: 2.533895
Loss Generator P: 0.647107
Gradient discriminator: 0.211889
Gradient professor: 3.302584
Loss Generator D: 2.884248
Loss Generator P: 0.368378
Gradient discriminator: 17.124297
Gradient professor: -6.964623
Loss Generator D: 2.435614
Loss Generator P: 0.449240
Gradient discriminator: 20.030652
Gradient professor: -7.903214
Loss Generator D: 2.848061
Loss Generator P: 0.412863
Gradient discriminator: -2.265834
Gradient professor: 9.695594
Loss Generator D: 3.111769
Loss Generator P: 0.325387
Gradient discriminator: -5.472941
Gradient professor: -20.982384
Loss Generator D: 2.818725
Loss Generator P: 0.467333
Gradient discriminator: 4.696455
Gradient professor: 5.011184
Loss Generator D: 3.032198
Loss Generator P: 0.399452
Gradient discriminator: 8.359236
Gradient professor: -1.781357
Loss Generator D: 2.860623
Loss Generator P: 0.375367
Generator    : Epoch:     15, update:    3740, cost:   0.375367
Gradient discriminator: -3.895514
Gradient professor: -13.402219
Loss Generator D: 3.003126
Loss Generator P: 0.399514
Gradient discriminator: -25.016973
Gradient professor: -4.044551
Loss Generator D: 2.781532
Loss Generator P: 0.385717
Gradient discriminator: -6.043588
Gradient professor: 20.149033
Loss Generator D: 2.989239
Loss Generator P: 0.379054
Gradient discriminator: -2.395010
Gradient professor: -8.277507
Loss Generator D: 2.905625
Loss Generator P: 0.437974
Gradient discriminator: -2.990995
Gradient professor: -9.223089
Loss Generator D: 3.886649
Loss Generator P: 0.446132
Gradient discriminator: 3.335659
Gradient professor: -1.485380
Loss Generator D: 3.275204
Loss Generator P: 0.383948
Gradient discriminator: 5.333969
Gradient professor: -6.623079
Loss Generator D: 3.287524
Loss Generator P: 0.404121
Gradient discriminator: 9.785841
Gradient professor: 10.988019
Loss Generator D: 3.285208
Loss Generator P: 0.346921
Gradient discriminator: 15.095357
Gradient professor: -13.119626
Loss Generator D: 3.185125
Loss Generator P: 0.451519
Gradient discriminator: 34.926462
Gradient professor: -3.540944
Loss Generator D: 3.047778
Loss Generator P: 0.193311
Generator    : Epoch:     15, update:    3750, cost:   0.193311
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 15 finished with mean loss 1.60303 (PPL: 4.96808)
--> Epoch took 252.289 minutes, 60.549 sec/update
Epoch summary of Discriminator:
--> Epoch 15 finished with mean loss nan (PPL:  nan)
--> Epoch took 252.289 minutes, 60.549 sec/update
---------------------------------------------------------
Starting Epoch 16
-----------------
Gradient discriminator: 2.151675
Gradient professor: 14.892253
Loss Generator D: 2.440849
Loss Generator P: 0.561850
Gradient discriminator: 11.382383
Gradient professor: 1.590469
Loss Generator D: 2.849885
Loss Generator P: 0.413161
Gradient discriminator: -15.795775
Gradient professor: -9.253725
Loss Generator D: 2.641723
Loss Generator P: 0.461576
Gradient discriminator: 12.817039
Gradient professor: -18.074445
Loss Generator D: 2.319137
Loss Generator P: 0.531233
Gradient discriminator: 10.189173
Gradient professor: -3.396142
Loss Generator D: 2.846265
Loss Generator P: 0.438019
Gradient discriminator: -0.801871
Gradient professor: -0.473659
Loss Generator D: 2.835095
Loss Generator P: 0.494410
Gradient discriminator: 21.447148
Gradient professor: -23.415923
Loss Generator D: 2.751363
Loss Generator P: 0.536269
Gradient discriminator: -4.506421
Gradient professor: 32.111472
Loss Generator D: 2.496382
Loss Generator P: 0.370671
Gradient discriminator: -18.194674
Gradient professor: -16.169472
Loss Generator D: 2.760926
Loss Generator P: 0.550585
Gradient discriminator: -4.200269
Gradient professor: 34.829080
Loss Generator D: 2.511616
Loss Generator P: 0.564902
Generator    : Epoch:     16, update:    3760, cost:   0.564902
Gradient discriminator: 6.572677
Gradient professor: -20.709210
Loss Generator D: 3.144429
Loss Generator P: 0.707254
Gradient discriminator: 0.749304
Gradient professor: 9.482207
Loss Generator D: 3.243495
Loss Generator P: 0.416343
Gradient discriminator: -2.772774
Gradient professor: 39.361686
Loss Generator D: 3.229846
Loss Generator P: 0.550494
Gradient discriminator: 1.910627
Gradient professor: 11.799632
Loss Generator D: 3.202877
Loss Generator P: 0.543892
Gradient discriminator: -2.755978
Gradient professor: -1.425686
Loss Generator D: 3.112292
Loss Generator P: 0.336474
Gradient discriminator: -7.474699
Gradient professor: 11.102989
Loss Generator D: 3.208363
Loss Generator P: 0.300057
Gradient discriminator: -5.425532
Gradient professor: -7.619378
Loss Generator D: 3.244777
Loss Generator P: 0.459975
Gradient discriminator: 1.426826
Gradient professor: 5.744551
Loss Generator D: 3.147691
Loss Generator P: 0.443352
Gradient discriminator: -31.515969
Gradient professor: 14.747599
Loss Generator D: 3.074094
Loss Generator P: 0.470966
Gradient discriminator: 0.348686
Gradient professor: 20.998120
Loss Generator D: 3.074057
Loss Generator P: 0.528108
Generator    : Epoch:     16, update:    3770, cost:   0.528108
Gradient discriminator: 7.547078
Gradient professor: -2.223955
Loss Generator D: 3.336169
Loss Generator P: 0.458768
Gradient discriminator: 10.871268
Gradient professor: -17.266705
Loss Generator D: 3.273132
Loss Generator P: 0.420883
Gradient discriminator: -12.275242
Gradient professor: -22.769781
Loss Generator D: 3.090734
Loss Generator P: 0.402045
Gradient discriminator: 2.367488
Gradient professor: 18.822343
Loss Generator D: 2.895820
Loss Generator P: 0.685331
Gradient discriminator: 7.769599
Gradient professor: -18.405697
Loss Generator D: 3.385709
Loss Generator P: 0.637288
Gradient discriminator: 7.812861
Gradient professor: 1.404492
Loss Generator D: 3.291106
Loss Generator P: 0.419546
Gradient discriminator: -4.204501
Gradient professor: 0.326379
Loss Generator D: 2.807394
Loss Generator P: 0.354145
Gradient discriminator: 0.898880
Gradient professor: 11.033090
Loss Generator D: 2.810376
Loss Generator P: 0.436926
Gradient discriminator: 4.077460
Gradient professor: 6.194016
Loss Generator D: 2.788543
Loss Generator P: 0.371866
Gradient discriminator: 2.283551
Gradient professor: -6.226304
Loss Generator D: 3.217143
Loss Generator P: 0.410465
Generator    : Epoch:     16, update:    3780, cost:   0.410465
Gradient discriminator: -7.712440
Gradient professor: -13.150645
Loss Generator D: 3.316851
Loss Generator P: 0.398884
Gradient discriminator: 39.524833
Gradient professor: 13.786946
Loss Generator D: 3.032744
Loss Generator P: 0.351486
Gradient discriminator: -5.094860
Gradient professor: 13.497354
Loss Generator D: 3.024760
Loss Generator P: 0.603747
Gradient discriminator: 3.669096
Gradient professor: -8.919241
Loss Generator D: 3.189252
Loss Generator P: 0.644458
Gradient discriminator: 1.278870
Gradient professor: -15.290832
Loss Generator D: 2.759256
Loss Generator P: 0.402570
Gradient discriminator: 0.296487
Gradient professor: -3.045015
Loss Generator D: 2.786701
Loss Generator P: 0.385470
Gradient discriminator: -3.085126
Gradient professor: 14.036722
Loss Generator D: 3.133678
Loss Generator P: 0.331178
Gradient discriminator: -11.695028
Gradient professor: 1.545867
Loss Generator D: 2.958573
Loss Generator P: 0.434114
Gradient discriminator: -0.850027
Gradient professor: -8.466924
Loss Generator D: 2.909750
Loss Generator P: 0.393645
Gradient discriminator: -6.471588
Gradient professor: -11.091776
Loss Generator D: 3.198543
Loss Generator P: 0.599706
Generator    : Epoch:     16, update:    3790, cost:   0.599706
Gradient discriminator: 9.107489
Gradient professor: 1.891810
Loss Generator D: 2.606660
Loss Generator P: 0.469708
Gradient discriminator: 2.605756
Gradient professor: 49.494512
Loss Generator D: 3.082575
Loss Generator P: 0.455944
Gradient discriminator: -4.176288
Gradient professor: -9.950169
Loss Generator D: 3.142595
Loss Generator P: 0.415187
Gradient discriminator: 0.728821
Gradient professor: 14.347031
Loss Generator D: 2.865897
Loss Generator P: 0.399869
Gradient discriminator: -0.538913
Gradient professor: -6.987724
Loss Generator D: 3.166385
Loss Generator P: 0.559452
Gradient discriminator: -2.088444
Gradient professor: 12.850823
Loss Generator D: 2.895595
Loss Generator P: 0.469160
Gradient discriminator: 3.859951
Gradient professor: 4.528900
Loss Generator D: 2.613226
Loss Generator P: 0.375678
Gradient discriminator: -3.941124
Gradient professor: -1.570816
Loss Generator D: 2.328830
Loss Generator P: 0.507349
Gradient discriminator: -21.429695
Gradient professor: -8.543115
Loss Generator D: 2.722517
Loss Generator P: 0.662520
Gradient discriminator: -27.363275
Gradient professor: 1.800125
Loss Generator D: 2.390038
Loss Generator P: 0.507192
Generator    : Epoch:     16, update:    3800, cost:   0.507192
Validation 38 - LOSS = 1.726 (PPL: 5.617)
Calling beam-search process
Beam-search ended, took 2.10110 minutes.
Validation 38 - BLEU = 7.53, 14.3/8.9/6.1/4.1 (BP=1.000, ratio=4.141, hyp_len=17473, ref_len=4220)
Early stopping patience: 978 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 50.516551
Gradient professor: -8.110343
Loss Generator D: 2.407133
Loss Generator P: 0.485202
Gradient discriminator: 1.551006
Gradient professor: 23.802720
Loss Generator D: 2.472818
Loss Generator P: 0.488175
Gradient discriminator: 0.776536
Gradient professor: -8.763785
Loss Generator D: 1.859025
Loss Generator P: 0.406912
Gradient discriminator: -0.216381
Gradient professor: -2.966899
Loss Generator D: 2.073945
Loss Generator P: 0.547775
Gradient discriminator: 6.170268
Gradient professor: -31.535242
Loss Generator D: 2.430571
Loss Generator P: 0.504948
Gradient discriminator: -9.646949
Gradient professor: 14.739503
Loss Generator D: 2.754976
Loss Generator P: 0.372078
Gradient discriminator: 21.014275
Gradient professor: 18.099700
Loss Generator D: 2.394248
Loss Generator P: 0.359848
Gradient discriminator: 2.018654
Gradient professor: -2.583087
Loss Generator D: 2.848995
Loss Generator P: 0.375793
Gradient discriminator: 9.195932
Gradient professor: 3.542185
Loss Generator D: 2.952205
Loss Generator P: 0.372253
Gradient discriminator: 7.956853
Gradient professor: -2.534884
Loss Generator D: 2.831160
Loss Generator P: 0.442392
Generator    : Epoch:     16, update:    3810, cost:   0.442392
Gradient discriminator: 19.396001
Gradient professor: 5.684389
Loss Generator D: 2.085043
Loss Generator P: 0.512513
Gradient discriminator: 5.258164
Gradient professor: -15.853286
Loss Generator D: 2.156106
Loss Generator P: 0.590048
Gradient discriminator: 21.392512
Gradient professor: 0.274992
Loss Generator D: 2.012209
Loss Generator P: 0.529143
Gradient discriminator: 47.273622
Gradient professor: 23.262301
Loss Generator D: 1.991574
Loss Generator P: 0.476027
Gradient discriminator: 16.355315
Gradient professor: -22.970356
Loss Generator D: 1.731343
Loss Generator P: 0.539995
Gradient discriminator: 487.875788
Gradient professor: -27.061070
Loss Generator D: 1.786729
Loss Generator P: 0.467822
Gradient discriminator: 14.762676
Gradient professor: -8.056736
Loss Generator D: 1.797691
Loss Generator P: 0.509701
Gradient discriminator: 1.386984
Gradient professor: -7.478063
Loss Generator D: 2.155378
Loss Generator P: 0.378665
Gradient discriminator: 22.370958
Gradient professor: -17.449435
Loss Generator D: 1.374675
Loss Generator P: 0.576859
Gradient discriminator: -10.526474
Gradient professor: -2.361442
Loss Generator D: 1.675149
Loss Generator P: 0.454299
Generator    : Epoch:     16, update:    3820, cost:   0.454299
Gradient discriminator: 2.767870
Gradient professor: -10.477973
Loss Generator D: 1.976180
Loss Generator P: 0.381458
Gradient discriminator: 14.874549
Gradient professor: -0.060403
Loss Generator D: 1.759706
Loss Generator P: 0.336027
Gradient discriminator: 11.563885
Gradient professor: -10.465003
Loss Generator D: 1.089312
Loss Generator P: 0.455597
Gradient discriminator: 9.382930
Gradient professor: -12.286867
Loss Generator D: 1.247114
Loss Generator P: 0.499319
Gradient discriminator: -4.254721
Gradient professor: 2.580427
Loss Generator D: 1.531858
Loss Generator P: 0.433961
Gradient discriminator: 0.495050
Gradient professor: 13.990924
Loss Generator D: 1.646957
Loss Generator P: 0.410850
Gradient discriminator: -19.568000
Gradient professor: 4.921437
Loss Generator D: 1.587840
Loss Generator P: 0.443206
Gradient discriminator: 6.574079
Gradient professor: 5.233556
Loss Generator D: 2.546703
Loss Generator P: 0.544439
Gradient discriminator: 17.909556
Gradient professor: 2.868795
Loss Generator D: 2.236498
Loss Generator P: 0.258950
Gradient discriminator: 14.547704
Gradient professor: -4.039649
Loss Generator D: 2.068276
Loss Generator P: 0.293009
Generator    : Epoch:     16, update:    3830, cost:   0.293009
Gradient discriminator: 9.964154
Gradient professor: -5.292223
Loss Generator D: 2.562032
Loss Generator P: 0.379762
Gradient discriminator: 9.683390
Gradient professor: 4.251918
Loss Generator D: 2.339786
Loss Generator P: 0.367931
Gradient discriminator: -5.864020
Gradient professor: -6.579732
Loss Generator D: 2.012821
Loss Generator P: 0.361119
Gradient discriminator: 3.455550
Gradient professor: -1.387303
Loss Generator D: 2.509416
Loss Generator P: 0.311855
Gradient discriminator: 2.745431
Gradient professor: 11.104039
Loss Generator D: 2.740040
Loss Generator P: 0.311486
Gradient discriminator: -1.080307
Gradient professor: -3.718952
Loss Generator D: 2.354743
Loss Generator P: 0.294067
Gradient discriminator: 0.153465
Gradient professor: -14.767756
Loss Generator D: 2.806411
Loss Generator P: 0.321650
Gradient discriminator: -0.427744
Gradient professor: -22.753016
Loss Generator D: 3.238415
Loss Generator P: 0.468001
Gradient discriminator: -4.471729
Gradient professor: -1.196148
Loss Generator D: 3.098517
Loss Generator P: 0.399673
Gradient discriminator: 19.664937
Gradient professor: -7.144682
Loss Generator D: 3.351838
Loss Generator P: 0.557187
Generator    : Epoch:     16, update:    3840, cost:   0.557187
Gradient discriminator: -0.672548
Gradient professor: 9.919708
Loss Generator D: 3.304500
Loss Generator P: 0.364947
Gradient discriminator: -1.398423
Gradient professor: 3.799849
Loss Generator D: 2.965386
Loss Generator P: 0.525693
Gradient discriminator: -0.823184
Gradient professor: 7.754242
Loss Generator D: 3.291980
Loss Generator P: 0.383955
Gradient discriminator: -5.591833
Gradient professor: -3.236960
Loss Generator D: 2.951869
Loss Generator P: 0.271522
Gradient discriminator: 6.207941
Gradient professor: 1.694052
Loss Generator D: 3.275928
Loss Generator P: 0.354591
Gradient discriminator: -3.258072
Gradient professor: -15.475570
Loss Generator D: 3.186082
Loss Generator P: 0.401315
Gradient discriminator: 6.623208
Gradient professor: -7.645552
Loss Generator D: 3.985861
Loss Generator P: 0.389261
Gradient discriminator: 8.538460
Gradient professor: -14.115188
Loss Generator D: 3.395659
Loss Generator P: 0.348435
Gradient discriminator: -5.827945
Gradient professor: -7.814411
Loss Generator D: 3.524256
Loss Generator P: 0.335037
Gradient discriminator: -5.070353
Gradient professor: -1.774311
Loss Generator D: 3.990031
Loss Generator P: 0.386952
Generator    : Epoch:     16, update:    3850, cost:   0.386952
Gradient discriminator: 4.007988
Gradient professor: 7.395886
Loss Generator D: 3.906059
Loss Generator P: 0.494775
Gradient discriminator: 15.414213
Gradient professor: -12.910128
Loss Generator D: 3.061069
Loss Generator P: 0.439271
Gradient discriminator: -7.671736
Gradient professor: -2.459030
Loss Generator D: 3.274574
Loss Generator P: 0.332326
Gradient discriminator: 0.734332
Gradient professor: -13.321254
Loss Generator D: 3.173305
Loss Generator P: 0.383130
Gradient discriminator: 25.826729
Gradient professor: -1.407663
Loss Generator D: 3.463746
Loss Generator P: 0.276344
Gradient discriminator: 9.214284
Gradient professor: 34.031244
Loss Generator D: 3.741452
Loss Generator P: 0.438655
Gradient discriminator: -0.147981
Gradient professor: -20.253341
Loss Generator D: 3.097609
Loss Generator P: 0.309812
Gradient discriminator: -2.168015
Gradient professor: -23.411001
Loss Generator D: 3.086971
Loss Generator P: 0.361366
Gradient discriminator: 4.304100
Gradient professor: 1.807278
Loss Generator D: 3.768056
Loss Generator P: 0.415708
Gradient discriminator: 1.706607
Gradient professor: 7.338779
Loss Generator D: 3.165660
Loss Generator P: 0.370714
Generator    : Epoch:     16, update:    3860, cost:   0.370714
Gradient discriminator: -3.375141
Gradient professor: 1.113043
Loss Generator D: 3.130901
Loss Generator P: 0.494517
Gradient discriminator: -4.413152
Gradient professor: 17.927679
Loss Generator D: 3.083139
Loss Generator P: 0.408121
Gradient discriminator: 14.716181
Gradient professor: -15.064616
Loss Generator D: 4.010291
Loss Generator P: 0.293628
Gradient discriminator: 0.472072
Gradient professor: 2.128301
Loss Generator D: 3.249316
Loss Generator P: 0.297903
Gradient discriminator: -8.501731
Gradient professor: 8.815266
Loss Generator D: 4.068057
Loss Generator P: 0.393344
Gradient discriminator: 25.809607
Gradient professor: -4.229976
Loss Generator D: 3.280883
Loss Generator P: 0.546228
Gradient discriminator: 2.103132
Gradient professor: 2.147632
Loss Generator D: 3.168875
Loss Generator P: 0.253015
Gradient discriminator: -4.947056
Gradient professor: -1.047719
Loss Generator D: 3.808366
Loss Generator P: 0.463503
Gradient discriminator: 3.179592
Gradient professor: -10.163269
Loss Generator D: 3.978228
Loss Generator P: 0.311390
Gradient discriminator: -2.695529
Gradient professor: -4.002570
Loss Generator D: 3.542175
Loss Generator P: 0.361063
Generator    : Epoch:     16, update:    3870, cost:   0.361063
Gradient discriminator: 1.433487
Gradient professor: -31.678557
Loss Generator D: 4.007354
Loss Generator P: 0.402444
Gradient discriminator: 1.624456
Gradient professor: -11.963432
Loss Generator D: 3.104481
Loss Generator P: 0.416664
Gradient discriminator: 2.427797
Gradient professor: 1.784919
Loss Generator D: 3.435636
Loss Generator P: 0.430149
Gradient discriminator: 8.541954
Gradient professor: 14.200896
Loss Generator D: 3.458730
Loss Generator P: 0.466450
Gradient discriminator: -1.412358
Gradient professor: 10.842672
Loss Generator D: 2.906344
Loss Generator P: 0.461590
Gradient discriminator: 8.250077
Gradient professor: 14.144082
Loss Generator D: 3.431777
Loss Generator P: 0.451336
Gradient discriminator: 4.964549
Gradient professor: -0.855457
Loss Generator D: 3.137783
Loss Generator P: 0.449765
Gradient discriminator: 10.324151
Gradient professor: 5.718069
Loss Generator D: 3.599196
Loss Generator P: 0.480701
Gradient discriminator: -1.855861
Gradient professor: 29.491212
Loss Generator D: 3.699328
Loss Generator P: 0.491872
Gradient discriminator: 5.346129
Gradient professor: -12.602270
Loss Generator D: 3.963266
Loss Generator P: 0.452922
Generator    : Epoch:     16, update:    3880, cost:   0.452922
Gradient discriminator: 4.432226
Gradient professor: 13.457206
Loss Generator D: 3.809954
Loss Generator P: 0.419570
Gradient discriminator: 9.080757
Gradient professor: -19.606114
Loss Generator D: 3.257784
Loss Generator P: 0.406931
Gradient discriminator: 20.977917
Gradient professor: 2.082550
Loss Generator D: 2.596431
Loss Generator P: 0.325779
Gradient discriminator: -8.524930
Gradient professor: -18.360199
Loss Generator D: 3.625997
Loss Generator P: 0.555319
Gradient discriminator: -0.342855
Gradient professor: 4.822175
Loss Generator D: 2.707539
Loss Generator P: 0.433537
Gradient discriminator: 4.666631
Gradient professor: -16.409142
Loss Generator D: 3.581088
Loss Generator P: 0.302932
Gradient discriminator: -2.211069
Gradient professor: -7.086826
Loss Generator D: 3.426361
Loss Generator P: 0.320061
Gradient discriminator: -1.349031
Gradient professor: -3.668473
Loss Generator D: 3.958180
Loss Generator P: 0.267509
Gradient discriminator: -1.299018
Gradient professor: 39.464710
Loss Generator D: 3.375054
Loss Generator P: 0.493236
Gradient discriminator: 4.442360
Gradient professor: 0.433863
Loss Generator D: 2.992339
Loss Generator P: 0.408320
Generator    : Epoch:     16, update:    3890, cost:   0.408320
Gradient discriminator: 4.983127
Gradient professor: 16.452736
Loss Generator D: 2.956078
Loss Generator P: 0.399475
Gradient discriminator: -5.939951
Gradient professor: -7.580392
Loss Generator D: 3.578272
Loss Generator P: 0.421751
Gradient discriminator: 5.609037
Gradient professor: 0.695797
Loss Generator D: 3.285038
Loss Generator P: 0.593309
Gradient discriminator: -1.079651
Gradient professor: -6.126667
Loss Generator D: 3.308690
Loss Generator P: 0.428825
Gradient discriminator: 2.737481
Gradient professor: -16.222739
Loss Generator D: 3.129315
Loss Generator P: 0.542317
Gradient discriminator: -10.285701
Gradient professor: -0.022681
Loss Generator D: 2.794166
Loss Generator P: 0.517713
Gradient discriminator: -8.397107
Gradient professor: 0.507424
Loss Generator D: 2.538821
Loss Generator P: 0.344117
Gradient discriminator: 4.061423
Gradient professor: -6.001103
Loss Generator D: 2.572211
Loss Generator P: 0.365753
Gradient discriminator: -7.911100
Gradient professor: 4.864820
Loss Generator D: 2.689915
Loss Generator P: 0.332746
Gradient discriminator: 6.326785
Gradient professor: -2.698822
Loss Generator D: 2.660527
Loss Generator P: 0.290835
Generator    : Epoch:     16, update:    3900, cost:   0.290835
Validation 39 - LOSS = 1.723 (PPL: 5.601)
Calling beam-search process
Beam-search ended, took 2.17340 minutes.
Validation 39 - BLEU = 6.97, 13.1/8.3/5.6/3.9 (BP=1.000, ratio=4.523, hyp_len=19088, ref_len=4220)
Early stopping patience: 977 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 18.205547
Gradient professor: -8.241907
Loss Generator D: 3.243337
Loss Generator P: 0.494585
Gradient discriminator: -13.944280
Gradient professor: 0.468470
Loss Generator D: 2.856380
Loss Generator P: 0.484910
Gradient discriminator: 1.932131
Gradient professor: 2.285181
Loss Generator D: 2.672967
Loss Generator P: 0.439379
Gradient discriminator: 1.305747
Gradient professor: 17.830813
Loss Generator D: 2.968803
Loss Generator P: 0.373060
Gradient discriminator: 3.542047
Gradient professor: -20.762102
Loss Generator D: 2.913158
Loss Generator P: 0.505955
Gradient discriminator: 3.727461
Gradient professor: -20.856996
Loss Generator D: 2.637345
Loss Generator P: 0.370573
Gradient discriminator: -2.904747
Gradient professor: 10.783391
Loss Generator D: 3.141021
Loss Generator P: 0.427060
Gradient discriminator: 9.697925
Gradient professor: -6.327749
Loss Generator D: 2.475230
Loss Generator P: 0.290597
Gradient discriminator: 14.895441
Gradient professor: 11.151155
Loss Generator D: 2.853555
Loss Generator P: 0.326144
Gradient discriminator: 1.566946
Gradient professor: 1.493225
Loss Generator D: 2.516668
Loss Generator P: 0.447187
Generator    : Epoch:     16, update:    3910, cost:   0.447187
Gradient discriminator: -5.113723
Gradient professor: -7.590048
Loss Generator D: 2.725890
Loss Generator P: 0.488896
Gradient discriminator: 4.648066
Gradient professor: 21.881973
Loss Generator D: 3.145071
Loss Generator P: 0.527457
Gradient discriminator: 9.394339
Gradient professor: -16.337672
Loss Generator D: 2.991013
Loss Generator P: 0.521181
Gradient discriminator: -5.241942
Gradient professor: 18.083811
Loss Generator D: 2.870254
Loss Generator P: 0.512094
Gradient discriminator: 3.802980
Gradient professor: 2.857042
Loss Generator D: 2.741153
Loss Generator P: 0.609424
Gradient discriminator: -3.515622
Gradient professor: -19.139165
Loss Generator D: 2.553043
Loss Generator P: 0.493555
Gradient discriminator: 24.803121
Gradient professor: 22.676079
Loss Generator D: 2.362772
Loss Generator P: 0.569349
Gradient discriminator: -2.656193
Gradient professor: 13.075300
Loss Generator D: 2.937206
Loss Generator P: 0.354083
Gradient discriminator: 1.385959
Gradient professor: -21.395162
Loss Generator D: 2.297350
Loss Generator P: 0.478447
Gradient discriminator: 17.988115
Gradient professor: -0.298234
Loss Generator D: 2.972182
Loss Generator P: 0.455667
Generator    : Epoch:     16, update:    3920, cost:   0.455667
Gradient discriminator: -5.539525
Gradient professor: 7.106099
Loss Generator D: 2.601571
Loss Generator P: 0.366524
Gradient discriminator: -33.524995
Gradient professor: 8.858564
Loss Generator D: 2.193903
Loss Generator P: 0.354512
Gradient discriminator: 9.592121
Gradient professor: -6.766633
Loss Generator D: 3.173800
Loss Generator P: 0.401187
Gradient discriminator: 6.717665
Gradient professor: -26.044696
Loss Generator D: 3.142346
Loss Generator P: 0.272795
Gradient discriminator: 0.461717
Gradient professor: -5.538910
Loss Generator D: 3.011985
Loss Generator P: 0.342223
Gradient discriminator: -3.095789
Gradient professor: -21.974803
Loss Generator D: 3.302930
Loss Generator P: 0.461629
Gradient discriminator: 11.265977
Gradient professor: 15.455083
Loss Generator D: 2.504656
Loss Generator P: 0.606848
Gradient discriminator: -11.652955
Gradient professor: 35.020861
Loss Generator D: 2.566773
Loss Generator P: 0.681678
Gradient discriminator: -3.221601
Gradient professor: -3.908504
Loss Generator D: 2.542417
Loss Generator P: 0.562909
Gradient discriminator: -20.977569
Gradient professor: -2.448571
Loss Generator D: 2.350428
Loss Generator P: 0.382978
Generator    : Epoch:     16, update:    3930, cost:   0.382978
Gradient discriminator: 6.370359
Gradient professor: 12.671757
Loss Generator D: 2.486758
Loss Generator P: 0.425966
Gradient discriminator: 2.320028
Gradient professor: -9.960662
Loss Generator D: 2.234427
Loss Generator P: 0.440644
Gradient discriminator: -0.934166
Gradient professor: -5.208723
Loss Generator D: 2.290786
Loss Generator P: 0.442489
Gradient discriminator: 7.402927
Gradient professor: 5.947718
Loss Generator D: 2.258375
Loss Generator P: 0.608150
Gradient discriminator: -5.628769
Gradient professor: 9.205664
Loss Generator D: 2.499327
Loss Generator P: 0.514967
Gradient discriminator: 0.442635
Gradient professor: -15.251293
Loss Generator D: 2.585786
Loss Generator P: 0.425720
Gradient discriminator: 3.886770
Gradient professor: 23.985296
Loss Generator D: 2.534977
Loss Generator P: 0.480194
Gradient discriminator: 6.550548
Gradient professor: -9.097965
Loss Generator D: 2.637526
Loss Generator P: 0.573213
Gradient discriminator: -6.219459
Gradient professor: 8.020574
Loss Generator D: 2.681524
Loss Generator P: 0.503877
Gradient discriminator: -0.444899
Gradient professor: -24.353155
Loss Generator D: 2.634243
Loss Generator P: 0.496762
Generator    : Epoch:     16, update:    3940, cost:   0.496762
Gradient discriminator: -1.882229
Gradient professor: -1.276879
Loss Generator D: 2.708712
Loss Generator P: 0.553164
Gradient discriminator: 0.218791
Gradient professor: -0.596776
Loss Generator D: 2.352823
Loss Generator P: 0.349200
Gradient discriminator: 11.575309
Gradient professor: 12.086685
Loss Generator D: 2.310930
Loss Generator P: 0.704862
Gradient discriminator: -3.340814
Gradient professor: 4.789525
Loss Generator D: 2.486411
Loss Generator P: 0.624128
Gradient discriminator: 0.137029
Gradient professor: 22.179796
Loss Generator D: 2.301309
Loss Generator P: 0.392747
Gradient discriminator: 4.506367
Gradient professor: -13.293041
Loss Generator D: 2.734153
Loss Generator P: 0.505109
Gradient discriminator: 4.968490
Gradient professor: 7.304047
Loss Generator D: 2.762886
Loss Generator P: 0.490107
Gradient discriminator: 16.585996
Gradient professor: -11.307379
Loss Generator D: 2.150243
Loss Generator P: 0.543406
Gradient discriminator: -3.829558
Gradient professor: -7.309926
Loss Generator D: 2.490437
Loss Generator P: 0.480557
Gradient discriminator: -1.793955
Gradient professor: 11.421734
Loss Generator D: 2.682438
Loss Generator P: 0.432547
Generator    : Epoch:     16, update:    3950, cost:   0.432547
Gradient discriminator: -1.149931
Gradient professor: 9.933199
Loss Generator D: 2.847788
Loss Generator P: 0.482418
Gradient discriminator: 22.624639
Gradient professor: -11.603519
Loss Generator D: 2.607166
Loss Generator P: 0.417791
Gradient discriminator: -7.440765
Gradient professor: 4.695860
Loss Generator D: 2.782011
Loss Generator P: 0.405983
Gradient discriminator: 10.396452
Gradient professor: -6.271462
Loss Generator D: 2.537880
Loss Generator P: 0.370974
Gradient discriminator: -13.109040
Gradient professor: -3.613815
Loss Generator D: 3.023045
Loss Generator P: 0.339888
Gradient discriminator: -2.364880
Gradient professor: -5.794070
Loss Generator D: 2.839973
Loss Generator P: 0.314928
Gradient discriminator: -2.978874
Gradient professor: -7.866241
Loss Generator D: 3.339014
Loss Generator P: 0.481054
Gradient discriminator: -0.289839
Gradient professor: 7.398319
Loss Generator D: 3.003661
Loss Generator P: 0.485310
Gradient discriminator: 8.697323
Gradient professor: 2.196091
Loss Generator D: 2.619621
Loss Generator P: 0.367190
Gradient discriminator: 0.136414
Gradient professor: -1.305034
Loss Generator D: 2.561394
Loss Generator P: 0.488478
Generator    : Epoch:     16, update:    3960, cost:   0.488478
Gradient discriminator: 5.882504
Gradient professor: -18.802396
Loss Generator D: 3.040098
Loss Generator P: 0.516548
Gradient discriminator: -15.090510
Gradient professor: -3.640962
Loss Generator D: 2.689919
Loss Generator P: 0.552722
Gradient discriminator: 3.572573
Gradient professor: -8.074728
Loss Generator D: 3.019990
Loss Generator P: 0.489875
Gradient discriminator: -0.711969
Gradient professor: -17.744476
Loss Generator D: 2.522542
Loss Generator P: 0.358621
Gradient discriminator: 13.875028
Gradient professor: 10.312662
Loss Generator D: 3.392078
Loss Generator P: 0.489110
Gradient discriminator: -7.554362
Gradient professor: 20.935661
Loss Generator D: 3.275705
Loss Generator P: 0.514848
Gradient discriminator: 6.171258
Gradient professor: -12.632341
Loss Generator D: 2.746357
Loss Generator P: 0.461432
Gradient discriminator: 0.783863
Gradient professor: -8.133440
Loss Generator D: 3.057271
Loss Generator P: 0.457045
Gradient discriminator: 5.665636
Gradient professor: 17.435816
Loss Generator D: 2.868555
Loss Generator P: 0.376829
Gradient discriminator: 7.995518
Gradient professor: 0.342826
Loss Generator D: 2.900511
Loss Generator P: 0.356955
Generator    : Epoch:     16, update:    3970, cost:   0.356955
Gradient discriminator: -1.426782
Gradient professor: -3.579237
Loss Generator D: 2.879163
Loss Generator P: 0.448364
Gradient discriminator: -18.492272
Gradient professor: -6.054762
Loss Generator D: 2.804446
Loss Generator P: 0.430771
Gradient discriminator: -23.660725
Gradient professor: -4.532212
Loss Generator D: 2.925129
Loss Generator P: 0.472665
Gradient discriminator: 13.458718
Gradient professor: -7.869558
Loss Generator D: 2.923699
Loss Generator P: 0.356944
Gradient discriminator: 4.419395
Gradient professor: 20.362999
Loss Generator D: 2.607746
Loss Generator P: 0.355750
Gradient discriminator: -21.870256
Gradient professor: -7.939317
Loss Generator D: 2.873624
Loss Generator P: 0.461218
Gradient discriminator: 0.924137
Gradient professor: 1.609683
Loss Generator D: 2.966896
Loss Generator P: 0.368529
Gradient discriminator: -3.569938
Gradient professor: 10.818906
Loss Generator D: 3.295607
Loss Generator P: 0.411130
Gradient discriminator: -10.552065
Gradient professor: -7.709561
Loss Generator D: 3.149031
Loss Generator P: 0.415753
Gradient discriminator: 9.287095
Gradient professor: -7.242531
Loss Generator D: 2.907260
Loss Generator P: 0.426687
Generator    : Epoch:     16, update:    3980, cost:   0.426687
Gradient discriminator: -9.036382
Gradient professor: -10.297821
Loss Generator D: 2.935250
Loss Generator P: 0.518348
Gradient discriminator: -14.521344
Gradient professor: 9.662978
Loss Generator D: 2.509624
Loss Generator P: 0.605019
Gradient discriminator: -0.110236
Gradient professor: 13.565278
Loss Generator D: 2.630453
Loss Generator P: 0.625906
Gradient discriminator: 2.661626
Gradient professor: 20.149641
Loss Generator D: 2.533292
Loss Generator P: 0.323292
Gradient discriminator: 2.177284
Gradient professor: -8.393033
Loss Generator D: 2.208526
Loss Generator P: 0.461907
Gradient discriminator: 6.194050
Gradient professor: -4.942425
Loss Generator D: 2.615802
Loss Generator P: 0.392832
Gradient discriminator: 0.008020
Gradient professor: 3.142476
Loss Generator D: 2.782134
Loss Generator P: 0.265033
Gradient discriminator: -0.274449
Gradient professor: -9.134194
Loss Generator D: 2.656269
Loss Generator P: 0.426090
Gradient discriminator: -15.824672
Gradient professor: 6.440089
Loss Generator D: 2.601510
Loss Generator P: 0.370931
Gradient discriminator: 7.689425
Gradient professor: 11.488837
Loss Generator D: 2.348190
Loss Generator P: 0.427598
Generator    : Epoch:     16, update:    3990, cost:   0.427598
Gradient discriminator: -7.414437
Gradient professor: -1.773527
Loss Generator D: 2.327064
Loss Generator P: 0.392170
Gradient discriminator: -8.855691
Gradient professor: -0.697522
Loss Generator D: 2.589602
Loss Generator P: 0.425030
Gradient discriminator: -14.006033
Gradient professor: 4.022425
Loss Generator D: 2.697779
Loss Generator P: 0.347597
Gradient discriminator: -8.725820
Gradient professor: -0.573671
Loss Generator D: 2.719062
Loss Generator P: 0.372963
Gradient discriminator: 16.426413
Gradient professor: 4.520678
Loss Generator D: 2.914833
Loss Generator P: 0.455197
Gradient discriminator: 7.702455
Gradient professor: -1.280075
Loss Generator D: 2.984880
Loss Generator P: 0.327993
Gradient discriminator: 7.608840
Gradient professor: -8.730228
Loss Generator D: 2.896442
Loss Generator P: 0.365680
Gradient discriminator: 4.821217
Gradient professor: 12.562900
Loss Generator D: 3.398064
Loss Generator P: 0.348219
Gradient discriminator: -16.198495
Gradient professor: 10.944857
Loss Generator D: 2.925636
Loss Generator P: 0.406186
Gradient discriminator: -8.447379
Gradient professor: -11.183950
Loss Generator D: 3.260576
Loss Generator P: 0.198477
Generator    : Epoch:     16, update:    4000, cost:   0.198477
Validation 40 - LOSS = 1.644 (PPL: 5.174)
Calling beam-search process
Beam-search ended, took 1.69944 minutes.
Validation 40 - BLEU = 13.92, 25.5/16.5/11.4/7.8 (BP=1.000, ratio=2.529, hyp_len=10674, ref_len=4220)
Early stopping patience: 976 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 16 finished with mean loss 1.64054 (PPL: 5.15794)
--> Epoch took 301.088 minutes, 72.261 sec/update
Epoch summary of Discriminator:
--> Epoch 16 finished with mean loss nan (PPL:  nan)
--> Epoch took 301.088 minutes, 72.261 sec/update
---------------------------------------------------------
Starting Epoch 17
-----------------
Gradient discriminator: 2.128430
Gradient professor: 15.917496
Loss Generator D: 2.843406
Loss Generator P: 0.579945
Gradient discriminator: -11.761525
Gradient professor: 9.997371
Loss Generator D: 3.199173
Loss Generator P: 0.374211
Gradient discriminator: 4.516562
Gradient professor: -7.089283
Loss Generator D: 4.632688
Loss Generator P: 0.485012
Gradient discriminator: 14.002375
Gradient professor: 13.561712
Loss Generator D: 3.620981
Loss Generator P: 0.514689
Gradient discriminator: 4.140430
Gradient professor: -26.974579
Loss Generator D: 3.684515
Loss Generator P: 0.404946
Gradient discriminator: -14.925387
Gradient professor: -2.719663
Loss Generator D: 3.347050
Loss Generator P: 0.445203
Gradient discriminator: -4.232420
Gradient professor: -20.999372
Loss Generator D: 3.461663
Loss Generator P: 0.460763
Gradient discriminator: -14.231474
Gradient professor: 4.032647
Loss Generator D: 2.751699
Loss Generator P: 0.349599
Gradient discriminator: -21.432354
Gradient professor: -3.468070
Loss Generator D: 3.565368
Loss Generator P: 0.524314
Gradient discriminator: -2.928506
Gradient professor: 2.714252
Loss Generator D: 2.875104
Loss Generator P: 0.551882
Generator    : Epoch:     17, update:    4010, cost:   0.551882
Gradient discriminator: -4.716872
Gradient professor: 33.310597
Loss Generator D: 3.298850
Loss Generator P: 0.623867
Gradient discriminator: 7.373368
Gradient professor: -13.517984
Loss Generator D: 3.468062
Loss Generator P: 0.463128
Gradient discriminator: 1.246094
Gradient professor: 7.118657
Loss Generator D: 3.601204
Loss Generator P: 0.495294
Gradient discriminator: 25.268253
Gradient professor: -4.453806
Loss Generator D: 4.244235
Loss Generator P: 0.490568
Gradient discriminator: 5.539314
Gradient professor: -3.192980
Loss Generator D: 4.047618
Loss Generator P: 0.325259
Gradient discriminator: 5.506022
Gradient professor: -0.014683
Loss Generator D: 3.871925
Loss Generator P: 0.271386
Gradient discriminator: 20.235961
Gradient professor: -0.874717
Loss Generator D: 4.085988
Loss Generator P: 0.440900
Gradient discriminator: 17.784932
Gradient professor: 29.826549
Loss Generator D: 5.348359
Loss Generator P: 0.415445
Gradient discriminator: -1.026565
Gradient professor: -13.509237
Loss Generator D: 4.291671
Loss Generator P: 0.476685
Gradient discriminator: -1.113460
Gradient professor: 9.145756
Loss Generator D: 3.652611
Loss Generator P: 0.524996
Generator    : Epoch:     17, update:    4020, cost:   0.524996
Gradient discriminator: 0.862966
Gradient professor: -12.951678
Loss Generator D: 3.194460
Loss Generator P: 0.404163
Gradient discriminator: 6.788674
Gradient professor: 4.486232
Loss Generator D: 3.301145
Loss Generator P: 0.367365
Gradient discriminator: 4.732381
Gradient professor: -16.470991
Loss Generator D: 3.115704
Loss Generator P: 0.407491
Gradient discriminator: 21.715286
Gradient professor: 18.620841
Loss Generator D: 4.939915
Loss Generator P: 0.617889
Gradient discriminator: 30.166101
Gradient professor: -9.962083
Loss Generator D: 4.291546
Loss Generator P: 0.609426
Gradient discriminator: 6.988837
Gradient professor: -26.614143
Loss Generator D: 2.995646
Loss Generator P: 0.435300
Gradient discriminator: -8.551535
Gradient professor: -14.937791
Loss Generator D: 3.122743
Loss Generator P: 0.352492
Gradient discriminator: 5.933030
Gradient professor: 13.848766
Loss Generator D: 3.211730
Loss Generator P: 0.397670
Gradient discriminator: -8.009503
Gradient professor: 7.972666
Loss Generator D: 3.305744
Loss Generator P: 0.335589
Gradient discriminator: 12.134486
Gradient professor: 1.508945
Loss Generator D: 3.171510
Loss Generator P: 0.361770
Generator    : Epoch:     17, update:    4030, cost:   0.361770
Gradient discriminator: 1.289949
Gradient professor: 6.175214
Loss Generator D: 3.073519
Loss Generator P: 0.379385
Gradient discriminator: 0.519085
Gradient professor: 0.425397
Loss Generator D: 3.158891
Loss Generator P: 0.344992
Gradient discriminator: 6.050416
Gradient professor: 32.878195
Loss Generator D: 3.552363
Loss Generator P: 0.562827
Gradient discriminator: -10.950824
Gradient professor: -8.339830
Loss Generator D: 2.823814
Loss Generator P: 0.614919
Gradient discriminator: -1.913763
Gradient professor: -13.869010
Loss Generator D: 3.466313
Loss Generator P: 0.404161
Gradient discriminator: -9.292885
Gradient professor: -4.222663
Loss Generator D: 3.141113
Loss Generator P: 0.319463
Gradient discriminator: 8.880122
Gradient professor: 2.220956
Loss Generator D: 2.953908
Loss Generator P: 0.363438
Gradient discriminator: -7.899456
Gradient professor: -18.386413
Loss Generator D: 3.212876
Loss Generator P: 0.407256
Gradient discriminator: 6.415491
Gradient professor: 0.021068
Loss Generator D: 3.213563
Loss Generator P: 0.388002
Gradient discriminator: 4.365847
Gradient professor: 10.508846
Loss Generator D: 3.836132
Loss Generator P: 0.519543
Generator    : Epoch:     17, update:    4040, cost:   0.519543
Gradient discriminator: 16.530310
Gradient professor: 12.414660
Loss Generator D: 3.181402
Loss Generator P: 0.425327
Gradient discriminator: 4.367328
Gradient professor: 17.534391
Loss Generator D: 3.642516
Loss Generator P: 0.434097
Gradient discriminator: 0.931439
Gradient professor: -10.422812
Loss Generator D: 4.547835
Loss Generator P: 0.353704
Gradient discriminator: 16.064772
Gradient professor: -1.179687
Loss Generator D: 4.309144
Loss Generator P: 0.333638
Gradient discriminator: 16.052607
Gradient professor: -10.978061
Loss Generator D: 5.175613
Loss Generator P: 0.525046
Gradient discriminator: 12.793441
Gradient professor: -15.957806
Loss Generator D: 3.063908
Loss Generator P: 0.443847
Gradient discriminator: 1.318450
Gradient professor: 25.404417
Loss Generator D: 2.938825
Loss Generator P: 0.352654
Gradient discriminator: 9.455899
Gradient professor: -5.085445
Loss Generator D: 2.407949
Loss Generator P: 0.486977
Gradient discriminator: 12.911578
Gradient professor: -21.541737
Loss Generator D: 1.466739
Loss Generator P: 0.744977
Gradient discriminator: -4.911459
Gradient professor: -8.197712
Loss Generator D: 2.684348
Loss Generator P: 0.435664
Generator    : Epoch:     17, update:    4050, cost:   0.435664
Gradient discriminator: 0.283647
Gradient professor: 17.206178
Loss Generator D: 2.338731
Loss Generator P: 0.486049
Gradient discriminator: 0.252757
Gradient professor: -13.551172
Loss Generator D: 1.991026
Loss Generator P: 0.423611
Gradient discriminator: -2.176677
Gradient professor: 9.273228
Loss Generator D: 2.334868
Loss Generator P: 0.424448
Gradient discriminator: 1.705715
Gradient professor: -10.459468
Loss Generator D: 1.890832
Loss Generator P: 0.518605
Gradient discriminator: 8.722198
Gradient professor: -11.736091
Loss Generator D: 2.753445
Loss Generator P: 0.464029
Gradient discriminator: 3.545196
Gradient professor: 1.621605
Loss Generator D: 2.251631
Loss Generator P: 0.352560
Gradient discriminator: -1.648117
Gradient professor: 16.247689
Loss Generator D: 2.883690
Loss Generator P: 0.352172
Gradient discriminator: -7.522958
Gradient professor: 12.285501
Loss Generator D: 3.706992
Loss Generator P: 0.330733
Gradient discriminator: 1.538527
Gradient professor: -4.337598
Loss Generator D: 3.696377
Loss Generator P: 0.326247
Gradient discriminator: 3.961576
Gradient professor: -13.596265
Loss Generator D: 3.538618
Loss Generator P: 0.406295
Generator    : Epoch:     17, update:    4060, cost:   0.406295
Gradient discriminator: 3.947040
Gradient professor: 35.407679
Loss Generator D: 4.002616
Loss Generator P: 0.441077
Gradient discriminator: 0.939304
Gradient professor: -10.387892
Loss Generator D: 3.209816
Loss Generator P: 0.544642
Gradient discriminator: -5.182326
Gradient professor: 3.905450
Loss Generator D: 3.055436
Loss Generator P: 0.445167
Gradient discriminator: -4.743782
Gradient professor: -4.411386
Loss Generator D: 3.771909
Loss Generator P: 0.437097
Gradient discriminator: 7.064940
Gradient professor: 3.376138
Loss Generator D: 3.252406
Loss Generator P: 0.485593
Gradient discriminator: -8.121547
Gradient professor: -25.914798
Loss Generator D: 3.047762
Loss Generator P: 0.466263
Gradient discriminator: 8.900566
Gradient professor: 22.117992
Loss Generator D: 3.079322
Loss Generator P: 0.439861
Gradient discriminator: 0.950686
Gradient professor: -12.851551
Loss Generator D: 3.594907
Loss Generator P: 0.350769
Gradient discriminator: 8.103385
Gradient professor: 6.451764
Loss Generator D: 3.341061
Loss Generator P: 0.532328
Gradient discriminator: -2.144466
Gradient professor: -13.258335
Loss Generator D: 2.958511
Loss Generator P: 0.402899
Generator    : Epoch:     17, update:    4070, cost:   0.402899
Gradient discriminator: 1.623765
Gradient professor: 6.206617
Loss Generator D: 3.717686
Loss Generator P: 0.340718
Gradient discriminator: 7.564698
Gradient professor: -12.867669
Loss Generator D: 3.318481
Loss Generator P: 0.328985
Gradient discriminator: -3.745882
Gradient professor: 3.395365
Loss Generator D: 3.395525
Loss Generator P: 0.409837
Gradient discriminator: 5.315558
Gradient professor: 2.416126
Loss Generator D: 3.253381
Loss Generator P: 0.428431
Gradient discriminator: 16.218281
Gradient professor: 5.563314
Loss Generator D: 3.278393
Loss Generator P: 0.416012
Gradient discriminator: -2.649909
Gradient professor: -2.005960
Loss Generator D: 2.850213
Loss Generator P: 0.354302
Gradient discriminator: 1.988110
Gradient professor: -11.438728
Loss Generator D: 3.330265
Loss Generator P: 0.390747
Gradient discriminator: 6.473342
Gradient professor: 9.783799
Loss Generator D: 3.333220
Loss Generator P: 0.566492
Gradient discriminator: 12.982351
Gradient professor: 11.572352
Loss Generator D: 3.175523
Loss Generator P: 0.256606
Gradient discriminator: 13.947203
Gradient professor: -6.304987
Loss Generator D: 3.008603
Loss Generator P: 0.236399
Generator    : Epoch:     17, update:    4080, cost:   0.236399
Gradient discriminator: 9.814347
Gradient professor: 2.120110
Loss Generator D: 4.135472
Loss Generator P: 0.343836
Gradient discriminator: 15.722416
Gradient professor: 1.855871
Loss Generator D: 3.843490
Loss Generator P: 0.349577
Gradient discriminator: 5.747101
Gradient professor: -8.625183
Loss Generator D: 3.252428
Loss Generator P: 0.316229
Gradient discriminator: -1.614139
Gradient professor: -16.846806
Loss Generator D: 3.954183
Loss Generator P: 0.376402
Gradient discriminator: 8.898097
Gradient professor: 20.415489
Loss Generator D: 4.400980
Loss Generator P: 0.282204
Gradient discriminator: -123.019040
Gradient professor: -2.147784
Loss Generator D: 3.810980
Loss Generator P: 0.230307
Gradient discriminator: 1.143212
Gradient professor: 2.132275
Loss Generator D: 3.849757
Loss Generator P: 0.351706
Gradient discriminator: 6.675008
Gradient professor: -13.339085
Loss Generator D: 3.775734
Loss Generator P: 0.435921
Gradient discriminator: 11.513918
Gradient professor: -22.303349
Loss Generator D: 3.764998
Loss Generator P: 0.376238
Gradient discriminator: 2.396352
Gradient professor: 22.252217
Loss Generator D: 4.126842
Loss Generator P: 0.570667
Generator    : Epoch:     17, update:    4090, cost:   0.570667
Gradient discriminator: -2.460318
Gradient professor: 5.158918
Loss Generator D: 4.016051
Loss Generator P: 0.415231
Gradient discriminator: 14.039018
Gradient professor: -13.183202
Loss Generator D: 3.816496
Loss Generator P: 0.511954
Gradient discriminator: 9.573652
Gradient professor: -7.023709
Loss Generator D: 4.782912
Loss Generator P: 0.337833
Gradient discriminator: -0.312560
Gradient professor: -1.677792
Loss Generator D: 4.083729
Loss Generator P: 0.319100
Gradient discriminator: 8.698826
Gradient professor: 1.581664
Loss Generator D: 3.736745
Loss Generator P: 0.323685
Gradient discriminator: 5.353624
Gradient professor: -16.478764
Loss Generator D: 4.304368
Loss Generator P: 0.407107
Gradient discriminator: 6.895103
Gradient professor: -20.751227
Loss Generator D: 5.030804
Loss Generator P: 0.367736
Gradient discriminator: 13.128514
Gradient professor: -0.491734
Loss Generator D: 4.418717
Loss Generator P: 0.316573
Gradient discriminator: -2.382245
Gradient professor: -14.566973
Loss Generator D: 4.729866
Loss Generator P: 0.430813
Gradient discriminator: -3.545935
Gradient professor: -5.304524
Loss Generator D: 5.957021
Loss Generator P: 0.404696
Generator    : Epoch:     17, update:    4100, cost:   0.404696
Validation 41 - LOSS = 1.651 (PPL: 5.215)
Calling beam-search process
Beam-search ended, took 1.56920 minutes.
Validation 41 - BLEU = 16.32, 28.4/19.1/13.6/9.6 (BP=1.000, ratio=2.318, hyp_len=9783, ref_len=4220)
Early stopping patience: 975 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -5.915610
Gradient professor: 2.292423
Loss Generator D: 5.978106
Loss Generator P: 0.531556
Gradient discriminator: 4.687314
Gradient professor: -6.665927
Loss Generator D: 4.288741
Loss Generator P: 0.494724
Gradient discriminator: -4.136548
Gradient professor: 0.331224
Loss Generator D: 5.158090
Loss Generator P: 0.374155
Gradient discriminator: -5.909773
Gradient professor: 15.063887
Loss Generator D: 4.639665
Loss Generator P: 0.478153
Gradient discriminator: 6.818419
Gradient professor: 11.949708
Loss Generator D: 4.602551
Loss Generator P: 0.267867
Gradient discriminator: -1.841232
Gradient professor: -10.075539
Loss Generator D: 4.877624
Loss Generator P: 0.470198
Gradient discriminator: -1.754324
Gradient professor: -11.753139
Loss Generator D: 3.552951
Loss Generator P: 0.287197
Gradient discriminator: -6.324651
Gradient professor: 1.770183
Loss Generator D: 3.445720
Loss Generator P: 0.316955
Gradient discriminator: -3.909782
Gradient professor: 0.958212
Loss Generator D: 4.337451
Loss Generator P: 0.457851
Gradient discriminator: -2.485243
Gradient professor: -23.415908
Loss Generator D: 3.988857
Loss Generator P: 0.342087
Generator    : Epoch:     17, update:    4110, cost:   0.342087
Gradient discriminator: -11.816480
Gradient professor: 19.891539
Loss Generator D: 3.541448
Loss Generator P: 0.426119
Gradient discriminator: 2.510277
Gradient professor: 8.657063
Loss Generator D: 3.815743
Loss Generator P: 0.378899
Gradient discriminator: 8.407156
Gradient professor: 8.085170
Loss Generator D: 4.200230
Loss Generator P: 0.291944
Gradient discriminator: -9.002061
Gradient professor: 8.034988
Loss Generator D: 4.184726
Loss Generator P: 0.315506
Gradient discriminator: -2.651593
Gradient professor: 2.409533
Loss Generator D: 4.095317
Loss Generator P: 0.366411
Gradient discriminator: -0.245900
Gradient professor: -14.591492
Loss Generator D: 3.454447
Loss Generator P: 0.456995
Gradient discriminator: 5.711723
Gradient professor: 6.437491
Loss Generator D: 3.367123
Loss Generator P: 0.241456
Gradient discriminator: -8.602527
Gradient professor: 12.978309
Loss Generator D: 3.838450
Loss Generator P: 0.453970
Gradient discriminator: 7.352137
Gradient professor: -5.467353
Loss Generator D: 4.593090
Loss Generator P: 0.399461
Gradient discriminator: 0.143179
Gradient professor: -14.424379
Loss Generator D: 3.787431
Loss Generator P: 0.344772
Generator    : Epoch:     17, update:    4120, cost:   0.344772
Gradient discriminator: 4.535631
Gradient professor: -20.110356
Loss Generator D: 3.983674
Loss Generator P: 0.395187
Gradient discriminator: -6.972557
Gradient professor: -0.575132
Loss Generator D: 3.366431
Loss Generator P: 0.377538
Gradient discriminator: -2.152983
Gradient professor: 20.550976
Loss Generator D: 4.188161
Loss Generator P: 0.422766
Gradient discriminator: 7.196331
Gradient professor: -16.947603
Loss Generator D: 3.310940
Loss Generator P: 0.457607
Gradient discriminator: -6.257568
Gradient professor: 13.104721
Loss Generator D: 2.849271
Loss Generator P: 0.456679
Gradient discriminator: 1.955977
Gradient professor: -2.110650
Loss Generator D: 3.687756
Loss Generator P: 0.457924
Gradient discriminator: 1.155423
Gradient professor: 6.325074
Loss Generator D: 3.213271
Loss Generator P: 0.401472
Gradient discriminator: 2.784297
Gradient professor: 6.485084
Loss Generator D: 3.747052
Loss Generator P: 0.432750
Gradient discriminator: 0.323952
Gradient professor: -1.362720
Loss Generator D: 3.773824
Loss Generator P: 0.505944
Gradient discriminator: -3.266963
Gradient professor: -24.150943
Loss Generator D: 4.084996
Loss Generator P: 0.395405
Generator    : Epoch:     17, update:    4130, cost:   0.395405
Gradient discriminator: 8.027544
Gradient professor: -2.601406
Loss Generator D: 3.671866
Loss Generator P: 0.433031
Gradient discriminator: -6.452611
Gradient professor: -25.516145
Loss Generator D: 3.273527
Loss Generator P: 0.422927
Gradient discriminator: 12.354459
Gradient professor: 5.444406
Loss Generator D: 2.872695
Loss Generator P: 0.368413
Gradient discriminator: 4.671766
Gradient professor: -15.046782
Loss Generator D: 3.585726
Loss Generator P: 0.512917
Gradient discriminator: -4.330287
Gradient professor: -0.908357
Loss Generator D: 2.769833
Loss Generator P: 0.383521
Gradient discriminator: -2.751753
Gradient professor: -5.766306
Loss Generator D: 3.453276
Loss Generator P: 0.295437
Gradient discriminator: 3.873832
Gradient professor: -1.864272
Loss Generator D: 3.408581
Loss Generator P: 0.333843
Gradient discriminator: 1.107403
Gradient professor: -4.451068
Loss Generator D: 3.638306
Loss Generator P: 0.221495
Gradient discriminator: 5.898389
Gradient professor: 8.151561
Loss Generator D: 3.289375
Loss Generator P: 0.482375
Gradient discriminator: -0.167799
Gradient professor: -0.424031
Loss Generator D: 3.231204
Loss Generator P: 0.370192
Generator    : Epoch:     17, update:    4140, cost:   0.370192
Gradient discriminator: -11.802144
Gradient professor: -10.779345
Loss Generator D: 2.954928
Loss Generator P: 0.328600
Gradient discriminator: 13.431306
Gradient professor: 26.527904
Loss Generator D: 3.364291
Loss Generator P: 0.362211
Gradient discriminator: -1.853475
Gradient professor: 11.704361
Loss Generator D: 3.534880
Loss Generator P: 0.577432
Gradient discriminator: -4.152904
Gradient professor: 3.957175
Loss Generator D: 3.381536
Loss Generator P: 0.426172
Gradient discriminator: -3.104585
Gradient professor: -9.825089
Loss Generator D: 3.153182
Loss Generator P: 0.491153
Gradient discriminator: 1.849753
Gradient professor: -21.610759
Loss Generator D: 3.107191
Loss Generator P: 0.468913
Gradient discriminator: 9.984581
Gradient professor: 1.954359
Loss Generator D: 3.369756
Loss Generator P: 0.289718
Gradient discriminator: -1.196044
Gradient professor: -2.990898
Loss Generator D: 3.097394
Loss Generator P: 0.361327
Gradient discriminator: -8.432128
Gradient professor: 4.694830
Loss Generator D: 3.038249
Loss Generator P: 0.367790
Gradient discriminator: -5.586358
Gradient professor: -12.101820
Loss Generator D: 3.225603
Loss Generator P: 0.279814
Generator    : Epoch:     17, update:    4150, cost:   0.279814
Gradient discriminator: 0.326742
Gradient professor: 19.162101
Loss Generator D: 3.128791
Loss Generator P: 0.491187
Gradient discriminator: 53.941236
Gradient professor: 6.948291
Loss Generator D: 2.912787
Loss Generator P: 0.457200
Gradient discriminator: 24.007234
Gradient professor: -14.537151
Loss Generator D: 2.807607
Loss Generator P: 0.376646
Gradient discriminator: 7.261248
Gradient professor: -1.707712
Loss Generator D: 2.671276
Loss Generator P: 0.317017
Gradient discriminator: 17.675985
Gradient professor: -2.286443
Loss Generator D: 2.657430
Loss Generator P: 0.469587
Gradient discriminator: -2.492810
Gradient professor: -13.445224
Loss Generator D: 2.665480
Loss Generator P: 0.368093
Gradient discriminator: -24.514587
Gradient professor: -4.500466
Loss Generator D: 2.771891
Loss Generator P: 0.346670
Gradient discriminator: 7.193077
Gradient professor: 5.538576
Loss Generator D: 2.732164
Loss Generator P: 0.273793
Gradient discriminator: -24.776461
Gradient professor: -15.271215
Loss Generator D: 2.719582
Loss Generator P: 0.288943
Gradient discriminator: -9.713638
Gradient professor: 23.619271
Loss Generator D: 2.402085
Loss Generator P: 0.422250
Generator    : Epoch:     17, update:    4160, cost:   0.422250
Gradient discriminator: -4.987796
Gradient professor: -11.424425
Loss Generator D: 2.969106
Loss Generator P: 0.359866
Gradient discriminator: 7.349515
Gradient professor: 12.004477
Loss Generator D: 3.021257
Loss Generator P: 0.503537
Gradient discriminator: 9.258347
Gradient professor: 32.902578
Loss Generator D: 2.941624
Loss Generator P: 0.491286
Gradient discriminator: 8.256508
Gradient professor: -9.993722
Loss Generator D: 3.002574
Loss Generator P: 0.452377
Gradient discriminator: -2.761097
Gradient professor: 22.268715
Loss Generator D: 2.739455
Loss Generator P: 0.584166
Gradient discriminator: -10.894471
Gradient professor: -16.550586
Loss Generator D: 2.853419
Loss Generator P: 0.496843
Gradient discriminator: -19.895822
Gradient professor: 0.036639
Loss Generator D: 2.397853
Loss Generator P: 0.591451
Gradient discriminator: 0.473548
Gradient professor: -3.370489
Loss Generator D: 2.788453
Loss Generator P: 0.296150
Gradient discriminator: -0.006030
Gradient professor: -6.535690
Loss Generator D: 2.307675
Loss Generator P: 0.390777
Gradient discriminator: 11.923961
Gradient professor: 11.478819
Loss Generator D: 2.579857
Loss Generator P: 0.428689
Generator    : Epoch:     17, update:    4170, cost:   0.428689
Gradient discriminator: -8.055391
Gradient professor: 10.471910
Loss Generator D: 2.982241
Loss Generator P: 0.324631
Gradient discriminator: -8.903183
Gradient professor: 8.449938
Loss Generator D: 2.322786
Loss Generator P: 0.284142
Gradient discriminator: 22.468791
Gradient professor: 10.777746
Loss Generator D: 2.575756
Loss Generator P: 0.322967
Gradient discriminator: -11.358357
Gradient professor: -5.091954
Loss Generator D: 2.507270
Loss Generator P: 0.249460
Gradient discriminator: -11.692796
Gradient professor: -10.356053
Loss Generator D: 2.611981
Loss Generator P: 0.313064
Gradient discriminator: 2.675882
Gradient professor: -9.778890
Loss Generator D: 3.035038
Loss Generator P: 0.432984
Gradient discriminator: 9.539242
Gradient professor: -2.080129
Loss Generator D: 2.386751
Loss Generator P: 0.491448
Gradient discriminator: -0.138078
Gradient professor: 24.136750
Loss Generator D: 2.678421
Loss Generator P: 0.620754
Gradient discriminator: -0.372817
Gradient professor: 15.703510
Loss Generator D: 2.863891
Loss Generator P: 0.534215
Gradient discriminator: -20.552520
Gradient professor: 10.161216
Loss Generator D: 3.063468
Loss Generator P: 0.316398
Generator    : Epoch:     17, update:    4180, cost:   0.316398
Gradient discriminator: 8.116804
Gradient professor: 1.495828
Loss Generator D: 2.661578
Loss Generator P: 0.357012
Gradient discriminator: -3.116953
Gradient professor: -10.346973
Loss Generator D: 2.512599
Loss Generator P: 0.359291
Gradient discriminator: -11.279401
Gradient professor: 14.631956
Loss Generator D: 2.654968
Loss Generator P: 0.387750
Gradient discriminator: 17.854661
Gradient professor: -18.842140
Loss Generator D: 2.541169
Loss Generator P: 0.559459
Gradient discriminator: 23.089418
Gradient professor: 4.149725
Loss Generator D: 2.781863
Loss Generator P: 0.482980
Gradient discriminator: -9.515518
Gradient professor: 7.848062
Loss Generator D: 2.444640
Loss Generator P: 0.395734
Gradient discriminator: 2.393471
Gradient professor: 8.467368
Loss Generator D: 2.275067
Loss Generator P: 0.423743
Gradient discriminator: -4.546950
Gradient professor: 18.441446
Loss Generator D: 2.678255
Loss Generator P: 0.483941
Gradient discriminator: 5.899625
Gradient professor: 7.754644
Loss Generator D: 2.410087
Loss Generator P: 0.448611
Gradient discriminator: -9.388866
Gradient professor: -46.019642
Loss Generator D: 2.244354
Loss Generator P: 0.430805
Generator    : Epoch:     17, update:    4190, cost:   0.430805
Gradient discriminator: -13.869680
Gradient professor: -3.151067
Loss Generator D: 2.468287
Loss Generator P: 0.480374
Gradient discriminator: 10.014062
Gradient professor: -4.580025
Loss Generator D: 2.650060
Loss Generator P: 0.305234
Gradient discriminator: 12.362926
Gradient professor: -1.589138
Loss Generator D: 2.689226
Loss Generator P: 0.626238
Gradient discriminator: 10.406643
Gradient professor: 1.297587
Loss Generator D: 2.535957
Loss Generator P: 0.632986
Gradient discriminator: 5.952506
Gradient professor: 5.187965
Loss Generator D: 2.204162
Loss Generator P: 0.341545
Gradient discriminator: 2.465529
Gradient professor: 18.289378
Loss Generator D: 3.075757
Loss Generator P: 0.438209
Gradient discriminator: 19.594230
Gradient professor: 13.455809
Loss Generator D: 2.663862
Loss Generator P: 0.408212
Gradient discriminator: 10.444348
Gradient professor: -3.578791
Loss Generator D: 2.048092
Loss Generator P: 0.509336
Gradient discriminator: -14.968261
Gradient professor: -6.924888
Loss Generator D: 2.471545
Loss Generator P: 0.458241
Gradient discriminator: 1.693913
Gradient professor: 4.961780
Loss Generator D: 2.854405
Loss Generator P: 0.360123
Generator    : Epoch:     17, update:    4200, cost:   0.360123
Validation 42 - LOSS = 1.655 (PPL: 5.232)
Calling beam-search process
Beam-search ended, took 1.51865 minutes.
Validation 42 - BLEU = 16.62, 30.1/19.5/13.7/9.5 (BP=1.000, ratio=2.144, hyp_len=9047, ref_len=4220)
Early stopping patience: 974 validation left
--> Current BEST BLEU = 18.270 at validation 16
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 30.952493
Gradient professor: 4.242351
Loss Generator D: 2.870867
Loss Generator P: 0.402125
Gradient discriminator: -0.288094
Gradient professor: -0.902699
Loss Generator D: 2.408516
Loss Generator P: 0.400409
Gradient discriminator: 12.200622
Gradient professor: 10.758484
Loss Generator D: 2.653617
Loss Generator P: 0.356041
Gradient discriminator: -4.459947
Gradient professor: -1.211097
Loss Generator D: 2.695956
Loss Generator P: 0.328996
Gradient discriminator: -0.591338
Gradient professor: -8.528776
Loss Generator D: 2.563454
Loss Generator P: 0.262302
Gradient discriminator: 3.102745
Gradient professor: -9.796039
Loss Generator D: 2.600436
Loss Generator P: 0.311098
Gradient discriminator: 11.440918
Gradient professor: 4.661066
Loss Generator D: 2.984538
Loss Generator P: 0.415476
Gradient discriminator: 2.279476
Gradient professor: -0.379422
Loss Generator D: 2.796410
Loss Generator P: 0.454746
Gradient discriminator: -8.311359
Gradient professor: -5.751171
Loss Generator D: 2.075892
Loss Generator P: 0.297095
Gradient discriminator: 25.356202
Gradient professor: -27.488214
Loss Generator D: 2.687075
Loss Generator P: 0.472893
Generator    : Epoch:     17, update:    4210, cost:   0.472893
Gradient discriminator: 43.800751
Gradient professor: -7.164356
Loss Generator D: 2.807397
Loss Generator P: 0.474114
Gradient discriminator: -4.942380
Gradient professor: 1.726256
Loss Generator D: 2.404744
Loss Generator P: 0.475731
Gradient discriminator: 5.936172
Gradient professor: -4.849245
Loss Generator D: 2.805472
Loss Generator P: 0.408562
Gradient discriminator: 4.630325
Gradient professor: -7.057300
Loss Generator D: 2.310863
Loss Generator P: 0.377194
Gradient discriminator: 3.374552
Gradient professor: -1.986749
Loss Generator D: 3.097287
Loss Generator P: 0.426996
Gradient discriminator: 7.850029
Gradient professor: 7.112076
Loss Generator D: 2.806319
Loss Generator P: 0.499944
Gradient discriminator: -9.086247
Gradient professor: -10.560728
Loss Generator D: 2.671699
Loss Generator P: 0.406355
Gradient discriminator: 0.399326
Gradient professor: -7.834218
Loss Generator D: 2.953226
Loss Generator P: 0.389243
Gradient discriminator: 7.889876
Gradient professor: 10.353242
Loss Generator D: 3.057784
Loss Generator P: 0.340959
Gradient discriminator: 15.914301
Gradient professor: -14.033442
Loss Generator D: 2.665608
Loss Generator P: 0.279952
Generator    : Epoch:     17, update:    4220, cost:   0.279952
Gradient discriminator: 9.713761
Gradient professor: -10.338183
Loss Generator D: 2.804220
Loss Generator P: 0.364090
Gradient discriminator: 5.108359
Gradient professor: -9.927296
Loss Generator D: 2.681029
Loss Generator P: 0.385927
Gradient discriminator: -6.782905
Gradient professor: 7.630542
Loss Generator D: 2.714165
Loss Generator P: 0.421662
Gradient discriminator: 25.254380
Gradient professor: -1.779792
Loss Generator D: 3.086123
Loss Generator P: 0.309724
Gradient discriminator: 16.387695
Gradient professor: 8.770234
Loss Generator D: 2.748404
Loss Generator P: 0.316124
Gradient discriminator: 17.667595
Gradient professor: -11.448712
Loss Generator D: 2.660625
Loss Generator P: 0.383527
Gradient discriminator: 1.477662
Gradient professor: -11.436805
Loss Generator D: 2.805316
Loss Generator P: 0.333615
Gradient discriminator: 29.402803
Gradient professor: 3.280759
Loss Generator D: 3.329304
Loss Generator P: 0.339571
Gradient discriminator: 11.267145
Gradient professor: -6.590123
Loss Generator D: 3.033275
Loss Generator P: 0.371018
Gradient discriminator: -3.447054
Gradient professor: -7.860511
Loss Generator D: 2.812697
Loss Generator P: 0.359566
Generator    : Epoch:     17, update:    4230, cost:   0.359566
Gradient discriminator: -1.800128
Gradient professor: -6.135359
Loss Generator D: 3.226954
Loss Generator P: 0.442430
Gradient discriminator: -23.558147
Gradient professor: -4.425925
Loss Generator D: 2.793404
Loss Generator P: 0.488002
Gradient discriminator: 10.910387
Gradient professor: 5.922321
Loss Generator D: 2.857912
Loss Generator P: 0.532212
Gradient discriminator: -0.809258
Gradient professor: 10.079490
Loss Generator D: 2.836715
Loss Generator P: 0.267257
Gradient discriminator: -12.678434
Gradient professor: -4.309034
Loss Generator D: 2.356827
Loss Generator P: 0.353658
Gradient discriminator: 0.395574
Gradient professor: -1.496134
Loss Generator D: 2.739456
Loss Generator P: 0.316641
Gradient discriminator: -4.944191
Gradient professor: 8.032891
Loss Generator D: 2.948000
Loss Generator P: 0.275138
Gradient discriminator: -4.737043
Gradient professor: 8.761472
Loss Generator D: 2.500594
Loss Generator P: 0.430722
Gradient discriminator: -1.465425
Gradient professor: -11.261093
Loss Generator D: 2.798487
Loss Generator P: 0.317841
Gradient discriminator: 12.018187
Gradient professor: 7.503974
Loss Generator D: 2.602314
Loss Generator P: 0.340171
Generator    : Epoch:     17, update:    4240, cost:   0.340171
Gradient discriminator: 25.522746
Gradient professor: 10.259409
Loss Generator D: 2.716609
Loss Generator P: 0.331706
Gradient discriminator: -64.368247
Gradient professor: 12.473448
Loss Generator D: 2.733276
Loss Generator P: 0.333892
Gradient discriminator: -10.903707
Gradient professor: 39.121084
Loss Generator D: 2.621030
Loss Generator P: 0.304855
Gradient discriminator: 16.583362
Gradient professor: 4.184266
Loss Generator D: 2.616349
Loss Generator P: 0.347931
Gradient discriminator: -0.816795
Gradient professor: 20.981165
Loss Generator D: 3.608976
Loss Generator P: 0.405168
Gradient discriminator: -10.103083
Gradient professor: -4.410561
Loss Generator D: 2.853325
Loss Generator P: 0.285017
Gradient discriminator: -7.153226
Gradient professor: 3.973480
Loss Generator D: 2.959003
Loss Generator P: 0.331376
Gradient discriminator: 60.306516
Gradient professor: 11.113293
Loss Generator D: 3.140213
Loss Generator P: 0.281492
Gradient discriminator: 14.100708
Gradient professor: -13.731212
Loss Generator D: 2.689681
Loss Generator P: 0.340166
Gradient discriminator: 13.664213
Gradient professor: 0.062379
Loss Generator D: 2.797087
Loss Generator P: 0.193173
Generator    : Epoch:     17, update:    4250, cost:   0.193173
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 17 finished with mean loss 1.82059 (PPL: 6.17549)
--> Epoch took 219.906 minutes, 52.777 sec/update
Epoch summary of Discriminator:
--> Epoch 17 finished with mean loss nan (PPL:  nan)
--> Epoch took 219.906 minutes, 52.777 sec/update
---------------------------------------------------------
Starting Epoch 18
-----------------
Gradient discriminator: -0.290699
Gradient professor: -12.321190
Loss Generator D: 2.163509
Loss Generator P: 0.475042
Gradient discriminator: -16.630205
Gradient professor: 1.586110
Loss Generator D: 2.410183
Loss Generator P: 0.325740
Gradient discriminator: 19.882274
Gradient professor: 8.454659
Loss Generator D: 2.699083
Loss Generator P: 0.425361
Gradient discriminator: -6.219722
Gradient professor: -15.213943
Loss Generator D: 2.482266
Loss Generator P: 0.464852
Gradient discriminator: 11.144580
Gradient professor: -5.856052
Loss Generator D: 3.080739
Loss Generator P: 0.396015
Gradient discriminator: -7.888833
Gradient professor: 0.532928
Loss Generator D: 2.588325
Loss Generator P: 0.392693
Gradient discriminator: -5.913392
Gradient professor: -0.840108
Loss Generator D: 2.826083
Loss Generator P: 0.379167
Gradient discriminator: -3.325750
Gradient professor: 9.668579
Loss Generator D: 2.142731
Loss Generator P: 0.323733
Gradient discriminator: 16.123353
Gradient professor: -9.966562
Loss Generator D: 2.795807
Loss Generator P: 0.433348
Gradient discriminator: 13.928610
Gradient professor: 6.520280
Loss Generator D: 2.656720
Loss Generator P: 0.507192
Generator    : Epoch:     18, update:    4260, cost:   0.507192
Gradient discriminator: -1.058662
Gradient professor: 30.795018
Loss Generator D: 3.200380
Loss Generator P: 0.567427
Gradient discriminator: 14.850140
Gradient professor: -9.060495
Loss Generator D: 3.018967
Loss Generator P: 0.370998
Gradient discriminator: -11.590087
Gradient professor: 1.781359
Loss Generator D: 2.626849
Loss Generator P: 0.478106
Gradient discriminator: -6.985925
Gradient professor: -29.566424
Loss Generator D: 3.115100
Loss Generator P: 0.459610
Gradient discriminator: -3.206162
Gradient professor: 14.213280
Loss Generator D: 3.137983
Loss Generator P: 0.296140
Gradient discriminator: -10.260123
Gradient professor: -4.171525
Loss Generator D: 2.857999
Loss Generator P: 0.249400
Gradient discriminator: 7.475032
Gradient professor: -17.476152
Loss Generator D: 3.323724
Loss Generator P: 0.381885
Gradient discriminator: -1.243096
Gradient professor: 18.995956
Loss Generator D: 3.309204
Loss Generator P: 0.359923
Gradient discriminator: -3.685903
Gradient professor: -7.439022
Loss Generator D: 2.999629
Loss Generator P: 0.400497
Gradient discriminator: -0.358591
Gradient professor: 17.124353
Loss Generator D: 2.578458
Loss Generator P: 0.463597
Generator    : Epoch:     18, update:    4270, cost:   0.463597
Gradient discriminator: 1.033980
Gradient professor: -9.665035
Loss Generator D: 3.026786
Loss Generator P: 0.394664
Gradient discriminator: 5.062592
Gradient professor: 2.131542
Loss Generator D: 3.296033
Loss Generator P: 0.341074
Gradient discriminator: -18.903250
Gradient professor: 9.967073
Loss Generator D: 2.697636
Loss Generator P: 0.287418
Gradient discriminator: 23.157569
Gradient professor: 2.022937
Loss Generator D: 2.974330
Loss Generator P: 0.529874
Gradient discriminator: -7.504880
Gradient professor: 2.922421
Loss Generator D: 3.169535
Loss Generator P: 0.524947
Gradient discriminator: -7.568861
Gradient professor: 7.152564
Loss Generator D: 3.139267
Loss Generator P: 0.350894
Gradient discriminator: -15.610204
Gradient professor: -7.014629
Loss Generator D: 2.418386
Loss Generator P: 0.270920
Gradient discriminator: -11.274447
Gradient professor: 22.374168
Loss Generator D: 2.415535
Loss Generator P: 0.374493
Gradient discriminator: -3.984184
Gradient professor: 2.274575
Loss Generator D: 2.827292
Loss Generator P: 0.318789
Gradient discriminator: -23.064279
Gradient professor: 3.615045
Loss Generator D: 2.972202
Loss Generator P: 0.343497
Generator    : Epoch:     18, update:    4280, cost:   0.343497
Gradient discriminator: -19.792774
Gradient professor: 0.061390
Loss Generator D: 3.026215
Loss Generator P: 0.312739
Gradient discriminator: -1.551586
Gradient professor: 4.873769
Loss Generator D: 2.907917
Loss Generator P: 0.317691
Gradient discriminator: -6.814749
Gradient professor: 5.612215
Loss Generator D: 3.322958
Loss Generator P: 0.492090
Gradient discriminator: 1.296576
Gradient professor: 12.979469
Loss Generator D: 2.783931
Loss Generator P: 0.569207
Gradient discriminator: 1.491354
Gradient professor: -16.029016
Loss Generator D: 3.129581
Loss Generator P: 0.370648
Gradient discriminator: -3.060231
Gradient professor: -5.881816
Loss Generator D: 2.723340
Loss Generator P: 0.307926
Gradient discriminator: -9.721581
Gradient professor: 6.306851
Loss Generator D: 2.758301
Loss Generator P: 0.310733
Gradient discriminator: 2.352157
Gradient professor: -3.762085
Loss Generator D: 3.034300
Loss Generator P: 0.377688
Gradient discriminator: 11.245188
Gradient professor: 3.749455
Loss Generator D: 2.794952
Loss Generator P: 0.347224
Gradient discriminator: 12.607918
Gradient professor: -25.221756
Loss Generator D: 3.093521
Loss Generator P: 0.469082
Generator    : Epoch:     18, update:    4290, cost:   0.469082
Gradient discriminator: 5.079623
Gradient professor: -13.355915
Loss Generator D: 2.535838
Loss Generator P: 0.345361
Gradient discriminator: -5.974571
Gradient professor: 25.033224
Loss Generator D: 3.137481
Loss Generator P: 0.372211
Gradient discriminator: 2.227971
Gradient professor: 10.933914
Loss Generator D: 3.319119
Loss Generator P: 0.320577
Gradient discriminator: -2.332656
Gradient professor: 2.882472
Loss Generator D: 3.190254
Loss Generator P: 0.330521
Gradient discriminator: -10.531694
Gradient professor: 17.243465
Loss Generator D: 3.199153
Loss Generator P: 0.462431
Gradient discriminator: 2.184308
Gradient professor: -7.187439
Loss Generator D: 3.379931
Loss Generator P: 0.488237
Gradient discriminator: -3.545659
Gradient professor: 2.972733
Loss Generator D: 2.748860
Loss Generator P: 0.273843
Gradient discriminator: 9.454042
Gradient professor: -20.022971
Loss Generator D: 3.074619
Loss Generator P: 0.433321
Gradient discriminator: 1.045772
Gradient professor: 4.772497
Loss Generator D: 3.275965
Loss Generator P: 0.629429
Gradient discriminator: -2.796594
Gradient professor: -5.374402
Loss Generator D: 3.100435
Loss Generator P: 0.397769
Generator    : Epoch:     18, update:    4300, cost:   0.397769
Validation 43 - LOSS = 1.746 (PPL: 5.734)
Calling beam-search process
Beam-search ended, took 1.49277 minutes.
Validation 43 - BLEU = 18.70, 32.8/21.6/15.6/11.1 (BP=1.000, ratio=1.965, hyp_len=8291, ref_len=4220)
Saving model with best validation BLEU
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 3.130246
Gradient professor: 13.037729
Loss Generator D: 3.259036
Loss Generator P: 0.446926
Gradient discriminator: -13.669372
Gradient professor: 24.861005
Loss Generator D: 3.342948
Loss Generator P: 0.387790
Gradient discriminator: -9.989950
Gradient professor: -8.191234
Loss Generator D: 2.540300
Loss Generator P: 0.406323
Gradient discriminator: 13.477495
Gradient professor: 9.672452
Loss Generator D: 2.906518
Loss Generator P: 0.430683
Gradient discriminator: 0.953506
Gradient professor: -3.450316
Loss Generator D: 2.761479
Loss Generator P: 0.421103
Gradient discriminator: 9.226213
Gradient professor: 10.251631
Loss Generator D: 2.906377
Loss Generator P: 0.271772
Gradient discriminator: -23.427857
Gradient professor: -1.333154
Loss Generator D: 2.344950
Loss Generator P: 0.313754
Gradient discriminator: 20.841445
Gradient professor: 12.924511
Loss Generator D: 2.846183
Loss Generator P: 0.312427
Gradient discriminator: 35.269100
Gradient professor: 8.779886
Loss Generator D: 2.595255
Loss Generator P: 0.303234
Gradient discriminator: -49.907683
Gradient professor: -16.890637
Loss Generator D: 2.438776
Loss Generator P: 0.333847
Generator    : Epoch:     18, update:    4310, cost:   0.333847
Gradient discriminator: 18.500555
Gradient professor: 11.330027
Loss Generator D: 2.413683
Loss Generator P: 0.378770
Gradient discriminator: 1.819386
Gradient professor: 6.644944
Loss Generator D: 2.473309
Loss Generator P: 0.500678
Gradient discriminator: 3.938972
Gradient professor: 2.719993
Loss Generator D: 2.110261
Loss Generator P: 0.464251
Gradient discriminator: -0.298006
Gradient professor: 2.806603
Loss Generator D: 2.397671
Loss Generator P: 0.392555
Gradient discriminator: 4.675480
Gradient professor: 2.155964
Loss Generator D: 2.344192
Loss Generator P: 0.478396
Gradient discriminator: 5.329443
Gradient professor: -1.052816
Loss Generator D: 2.004122
Loss Generator P: 0.409406
Gradient discriminator: -7.248001
Gradient professor: 12.315369
Loss Generator D: 2.489254
Loss Generator P: 0.391019
Gradient discriminator: 2.522517
Gradient professor: 6.165863
Loss Generator D: 2.823572
Loss Generator P: 0.317529
Gradient discriminator: 10.744967
Gradient professor: -4.403221
Loss Generator D: 2.027931
Loss Generator P: 0.460089
Gradient discriminator: -28.013522
Gradient professor: -12.918138
Loss Generator D: 1.987013
Loss Generator P: 0.323988
Generator    : Epoch:     18, update:    4320, cost:   0.323988
Gradient discriminator: 5.412903
Gradient professor: 11.212225
Loss Generator D: 2.362746
Loss Generator P: 0.288449
Gradient discriminator: 7.466756
Gradient professor: 4.127862
Loss Generator D: 2.597910
Loss Generator P: 0.281223
Gradient discriminator: 11.686722
Gradient professor: 16.738750
Loss Generator D: 2.725356
Loss Generator P: 0.311255
Gradient discriminator: -2.400336
Gradient professor: 10.507633
Loss Generator D: 2.516414
Loss Generator P: 0.389907
Gradient discriminator: -3.558655
Gradient professor: -2.459254
Loss Generator D: 2.623121
Loss Generator P: 0.370295
Gradient discriminator: 8.567740
Gradient professor: 0.330955
Loss Generator D: 2.218745
Loss Generator P: 0.307934
Gradient discriminator: -2.638316
Gradient professor: -4.854730
Loss Generator D: 3.330026
Loss Generator P: 0.334507
Gradient discriminator: 25.870004
Gradient professor: 12.171096
Loss Generator D: 2.453638
Loss Generator P: 0.495610
Gradient discriminator: 14.582474
Gradient professor: 6.470391
Loss Generator D: 2.009951
Loss Generator P: 0.215187
Gradient discriminator: -1.766962
Gradient professor: -20.422299
Loss Generator D: 2.574970
Loss Generator P: 0.227980
Generator    : Epoch:     18, update:    4330, cost:   0.227980
Gradient discriminator: 3.199979
Gradient professor: 5.006300
Loss Generator D: 3.104473
Loss Generator P: 0.298892
Gradient discriminator: 10.601232
Gradient professor: 3.980624
Loss Generator D: 3.236264
Loss Generator P: 0.297055
Gradient discriminator: 12.334173
Gradient professor: -0.844529
Loss Generator D: 2.609303
Loss Generator P: 0.317497
Gradient discriminator: -6.953769
Gradient professor: -3.655897
Loss Generator D: 2.639505
Loss Generator P: 0.201656
Gradient discriminator: 1.011415
Gradient professor: 7.858211
Loss Generator D: 3.137211
Loss Generator P: 0.246859
Gradient discriminator: -8.787246
Gradient professor: 1.037925
Loss Generator D: 2.825010
Loss Generator P: 0.233286
Gradient discriminator: 11.625794
Gradient professor: 3.135140
Loss Generator D: 3.302994
Loss Generator P: 0.283931
Gradient discriminator: 6.159350
Gradient professor: -0.800467
Loss Generator D: 2.908399
Loss Generator P: 0.364080
Gradient discriminator: 13.600325
Gradient professor: -24.913947
Loss Generator D: 3.126707
Loss Generator P: 0.330003
Gradient discriminator: -1.916279
Gradient professor: 0.538539
Loss Generator D: 2.998866
Loss Generator P: 0.467832
Generator    : Epoch:     18, update:    4340, cost:   0.467832
Gradient discriminator: 1.788735
Gradient professor: 18.102635
Loss Generator D: 2.720914
Loss Generator P: 0.295369
Gradient discriminator: -9.468653
Gradient professor: 1.375729
Loss Generator D: 2.896209
Loss Generator P: 0.476301
Gradient discriminator: -1.482830
Gradient professor: 5.100953
Loss Generator D: 2.755654
Loss Generator P: 0.270276
Gradient discriminator: 3.221131
Gradient professor: -1.487592
Loss Generator D: 2.720518
Loss Generator P: 0.235771
Gradient discriminator: -3.331316
Gradient professor: 3.911428
Loss Generator D: 3.087595
Loss Generator P: 0.247920
Gradient discriminator: 7.796888
Gradient professor: -6.730953
Loss Generator D: 2.902703
Loss Generator P: 0.333335
Gradient discriminator: 0.757827
Gradient professor: -7.997225
Loss Generator D: 3.500001
Loss Generator P: 0.331028
Gradient discriminator: 0.460632
Gradient professor: -8.765225
Loss Generator D: 3.137541
Loss Generator P: 0.261024
Gradient discriminator: -1.748910
Gradient professor: 1.528601
Loss Generator D: 3.528340
Loss Generator P: 0.255159
Gradient discriminator: -9.146672
Gradient professor: -6.061453
Loss Generator D: 3.294617
Loss Generator P: 0.293683
Generator    : Epoch:     18, update:    4350, cost:   0.293683
Gradient discriminator: 9.010941
Gradient professor: 7.841403
Loss Generator D: 3.371639
Loss Generator P: 0.379850
Gradient discriminator: 1.075515
Gradient professor: -9.039962
Loss Generator D: 2.600813
Loss Generator P: 0.374792
Gradient discriminator: -3.301461
Gradient professor: -17.937800
Loss Generator D: 3.269309
Loss Generator P: 0.269358
Gradient discriminator: -8.923276
Gradient professor: 3.266477
Loss Generator D: 2.571334
Loss Generator P: 0.299083
Gradient discriminator: -1.928727
Gradient professor: 10.245250
Loss Generator D: 2.993521
Loss Generator P: 0.232435
Gradient discriminator: -6.864860
Gradient professor: -4.971407
Loss Generator D: 3.354624
Loss Generator P: 0.358983
Gradient discriminator: -42.456507
Gradient professor: -16.046256
Loss Generator D: 2.795968
Loss Generator P: 0.211041
Gradient discriminator: 6.347443
Gradient professor: -1.307086
Loss Generator D: 3.026379
Loss Generator P: 0.300437
Gradient discriminator: -2.201523
Gradient professor: 17.077677
Loss Generator D: 3.528789
Loss Generator P: 0.360828
Gradient discriminator: -3.683977
Gradient professor: -1.162496
Loss Generator D: 2.866685
Loss Generator P: 0.346326
Generator    : Epoch:     18, update:    4360, cost:   0.346326
Gradient discriminator: -3.469629
Gradient professor: -2.664557
Loss Generator D: 3.130883
Loss Generator P: 0.353021
Gradient discriminator: -1.246501
Gradient professor: 32.617002
Loss Generator D: 2.745795
Loss Generator P: 0.293959
Gradient discriminator: 3.289492
Gradient professor: -7.262672
Loss Generator D: 3.463745
Loss Generator P: 0.233704
Gradient discriminator: -9.613337
Gradient professor: 2.362494
Loss Generator D: 2.875978
Loss Generator P: 0.245640
Gradient discriminator: -1.657894
Gradient professor: 11.939172
Loss Generator D: 3.379840
Loss Generator P: 0.312869
Gradient discriminator: 7.257132
Gradient professor: -4.493204
Loss Generator D: 3.045082
Loss Generator P: 0.438557
Gradient discriminator: -5.541236
Gradient professor: 1.644433
Loss Generator D: 2.977301
Loss Generator P: 0.217754
Gradient discriminator: 2.222968
Gradient professor: 22.896907
Loss Generator D: 3.154664
Loss Generator P: 0.383786
Gradient discriminator: 13.660162
Gradient professor: -5.083378
Loss Generator D: 2.931547
Loss Generator P: 0.286705
Gradient discriminator: 4.685348
Gradient professor: -6.028111
Loss Generator D: 2.239104
Loss Generator P: 0.310544
Generator    : Epoch:     18, update:    4370, cost:   0.310544
Gradient discriminator: -23.127912
Gradient professor: -3.058992
Loss Generator D: 2.478269
Loss Generator P: 0.337352
Gradient discriminator: -11.458602
Gradient professor: -5.478334
Loss Generator D: 2.284932
Loss Generator P: 0.318620
Gradient discriminator: 34.376510
Gradient professor: 26.353603
Loss Generator D: 2.996598
Loss Generator P: 0.341010
Gradient discriminator: 22.261695
Gradient professor: 8.075966
Loss Generator D: 2.371912
Loss Generator P: 0.422784
Gradient discriminator: -7.181500
Gradient professor: -2.369267
Loss Generator D: 2.323215
Loss Generator P: 0.385727
Gradient discriminator: -4.553778
Gradient professor: 26.835004
Loss Generator D: 2.164629
Loss Generator P: 0.400661
Gradient discriminator: 4.639874
Gradient professor: -4.933662
Loss Generator D: 2.126058
Loss Generator P: 0.356145
Gradient discriminator: -7.552986
Gradient professor: 10.200559
Loss Generator D: 2.522000
Loss Generator P: 0.417469
Gradient discriminator: -0.121777
Gradient professor: 2.766463
Loss Generator D: 2.606021
Loss Generator P: 0.442944
Gradient discriminator: 1.468465
Gradient professor: -10.165090
Loss Generator D: 2.736225
Loss Generator P: 0.351207
Generator    : Epoch:     18, update:    4380, cost:   0.351207
Gradient discriminator: -0.812545
Gradient professor: 1.497542
Loss Generator D: 2.976744
Loss Generator P: 0.342677
Gradient discriminator: 0.291891
Gradient professor: -19.204309
Loss Generator D: 2.717597
Loss Generator P: 0.338874
Gradient discriminator: 11.913691
Gradient professor: 19.449199
Loss Generator D: 2.111653
Loss Generator P: 0.338515
Gradient discriminator: -0.477824
Gradient professor: -11.377869
Loss Generator D: 2.655700
Loss Generator P: 0.510071
Gradient discriminator: -4.502457
Gradient professor: -8.488917
Loss Generator D: 2.105216
Loss Generator P: 0.379864
Gradient discriminator: 1.400015
Gradient professor: -4.825299
Loss Generator D: 2.633512
Loss Generator P: 0.248466
Gradient discriminator: 4.948292
Gradient professor: 11.610466
Loss Generator D: 2.703220
Loss Generator P: 0.302858
Gradient discriminator: -1.194922
Gradient professor: -0.413172
Loss Generator D: 2.909275
Loss Generator P: 0.201955
Gradient discriminator: -9.349196
Gradient professor: 10.284996
Loss Generator D: 2.845774
Loss Generator P: 0.392058
Gradient discriminator: 0.530225
Gradient professor: 4.225674
Loss Generator D: 2.641731
Loss Generator P: 0.348212
Generator    : Epoch:     18, update:    4390, cost:   0.348212
Gradient discriminator: 8.025230
Gradient professor: -5.542305
Loss Generator D: 2.756788
Loss Generator P: 0.289136
Gradient discriminator: 3.087939
Gradient professor: 14.090542
Loss Generator D: 2.814141
Loss Generator P: 0.343458
Gradient discriminator: -1.512521
Gradient professor: 28.834102
Loss Generator D: 2.920848
Loss Generator P: 0.535385
Gradient discriminator: 1.004697
Gradient professor: -0.364067
Loss Generator D: 3.327023
Loss Generator P: 0.370059
Gradient discriminator: 1.570226
Gradient professor: -31.120057
Loss Generator D: 2.754469
Loss Generator P: 0.464340
Gradient discriminator: -2.536287
Gradient professor: -5.846191
Loss Generator D: 2.677965
Loss Generator P: 0.422424
Gradient discriminator: -0.619393
Gradient professor: 3.937022
Loss Generator D: 2.615180
Loss Generator P: 0.244622
Gradient discriminator: -0.937219
Gradient professor: 7.093744
Loss Generator D: 2.763855
Loss Generator P: 0.327527
Gradient discriminator: -0.159184
Gradient professor: -5.912992
Loss Generator D: 2.855423
Loss Generator P: 0.302557
Gradient discriminator: 4.566352
Gradient professor: 8.167806
Loss Generator D: 2.859933
Loss Generator P: 0.272639
Generator    : Epoch:     18, update:    4400, cost:   0.272639
Validation 44 - LOSS = 1.721 (PPL: 5.593)
Calling beam-search process
Beam-search ended, took 1.87779 minutes.
Validation 44 - BLEU = 10.38, 19.5/12.3/8.4/5.7 (BP=1.000, ratio=3.081, hyp_len=13003, ref_len=4220)
Early stopping patience: 999 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -11.403042
Gradient professor: 4.765233
Loss Generator D: 2.862269
Loss Generator P: 0.408540
Gradient discriminator: 5.431163
Gradient professor: 0.754410
Loss Generator D: 2.646330
Loss Generator P: 0.452232
Gradient discriminator: 23.247035
Gradient professor: -3.459521
Loss Generator D: 2.656359
Loss Generator P: 0.349310
Gradient discriminator: 0.288899
Gradient professor: -1.548896
Loss Generator D: 2.521180
Loss Generator P: 0.277586
Gradient discriminator: -12.123818
Gradient professor: 4.610671
Loss Generator D: 2.849690
Loss Generator P: 0.424153
Gradient discriminator: -10.975810
Gradient professor: -18.491074
Loss Generator D: 2.342803
Loss Generator P: 0.332675
Gradient discriminator: 3.552531
Gradient professor: -2.010890
Loss Generator D: 2.796847
Loss Generator P: 0.322210
Gradient discriminator: 6.382954
Gradient professor: -3.990466
Loss Generator D: 2.496281
Loss Generator P: 0.286366
Gradient discriminator: 5.647944
Gradient professor: 2.987379
Loss Generator D: 2.766499
Loss Generator P: 0.256583
Gradient discriminator: 0.517714
Gradient professor: -13.706853
Loss Generator D: 2.401244
Loss Generator P: 0.370359
Generator    : Epoch:     18, update:    4410, cost:   0.370359
Gradient discriminator: -6.039294
Gradient professor: 5.629086
Loss Generator D: 2.547945
Loss Generator P: 0.361516
Gradient discriminator: 7.254785
Gradient professor: 16.518902
Loss Generator D: 2.497371
Loss Generator P: 0.443295
Gradient discriminator: -0.799917
Gradient professor: -6.627237
Loss Generator D: 2.521014
Loss Generator P: 0.447620
Gradient discriminator: -2.586825
Gradient professor: 5.156683
Loss Generator D: 2.432653
Loss Generator P: 0.380470
Gradient discriminator: 0.549917
Gradient professor: 2.420757
Loss Generator D: 2.261336
Loss Generator P: 0.530836
Gradient discriminator: 0.733344
Gradient professor: 14.524136
Loss Generator D: 2.133770
Loss Generator P: 0.402745
Gradient discriminator: -3.889135
Gradient professor: 5.270058
Loss Generator D: 1.790734
Loss Generator P: 0.468882
Gradient discriminator: -2.738989
Gradient professor: -11.820229
Loss Generator D: 2.698161
Loss Generator P: 0.269828
Gradient discriminator: 2.596928
Gradient professor: -5.203771
Loss Generator D: 2.243889
Loss Generator P: 0.377943
Gradient discriminator: -15.835570
Gradient professor: 12.858286
Loss Generator D: 2.571207
Loss Generator P: 0.370213
Generator    : Epoch:     18, update:    4420, cost:   0.370213
Gradient discriminator: 0.833457
Gradient professor: -4.657325
Loss Generator D: 2.787502
Loss Generator P: 0.295523
Gradient discriminator: -10.837643
Gradient professor: 6.754423
Loss Generator D: 1.970063
Loss Generator P: 0.291980
Gradient discriminator: 1.334809
Gradient professor: 0.123357
Loss Generator D: 2.753461
Loss Generator P: 0.312149
Gradient discriminator: 7.475864
Gradient professor: -13.251406
Loss Generator D: 2.588550
Loss Generator P: 0.238964
Gradient discriminator: -2.729689
Gradient professor: -6.961452
Loss Generator D: 2.639917
Loss Generator P: 0.266896
Gradient discriminator: -2.347608
Gradient professor: -14.804328
Loss Generator D: 2.923253
Loss Generator P: 0.415411
Gradient discriminator: -5.931917
Gradient professor: 10.196770
Loss Generator D: 2.295206
Loss Generator P: 0.453640
Gradient discriminator: 13.116066
Gradient professor: 9.606874
Loss Generator D: 2.203319
Loss Generator P: 0.619102
Gradient discriminator: 11.757295
Gradient professor: -20.138737
Loss Generator D: 2.411322
Loss Generator P: 0.496255
Gradient discriminator: 5.629819
Gradient professor: 1.965799
Loss Generator D: 2.444599
Loss Generator P: 0.286331
Generator    : Epoch:     18, update:    4430, cost:   0.286331
Gradient discriminator: -17.982068
Gradient professor: 0.013156
Loss Generator D: 2.371886
Loss Generator P: 0.379563
Gradient discriminator: 6.304067
Gradient professor: -13.796234
Loss Generator D: 2.209598
Loss Generator P: 0.326371
Gradient discriminator: -8.328514
Gradient professor: -9.296601
Loss Generator D: 2.750910
Loss Generator P: 0.343003
Gradient discriminator: 10.778657
Gradient professor: 11.513931
Loss Generator D: 2.610372
Loss Generator P: 0.505994
Gradient discriminator: -6.900337
Gradient professor: 23.464229
Loss Generator D: 2.601891
Loss Generator P: 0.468854
Gradient discriminator: -44.130574
Gradient professor: -16.437714
Loss Generator D: 2.757499
Loss Generator P: 0.314490
Gradient discriminator: -0.183637
Gradient professor: 7.537326
Loss Generator D: 2.200721
Loss Generator P: 0.368651
Gradient discriminator: 12.527348
Gradient professor: 3.595785
Loss Generator D: 2.534665
Loss Generator P: 0.457203
Gradient discriminator: -9.657684
Gradient professor: 4.767926
Loss Generator D: 2.467953
Loss Generator P: 0.416202
Gradient discriminator: 5.730363
Gradient professor: -18.644541
Loss Generator D: 2.548829
Loss Generator P: 0.378495
Generator    : Epoch:     18, update:    4440, cost:   0.378495
Gradient discriminator: 8.105047
Gradient professor: -6.467054
Loss Generator D: 2.285600
Loss Generator P: 0.430622
Gradient discriminator: 7.000803
Gradient professor: 0.057090
Loss Generator D: 2.370951
Loss Generator P: 0.273167
Gradient discriminator: -7.078748
Gradient professor: -17.972916
Loss Generator D: 2.705848
Loss Generator P: 0.548446
Gradient discriminator: -3.906135
Gradient professor: 23.238465
Loss Generator D: 2.508986
Loss Generator P: 0.541011
Gradient discriminator: 8.650105
Gradient professor: 12.026798
Loss Generator D: 2.300697
Loss Generator P: 0.276814
Gradient discriminator: 11.641140
Gradient professor: -2.216517
Loss Generator D: 2.968321
Loss Generator P: 0.404307
Gradient discriminator: -16.514085
Gradient professor: 13.270511
Loss Generator D: 2.959662
Loss Generator P: 0.380450
Gradient discriminator: 25.143283
Gradient professor: -7.966458
Loss Generator D: 2.089039
Loss Generator P: 0.458933
Gradient discriminator: -3.778561
Gradient professor: 0.946248
Loss Generator D: 2.526778
Loss Generator P: 0.394245
Gradient discriminator: -1.311049
Gradient professor: -10.960567
Loss Generator D: 2.671858
Loss Generator P: 0.327546
Generator    : Epoch:     18, update:    4450, cost:   0.327546
Gradient discriminator: -1.278479
Gradient professor: 14.502614
Loss Generator D: 2.996384
Loss Generator P: 0.352308
Gradient discriminator: -8.760809
Gradient professor: -17.782343
Loss Generator D: 2.499735
Loss Generator P: 0.323129
Gradient discriminator: -1.488149
Gradient professor: 11.833107
Loss Generator D: 2.969234
Loss Generator P: 0.312877
Gradient discriminator: 4.437575
Gradient professor: 3.333284
Loss Generator D: 2.703448
Loss Generator P: 0.295150
Gradient discriminator: 47.795650
Gradient professor: -11.052194
Loss Generator D: 2.893668
Loss Generator P: 0.262461
Gradient discriminator: 10.840881
Gradient professor: -3.997178
Loss Generator D: 2.517973
Loss Generator P: 0.246009
Gradient discriminator: 10.863600
Gradient professor: -0.333304
Loss Generator D: 2.842869
Loss Generator P: 0.388128
Gradient discriminator: -15.862799
Gradient professor: -9.923532
Loss Generator D: 2.877535
Loss Generator P: 0.382484
Gradient discriminator: -3.196117
Gradient professor: -7.464945
Loss Generator D: 2.417593
Loss Generator P: 0.294217
Gradient discriminator: 20.437053
Gradient professor: -19.986101
Loss Generator D: 2.509751
Loss Generator P: 0.426653
Generator    : Epoch:     18, update:    4460, cost:   0.426653
Gradient discriminator: 28.071854
Gradient professor: -3.012396
Loss Generator D: 2.511378
Loss Generator P: 0.424101
Gradient discriminator: -36.780148
Gradient professor: 14.373796
Loss Generator D: 2.639253
Loss Generator P: 0.454967
Gradient discriminator: 15.773905
Gradient professor: -9.168446
Loss Generator D: 2.895515
Loss Generator P: 0.349605
Gradient discriminator: -9.935507
Gradient professor: -5.815618
Loss Generator D: 1.950955
Loss Generator P: 0.268551
Gradient discriminator: 15.466777
Gradient professor: -8.425062
Loss Generator D: 2.528302
Loss Generator P: 0.388897
Gradient discriminator: -7.401097
Gradient professor: -2.771528
Loss Generator D: 2.353283
Loss Generator P: 0.382666
Gradient discriminator: 2.038124
Gradient professor: -22.025808
Loss Generator D: 2.294879
Loss Generator P: 0.350324
Gradient discriminator: 1.381230
Gradient professor: 3.336865
Loss Generator D: 2.463857
Loss Generator P: 0.339242
Gradient discriminator: -2.146897
Gradient professor: 1.026125
Loss Generator D: 2.718630
Loss Generator P: 0.297560
Gradient discriminator: -2.553555
Gradient professor: -1.399370
Loss Generator D: 2.395032
Loss Generator P: 0.262612
Generator    : Epoch:     18, update:    4470, cost:   0.262612
Gradient discriminator: 8.198088
Gradient professor: -2.600805
Loss Generator D: 2.628616
Loss Generator P: 0.320101
Gradient discriminator: 24.745374
Gradient professor: -12.633615
Loss Generator D: 2.429459
Loss Generator P: 0.315725
Gradient discriminator: -3.480103
Gradient professor: 16.069932
Loss Generator D: 2.851694
Loss Generator P: 0.381760
Gradient discriminator: 7.552230
Gradient professor: -1.613182
Loss Generator D: 2.687026
Loss Generator P: 0.242494
Gradient discriminator: 9.137738
Gradient professor: -0.951099
Loss Generator D: 2.730981
Loss Generator P: 0.264587
Gradient discriminator: -12.525498
Gradient professor: 3.172329
Loss Generator D: 2.891421
Loss Generator P: 0.361599
Gradient discriminator: 8.767538
Gradient professor: -1.268656
Loss Generator D: 3.023867
Loss Generator P: 0.292559
Gradient discriminator: -2.189264
Gradient professor: -3.307181
Loss Generator D: 3.358550
Loss Generator P: 0.298474
Gradient discriminator: -8.658087
Gradient professor: 2.695074
Loss Generator D: 2.639761
Loss Generator P: 0.326910
Gradient discriminator: -7.600570
Gradient professor: -6.323326
Loss Generator D: 2.826787
Loss Generator P: 0.333446
Generator    : Epoch:     18, update:    4480, cost:   0.333446
Gradient discriminator: 0.048926
Gradient professor: -14.912440
Loss Generator D: 3.028059
Loss Generator P: 0.439632
Gradient discriminator: 16.496285
Gradient professor: -9.147274
Loss Generator D: 2.855643
Loss Generator P: 0.490448
Gradient discriminator: 19.246165
Gradient professor: 16.837958
Loss Generator D: 2.971440
Loss Generator P: 0.464472
Gradient discriminator: -5.838204
Gradient professor: 8.613327
Loss Generator D: 2.925514
Loss Generator P: 0.215800
Gradient discriminator: 16.446376
Gradient professor: 10.212024
Loss Generator D: 2.615678
Loss Generator P: 0.375021
Gradient discriminator: 1.896021
Gradient professor: -10.617175
Loss Generator D: 2.777326
Loss Generator P: 0.308958
Gradient discriminator: 2.277543
Gradient professor: 7.195982
Loss Generator D: 2.906951
Loss Generator P: 0.259642
Gradient discriminator: 8.914716
Gradient professor: -14.409460
Loss Generator D: 2.933424
Loss Generator P: 0.382467
Gradient discriminator: -5.624029
Gradient professor: 5.928397
Loss Generator D: 3.242000
Loss Generator P: 0.286611
Gradient discriminator: 1.744590
Gradient professor: 3.844187
Loss Generator D: 3.440448
Loss Generator P: 0.380004
Generator    : Epoch:     18, update:    4490, cost:   0.380004
Gradient discriminator: 17.290908
Gradient professor: -3.821854
Loss Generator D: 2.862950
Loss Generator P: 0.306623
Gradient discriminator: -0.334028
Gradient professor: -13.221220
Loss Generator D: 2.841578
Loss Generator P: 0.353079
Gradient discriminator: 5.984576
Gradient professor: -10.394135
Loss Generator D: 2.876356
Loss Generator P: 0.318343
Gradient discriminator: 9.138836
Gradient professor: 6.622665
Loss Generator D: 2.673914
Loss Generator P: 0.316599
Gradient discriminator: 2.022233
Gradient professor: 10.574655
Loss Generator D: 3.654064
Loss Generator P: 0.360863
Gradient discriminator: 4.146239
Gradient professor: -9.909623
Loss Generator D: 3.427297
Loss Generator P: 0.308494
Gradient discriminator: 15.203710
Gradient professor: -12.999747
Loss Generator D: 3.081651
Loss Generator P: 0.332151
Gradient discriminator: -3.831673
Gradient professor: -16.711541
Loss Generator D: 3.367282
Loss Generator P: 0.230162
Gradient discriminator: 3.426040
Gradient professor: 10.318711
Loss Generator D: 3.179164
Loss Generator P: 0.306477
Gradient discriminator: -3.930876
Gradient professor: -9.060911
Loss Generator D: 3.218631
Loss Generator P: 0.159104
Generator    : Epoch:     18, update:    4500, cost:   0.159104
Validation 45 - LOSS = 1.689 (PPL: 5.412)
Calling beam-search process
Beam-search ended, took 1.95266 minutes.
Validation 45 - BLEU = 11.61, 21.0/13.7/9.6/6.6 (BP=1.000, ratio=3.047, hyp_len=12858, ref_len=4220)
Early stopping patience: 998 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 18 finished with mean loss 1.55574 (PPL: 4.73859)
--> Epoch took 250.030 minutes, 60.007 sec/update
Epoch summary of Discriminator:
--> Epoch 18 finished with mean loss nan (PPL:  nan)
--> Epoch took 250.030 minutes, 60.007 sec/update
---------------------------------------------------------
Starting Epoch 19
-----------------
Gradient discriminator: 13.808214
Gradient professor: -0.003139
Loss Generator D: 2.768399
Loss Generator P: 0.460395
Gradient discriminator: 7.730210
Gradient professor: -16.230816
Loss Generator D: 2.858190
Loss Generator P: 0.327551
Gradient discriminator: 2.971821
Gradient professor: 27.772617
Loss Generator D: 2.763610
Loss Generator P: 0.372721
Gradient discriminator: 10.468293
Gradient professor: -13.237121
Loss Generator D: 2.524429
Loss Generator P: 0.449983
Gradient discriminator: -7.537741
Gradient professor: 4.243762
Loss Generator D: 2.859462
Loss Generator P: 0.303840
Gradient discriminator: -4.209596
Gradient professor: -25.608643
Loss Generator D: 2.680941
Loss Generator P: 0.364866
Gradient discriminator: 0.642530
Gradient professor: -10.897004
Loss Generator D: 2.826264
Loss Generator P: 0.350719
Gradient discriminator: 9.357065
Gradient professor: -0.366436
Loss Generator D: 2.120492
Loss Generator P: 0.301911
Gradient discriminator: 15.372142
Gradient professor: -6.199079
Loss Generator D: 2.556474
Loss Generator P: 0.427331
Gradient discriminator: 12.582931
Gradient professor: 9.478949
Loss Generator D: 2.289115
Loss Generator P: 0.463707
Generator    : Epoch:     19, update:    4510, cost:   0.463707
Gradient discriminator: 4.307098
Gradient professor: 16.078077
Loss Generator D: 2.823924
Loss Generator P: 0.505332
Gradient discriminator: -3.740221
Gradient professor: -7.430661
Loss Generator D: 2.817197
Loss Generator P: 0.367618
Gradient discriminator: 13.776167
Gradient professor: 12.586069
Loss Generator D: 2.536830
Loss Generator P: 0.442975
Gradient discriminator: 6.962006
Gradient professor: -4.349027
Loss Generator D: 2.885787
Loss Generator P: 0.433366
Gradient discriminator: 0.788331
Gradient professor: -4.427837
Loss Generator D: 2.759954
Loss Generator P: 0.250390
Gradient discriminator: 1.669356
Gradient professor: -5.408965
Loss Generator D: 2.604161
Loss Generator P: 0.212708
Gradient discriminator: 2.731973
Gradient professor: 13.087045
Loss Generator D: 3.038026
Loss Generator P: 0.337205
Gradient discriminator: -3.655445
Gradient professor: 2.062642
Loss Generator D: 2.454549
Loss Generator P: 0.334316
Gradient discriminator: 4.633086
Gradient professor: -23.003387
Loss Generator D: 2.159176
Loss Generator P: 0.417486
Gradient discriminator: -21.093667
Gradient professor: 10.324723
Loss Generator D: 2.178065
Loss Generator P: 0.421890
Generator    : Epoch:     19, update:    4520, cost:   0.421890
Gradient discriminator: -5.574537
Gradient professor: -2.717721
Loss Generator D: 2.298870
Loss Generator P: 0.321040
Gradient discriminator: 7.233377
Gradient professor: 6.950135
Loss Generator D: 2.929508
Loss Generator P: 0.318866
Gradient discriminator: -0.139630
Gradient professor: 9.876524
Loss Generator D: 2.468065
Loss Generator P: 0.261981
Gradient discriminator: 7.594534
Gradient professor: -36.783195
Loss Generator D: 2.439707
Loss Generator P: 0.541116
Gradient discriminator: -0.638928
Gradient professor: 7.413737
Loss Generator D: 2.638131
Loss Generator P: 0.469225
Gradient discriminator: -3.610290
Gradient professor: -3.326786
Loss Generator D: 2.551145
Loss Generator P: 0.332454
Gradient discriminator: -0.604678
Gradient professor: -0.399069
Loss Generator D: 2.269714
Loss Generator P: 0.214994
Gradient discriminator: 2.994949
Gradient professor: -4.952248
Loss Generator D: 2.775310
Loss Generator P: 0.356099
Gradient discriminator: 2.356159
Gradient professor: 19.628856
Loss Generator D: 2.646065
Loss Generator P: 0.288878
Gradient discriminator: 5.801850
Gradient professor: 8.664294
Loss Generator D: 2.776992
Loss Generator P: 0.320705
Generator    : Epoch:     19, update:    4530, cost:   0.320705
Gradient discriminator: -5.809729
Gradient professor: 3.031126
Loss Generator D: 2.727676
Loss Generator P: 0.278024
Gradient discriminator: -1.859236
Gradient professor: 5.701506
Loss Generator D: 2.845094
Loss Generator P: 0.258772
Gradient discriminator: -7.182024
Gradient professor: 7.854285
Loss Generator D: 3.251599
Loss Generator P: 0.466603
Gradient discriminator: -3.295145
Gradient professor: -4.814389
Loss Generator D: 2.714565
Loss Generator P: 0.524118
Gradient discriminator: 0.082277
Gradient professor: -11.476269
Loss Generator D: 2.829139
Loss Generator P: 0.299774
Gradient discriminator: 3.176552
Gradient professor: 8.086038
Loss Generator D: 2.573822
Loss Generator P: 0.277562
Gradient discriminator: 15.298878
Gradient professor: -4.039744
Loss Generator D: 2.482341
Loss Generator P: 0.266445
Gradient discriminator: 7.313348
Gradient professor: 16.584571
Loss Generator D: 2.700361
Loss Generator P: 0.332858
Gradient discriminator: 13.624291
Gradient professor: -0.323844
Loss Generator D: 2.663181
Loss Generator P: 0.330128
Gradient discriminator: 4.703598
Gradient professor: 20.480099
Loss Generator D: 2.688744
Loss Generator P: 0.502695
Generator    : Epoch:     19, update:    4540, cost:   0.502695
Gradient discriminator: -7.715186
Gradient professor: 5.580811
Loss Generator D: 2.437795
Loss Generator P: 0.373731
Gradient discriminator: 3.254138
Gradient professor: 11.154322
Loss Generator D: 2.411201
Loss Generator P: 0.343608
Gradient discriminator: 10.233775
Gradient professor: -1.240788
Loss Generator D: 2.606216
Loss Generator P: 0.322093
Gradient discriminator: 4.043813
Gradient professor: 4.233441
Loss Generator D: 2.519157
Loss Generator P: 0.274040
Gradient discriminator: 1.516853
Gradient professor: -23.554057
Loss Generator D: 2.248741
Loss Generator P: 0.423398
Gradient discriminator: 14.330214
Gradient professor: 13.773271
Loss Generator D: 1.617864
Loss Generator P: 0.422688
Gradient discriminator: -0.302216
Gradient professor: 4.356210
Loss Generator D: 1.414837
Loss Generator P: 0.293972
Gradient discriminator: -6.910079
Gradient professor: 0.184343
Loss Generator D: 1.715174
Loss Generator P: 0.396901
Gradient discriminator: -18.104277
Gradient professor: 0.981845
Loss Generator D: 1.502907
Loss Generator P: 0.563796
Gradient discriminator: -12.401634
Gradient professor: 0.980763
Loss Generator D: 1.320851
Loss Generator P: 0.371785
Generator    : Epoch:     19, update:    4550, cost:   0.371785
Gradient discriminator: 2.946984
Gradient professor: 17.243460
Loss Generator D: 1.638839
Loss Generator P: 0.405012
Gradient discriminator: -5.635609
Gradient professor: 6.636468
Loss Generator D: 1.583447
Loss Generator P: 0.349700
Gradient discriminator: 3.312574
Gradient professor: -7.496318
Loss Generator D: 1.803212
Loss Generator P: 0.338908
Gradient discriminator: 17.018146
Gradient professor: 6.275250
Loss Generator D: 1.741403
Loss Generator P: 0.426069
Gradient discriminator: 1.936609
Gradient professor: -16.498061
Loss Generator D: 1.356410
Loss Generator P: 0.409013
Gradient discriminator: -2.803333
Gradient professor: -0.125557
Loss Generator D: 1.775092
Loss Generator P: 0.271243
Gradient discriminator: -4.774583
Gradient professor: 0.105921
Loss Generator D: 1.423651
Loss Generator P: 0.265143
Gradient discriminator: -5.835424
Gradient professor: 8.078475
Loss Generator D: 2.001457
Loss Generator P: 0.274132
Gradient discriminator: -2.053821
Gradient professor: -0.336110
Loss Generator D: 2.290064
Loss Generator P: 0.315779
Gradient discriminator: 2.438296
Gradient professor: -4.977866
Loss Generator D: 2.320570
Loss Generator P: 0.314532
Generator    : Epoch:     19, update:    4560, cost:   0.314532
Gradient discriminator: 10.379257
Gradient professor: 0.870580
Loss Generator D: 1.751579
Loss Generator P: 0.368384
Gradient discriminator: -0.447672
Gradient professor: 12.153815
Loss Generator D: 1.625715
Loss Generator P: 0.472363
Gradient discriminator: 7.620583
Gradient professor: 21.227988
Loss Generator D: 1.725719
Loss Generator P: 0.398605
Gradient discriminator: -6.241445
Gradient professor: -5.325654
Loss Generator D: 1.688245
Loss Generator P: 0.342409
Gradient discriminator: -5.104128
Gradient professor: -7.864153
Loss Generator D: 1.702882
Loss Generator P: 0.479787
Gradient discriminator: 10.146830
Gradient professor: -14.055814
Loss Generator D: 1.816640
Loss Generator P: 0.400232
Gradient discriminator: -6.146393
Gradient professor: 7.368909
Loss Generator D: 1.915755
Loss Generator P: 0.328082
Gradient discriminator: -1.923709
Gradient professor: 21.234683
Loss Generator D: 2.339032
Loss Generator P: 0.312337
Gradient discriminator: 5.298341
Gradient professor: 13.235158
Loss Generator D: 2.116537
Loss Generator P: 0.427931
Gradient discriminator: -0.286355
Gradient professor: -2.884056
Loss Generator D: 1.494075
Loss Generator P: 0.310010
Generator    : Epoch:     19, update:    4570, cost:   0.310010
Gradient discriminator: -1.177451
Gradient professor: 21.848375
Loss Generator D: 2.056221
Loss Generator P: 0.263157
Gradient discriminator: -4.414018
Gradient professor: -5.772795
Loss Generator D: 2.023280
Loss Generator P: 0.294058
Gradient discriminator: 4.686180
Gradient professor: 19.165117
Loss Generator D: 1.812613
Loss Generator P: 0.314348
Gradient discriminator: 5.522579
Gradient professor: -9.781890
Loss Generator D: 1.519831
Loss Generator P: 0.383357
Gradient discriminator: 7.419417
Gradient professor: -12.544132
Loss Generator D: 1.781071
Loss Generator P: 0.345974
Gradient discriminator: 4.641029
Gradient professor: 9.130602
Loss Generator D: 1.549562
Loss Generator P: 0.280092
Gradient discriminator: 2.132856
Gradient professor: 4.607363
Loss Generator D: 1.870660
Loss Generator P: 0.350595
Gradient discriminator: 1.513703
Gradient professor: -1.142551
Loss Generator D: 1.652813
Loss Generator P: 0.415789
Gradient discriminator: -8.518350
Gradient professor: -2.202874
Loss Generator D: 1.311786
Loss Generator P: 0.208490
Gradient discriminator: 1.199637
Gradient professor: -0.661407
Loss Generator D: 1.908232
Loss Generator P: 0.239986
Generator    : Epoch:     19, update:    4580, cost:   0.239986
Gradient discriminator: 23.961520
Gradient professor: -16.533283
Loss Generator D: 1.264597
Loss Generator P: 0.295894
Gradient discriminator: 3.390030
Gradient professor: -2.403294
Loss Generator D: 1.369531
Loss Generator P: 0.344047
Gradient discriminator: 4.254821
Gradient professor: -1.074721
Loss Generator D: 1.593266
Loss Generator P: 0.294402
Gradient discriminator: -0.320117
Gradient professor: -6.627588
Loss Generator D: 1.485715
Loss Generator P: 0.229897
Gradient discriminator: 4.232471
Gradient professor: -2.878363
Loss Generator D: 2.137100
Loss Generator P: 0.254666
Gradient discriminator: -10.886329
Gradient professor: -0.550285
Loss Generator D: 2.124429
Loss Generator P: 0.260363
Gradient discriminator: 0.947080
Gradient professor: 2.219529
Loss Generator D: 2.015214
Loss Generator P: 0.256162
Gradient discriminator: -8.349930
Gradient professor: -9.459756
Loss Generator D: 2.429398
Loss Generator P: 0.379678
Gradient discriminator: 14.537719
Gradient professor: -9.282444
Loss Generator D: 2.627280
Loss Generator P: 0.314348
Gradient discriminator: -3.188510
Gradient professor: -2.631501
Loss Generator D: 2.396141
Loss Generator P: 0.400896
Generator    : Epoch:     19, update:    4590, cost:   0.400896
Gradient discriminator: -1.689060
Gradient professor: 12.012987
Loss Generator D: 2.471593
Loss Generator P: 0.283603
Gradient discriminator: 14.913154
Gradient professor: 23.021964
Loss Generator D: 2.559036
Loss Generator P: 0.417318
Gradient discriminator: 7.036978
Gradient professor: 0.573920
Loss Generator D: 2.555514
Loss Generator P: 0.263638
Gradient discriminator: -1.444855
Gradient professor: -1.873036
Loss Generator D: 2.546986
Loss Generator P: 0.234450
Gradient discriminator: -15.762497
Gradient professor: 12.227483
Loss Generator D: 2.910275
Loss Generator P: 0.305050
Gradient discriminator: 3.420495
Gradient professor: -2.499350
Loss Generator D: 2.449460
Loss Generator P: 0.317585
Gradient discriminator: 8.822016
Gradient professor: -9.835263
Loss Generator D: 3.107335
Loss Generator P: 0.322320
Gradient discriminator: -8.853719
Gradient professor: -9.857876
Loss Generator D: 2.559697
Loss Generator P: 0.249181
Gradient discriminator: 0.386761
Gradient professor: -4.565797
Loss Generator D: 2.735653
Loss Generator P: 0.253590
Gradient discriminator: -2.440930
Gradient professor: 10.918110
Loss Generator D: 2.386744
Loss Generator P: 0.300307
Generator    : Epoch:     19, update:    4600, cost:   0.300307
Validation 46 - LOSS = 1.714 (PPL: 5.550)
Calling beam-search process
Beam-search ended, took 2.53954 minutes.
Validation 46 - BLEU = 6.10, 11.1/7.3/5.0/3.4 (BP=1.000, ratio=4.897, hyp_len=20666, ref_len=4220)
Early stopping patience: 997 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -1.389186
Gradient professor: -4.577843
Loss Generator D: 1.713794
Loss Generator P: 0.406628
Gradient discriminator: 3.619940
Gradient professor: 3.127239
Loss Generator D: 1.808958
Loss Generator P: 0.292296
Gradient discriminator: -7.219440
Gradient professor: -13.613738
Loss Generator D: 2.101952
Loss Generator P: 0.265179
Gradient discriminator: 13.097346
Gradient professor: -1.687338
Loss Generator D: 2.335637
Loss Generator P: 0.317016
Gradient discriminator: -1.021936
Gradient professor: -8.767711
Loss Generator D: 2.837680
Loss Generator P: 0.215787
Gradient discriminator: 0.336199
Gradient professor: 13.301284
Loss Generator D: 2.777374
Loss Generator P: 0.318844
Gradient discriminator: 6.002939
Gradient professor: -14.120024
Loss Generator D: 2.355298
Loss Generator P: 0.202155
Gradient discriminator: -1.553988
Gradient professor: -3.838904
Loss Generator D: 2.572200
Loss Generator P: 0.288734
Gradient discriminator: 13.377285
Gradient professor: -13.526378
Loss Generator D: 2.663453
Loss Generator P: 0.319090
Gradient discriminator: -5.200437
Gradient professor: -8.690306
Loss Generator D: 2.721323
Loss Generator P: 0.276865
Generator    : Epoch:     19, update:    4610, cost:   0.276865
Gradient discriminator: -1.065889
Gradient professor: 9.925815
Loss Generator D: 2.922479
Loss Generator P: 0.335790
Gradient discriminator: 2.997718
Gradient professor: 2.317055
Loss Generator D: 3.111824
Loss Generator P: 0.278863
Gradient discriminator: 5.494914
Gradient professor: -9.846904
Loss Generator D: 3.561968
Loss Generator P: 0.223383
Gradient discriminator: -0.214807
Gradient professor: 1.397588
Loss Generator D: 2.866463
Loss Generator P: 0.226798
Gradient discriminator: -2.812602
Gradient professor: -2.015823
Loss Generator D: 3.551297
Loss Generator P: 0.346449
Gradient discriminator: -1.617951
Gradient professor: 9.530546
Loss Generator D: 3.108403
Loss Generator P: 0.390146
Gradient discriminator: 7.669498
Gradient professor: -6.609914
Loss Generator D: 3.274403
Loss Generator P: 0.223152
Gradient discriminator: 2.112120
Gradient professor: -4.391402
Loss Generator D: 3.323323
Loss Generator P: 0.437246
Gradient discriminator: -3.468355
Gradient professor: -4.300590
Loss Generator D: 3.231997
Loss Generator P: 0.286091
Gradient discriminator: 1.769395
Gradient professor: -3.510560
Loss Generator D: 3.032676
Loss Generator P: 0.293154
Generator    : Epoch:     19, update:    4620, cost:   0.293154
Gradient discriminator: -8.267493
Gradient professor: -6.913961
Loss Generator D: 3.145447
Loss Generator P: 0.324854
Gradient discriminator: -0.842273
Gradient professor: -4.754154
Loss Generator D: 2.889970
Loss Generator P: 0.326470
Gradient discriminator: 5.024834
Gradient professor: 5.854482
Loss Generator D: 3.289799
Loss Generator P: 0.345287
Gradient discriminator: -5.918831
Gradient professor: -14.853193
Loss Generator D: 3.024608
Loss Generator P: 0.371393
Gradient discriminator: -2.838556
Gradient professor: 24.808917
Loss Generator D: 2.473852
Loss Generator P: 0.376731
Gradient discriminator: 5.616689
Gradient professor: 22.042654
Loss Generator D: 2.938349
Loss Generator P: 0.379549
Gradient discriminator: -5.574916
Gradient professor: -2.202015
Loss Generator D: 2.776004
Loss Generator P: 0.301372
Gradient discriminator: 1.429018
Gradient professor: 14.948404
Loss Generator D: 3.099149
Loss Generator P: 0.351576
Gradient discriminator: 1.785147
Gradient professor: 16.385878
Loss Generator D: 3.317860
Loss Generator P: 0.397799
Gradient discriminator: -7.970814
Gradient professor: 14.749674
Loss Generator D: 3.460634
Loss Generator P: 0.337463
Generator    : Epoch:     19, update:    4630, cost:   0.337463
Gradient discriminator: -0.174829
Gradient professor: -9.823013
Loss Generator D: 2.995119
Loss Generator P: 0.323602
Gradient discriminator: -5.080432
Gradient professor: -6.009932
Loss Generator D: 3.058415
Loss Generator P: 0.283799
Gradient discriminator: 5.482981
Gradient professor: 6.676956
Loss Generator D: 2.387192
Loss Generator P: 0.255501
Gradient discriminator: 0.166679
Gradient professor: -14.465181
Loss Generator D: 2.968913
Loss Generator P: 0.499797
Gradient discriminator: 11.168036
Gradient professor: 1.083202
Loss Generator D: 2.435449
Loss Generator P: 0.281316
Gradient discriminator: -2.051169
Gradient professor: -2.259094
Loss Generator D: 2.926208
Loss Generator P: 0.227024
Gradient discriminator: 1.758134
Gradient professor: -13.722853
Loss Generator D: 2.685471
Loss Generator P: 0.274617
Gradient discriminator: -0.466392
Gradient professor: 10.874050
Loss Generator D: 2.697288
Loss Generator P: 0.234094
Gradient discriminator: -8.808985
Gradient professor: 23.049015
Loss Generator D: 2.184141
Loss Generator P: 0.362296
Gradient discriminator: -3.994750
Gradient professor: 16.320043
Loss Generator D: 2.257208
Loss Generator P: 0.326692
Generator    : Epoch:     19, update:    4640, cost:   0.326692
Gradient discriminator: 3.171935
Gradient professor: -17.621704
Loss Generator D: 2.019126
Loss Generator P: 0.254836
Gradient discriminator: -5.229118
Gradient professor: -6.820156
Loss Generator D: 2.051473
Loss Generator P: 0.302723
Gradient discriminator: -4.505659
Gradient professor: 24.895206
Loss Generator D: 2.148832
Loss Generator P: 0.473043
Gradient discriminator: -1.216491
Gradient professor: 0.944415
Loss Generator D: 2.200588
Loss Generator P: 0.354811
Gradient discriminator: 4.845295
Gradient professor: -2.393888
Loss Generator D: 1.945088
Loss Generator P: 0.423279
Gradient discriminator: 9.146609
Gradient professor: -13.391814
Loss Generator D: 2.389197
Loss Generator P: 0.392989
Gradient discriminator: 3.130730
Gradient professor: 1.450992
Loss Generator D: 2.136442
Loss Generator P: 0.238052
Gradient discriminator: 9.079013
Gradient professor: 12.565403
Loss Generator D: 1.920159
Loss Generator P: 0.294896
Gradient discriminator: -16.231365
Gradient professor: 14.548490
Loss Generator D: 2.182608
Loss Generator P: 0.282634
Gradient discriminator: -7.147050
Gradient professor: -6.274074
Loss Generator D: 2.591233
Loss Generator P: 0.239670
Generator    : Epoch:     19, update:    4650, cost:   0.239670
Gradient discriminator: 6.138720
Gradient professor: -21.290982
Loss Generator D: 2.917957
Loss Generator P: 0.387002
Gradient discriminator: 0.243729
Gradient professor: 9.081374
Loss Generator D: 2.264756
Loss Generator P: 0.404610
Gradient discriminator: -3.786574
Gradient professor: -5.261875
Loss Generator D: 2.082876
Loss Generator P: 0.332155
Gradient discriminator: 2.780103
Gradient professor: 10.421944
Loss Generator D: 2.222375
Loss Generator P: 0.286382
Gradient discriminator: 5.008559
Gradient professor: 6.842415
Loss Generator D: 1.933786
Loss Generator P: 0.424466
Gradient discriminator: 1.895817
Gradient professor: -18.591177
Loss Generator D: 1.699311
Loss Generator P: 0.306906
Gradient discriminator: 5.297873
Gradient professor: -8.279591
Loss Generator D: 1.574332
Loss Generator P: 0.305785
Gradient discriminator: 1.093135
Gradient professor: -6.835052
Loss Generator D: 1.718218
Loss Generator P: 0.258166
Gradient discriminator: 3.259309
Gradient professor: -9.888567
Loss Generator D: 1.547226
Loss Generator P: 0.227227
Gradient discriminator: -0.232678
Gradient professor: -0.557887
Loss Generator D: 1.303578
Loss Generator P: 0.374847
Generator    : Epoch:     19, update:    4660, cost:   0.374847
Gradient discriminator: -10.236542
Gradient professor: -1.352595
Loss Generator D: 1.965784
Loss Generator P: 0.386787
Gradient discriminator: -8.081226
Gradient professor: -1.482867
Loss Generator D: 2.302241
Loss Generator P: 0.428840
Gradient discriminator: 3.131550
Gradient professor: 9.816506
Loss Generator D: 1.719284
Loss Generator P: 0.422304
Gradient discriminator: 0.006833
Gradient professor: 5.767969
Loss Generator D: 1.921773
Loss Generator P: 0.426253
Gradient discriminator: 2.518492
Gradient professor: -11.053936
Loss Generator D: 2.192785
Loss Generator P: 0.509368
Gradient discriminator: 0.136680
Gradient professor: 15.824814
Loss Generator D: 2.085141
Loss Generator P: 0.402439
Gradient discriminator: -18.554453
Gradient professor: 20.801146
Loss Generator D: 1.704709
Loss Generator P: 0.439165
Gradient discriminator: 6.907120
Gradient professor: -6.371174
Loss Generator D: 1.907389
Loss Generator P: 0.257733
Gradient discriminator: -2.073683
Gradient professor: -1.074497
Loss Generator D: 1.750225
Loss Generator P: 0.347428
Gradient discriminator: 2.159513
Gradient professor: -0.818931
Loss Generator D: 1.877960
Loss Generator P: 0.367053
Generator    : Epoch:     19, update:    4670, cost:   0.367053
Gradient discriminator: -7.267804
Gradient professor: -0.202814
Loss Generator D: 2.132300
Loss Generator P: 0.279559
Gradient discriminator: 1.454065
Gradient professor: -4.041456
Loss Generator D: 1.533308
Loss Generator P: 0.233592
Gradient discriminator: -0.891076
Gradient professor: 12.112872
Loss Generator D: 2.380831
Loss Generator P: 0.308813
Gradient discriminator: -5.968468
Gradient professor: -10.759542
Loss Generator D: 2.290272
Loss Generator P: 0.212710
Gradient discriminator: -4.748808
Gradient professor: -2.025648
Loss Generator D: 2.172616
Loss Generator P: 0.255990
Gradient discriminator: 1.232859
Gradient professor: -1.587986
Loss Generator D: 2.214356
Loss Generator P: 0.352405
Gradient discriminator: -12.106571
Gradient professor: 1.365546
Loss Generator D: 2.217249
Loss Generator P: 0.429733
Gradient discriminator: 0.636028
Gradient professor: 43.037562
Loss Generator D: 1.997206
Loss Generator P: 0.534152
Gradient discriminator: 17.489226
Gradient professor: -9.966334
Loss Generator D: 2.094172
Loss Generator P: 0.455698
Gradient discriminator: -7.280993
Gradient professor: -16.148753
Loss Generator D: 1.809353
Loss Generator P: 0.264179
Generator    : Epoch:     19, update:    4680, cost:   0.264179
Gradient discriminator: -8.417635
Gradient professor: 2.395971
Loss Generator D: 1.965722
Loss Generator P: 0.291125
Gradient discriminator: 16.976347
Gradient professor: 4.630296
Loss Generator D: 1.912825
Loss Generator P: 0.299570
Gradient discriminator: -3.246587
Gradient professor: -0.574779
Loss Generator D: 2.137890
Loss Generator P: 0.317123
Gradient discriminator: 4.318547
Gradient professor: -14.655954
Loss Generator D: 2.107405
Loss Generator P: 0.490613
Gradient discriminator: 2.035725
Gradient professor: 21.918230
Loss Generator D: 2.204322
Loss Generator P: 0.428575
Gradient discriminator: 6.203284
Gradient professor: -9.140009
Loss Generator D: 2.062964
Loss Generator P: 0.295182
Gradient discriminator: 3.371731
Gradient professor: 11.807699
Loss Generator D: 1.968164
Loss Generator P: 0.383703
Gradient discriminator: -2.447994
Gradient professor: -1.248541
Loss Generator D: 2.067462
Loss Generator P: 0.400815
Gradient discriminator: 3.673556
Gradient professor: 14.705731
Loss Generator D: 2.314101
Loss Generator P: 0.373510
Gradient discriminator: 5.977803
Gradient professor: -24.514723
Loss Generator D: 2.187943
Loss Generator P: 0.363919
Generator    : Epoch:     19, update:    4690, cost:   0.363919
Gradient discriminator: 0.201090
Gradient professor: -1.861994
Loss Generator D: 2.375705
Loss Generator P: 0.419009
Gradient discriminator: -3.198760
Gradient professor: -12.048188
Loss Generator D: 2.142515
Loss Generator P: 0.284293
Gradient discriminator: 3.564051
Gradient professor: -12.224361
Loss Generator D: 2.348072
Loss Generator P: 0.542470
Gradient discriminator: 1.997123
Gradient professor: 31.452544
Loss Generator D: 1.816206
Loss Generator P: 0.505023
Gradient discriminator: 7.404722
Gradient professor: 14.073097
Loss Generator D: 2.065015
Loss Generator P: 0.254343
Gradient discriminator: -5.957751
Gradient professor: -2.893241
Loss Generator D: 2.349205
Loss Generator P: 0.396687
Gradient discriminator: -2.065881
Gradient professor: -12.644353
Loss Generator D: 2.306330
Loss Generator P: 0.335193
Gradient discriminator: 15.062359
Gradient professor: 6.292327
Loss Generator D: 2.028567
Loss Generator P: 0.444071
Gradient discriminator: -6.368055
Gradient professor: 1.986627
Loss Generator D: 2.181956
Loss Generator P: 0.373330
Gradient discriminator: 1.298970
Gradient professor: 0.362566
Loss Generator D: 2.405266
Loss Generator P: 0.279338
Generator    : Epoch:     19, update:    4700, cost:   0.279338
Validation 47 - LOSS = 1.700 (PPL: 5.474)
Calling beam-search process
Beam-search ended, took 2.04157 minutes.
Validation 47 - BLEU = 8.79, 16.5/10.4/7.2/4.8 (BP=1.000, ratio=3.488, hyp_len=14719, ref_len=4220)
Early stopping patience: 996 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 10.593431
Gradient professor: 4.053760
Loss Generator D: 2.869353
Loss Generator P: 0.335028
Gradient discriminator: 0.392309
Gradient professor: -12.215804
Loss Generator D: 2.124607
Loss Generator P: 0.348180
Gradient discriminator: 7.818078
Gradient professor: 7.033605
Loss Generator D: 2.521818
Loss Generator P: 0.319922
Gradient discriminator: 5.320678
Gradient professor: -8.959442
Loss Generator D: 2.210124
Loss Generator P: 0.301441
Gradient discriminator: -4.479434
Gradient professor: -16.755887
Loss Generator D: 2.303299
Loss Generator P: 0.255823
Gradient discriminator: 9.340206
Gradient professor: -6.595792
Loss Generator D: 2.260083
Loss Generator P: 0.239329
Gradient discriminator: 14.694373
Gradient professor: -21.750907
Loss Generator D: 2.912380
Loss Generator P: 0.347929
Gradient discriminator: -15.199758
Gradient professor: -13.961315
Loss Generator D: 2.763179
Loss Generator P: 0.391969
Gradient discriminator: -5.697543
Gradient professor: -5.648014
Loss Generator D: 2.290432
Loss Generator P: 0.318556
Gradient discriminator: 5.842013
Gradient professor: -26.027001
Loss Generator D: 2.755426
Loss Generator P: 0.423946
Generator    : Epoch:     19, update:    4710, cost:   0.423946
Gradient discriminator: 7.057525
Gradient professor: -2.084180
Loss Generator D: 2.877947
Loss Generator P: 0.408386
Gradient discriminator: -3.323521
Gradient professor: -5.688836
Loss Generator D: 2.228931
Loss Generator P: 0.436225
Gradient discriminator: 0.837970
Gradient professor: 8.514210
Loss Generator D: 2.802978
Loss Generator P: 0.307250
Gradient discriminator: -11.283259
Gradient professor: -11.388531
Loss Generator D: 2.489031
Loss Generator P: 0.297417
Gradient discriminator: 3.083709
Gradient professor: 5.612385
Loss Generator D: 2.953454
Loss Generator P: 0.373667
Gradient discriminator: -1.877477
Gradient professor: 13.310401
Loss Generator D: 2.579061
Loss Generator P: 0.357427
Gradient discriminator: 9.314098
Gradient professor: 7.044714
Loss Generator D: 2.669065
Loss Generator P: 0.347192
Gradient discriminator: 4.364982
Gradient professor: -7.011087
Loss Generator D: 2.445920
Loss Generator P: 0.351557
Gradient discriminator: -3.517706
Gradient professor: -4.483647
Loss Generator D: 2.468300
Loss Generator P: 0.272880
Gradient discriminator: -0.088954
Gradient professor: -10.140137
Loss Generator D: 2.425357
Loss Generator P: 0.255475
Generator    : Epoch:     19, update:    4720, cost:   0.255475
Gradient discriminator: 16.789512
Gradient professor: 2.558058
Loss Generator D: 2.487440
Loss Generator P: 0.325253
Gradient discriminator: -1.071493
Gradient professor: -6.245271
Loss Generator D: 2.368554
Loss Generator P: 0.331958
Gradient discriminator: -35.750494
Gradient professor: 11.499839
Loss Generator D: 2.463728
Loss Generator P: 0.354027
Gradient discriminator: -0.225358
Gradient professor: -4.610201
Loss Generator D: 2.932074
Loss Generator P: 0.260546
Gradient discriminator: 1.746969
Gradient professor: 9.418692
Loss Generator D: 2.518292
Loss Generator P: 0.243145
Gradient discriminator: -0.506315
Gradient professor: -11.223152
Loss Generator D: 2.590316
Loss Generator P: 0.305116
Gradient discriminator: -5.289356
Gradient professor: -2.994853
Loss Generator D: 2.678056
Loss Generator P: 0.277998
Gradient discriminator: -6.300189
Gradient professor: 8.307021
Loss Generator D: 2.677971
Loss Generator P: 0.302050
Gradient discriminator: 3.189182
Gradient professor: -0.950578
Loss Generator D: 2.958735
Loss Generator P: 0.378400
Gradient discriminator: -5.190711
Gradient professor: -0.592031
Loss Generator D: 2.985385
Loss Generator P: 0.306744
Generator    : Epoch:     19, update:    4730, cost:   0.306744
Gradient discriminator: -8.928122
Gradient professor: -6.345530
Loss Generator D: 2.856974
Loss Generator P: 0.439740
Gradient discriminator: -7.687226
Gradient professor: -21.125380
Loss Generator D: 2.420408
Loss Generator P: 0.514134
Gradient discriminator: 7.371424
Gradient professor: 14.655810
Loss Generator D: 2.666311
Loss Generator P: 0.434838
Gradient discriminator: -4.987314
Gradient professor: -2.518432
Loss Generator D: 2.823634
Loss Generator P: 0.209449
Gradient discriminator: -1.221549
Gradient professor: 9.673834
Loss Generator D: 2.476669
Loss Generator P: 0.415860
Gradient discriminator: -0.372792
Gradient professor: -16.106004
Loss Generator D: 2.872008
Loss Generator P: 0.300644
Gradient discriminator: -0.914310
Gradient professor: 6.807135
Loss Generator D: 3.165809
Loss Generator P: 0.207903
Gradient discriminator: -13.312871
Gradient professor: -11.272510
Loss Generator D: 2.793576
Loss Generator P: 0.384496
Gradient discriminator: 1.424747
Gradient professor: -13.454101
Loss Generator D: 2.613538
Loss Generator P: 0.309968
Gradient discriminator: 0.780091
Gradient professor: 9.701911
Loss Generator D: 2.834471
Loss Generator P: 0.315896
Generator    : Epoch:     19, update:    4740, cost:   0.315896
Gradient discriminator: 91.246911
Gradient professor: -2.212414
Loss Generator D: 2.557050
Loss Generator P: 0.265154
Gradient discriminator: -2.685432
Gradient professor: -11.752546
Loss Generator D: 2.659791
Loss Generator P: 0.298157
Gradient discriminator: -3.975553
Gradient professor: 16.894937
Loss Generator D: 2.652089
Loss Generator P: 0.274930
Gradient discriminator: 5.537663
Gradient professor: -13.655488
Loss Generator D: 2.435335
Loss Generator P: 0.304541
Gradient discriminator: 0.649857
Gradient professor: 9.135931
Loss Generator D: 2.924448
Loss Generator P: 0.314654
Gradient discriminator: -4.031122
Gradient professor: 11.507609
Loss Generator D: 2.939973
Loss Generator P: 0.246077
Gradient discriminator: 10.304399
Gradient professor: -5.126759
Loss Generator D: 2.934732
Loss Generator P: 0.285431
Gradient discriminator: 8.963429
Gradient professor: 12.588066
Loss Generator D: 2.727110
Loss Generator P: 0.198043
Gradient discriminator: -4.539432
Gradient professor: 3.571362
Loss Generator D: 2.509501
Loss Generator P: 0.305882
Gradient discriminator: -4.661528
Gradient professor: -11.917629
Loss Generator D: 2.690818
Loss Generator P: 0.153813
Generator    : Epoch:     19, update:    4750, cost:   0.153813
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 19 finished with mean loss 1.35684 (PPL: 3.88390)
--> Epoch took 336.421 minutes, 80.741 sec/update
Epoch summary of Discriminator:
--> Epoch 19 finished with mean loss nan (PPL:  nan)
--> Epoch took 336.421 minutes, 80.741 sec/update
---------------------------------------------------------
Starting Epoch 20
-----------------
Gradient discriminator: -0.474623
Gradient professor: -20.192306
Loss Generator D: 2.513928
Loss Generator P: 0.410683
Gradient discriminator: -6.124122
Gradient professor: 3.619534
Loss Generator D: 2.583268
Loss Generator P: 0.323109
Gradient discriminator: 7.819491
Gradient professor: -16.882740
Loss Generator D: 2.727468
Loss Generator P: 0.326911
Gradient discriminator: 12.449199
Gradient professor: -25.903599
Loss Generator D: 2.434763
Loss Generator P: 0.437996
Gradient discriminator: -7.792429
Gradient professor: -30.004769
Loss Generator D: 2.679952
Loss Generator P: 0.281024
Gradient discriminator: 2.246890
Gradient professor: 20.714324
Loss Generator D: 2.555166
Loss Generator P: 0.338169
Gradient discriminator: -3.090064
Gradient professor: 10.786040
Loss Generator D: 2.870660
Loss Generator P: 0.348675
Gradient discriminator: 11.795785
Gradient professor: 1.459784
Loss Generator D: 2.112307
Loss Generator P: 0.279431
Gradient discriminator: 6.681908
Gradient professor: -7.095384
Loss Generator D: 2.725692
Loss Generator P: 0.400375
Gradient discriminator: -3.931376
Gradient professor: 16.167408
Loss Generator D: 2.503863
Loss Generator P: 0.456839
Generator    : Epoch:     20, update:    4760, cost:   0.456839
Gradient discriminator: 0.662090
Gradient professor: 30.600597
Loss Generator D: 2.984460
Loss Generator P: 0.481990
Gradient discriminator: -1.043419
Gradient professor: -14.006098
Loss Generator D: 2.805943
Loss Generator P: 0.316979
Gradient discriminator: 6.212639
Gradient professor: 17.519212
Loss Generator D: 2.544461
Loss Generator P: 0.424197
Gradient discriminator: 3.554061
Gradient professor: -17.631545
Loss Generator D: 2.888394
Loss Generator P: 0.425644
Gradient discriminator: 1.788345
Gradient professor: 3.047898
Loss Generator D: 2.422829
Loss Generator P: 0.243362
Gradient discriminator: -3.135581
Gradient professor: -6.083559
Loss Generator D: 2.483531
Loss Generator P: 0.218592
Gradient discriminator: -10.915516
Gradient professor: 4.964263
Loss Generator D: 2.484677
Loss Generator P: 0.278615
Gradient discriminator: -26.374499
Gradient professor: 9.169658
Loss Generator D: 2.515871
Loss Generator P: 0.290482
Gradient discriminator: 13.680763
Gradient professor: 11.781012
Loss Generator D: 3.111691
Loss Generator P: 0.350976
Gradient discriminator: 5.737671
Gradient professor: 2.502440
Loss Generator D: 2.677865
Loss Generator P: 0.384108
Generator    : Epoch:     20, update:    4770, cost:   0.384108
Gradient discriminator: -1.458075
Gradient professor: -16.980649
Loss Generator D: 2.612478
Loss Generator P: 0.316135
Gradient discriminator: -165.131372
Gradient professor: 3.401605
Loss Generator D: 2.778331
Loss Generator P: 0.250775
Gradient discriminator: 5.578173
Gradient professor: 3.639290
Loss Generator D: 2.898650
Loss Generator P: 0.271660
Gradient discriminator: -2.999446
Gradient professor: -2.078581
Loss Generator D: 2.675265
Loss Generator P: 0.480894
Gradient discriminator: 0.271754
Gradient professor: -0.703303
Loss Generator D: 3.120422
Loss Generator P: 0.438751
Gradient discriminator: 16.060524
Gradient professor: -1.033014
Loss Generator D: 2.810988
Loss Generator P: 0.326232
Gradient discriminator: -3.202149
Gradient professor: -1.317213
Loss Generator D: 2.137410
Loss Generator P: 0.252129
Gradient discriminator: -0.614037
Gradient professor: 16.615895
Loss Generator D: 2.427708
Loss Generator P: 0.308853
Gradient discriminator: 2.063959
Gradient professor: -2.624867
Loss Generator D: 2.915502
Loss Generator P: 0.303408
Gradient discriminator: -13.433673
Gradient professor: 1.395776
Loss Generator D: 2.898087
Loss Generator P: 0.306499
Generator    : Epoch:     20, update:    4780, cost:   0.306499
Gradient discriminator: -0.381283
Gradient professor: -1.509814
Loss Generator D: 2.804965
Loss Generator P: 0.250252
Gradient discriminator: -1.049303
Gradient professor: -1.306180
Loss Generator D: 3.048450
Loss Generator P: 0.241681
Gradient discriminator: 4.843575
Gradient professor: 15.011912
Loss Generator D: 3.358288
Loss Generator P: 0.421610
Gradient discriminator: 2.860762
Gradient professor: -4.083712
Loss Generator D: 2.672815
Loss Generator P: 0.480560
Gradient discriminator: -3.603560
Gradient professor: -2.774519
Loss Generator D: 3.007900
Loss Generator P: 0.314218
Gradient discriminator: -2.775861
Gradient professor: -11.735244
Loss Generator D: 2.642738
Loss Generator P: 0.249193
Gradient discriminator: -2.202446
Gradient professor: -31.801063
Loss Generator D: 2.945606
Loss Generator P: 0.259013
Gradient discriminator: -4.022769
Gradient professor: -3.517649
Loss Generator D: 2.996108
Loss Generator P: 0.289245
Gradient discriminator: -5.097240
Gradient professor: 1.430663
Loss Generator D: 2.640716
Loss Generator P: 0.328165
Gradient discriminator: 4.697676
Gradient professor: -10.394256
Loss Generator D: 3.390558
Loss Generator P: 0.564589
Generator    : Epoch:     20, update:    4790, cost:   0.564589
Gradient discriminator: -6.877627
Gradient professor: 0.312583
Loss Generator D: 2.662860
Loss Generator P: 0.312825
Gradient discriminator: 17.878394
Gradient professor: -1.421094
Loss Generator D: 3.431584
Loss Generator P: 0.315255
Gradient discriminator: 0.575621
Gradient professor: 20.673386
Loss Generator D: 3.079220
Loss Generator P: 0.337543
Gradient discriminator: -1.737672
Gradient professor: 1.110906
Loss Generator D: 3.011304
Loss Generator P: 0.274414
Gradient discriminator: 6.540111
Gradient professor: -6.918111
Loss Generator D: 3.157886
Loss Generator P: 0.410725
Gradient discriminator: 11.504417
Gradient professor: 11.378265
Loss Generator D: 2.984213
Loss Generator P: 0.361196
Gradient discriminator: -10.116316
Gradient professor: 5.998914
Loss Generator D: 2.714244
Loss Generator P: 0.230969
Gradient discriminator: -0.173998
Gradient professor: -15.290403
Loss Generator D: 2.681885
Loss Generator P: 0.402848
Gradient discriminator: -2.260855
Gradient professor: 14.003439
Loss Generator D: 2.874920
Loss Generator P: 0.558624
Gradient discriminator: -3.239732
Gradient professor: 10.105975
Loss Generator D: 2.886332
Loss Generator P: 0.309833
Generator    : Epoch:     20, update:    4800, cost:   0.309833
Validation 48 - LOSS = 1.767 (PPL: 5.851)
Calling beam-search process
Beam-search ended, took 1.58117 minutes.
Validation 48 - BLEU = 17.56, 31.4/20.3/14.5/10.3 (BP=1.000, ratio=2.048, hyp_len=8642, ref_len=4220)
Early stopping patience: 995 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 4.662106
Gradient professor: 24.618065
Loss Generator D: 2.807053
Loss Generator P: 0.360571
Gradient discriminator: -8.057652
Gradient professor: -0.898329
Loss Generator D: 2.890735
Loss Generator P: 0.291476
Gradient discriminator: 14.716006
Gradient professor: 9.748995
Loss Generator D: 2.132929
Loss Generator P: 0.277249
Gradient discriminator: 1.730657
Gradient professor: 0.911322
Loss Generator D: 2.828717
Loss Generator P: 0.388968
Gradient discriminator: -6.960567
Gradient professor: -5.149823
Loss Generator D: 2.829200
Loss Generator P: 0.329128
Gradient discriminator: 1.182331
Gradient professor: -7.089708
Loss Generator D: 2.937003
Loss Generator P: 0.236676
Gradient discriminator: 9.804988
Gradient professor: -8.276774
Loss Generator D: 2.303106
Loss Generator P: 0.251650
Gradient discriminator: -2.608842
Gradient professor: -8.542708
Loss Generator D: 3.037472
Loss Generator P: 0.252094
Gradient discriminator: -4.436197
Gradient professor: 5.432737
Loss Generator D: 2.724335
Loss Generator P: 0.301046
Gradient discriminator: -8.467985
Gradient professor: 8.112782
Loss Generator D: 2.806819
Loss Generator P: 0.314239
Generator    : Epoch:     20, update:    4810, cost:   0.314239
Gradient discriminator: 5.511038
Gradient professor: 1.742816
Loss Generator D: 2.601576
Loss Generator P: 0.317894
Gradient discriminator: -2.076880
Gradient professor: 14.616404
Loss Generator D: 2.721735
Loss Generator P: 0.509899
Gradient discriminator: 7.164206
Gradient professor: 30.118993
Loss Generator D: 2.459256
Loss Generator P: 0.361025
Gradient discriminator: 0.190035
Gradient professor: 4.102649
Loss Generator D: 2.613023
Loss Generator P: 0.316824
Gradient discriminator: 12.833923
Gradient professor: -4.658245
Loss Generator D: 2.358109
Loss Generator P: 0.381769
Gradient discriminator: -0.174375
Gradient professor: -16.489229
Loss Generator D: 2.315497
Loss Generator P: 0.367769
Gradient discriminator: 1.712423
Gradient professor: -1.555650
Loss Generator D: 2.563487
Loss Generator P: 0.322154
Gradient discriminator: 5.368136
Gradient professor: 14.498173
Loss Generator D: 2.865293
Loss Generator P: 0.254216
Gradient discriminator: 0.031562
Gradient professor: 21.060474
Loss Generator D: 2.797415
Loss Generator P: 0.406555
Gradient discriminator: 20.457413
Gradient professor: -1.531307
Loss Generator D: 2.644262
Loss Generator P: 0.283604
Generator    : Epoch:     20, update:    4820, cost:   0.283604
Gradient discriminator: -4.002251
Gradient professor: 4.156485
Loss Generator D: 3.160937
Loss Generator P: 0.287552
Gradient discriminator: 8.683319
Gradient professor: 2.278220
Loss Generator D: 2.654088
Loss Generator P: 0.249898
Gradient discriminator: 4.907398
Gradient professor: 0.541307
Loss Generator D: 2.695160
Loss Generator P: 0.293362
Gradient discriminator: -2.897307
Gradient professor: 5.021093
Loss Generator D: 2.691759
Loss Generator P: 0.361294
Gradient discriminator: 3.125847
Gradient professor: 14.139885
Loss Generator D: 2.660000
Loss Generator P: 0.280628
Gradient discriminator: -3.989967
Gradient professor: -0.113395
Loss Generator D: 2.114200
Loss Generator P: 0.262602
Gradient discriminator: 0.843559
Gradient professor: 2.141448
Loss Generator D: 3.166364
Loss Generator P: 0.285867
Gradient discriminator: -43.577116
Gradient professor: -13.358417
Loss Generator D: 2.909386
Loss Generator P: 0.381778
Gradient discriminator: 3.284779
Gradient professor: -2.715330
Loss Generator D: 2.286354
Loss Generator P: 0.267911
Gradient discriminator: 2.469909
Gradient professor: -6.045845
Loss Generator D: 2.625586
Loss Generator P: 0.260783
Generator    : Epoch:     20, update:    4830, cost:   0.260783
Gradient discriminator: 4.716304
Gradient professor: 0.984625
Loss Generator D: 3.242520
Loss Generator P: 0.278864
Gradient discriminator: 0.291141
Gradient professor: 5.724683
Loss Generator D: 3.239249
Loss Generator P: 0.242893
Gradient discriminator: -6.124474
Gradient professor: -1.754332
Loss Generator D: 2.657912
Loss Generator P: 0.250946
Gradient discriminator: 13.743556
Gradient professor: -9.002872
Loss Generator D: 2.559745
Loss Generator P: 0.176400
Gradient discriminator: 6.237472
Gradient professor: 11.777929
Loss Generator D: 3.184056
Loss Generator P: 0.222266
Gradient discriminator: -1.708179
Gradient professor: 3.235564
Loss Generator D: 2.698961
Loss Generator P: 0.233989
Gradient discriminator: 10.321727
Gradient professor: -8.885351
Loss Generator D: 2.909278
Loss Generator P: 0.198919
Gradient discriminator: -2.734744
Gradient professor: -20.741747
Loss Generator D: 2.886270
Loss Generator P: 0.364442
Gradient discriminator: 10.271386
Gradient professor: 5.362909
Loss Generator D: 2.996369
Loss Generator P: 0.280938
Gradient discriminator: 6.723010
Gradient professor: 2.256253
Loss Generator D: 2.914715
Loss Generator P: 0.330220
Generator    : Epoch:     20, update:    4840, cost:   0.330220
Gradient discriminator: 6.975455
Gradient professor: 7.897193
Loss Generator D: 2.732781
Loss Generator P: 0.264472
Gradient discriminator: 7.328603
Gradient professor: 23.248631
Loss Generator D: 2.769614
Loss Generator P: 0.385374
Gradient discriminator: 0.669313
Gradient professor: -5.181865
Loss Generator D: 2.924398
Loss Generator P: 0.229941
Gradient discriminator: -2.372527
Gradient professor: -2.758611
Loss Generator D: 2.375704
Loss Generator P: 0.209437
Gradient discriminator: 6.056074
Gradient professor: -2.872311
Loss Generator D: 2.793244
Loss Generator P: 0.225357
Gradient discriminator: -0.656174
Gradient professor: 3.159258
Loss Generator D: 2.646683
Loss Generator P: 0.297145
Gradient discriminator: -8.031114
Gradient professor: -16.243497
Loss Generator D: 3.074733
Loss Generator P: 0.269803
Gradient discriminator: 13.411868
Gradient professor: -6.350641
Loss Generator D: 2.453262
Loss Generator P: 0.234833
Gradient discriminator: -2.854105
Gradient professor: 3.916933
Loss Generator D: 3.000576
Loss Generator P: 0.222753
Gradient discriminator: 4.943603
Gradient professor: -15.655538
Loss Generator D: 2.898778
Loss Generator P: 0.271097
Generator    : Epoch:     20, update:    4850, cost:   0.271097
Gradient discriminator: 11.561830
Gradient professor: -14.283832
Loss Generator D: 2.402364
Loss Generator P: 0.317445
Gradient discriminator: -7.896410
Gradient professor: -0.214592
Loss Generator D: 2.195097
Loss Generator P: 0.308274
Gradient discriminator: 8.394156
Gradient professor: -7.427926
Loss Generator D: 2.053768
Loss Generator P: 0.223487
Gradient discriminator: 3.239959
Gradient professor: 8.471916
Loss Generator D: 1.817006
Loss Generator P: 0.286089
Gradient discriminator: 2.776889
Gradient professor: 1.258773
Loss Generator D: 2.170720
Loss Generator P: 0.190875
Gradient discriminator: 3.055163
Gradient professor: -1.479915
Loss Generator D: 2.167926
Loss Generator P: 0.294178
Gradient discriminator: 7.548887
Gradient professor: 10.667523
Loss Generator D: 2.057277
Loss Generator P: 0.208386
Gradient discriminator: 8.188012
Gradient professor: -10.624051
Loss Generator D: 2.523142
Loss Generator P: 0.293127
Gradient discriminator: -10.091911
Gradient professor: -4.279927
Loss Generator D: 2.581406
Loss Generator P: 0.304826
Gradient discriminator: -0.552404
Gradient professor: -3.373513
Loss Generator D: 2.205114
Loss Generator P: 0.274792
Generator    : Epoch:     20, update:    4860, cost:   0.274792
Gradient discriminator: 3.963942
Gradient professor: -1.498030
Loss Generator D: 2.585434
Loss Generator P: 0.344020
Gradient discriminator: 10.393691
Gradient professor: 5.744565
Loss Generator D: 2.396718
Loss Generator P: 0.237465
Gradient discriminator: 1.196004
Gradient professor: -0.522184
Loss Generator D: 2.887865
Loss Generator P: 0.244274
Gradient discriminator: 1.989526
Gradient professor: -12.661680
Loss Generator D: 2.649847
Loss Generator P: 0.202497
Gradient discriminator: 2.284536
Gradient professor: 1.334620
Loss Generator D: 2.706771
Loss Generator P: 0.295312
Gradient discriminator: -6.490099
Gradient professor: -4.548456
Loss Generator D: 2.740011
Loss Generator P: 0.369631
Gradient discriminator: -7.460610
Gradient professor: 7.997561
Loss Generator D: 2.610639
Loss Generator P: 0.198096
Gradient discriminator: 3.323474
Gradient professor: -17.282853
Loss Generator D: 2.817055
Loss Generator P: 0.356514
Gradient discriminator: -4.147163
Gradient professor: -4.493810
Loss Generator D: 2.757566
Loss Generator P: 0.235538
Gradient discriminator: -6.933416
Gradient professor: -5.836946
Loss Generator D: 2.267902
Loss Generator P: 0.242510
Generator    : Epoch:     20, update:    4870, cost:   0.242510
Gradient discriminator: -3.342597
Gradient professor: -9.399459
Loss Generator D: 2.486399
Loss Generator P: 0.287334
Gradient discriminator: -0.530062
Gradient professor: -14.903988
Loss Generator D: 2.183364
Loss Generator P: 0.285280
Gradient discriminator: 1.217986
Gradient professor: -1.683975
Loss Generator D: 2.347890
Loss Generator P: 0.299956
Gradient discriminator: -19.418254
Gradient professor: 22.544778
Loss Generator D: 2.357796
Loss Generator P: 0.375308
Gradient discriminator: -10.647134
Gradient professor: 11.302620
Loss Generator D: 1.944674
Loss Generator P: 0.349407
Gradient discriminator: 5.243713
Gradient professor: 4.882255
Loss Generator D: 2.065392
Loss Generator P: 0.358350
Gradient discriminator: 15.354331
Gradient professor: 16.553328
Loss Generator D: 2.407828
Loss Generator P: 0.284520
Gradient discriminator: -6.601525
Gradient professor: 8.654646
Loss Generator D: 2.350238
Loss Generator P: 0.385046
Gradient discriminator: -0.982895
Gradient professor: 9.769953
Loss Generator D: 2.566830
Loss Generator P: 0.367625
Gradient discriminator: -0.982809
Gradient professor: -22.897801
Loss Generator D: 2.280009
Loss Generator P: 0.329157
Generator    : Epoch:     20, update:    4880, cost:   0.329157
Gradient discriminator: -6.405673
Gradient professor: -0.369271
Loss Generator D: 2.268258
Loss Generator P: 0.270369
Gradient discriminator: 3.699991
Gradient professor: -18.359719
Loss Generator D: 2.290659
Loss Generator P: 0.290092
Gradient discriminator: 7.124950
Gradient professor: 12.820739
Loss Generator D: 1.643688
Loss Generator P: 0.213595
Gradient discriminator: 20.920654
Gradient professor: 3.243727
Loss Generator D: 1.844743
Loss Generator P: 0.456467
Gradient discriminator: -7.780244
Gradient professor: -1.133913
Loss Generator D: 1.769600
Loss Generator P: 0.282930
Gradient discriminator: -1.039058
Gradient professor: -17.897375
Loss Generator D: 2.382553
Loss Generator P: 0.239676
Gradient discriminator: -3.112133
Gradient professor: 10.919046
Loss Generator D: 2.509879
Loss Generator P: 0.259609
Gradient discriminator: -8.173925
Gradient professor: -12.328852
Loss Generator D: 2.513824
Loss Generator P: 0.239421
Gradient discriminator: 0.179521
Gradient professor: 12.981114
Loss Generator D: 2.566283
Loss Generator P: 0.336945
Gradient discriminator: 7.079766
Gradient professor: 4.757488
Loss Generator D: 2.401223
Loss Generator P: 0.364732
Generator    : Epoch:     20, update:    4890, cost:   0.364732
Gradient discriminator: 3.147197
Gradient professor: 5.323699
Loss Generator D: 2.116506
Loss Generator P: 0.234588
Gradient discriminator: 7.500139
Gradient professor: -2.469385
Loss Generator D: 2.278606
Loss Generator P: 0.310746
Gradient discriminator: 9.811037
Gradient professor: 0.484301
Loss Generator D: 2.508965
Loss Generator P: 0.421008
Gradient discriminator: -0.240610
Gradient professor: -19.195506
Loss Generator D: 2.779845
Loss Generator P: 0.311227
Gradient discriminator: 4.923098
Gradient professor: 15.345752
Loss Generator D: 2.327171
Loss Generator P: 0.399613
Gradient discriminator: 8.629015
Gradient professor: -4.970267
Loss Generator D: 2.424024
Loss Generator P: 0.355883
Gradient discriminator: -10.682860
Gradient professor: -2.815225
Loss Generator D: 2.568258
Loss Generator P: 0.221355
Gradient discriminator: -4.172190
Gradient professor: -6.054252
Loss Generator D: 2.436521
Loss Generator P: 0.274124
Gradient discriminator: 10.508631
Gradient professor: 8.058233
Loss Generator D: 2.657949
Loss Generator P: 0.269535
Gradient discriminator: 11.804700
Gradient professor: -4.015777
Loss Generator D: 2.576736
Loss Generator P: 0.244892
Generator    : Epoch:     20, update:    4900, cost:   0.244892
Validation 49 - LOSS = 1.769 (PPL: 5.867)
Calling beam-search process
Beam-search ended, took 2.27572 minutes.
Validation 49 - BLEU = 6.77, 13.0/8.1/5.5/3.7 (BP=1.000, ratio=4.121, hyp_len=17392, ref_len=4220)
Early stopping patience: 994 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 12.319641
Gradient professor: -5.257517
Loss Generator D: 2.694643
Loss Generator P: 0.378242
Gradient discriminator: -0.401367
Gradient professor: 16.764038
Loss Generator D: 2.788657
Loss Generator P: 0.381361
Gradient discriminator: -4.742017
Gradient professor: 3.312861
Loss Generator D: 2.670124
Loss Generator P: 0.326139
Gradient discriminator: 2.945688
Gradient professor: -8.086506
Loss Generator D: 2.487068
Loss Generator P: 0.261966
Gradient discriminator: 10.450082
Gradient professor: 3.585773
Loss Generator D: 2.844098
Loss Generator P: 0.381878
Gradient discriminator: 1.370533
Gradient professor: -1.379899
Loss Generator D: 2.626286
Loss Generator P: 0.288597
Gradient discriminator: -2.470579
Gradient professor: -10.875578
Loss Generator D: 2.917548
Loss Generator P: 0.321386
Gradient discriminator: 9.374678
Gradient professor: 13.264963
Loss Generator D: 2.456534
Loss Generator P: 0.237674
Gradient discriminator: 2.087979
Gradient professor: 2.315076
Loss Generator D: 2.999870
Loss Generator P: 0.236328
Gradient discriminator: -2.609405
Gradient professor: 1.579242
Loss Generator D: 2.802280
Loss Generator P: 0.377179
Generator    : Epoch:     20, update:    4910, cost:   0.377179
Gradient discriminator: -6.825440
Gradient professor: -3.334884
Loss Generator D: 2.758617
Loss Generator P: 0.344690
Gradient discriminator: 3.812961
Gradient professor: 8.612645
Loss Generator D: 2.660965
Loss Generator P: 0.359233
Gradient discriminator: 2.340866
Gradient professor: 2.739565
Loss Generator D: 2.523515
Loss Generator P: 0.395001
Gradient discriminator: -1.702166
Gradient professor: 2.716804
Loss Generator D: 2.840248
Loss Generator P: 0.420553
Gradient discriminator: 52.508076
Gradient professor: -19.918199
Loss Generator D: 2.456213
Loss Generator P: 0.422008
Gradient discriminator: 7.071377
Gradient professor: 7.258127
Loss Generator D: 2.710139
Loss Generator P: 0.392307
Gradient discriminator: -0.141264
Gradient professor: 9.020939
Loss Generator D: 2.984404
Loss Generator P: 0.387494
Gradient discriminator: -0.487639
Gradient professor: 9.554194
Loss Generator D: 3.047428
Loss Generator P: 0.221242
Gradient discriminator: 2.049894
Gradient professor: -15.733621
Loss Generator D: 2.484479
Loss Generator P: 0.333905
Gradient discriminator: -10.552355
Gradient professor: -20.326080
Loss Generator D: 3.198701
Loss Generator P: 0.358686
Generator    : Epoch:     20, update:    4920, cost:   0.358686
Gradient discriminator: 5.203880
Gradient professor: 5.896577
Loss Generator D: 2.858470
Loss Generator P: 0.253689
Gradient discriminator: -8.060778
Gradient professor: -5.226588
Loss Generator D: 2.285353
Loss Generator P: 0.235310
Gradient discriminator: 5.324123
Gradient professor: 1.243260
Loss Generator D: 2.933786
Loss Generator P: 0.291218
Gradient discriminator: 9.951006
Gradient professor: -3.682581
Loss Generator D: 2.877328
Loss Generator P: 0.243426
Gradient discriminator: 9.613428
Gradient professor: -5.952426
Loss Generator D: 2.911031
Loss Generator P: 0.215099
Gradient discriminator: 5.444618
Gradient professor: -18.367001
Loss Generator D: 3.289068
Loss Generator P: 0.312242
Gradient discriminator: -8.594565
Gradient professor: -11.109027
Loss Generator D: 2.455876
Loss Generator P: 0.364429
Gradient discriminator: 14.249828
Gradient professor: -5.837694
Loss Generator D: 2.763208
Loss Generator P: 0.508381
Gradient discriminator: 1.137322
Gradient professor: 1.744588
Loss Generator D: 2.917017
Loss Generator P: 0.438010
Gradient discriminator: 4.641345
Gradient professor: -2.368705
Loss Generator D: 3.251685
Loss Generator P: 0.243538
Generator    : Epoch:     20, update:    4930, cost:   0.243538
Gradient discriminator: -4.638813
Gradient professor: 7.220907
Loss Generator D: 2.896528
Loss Generator P: 0.286045
Gradient discriminator: -1.431292
Gradient professor: -4.301367
Loss Generator D: 2.565326
Loss Generator P: 0.280581
Gradient discriminator: 0.052054
Gradient professor: 17.233548
Loss Generator D: 2.617586
Loss Generator P: 0.311823
Gradient discriminator: 1.215325
Gradient professor: 3.864653
Loss Generator D: 3.016107
Loss Generator P: 0.414935
Gradient discriminator: 3.392610
Gradient professor: -8.162706
Loss Generator D: 2.915058
Loss Generator P: 0.408687
Gradient discriminator: 4.531380
Gradient professor: -9.178355
Loss Generator D: 2.543517
Loss Generator P: 0.287066
Gradient discriminator: -6.670301
Gradient professor: -5.754647
Loss Generator D: 2.368930
Loss Generator P: 0.334485
Gradient discriminator: -7.922660
Gradient professor: -19.359559
Loss Generator D: 2.703727
Loss Generator P: 0.398526
Gradient discriminator: -17.778772
Gradient professor: 12.498723
Loss Generator D: 2.909734
Loss Generator P: 0.420311
Gradient discriminator: 5.219925
Gradient professor: -11.273162
Loss Generator D: 2.591405
Loss Generator P: 0.372131
Generator    : Epoch:     20, update:    4940, cost:   0.372131
Gradient discriminator: 1.139345
Gradient professor: 3.256848
Loss Generator D: 2.830320
Loss Generator P: 0.377698
Gradient discriminator: -7.454811
Gradient professor: 3.486222
Loss Generator D: 2.389451
Loss Generator P: 0.232477
Gradient discriminator: -0.898101
Gradient professor: -21.471630
Loss Generator D: 2.732650
Loss Generator P: 0.474816
Gradient discriminator: 1.050296
Gradient professor: 13.528561
Loss Generator D: 2.485033
Loss Generator P: 0.438027
Gradient discriminator: -6.390466
Gradient professor: 6.679540
Loss Generator D: 2.249173
Loss Generator P: 0.243992
Gradient discriminator: -0.023375
Gradient professor: 10.572602
Loss Generator D: 3.077548
Loss Generator P: 0.429412
Gradient discriminator: 4.200884
Gradient professor: 15.938723
Loss Generator D: 2.846173
Loss Generator P: 0.368182
Gradient discriminator: 3.390491
Gradient professor: -6.421257
Loss Generator D: 2.251504
Loss Generator P: 0.455691
Gradient discriminator: -20.407215
Gradient professor: 9.682389
Loss Generator D: 2.633584
Loss Generator P: 0.353838
Gradient discriminator: 15.277204
Gradient professor: -10.141390
Loss Generator D: 2.831808
Loss Generator P: 0.243555
Generator    : Epoch:     20, update:    4950, cost:   0.243555
Gradient discriminator: 7.179163
Gradient professor: 1.707006
Loss Generator D: 2.878704
Loss Generator P: 0.382725
Gradient discriminator: -6.509266
Gradient professor: -10.759308
Loss Generator D: 2.575315
Loss Generator P: 0.282591
Gradient discriminator: 0.976994
Gradient professor: 2.735657
Loss Generator D: 2.892806
Loss Generator P: 0.264528
Gradient discriminator: 4.525532
Gradient professor: -7.932786
Loss Generator D: 2.764727
Loss Generator P: 0.284649
Gradient discriminator: 12.200528
Gradient professor: -3.442629
Loss Generator D: 2.428519
Loss Generator P: 0.261324
Gradient discriminator: 2.798121
Gradient professor: 5.461492
Loss Generator D: 2.475135
Loss Generator P: 0.207107
Gradient discriminator: -0.207278
Gradient professor: -3.361474
Loss Generator D: 3.310292
Loss Generator P: 0.333084
Gradient discriminator: -2.548700
Gradient professor: -1.927799
Loss Generator D: 2.779217
Loss Generator P: 0.349959
Gradient discriminator: -11.078497
Gradient professor: -3.565398
Loss Generator D: 2.256818
Loss Generator P: 0.292073
Gradient discriminator: 2.158944
Gradient professor: 9.603619
Loss Generator D: 2.506776
Loss Generator P: 0.365790
Generator    : Epoch:     20, update:    4960, cost:   0.365790
Gradient discriminator: -5.785894
Gradient professor: -1.132204
Loss Generator D: 2.771045
Loss Generator P: 0.376110
Gradient discriminator: -0.333802
Gradient professor: 14.593211
Loss Generator D: 2.457370
Loss Generator P: 0.382407
Gradient discriminator: 5.917040
Gradient professor: 7.588502
Loss Generator D: 2.956586
Loss Generator P: 0.276873
Gradient discriminator: -1.539200
Gradient professor: 5.144266
Loss Generator D: 2.091752
Loss Generator P: 0.277008
Gradient discriminator: -3.909960
Gradient professor: 2.333573
Loss Generator D: 2.943113
Loss Generator P: 0.354134
Gradient discriminator: -6.550831
Gradient professor: 13.225851
Loss Generator D: 2.754955
Loss Generator P: 0.371233
Gradient discriminator: 4.157987
Gradient professor: -5.072951
Loss Generator D: 2.751517
Loss Generator P: 0.341886
Gradient discriminator: 5.038797
Gradient professor: -5.359671
Loss Generator D: 2.114692
Loss Generator P: 0.310047
Gradient discriminator: 8.038503
Gradient professor: 9.613344
Loss Generator D: 2.347572
Loss Generator P: 0.273516
Gradient discriminator: -1.939950
Gradient professor: 1.556861
Loss Generator D: 2.364389
Loss Generator P: 0.262747
Generator    : Epoch:     20, update:    4970, cost:   0.262747
Gradient discriminator: 5.539715
Gradient professor: -2.124702
Loss Generator D: 2.583416
Loss Generator P: 0.369238
Gradient discriminator: -25.137195
Gradient professor: -7.281110
Loss Generator D: 2.320360
Loss Generator P: 0.288347
Gradient discriminator: 2.739080
Gradient professor: -13.251946
Loss Generator D: 2.232502
Loss Generator P: 0.329534
Gradient discriminator: 3.165783
Gradient professor: 4.667203
Loss Generator D: 2.738174
Loss Generator P: 0.233734
Gradient discriminator: -12.737633
Gradient professor: -4.582130
Loss Generator D: 2.684722
Loss Generator P: 0.227293
Gradient discriminator: -17.804210
Gradient professor: -6.092182
Loss Generator D: 2.337617
Loss Generator P: 0.310144
Gradient discriminator: 0.909791
Gradient professor: 10.588631
Loss Generator D: 2.648867
Loss Generator P: 0.260569
Gradient discriminator: 2.897788
Gradient professor: 7.689262
Loss Generator D: 2.709909
Loss Generator P: 0.282002
Gradient discriminator: 2.506287
Gradient professor: 8.359252
Loss Generator D: 2.639827
Loss Generator P: 0.291682
Gradient discriminator: -9.365136
Gradient professor: -14.426017
Loss Generator D: 2.657915
Loss Generator P: 0.298868
Generator    : Epoch:     20, update:    4980, cost:   0.298868
Gradient discriminator: -1.674545
Gradient professor: -29.155497
Loss Generator D: 2.800035
Loss Generator P: 0.433164
Gradient discriminator: 4.520313
Gradient professor: 6.418339
Loss Generator D: 2.510898
Loss Generator P: 0.426980
Gradient discriminator: 0.980981
Gradient professor: -4.211247
Loss Generator D: 2.823348
Loss Generator P: 0.435231
Gradient discriminator: -0.242941
Gradient professor: 6.726345
Loss Generator D: 2.628994
Loss Generator P: 0.194492
Gradient discriminator: -0.040892
Gradient professor: 5.952405
Loss Generator D: 2.381262
Loss Generator P: 0.334392
Gradient discriminator: -4.185759
Gradient professor: -13.329169
Loss Generator D: 2.504981
Loss Generator P: 0.267797
Gradient discriminator: 1.884850
Gradient professor: 7.209188
Loss Generator D: 2.628807
Loss Generator P: 0.211386
Gradient discriminator: 0.074699
Gradient professor: -12.612211
Loss Generator D: 2.347688
Loss Generator P: 0.335750
Gradient discriminator: -0.105646
Gradient professor: 2.761019
Loss Generator D: 2.613947
Loss Generator P: 0.256069
Gradient discriminator: -0.293851
Gradient professor: 3.406784
Loss Generator D: 2.722282
Loss Generator P: 0.276370
Generator    : Epoch:     20, update:    4990, cost:   0.276370
Gradient discriminator: 6.935623
Gradient professor: -26.447254
Loss Generator D: 2.573009
Loss Generator P: 0.287276
Gradient discriminator: -15.239286
Gradient professor: 5.572062
Loss Generator D: 2.657209
Loss Generator P: 0.309300
Gradient discriminator: -6.541725
Gradient professor: 2.452696
Loss Generator D: 2.655193
Loss Generator P: 0.265474
Gradient discriminator: 9.010866
Gradient professor: -2.056290
Loss Generator D: 2.490450
Loss Generator P: 0.257872
Gradient discriminator: 9.303507
Gradient professor: 4.317872
Loss Generator D: 3.286827
Loss Generator P: 0.265561
Gradient discriminator: -0.711086
Gradient professor: 2.443967
Loss Generator D: 3.142337
Loss Generator P: 0.244507
Gradient discriminator: 6.345524
Gradient professor: -3.333272
Loss Generator D: 2.893389
Loss Generator P: 0.262617
Gradient discriminator: 5.751254
Gradient professor: 17.351349
Loss Generator D: 2.910578
Loss Generator P: 0.173232
Gradient discriminator: 0.997680
Gradient professor: -11.151637
Loss Generator D: 2.766982
Loss Generator P: 0.261658
Gradient discriminator: 7.167364
Gradient professor: -2.276624
Loss Generator D: 3.117670
Loss Generator P: 0.184376
Generator    : Epoch:     20, update:    5000, cost:   0.184376
Validation 50 - LOSS = 1.714 (PPL: 5.552)
Calling beam-search process
Beam-search ended, took 1.53716 minutes.
Validation 50 - BLEU = 16.56, 29.3/19.2/13.7/9.7 (BP=1.000, ratio=2.232, hyp_len=9418, ref_len=4220)
Early stopping patience: 993 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 20 finished with mean loss 1.48470 (PPL: 4.41365)
--> Epoch took 220.530 minutes, 52.927 sec/update
Epoch summary of Discriminator:
--> Epoch 20 finished with mean loss nan (PPL:  nan)
--> Epoch took 220.530 minutes, 52.927 sec/update
---------------------------------------------------------
Starting Epoch 21
-----------------
Gradient discriminator: 2.446640
Gradient professor: -6.634645
Loss Generator D: 2.673212
Loss Generator P: 0.433417
Gradient discriminator: 4.394939
Gradient professor: 2.556296
Loss Generator D: 3.043004
Loss Generator P: 0.290140
Gradient discriminator: 9.089038
Gradient professor: 7.176683
Loss Generator D: 3.379042
Loss Generator P: 0.386061
Gradient discriminator: -1.012073
Gradient professor: 10.833758
Loss Generator D: 2.731378
Loss Generator P: 0.427127
Gradient discriminator: 2.135149
Gradient professor: 3.450071
Loss Generator D: 3.007200
Loss Generator P: 0.241516
Gradient discriminator: -1.914053
Gradient professor: -20.763853
Loss Generator D: 2.800050
Loss Generator P: 0.320245
Gradient discriminator: -3.249757
Gradient professor: -12.024947
Loss Generator D: 3.121653
Loss Generator P: 0.312560
Gradient discriminator: 8.139681
Gradient professor: 7.975919
Loss Generator D: 2.441249
Loss Generator P: 0.275134
Gradient discriminator: 7.224508
Gradient professor: 19.441119
Loss Generator D: 3.078169
Loss Generator P: 0.368554
Gradient discriminator: -0.491150
Gradient professor: -8.740133
Loss Generator D: 2.590270
Loss Generator P: 0.425633
Generator    : Epoch:     21, update:    5010, cost:   0.425633
Gradient discriminator: 8.677710
Gradient professor: 1.980945
Loss Generator D: 3.421211
Loss Generator P: 0.438612
Gradient discriminator: 7.388796
Gradient professor: -15.940583
Loss Generator D: 3.469552
Loss Generator P: 0.333267
Gradient discriminator: 0.983911
Gradient professor: 0.973405
Loss Generator D: 2.989996
Loss Generator P: 0.437133
Gradient discriminator: -4.118371
Gradient professor: -3.902988
Loss Generator D: 3.242331
Loss Generator P: 0.358098
Gradient discriminator: -1.970356
Gradient professor: 8.545488
Loss Generator D: 3.177786
Loss Generator P: 0.205378
Gradient discriminator: -2.192819
Gradient professor: 8.660367
Loss Generator D: 2.946097
Loss Generator P: 0.199025
Gradient discriminator: 3.416464
Gradient professor: 4.006314
Loss Generator D: 3.135229
Loss Generator P: 0.273180
Gradient discriminator: 7.284967
Gradient professor: -2.275695
Loss Generator D: 3.318408
Loss Generator P: 0.312748
Gradient discriminator: 1.034706
Gradient professor: 5.447809
Loss Generator D: 3.485444
Loss Generator P: 0.317024
Gradient discriminator: 6.822059
Gradient professor: 11.327169
Loss Generator D: 2.766515
Loss Generator P: 0.320304
Generator    : Epoch:     21, update:    5020, cost:   0.320304
Gradient discriminator: 3.473011
Gradient professor: -16.785730
Loss Generator D: 3.123621
Loss Generator P: 0.295574
Gradient discriminator: 11.258281
Gradient professor: -11.449404
Loss Generator D: 3.125305
Loss Generator P: 0.285209
Gradient discriminator: -9.231217
Gradient professor: 9.836886
Loss Generator D: 3.081040
Loss Generator P: 0.278935
Gradient discriminator: 5.336139
Gradient professor: -10.975211
Loss Generator D: 3.164719
Loss Generator P: 0.460097
Gradient discriminator: 6.788593
Gradient professor: 4.984328
Loss Generator D: 3.656895
Loss Generator P: 0.479252
Gradient discriminator: 1.906554
Gradient professor: -1.713389
Loss Generator D: 3.363804
Loss Generator P: 0.288074
Gradient discriminator: -8.874931
Gradient professor: -10.949432
Loss Generator D: 2.691279
Loss Generator P: 0.230767
Gradient discriminator: -5.072275
Gradient professor: -4.886072
Loss Generator D: 2.742880
Loss Generator P: 0.273388
Gradient discriminator: -9.908926
Gradient professor: 5.388309
Loss Generator D: 2.821888
Loss Generator P: 0.221102
Gradient discriminator: -0.028548
Gradient professor: 7.534903
Loss Generator D: 2.816976
Loss Generator P: 0.272899
Generator    : Epoch:     21, update:    5030, cost:   0.272899
Gradient discriminator: 6.827314
Gradient professor: -5.884787
Loss Generator D: 3.130532
Loss Generator P: 0.240246
Gradient discriminator: 4.124821
Gradient professor: 10.345767
Loss Generator D: 3.121541
Loss Generator P: 0.268032
Gradient discriminator: 1.766622
Gradient professor: 25.482944
Loss Generator D: 3.445773
Loss Generator P: 0.438392
Gradient discriminator: -4.199509
Gradient professor: 9.227689
Loss Generator D: 2.991493
Loss Generator P: 0.434595
Gradient discriminator: 2.117618
Gradient professor: 6.314273
Loss Generator D: 2.942645
Loss Generator P: 0.279819
Gradient discriminator: -1.394392
Gradient professor: 2.402953
Loss Generator D: 2.777167
Loss Generator P: 0.233408
Gradient discriminator: 2.823731
Gradient professor: 0.305796
Loss Generator D: 2.796740
Loss Generator P: 0.247776
Gradient discriminator: -29.281091
Gradient professor: -6.684242
Loss Generator D: 2.960906
Loss Generator P: 0.255383
Gradient discriminator: 1.856613
Gradient professor: 16.205458
Loss Generator D: 2.752651
Loss Generator P: 0.267567
Gradient discriminator: -2.155246
Gradient professor: -15.772921
Loss Generator D: 2.887746
Loss Generator P: 0.427562
Generator    : Epoch:     21, update:    5040, cost:   0.427562
Gradient discriminator: 4.125115
Gradient professor: 10.062225
Loss Generator D: 2.700230
Loss Generator P: 0.289858
Gradient discriminator: 2.519053
Gradient professor: 7.533945
Loss Generator D: 3.140365
Loss Generator P: 0.330114
Gradient discriminator: 1.489414
Gradient professor: -21.680138
Loss Generator D: 3.199306
Loss Generator P: 0.292368
Gradient discriminator: 6.807077
Gradient professor: 11.829279
Loss Generator D: 3.131992
Loss Generator P: 0.258445
Gradient discriminator: 1.420414
Gradient professor: -13.690028
Loss Generator D: 2.996353
Loss Generator P: 0.363429
Gradient discriminator: -1.108901
Gradient professor: 26.795810
Loss Generator D: 2.598058
Loss Generator P: 0.344050
Gradient discriminator: -0.773651
Gradient professor: 2.305124
Loss Generator D: 2.910477
Loss Generator P: 0.233157
Gradient discriminator: -6.932754
Gradient professor: -4.791897
Loss Generator D: 2.786048
Loss Generator P: 0.361753
Gradient discriminator: 2.649934
Gradient professor: -23.326544
Loss Generator D: 3.003074
Loss Generator P: 0.475828
Gradient discriminator: -0.154618
Gradient professor: 2.095234
Loss Generator D: 2.813219
Loss Generator P: 0.294850
Generator    : Epoch:     21, update:    5050, cost:   0.294850
Gradient discriminator: 1.206790
Gradient professor: 33.028552
Loss Generator D: 2.687364
Loss Generator P: 0.322773
Gradient discriminator: 1.234299
Gradient professor: -4.236928
Loss Generator D: 2.872945
Loss Generator P: 0.318085
Gradient discriminator: -8.503070
Gradient professor: 6.546400
Loss Generator D: 2.072580
Loss Generator P: 0.252985
Gradient discriminator: -7.910584
Gradient professor: 30.520329
Loss Generator D: 2.588449
Loss Generator P: 0.359649
Gradient discriminator: 0.579023
Gradient professor: -13.955989
Loss Generator D: 2.674792
Loss Generator P: 0.336358
Gradient discriminator: 7.315515
Gradient professor: 12.468771
Loss Generator D: 2.686701
Loss Generator P: 0.224303
Gradient discriminator: 4.789134
Gradient professor: -13.966631
Loss Generator D: 2.066069
Loss Generator P: 0.261812
Gradient discriminator: 7.775260
Gradient professor: 2.356241
Loss Generator D: 2.600806
Loss Generator P: 0.219347
Gradient discriminator: 15.630546
Gradient professor: -2.965106
Loss Generator D: 2.864716
Loss Generator P: 0.237134
Gradient discriminator: 0.930880
Gradient professor: 7.725699
Loss Generator D: 2.968449
Loss Generator P: 0.276085
Generator    : Epoch:     21, update:    5060, cost:   0.276085
Gradient discriminator: 24.281963
Gradient professor: 3.608260
Loss Generator D: 2.101879
Loss Generator P: 0.339248
Gradient discriminator: 5.552220
Gradient professor: -10.673620
Loss Generator D: 2.427149
Loss Generator P: 0.446760
Gradient discriminator: -3.521167
Gradient professor: 8.190641
Loss Generator D: 2.174420
Loss Generator P: 0.354481
Gradient discriminator: -4.776990
Gradient professor: 8.121489
Loss Generator D: 2.378461
Loss Generator P: 0.263589
Gradient discriminator: -10.471935
Gradient professor: 7.799125
Loss Generator D: 2.382643
Loss Generator P: 0.349839
Gradient discriminator: 43.133279
Gradient professor: -4.106534
Loss Generator D: 2.055296
Loss Generator P: 0.287036
Gradient discriminator: 1.330622
Gradient professor: 24.110153
Loss Generator D: 2.666397
Loss Generator P: 0.316758
Gradient discriminator: 0.389631
Gradient professor: 7.167154
Loss Generator D: 2.508055
Loss Generator P: 0.232454
Gradient discriminator: 14.293000
Gradient professor: 9.513555
Loss Generator D: 2.279435
Loss Generator P: 0.369859
Gradient discriminator: 4.033303
Gradient professor: -15.307182
Loss Generator D: 2.256229
Loss Generator P: 0.263538
Generator    : Epoch:     21, update:    5070, cost:   0.263538
Gradient discriminator: 4.021185
Gradient professor: 4.060753
Loss Generator D: 2.377170
Loss Generator P: 0.207700
Gradient discriminator: 12.994462
Gradient professor: -10.004569
Loss Generator D: 2.357684
Loss Generator P: 0.222224
Gradient discriminator: 7.265643
Gradient professor: -9.197086
Loss Generator D: 2.039551
Loss Generator P: 0.274378
Gradient discriminator: 8.475916
Gradient professor: -4.830408
Loss Generator D: 2.020874
Loss Generator P: 0.370333
Gradient discriminator: 2.310773
Gradient professor: 7.078088
Loss Generator D: 2.064034
Loss Generator P: 0.258222
Gradient discriminator: 16.963017
Gradient professor: 5.808627
Loss Generator D: 1.870534
Loss Generator P: 0.226352
Gradient discriminator: 6.659273
Gradient professor: -11.982885
Loss Generator D: 2.454273
Loss Generator P: 0.246498
Gradient discriminator: 6.767231
Gradient professor: -3.389245
Loss Generator D: 2.357608
Loss Generator P: 0.337851
Gradient discriminator: 6.285385
Gradient professor: 2.533814
Loss Generator D: 1.976762
Loss Generator P: 0.157961
Gradient discriminator: 0.215282
Gradient professor: -3.102301
Loss Generator D: 2.117687
Loss Generator P: 0.222960
Generator    : Epoch:     21, update:    5080, cost:   0.222960
Gradient discriminator: -4.966924
Gradient professor: 10.141277
Loss Generator D: 2.504973
Loss Generator P: 0.251786
Gradient discriminator: -2.168401
Gradient professor: 5.252667
Loss Generator D: 2.512785
Loss Generator P: 0.212775
Gradient discriminator: 0.742924
Gradient professor: 6.212752
Loss Generator D: 2.368628
Loss Generator P: 0.249203
Gradient discriminator: -2.199997
Gradient professor: -0.035449
Loss Generator D: 2.296941
Loss Generator P: 0.213313
Gradient discriminator: 3.966240
Gradient professor: 7.752214
Loss Generator D: 2.141073
Loss Generator P: 0.170280
Gradient discriminator: -1.809948
Gradient professor: 2.666824
Loss Generator D: 2.208323
Loss Generator P: 0.170812
Gradient discriminator: 0.307261
Gradient professor: -17.704588
Loss Generator D: 2.287935
Loss Generator P: 0.179196
Gradient discriminator: -6.861383
Gradient professor: -2.033930
Loss Generator D: 2.419358
Loss Generator P: 0.353678
Gradient discriminator: -1.763718
Gradient professor: 6.716329
Loss Generator D: 2.687723
Loss Generator P: 0.259380
Gradient discriminator: -15.770797
Gradient professor: 8.786226
Loss Generator D: 2.375937
Loss Generator P: 0.325781
Generator    : Epoch:     21, update:    5090, cost:   0.325781
Gradient discriminator: -5.002753
Gradient professor: 13.979967
Loss Generator D: 2.524633
Loss Generator P: 0.262113
Gradient discriminator: -0.904013
Gradient professor: -2.408409
Loss Generator D: 2.302505
Loss Generator P: 0.381490
Gradient discriminator: 3.104014
Gradient professor: 8.198750
Loss Generator D: 2.357508
Loss Generator P: 0.232385
Gradient discriminator: 1.202923
Gradient professor: -2.190069
Loss Generator D: 2.454927
Loss Generator P: 0.204490
Gradient discriminator: -10.657288
Gradient professor: 2.613775
Loss Generator D: 2.627203
Loss Generator P: 0.254651
Gradient discriminator: -7.271318
Gradient professor: -8.310377
Loss Generator D: 2.467716
Loss Generator P: 0.279130
Gradient discriminator: 11.465457
Gradient professor: 5.142214
Loss Generator D: 2.930981
Loss Generator P: 0.289238
Gradient discriminator: 5.902245
Gradient professor: 5.570192
Loss Generator D: 2.574731
Loss Generator P: 0.212796
Gradient discriminator: -7.910881
Gradient professor: -1.934176
Loss Generator D: 3.199619
Loss Generator P: 0.234579
Gradient discriminator: -3.342025
Gradient professor: 2.541471
Loss Generator D: 3.000021
Loss Generator P: 0.261187
Generator    : Epoch:     21, update:    5100, cost:   0.261187
Validation 51 - LOSS = 1.718 (PPL: 5.575)
Calling beam-search process
Beam-search ended, took 1.65318 minutes.
Validation 51 - BLEU = 14.91, 26.5/17.5/12.3/8.7 (BP=1.000, ratio=2.459, hyp_len=10377, ref_len=4220)
Early stopping patience: 992 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -0.969458
Gradient professor: -4.314210
Loss Generator D: 3.001239
Loss Generator P: 0.297500
Gradient discriminator: -5.158780
Gradient professor: -11.775406
Loss Generator D: 2.544116
Loss Generator P: 0.274793
Gradient discriminator: 3.813412
Gradient professor: -7.428116
Loss Generator D: 2.631233
Loss Generator P: 0.217949
Gradient discriminator: -12.000351
Gradient professor: -1.997338
Loss Generator D: 2.373368
Loss Generator P: 0.250677
Gradient discriminator: 10.839353
Gradient professor: 4.797643
Loss Generator D: 2.813031
Loss Generator P: 0.173959
Gradient discriminator: -8.871199
Gradient professor: 5.322688
Loss Generator D: 2.788634
Loss Generator P: 0.293287
Gradient discriminator: 0.858538
Gradient professor: -2.565615
Loss Generator D: 2.215695
Loss Generator P: 0.165163
Gradient discriminator: -2.007048
Gradient professor: 17.444747
Loss Generator D: 2.566942
Loss Generator P: 0.295881
Gradient discriminator: 2.301765
Gradient professor: 3.605944
Loss Generator D: 2.969017
Loss Generator P: 0.299492
Gradient discriminator: -2.755954
Gradient professor: 3.225046
Loss Generator D: 2.687967
Loss Generator P: 0.299360
Generator    : Epoch:     21, update:    5110, cost:   0.299360
Gradient discriminator: -1.158078
Gradient professor: -9.318417
Loss Generator D: 2.647757
Loss Generator P: 0.313715
Gradient discriminator: 2.924316
Gradient professor: 21.207105
Loss Generator D: 2.708452
Loss Generator P: 0.220633
Gradient discriminator: -1.872046
Gradient professor: 6.009085
Loss Generator D: 3.228156
Loss Generator P: 0.195236
Gradient discriminator: -2.973048
Gradient professor: -3.592888
Loss Generator D: 2.843808
Loss Generator P: 0.208595
Gradient discriminator: 4.514083
Gradient professor: 2.740711
Loss Generator D: 3.459047
Loss Generator P: 0.285860
Gradient discriminator: -0.992012
Gradient professor: -0.150378
Loss Generator D: 3.137305
Loss Generator P: 0.312144
Gradient discriminator: 3.508237
Gradient professor: 2.960053
Loss Generator D: 2.952415
Loss Generator P: 0.169617
Gradient discriminator: 19.239895
Gradient professor: -1.816496
Loss Generator D: 3.626354
Loss Generator P: 0.359529
Gradient discriminator: -1.333698
Gradient professor: -9.814080
Loss Generator D: 3.522649
Loss Generator P: 0.215372
Gradient discriminator: -1.018772
Gradient professor: -10.710962
Loss Generator D: 3.296013
Loss Generator P: 0.229683
Generator    : Epoch:     21, update:    5120, cost:   0.229683
Gradient discriminator: -7.517995
Gradient professor: -14.085901
Loss Generator D: 3.330911
Loss Generator P: 0.262266
Gradient discriminator: 4.748612
Gradient professor: -8.777823
Loss Generator D: 3.058669
Loss Generator P: 0.265487
Gradient discriminator: 9.812038
Gradient professor: 3.110172
Loss Generator D: 3.207644
Loss Generator P: 0.277068
Gradient discriminator: 10.634062
Gradient professor: 27.934695
Loss Generator D: 2.995939
Loss Generator P: 0.296020
Gradient discriminator: 11.853512
Gradient professor: -0.611697
Loss Generator D: 2.843195
Loss Generator P: 0.320459
Gradient discriminator: 0.536834
Gradient professor: 14.037895
Loss Generator D: 2.864302
Loss Generator P: 0.307618
Gradient discriminator: -2.046078
Gradient professor: 5.437437
Loss Generator D: 2.883948
Loss Generator P: 0.306451
Gradient discriminator: 0.802171
Gradient professor: 20.432771
Loss Generator D: 3.240097
Loss Generator P: 0.327921
Gradient discriminator: 2.006402
Gradient professor: -14.433764
Loss Generator D: 3.417697
Loss Generator P: 0.369828
Gradient discriminator: -6.812956
Gradient professor: -20.588034
Loss Generator D: 3.530976
Loss Generator P: 0.282015
Generator    : Epoch:     21, update:    5130, cost:   0.282015
Gradient discriminator: -1.550322
Gradient professor: -1.623131
Loss Generator D: 3.114170
Loss Generator P: 0.220398
Gradient discriminator: 0.670111
Gradient professor: -8.320253
Loss Generator D: 3.047155
Loss Generator P: 0.279584
Gradient discriminator: 4.731976
Gradient professor: 16.152471
Loss Generator D: 2.312513
Loss Generator P: 0.233447
Gradient discriminator: -2.018575
Gradient professor: -14.103096
Loss Generator D: 2.756045
Loss Generator P: 0.413386
Gradient discriminator: -1.500360
Gradient professor: 9.614783
Loss Generator D: 2.144285
Loss Generator P: 0.243862
Gradient discriminator: -4.384925
Gradient professor: -10.537127
Loss Generator D: 2.922971
Loss Generator P: 0.199650
Gradient discriminator: -7.248064
Gradient professor: -20.198718
Loss Generator D: 2.798424
Loss Generator P: 0.220670
Gradient discriminator: 4.324972
Gradient professor: -15.057927
Loss Generator D: 2.574069
Loss Generator P: 0.189876
Gradient discriminator: 4.488816
Gradient professor: 4.498607
Loss Generator D: 2.117236
Loss Generator P: 0.352065
Gradient discriminator: -5.873311
Gradient professor: 11.967651
Loss Generator D: 2.096947
Loss Generator P: 0.283441
Generator    : Epoch:     21, update:    5140, cost:   0.283441
Gradient discriminator: -12.876039
Gradient professor: -6.781291
Loss Generator D: 2.038682
Loss Generator P: 0.218244
Gradient discriminator: 8.689774
Gradient professor: 12.786721
Loss Generator D: 2.212584
Loss Generator P: 0.296277
Gradient discriminator: -2.832728
Gradient professor: -7.862367
Loss Generator D: 2.107546
Loss Generator P: 0.406804
Gradient discriminator: -3.493506
Gradient professor: -11.481195
Loss Generator D: 2.392461
Loss Generator P: 0.297494
Gradient discriminator: 6.844692
Gradient professor: -11.629452
Loss Generator D: 1.969881
Loss Generator P: 0.404713
Gradient discriminator: 2.178920
Gradient professor: 1.971231
Loss Generator D: 2.233849
Loss Generator P: 0.323858
Gradient discriminator: -7.353245
Gradient professor: 0.394883
Loss Generator D: 2.402210
Loss Generator P: 0.200046
Gradient discriminator: -0.538595
Gradient professor: 18.755930
Loss Generator D: 2.383812
Loss Generator P: 0.244661
Gradient discriminator: -20.156021
Gradient professor: -8.247128
Loss Generator D: 2.499374
Loss Generator P: 0.220513
Gradient discriminator: 8.212744
Gradient professor: -2.580314
Loss Generator D: 2.716307
Loss Generator P: 0.181443
Generator    : Epoch:     21, update:    5150, cost:   0.181443
Gradient discriminator: 4.991905
Gradient professor: 4.718380
Loss Generator D: 2.478515
Loss Generator P: 0.344903
Gradient discriminator: 1.983254
Gradient professor: 0.204511
Loss Generator D: 2.634710
Loss Generator P: 0.329648
Gradient discriminator: 3.174945
Gradient professor: 7.097398
Loss Generator D: 2.404254
Loss Generator P: 0.285532
Gradient discriminator: -2.392231
Gradient professor: -6.096506
Loss Generator D: 2.779879
Loss Generator P: 0.248120
Gradient discriminator: -2.983697
Gradient professor: 0.578058
Loss Generator D: 2.363279
Loss Generator P: 0.323571
Gradient discriminator: -4.270067
Gradient professor: -8.606298
Loss Generator D: 2.313117
Loss Generator P: 0.244382
Gradient discriminator: 9.962323
Gradient professor: -31.372866
Loss Generator D: 2.585764
Loss Generator P: 0.271716
Gradient discriminator: 2.103374
Gradient professor: -4.534173
Loss Generator D: 2.268917
Loss Generator P: 0.204272
Gradient discriminator: 9.463479
Gradient professor: 6.438943
Loss Generator D: 2.575134
Loss Generator P: 0.198211
Gradient discriminator: 1.746069
Gradient professor: -2.148539
Loss Generator D: 2.331580
Loss Generator P: 0.314452
Generator    : Epoch:     21, update:    5160, cost:   0.314452
Gradient discriminator: -0.941419
Gradient professor: 2.684530
Loss Generator D: 2.598459
Loss Generator P: 0.283279
Gradient discriminator: 4.582643
Gradient professor: 19.325422
Loss Generator D: 2.521195
Loss Generator P: 0.350196
Gradient discriminator: -3.706704
Gradient professor: 3.468651
Loss Generator D: 2.208286
Loss Generator P: 0.365044
Gradient discriminator: 5.873870
Gradient professor: 6.198434
Loss Generator D: 2.257251
Loss Generator P: 0.386515
Gradient discriminator: 13.861447
Gradient professor: -8.418340
Loss Generator D: 1.884797
Loss Generator P: 0.454875
Gradient discriminator: 4.175650
Gradient professor: 13.236066
Loss Generator D: 2.147909
Loss Generator P: 0.375009
Gradient discriminator: -2.671919
Gradient professor: 22.925600
Loss Generator D: 1.683575
Loss Generator P: 0.391576
Gradient discriminator: -3.123787
Gradient professor: -7.025244
Loss Generator D: 1.894782
Loss Generator P: 0.229977
Gradient discriminator: 1.178700
Gradient professor: -3.753664
Loss Generator D: 2.044852
Loss Generator P: 0.292534
Gradient discriminator: -1.324757
Gradient professor: 8.483210
Loss Generator D: 2.700930
Loss Generator P: 0.367693
Generator    : Epoch:     21, update:    5170, cost:   0.367693
Gradient discriminator: 0.973611
Gradient professor: -6.502163
Loss Generator D: 2.657583
Loss Generator P: 0.225419
Gradient discriminator: -2.961521
Gradient professor: -1.070220
Loss Generator D: 1.946941
Loss Generator P: 0.224321
Gradient discriminator: 5.743388
Gradient professor: 18.053097
Loss Generator D: 2.216856
Loss Generator P: 0.260728
Gradient discriminator: -3.026297
Gradient professor: -2.895861
Loss Generator D: 1.917812
Loss Generator P: 0.176683
Gradient discriminator: -2.567006
Gradient professor: -11.047739
Loss Generator D: 2.209557
Loss Generator P: 0.201051
Gradient discriminator: -0.165988
Gradient professor: -6.601117
Loss Generator D: 2.079872
Loss Generator P: 0.320375
Gradient discriminator: -3.354491
Gradient professor: -13.162099
Loss Generator D: 1.851737
Loss Generator P: 0.327053
Gradient discriminator: -13.683979
Gradient professor: 40.962121
Loss Generator D: 1.995442
Loss Generator P: 0.434811
Gradient discriminator: 9.334122
Gradient professor: -9.405332
Loss Generator D: 1.998485
Loss Generator P: 0.416753
Gradient discriminator: -0.001145
Gradient professor: 11.077151
Loss Generator D: 2.332406
Loss Generator P: 0.214614
Generator    : Epoch:     21, update:    5180, cost:   0.214614
Gradient discriminator: 2.192180
Gradient professor: -4.945727
Loss Generator D: 2.385763
Loss Generator P: 0.260685
Gradient discriminator: -18.339025
Gradient professor: -6.647715
Loss Generator D: 2.242893
Loss Generator P: 0.280014
Gradient discriminator: -3.591767
Gradient professor: 5.674740
Loss Generator D: 2.160558
Loss Generator P: 0.318947
Gradient discriminator: 8.068099
Gradient professor: -2.353985
Loss Generator D: 2.296598
Loss Generator P: 0.416119
Gradient discriminator: -15.270260
Gradient professor: 9.948597
Loss Generator D: 2.569812
Loss Generator P: 0.352501
Gradient discriminator: 4.632943
Gradient professor: 0.435744
Loss Generator D: 2.339023
Loss Generator P: 0.236355
Gradient discriminator: -8.665415
Gradient professor: -3.047346
Loss Generator D: 2.037863
Loss Generator P: 0.312722
Gradient discriminator: 0.751187
Gradient professor: 5.585886
Loss Generator D: 2.013763
Loss Generator P: 0.398248
Gradient discriminator: 2.320279
Gradient professor: 9.639316
Loss Generator D: 2.373712
Loss Generator P: 0.369046
Gradient discriminator: -4.087963
Gradient professor: -16.996143
Loss Generator D: 2.010870
Loss Generator P: 0.341076
Generator    : Epoch:     21, update:    5190, cost:   0.341076
Gradient discriminator: 3.104710
Gradient professor: 5.698930
Loss Generator D: 2.595741
Loss Generator P: 0.338355
Gradient discriminator: -4.853821
Gradient professor: -8.301525
Loss Generator D: 2.378610
Loss Generator P: 0.234219
Gradient discriminator: 5.794971
Gradient professor: -10.467767
Loss Generator D: 2.828704
Loss Generator P: 0.409394
Gradient discriminator: -9.339947
Gradient professor: 25.965624
Loss Generator D: 2.452750
Loss Generator P: 0.405208
Gradient discriminator: -0.569223
Gradient professor: 6.070372
Loss Generator D: 2.090608
Loss Generator P: 0.221518
Gradient discriminator: 0.448617
Gradient professor: 0.617390
Loss Generator D: 2.420960
Loss Generator P: 0.354352
Gradient discriminator: 0.196946
Gradient professor: 10.545050
Loss Generator D: 2.416870
Loss Generator P: 0.295262
Gradient discriminator: -5.328060
Gradient professor: 8.307393
Loss Generator D: 2.062832
Loss Generator P: 0.416213
Gradient discriminator: -4.986757
Gradient professor: 3.833177
Loss Generator D: 2.391475
Loss Generator P: 0.296449
Gradient discriminator: 3.816385
Gradient professor: 9.553570
Loss Generator D: 2.498072
Loss Generator P: 0.230762
Generator    : Epoch:     21, update:    5200, cost:   0.230762
Validation 52 - LOSS = 1.716 (PPL: 5.565)
Calling beam-search process
Beam-search ended, took 2.85165 minutes.
Validation 52 - BLEU = 5.14, 9.4/6.1/4.3/2.9 (BP=1.000, ratio=5.430, hyp_len=22913, ref_len=4220)
Early stopping patience: 991 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 11.599598
Gradient professor: 7.005557
Loss Generator D: 2.708985
Loss Generator P: 0.309889
Gradient discriminator: 2.724385
Gradient professor: -0.787428
Loss Generator D: 2.303378
Loss Generator P: 0.267823
Gradient discriminator: -4.764109
Gradient professor: 8.159560
Loss Generator D: 2.821279
Loss Generator P: 0.243127
Gradient discriminator: 3.562337
Gradient professor: -5.306049
Loss Generator D: 2.292495
Loss Generator P: 0.201688
Gradient discriminator: 2.136842
Gradient professor: 8.223159
Loss Generator D: 2.709210
Loss Generator P: 0.253792
Gradient discriminator: 4.803236
Gradient professor: -6.490139
Loss Generator D: 2.694565
Loss Generator P: 0.187865
Gradient discriminator: -12.488705
Gradient professor: -17.515795
Loss Generator D: 3.066633
Loss Generator P: 0.315337
Gradient discriminator: 1.095165
Gradient professor: -12.007704
Loss Generator D: 2.802896
Loss Generator P: 0.309943
Gradient discriminator: -2.188058
Gradient professor: 9.244167
Loss Generator D: 2.512615
Loss Generator P: 0.257742
Gradient discriminator: -0.558928
Gradient professor: -32.722190
Loss Generator D: 2.673017
Loss Generator P: 0.295872
Generator    : Epoch:     21, update:    5210, cost:   0.295872
Gradient discriminator: 0.739547
Gradient professor: 3.526433
Loss Generator D: 2.904908
Loss Generator P: 0.363736
Gradient discriminator: -0.787359
Gradient professor: 13.581551
Loss Generator D: 2.417958
Loss Generator P: 0.335093
Gradient discriminator: 4.125808
Gradient professor: 1.651471
Loss Generator D: 2.869945
Loss Generator P: 0.239735
Gradient discriminator: -4.422928
Gradient professor: -10.640652
Loss Generator D: 2.196950
Loss Generator P: 0.268332
Gradient discriminator: 42.900556
Gradient professor: 2.616913
Loss Generator D: 2.696662
Loss Generator P: 0.283428
Gradient discriminator: -2.188623
Gradient professor: 13.496767
Loss Generator D: 2.419294
Loss Generator P: 0.328650
Gradient discriminator: -3.085515
Gradient professor: 13.853726
Loss Generator D: 2.695708
Loss Generator P: 0.324852
Gradient discriminator: 4.315784
Gradient professor: -2.562098
Loss Generator D: 2.483629
Loss Generator P: 0.265158
Gradient discriminator: 8.710047
Gradient professor: -7.355791
Loss Generator D: 2.590448
Loss Generator P: 0.242834
Gradient discriminator: -0.730109
Gradient professor: -3.360345
Loss Generator D: 2.548166
Loss Generator P: 0.233145
Generator    : Epoch:     21, update:    5220, cost:   0.233145
Gradient discriminator: 1.179595
Gradient professor: -10.636141
Loss Generator D: 2.756863
Loss Generator P: 0.298330
Gradient discriminator: 10.663615
Gradient professor: -15.009975
Loss Generator D: 2.412837
Loss Generator P: 0.298935
Gradient discriminator: -5.201426
Gradient professor: -4.743837
Loss Generator D: 2.568786
Loss Generator P: 0.294785
Gradient discriminator: 1.014641
Gradient professor: -19.727384
Loss Generator D: 2.718577
Loss Generator P: 0.182109
Gradient discriminator: 4.048239
Gradient professor: 1.865254
Loss Generator D: 2.648203
Loss Generator P: 0.226884
Gradient discriminator: 5.688554
Gradient professor: 13.953319
Loss Generator D: 2.447810
Loss Generator P: 0.339512
Gradient discriminator: 5.013903
Gradient professor: 7.230131
Loss Generator D: 3.116381
Loss Generator P: 0.242593
Gradient discriminator: -1.414824
Gradient professor: 4.370737
Loss Generator D: 2.752053
Loss Generator P: 0.259680
Gradient discriminator: -1.530560
Gradient professor: -0.759450
Loss Generator D: 2.904066
Loss Generator P: 0.303530
Gradient discriminator: -10.332920
Gradient professor: -4.977880
Loss Generator D: 2.697255
Loss Generator P: 0.235596
Generator    : Epoch:     21, update:    5230, cost:   0.235596
Gradient discriminator: 1.780912
Gradient professor: -19.022773
Loss Generator D: 3.137227
Loss Generator P: 0.385696
Gradient discriminator: -0.253099
Gradient professor: 4.514094
Loss Generator D: 2.753865
Loss Generator P: 0.447468
Gradient discriminator: 8.306776
Gradient professor: 6.678459
Loss Generator D: 2.825345
Loss Generator P: 0.435398
Gradient discriminator: -3.517619
Gradient professor: 2.359417
Loss Generator D: 2.827569
Loss Generator P: 0.163047
Gradient discriminator: 1.457203
Gradient professor: 1.397595
Loss Generator D: 2.482362
Loss Generator P: 0.335643
Gradient discriminator: 1.680897
Gradient professor: -8.152526
Loss Generator D: 2.707783
Loss Generator P: 0.230795
Gradient discriminator: 0.638190
Gradient professor: 7.549636
Loss Generator D: 2.643880
Loss Generator P: 0.210699
Gradient discriminator: -11.874923
Gradient professor: 7.022771
Loss Generator D: 2.557481
Loss Generator P: 0.317968
Gradient discriminator: 1.949397
Gradient professor: 26.604661
Loss Generator D: 2.751990
Loss Generator P: 0.275813
Gradient discriminator: 4.517882
Gradient professor: 0.596062
Loss Generator D: 2.780547
Loss Generator P: 0.253201
Generator    : Epoch:     21, update:    5240, cost:   0.253201
Gradient discriminator: 2.258136
Gradient professor: -5.662926
Loss Generator D: 2.729970
Loss Generator P: 0.271103
Gradient discriminator: 2.371184
Gradient professor: -6.182540
Loss Generator D: 2.684101
Loss Generator P: 0.275874
Gradient discriminator: 4.321388
Gradient professor: 9.534673
Loss Generator D: 2.489154
Loss Generator P: 0.239817
Gradient discriminator: -5.866427
Gradient professor: 8.616507
Loss Generator D: 2.550144
Loss Generator P: 0.236608
Gradient discriminator: 0.087858
Gradient professor: -12.617935
Loss Generator D: 3.004379
Loss Generator P: 0.266068
Gradient discriminator: 4.494862
Gradient professor: 2.915555
Loss Generator D: 3.070413
Loss Generator P: 0.213151
Gradient discriminator: 6.006617
Gradient professor: -3.228796
Loss Generator D: 2.943544
Loss Generator P: 0.243964
Gradient discriminator: -7.210644
Gradient professor: 3.698060
Loss Generator D: 2.924291
Loss Generator P: 0.150711
Gradient discriminator: 1.273088
Gradient professor: 4.193821
Loss Generator D: 2.436226
Loss Generator P: 0.245227
Gradient discriminator: 0.517014
Gradient professor: -2.322170
Loss Generator D: 2.426588
Loss Generator P: 0.125868
Generator    : Epoch:     21, update:    5250, cost:   0.125868
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 21 finished with mean loss 1.46157 (PPL: 4.31271)
--> Epoch took 268.216 minutes, 64.372 sec/update
Epoch summary of Discriminator:
--> Epoch 21 finished with mean loss nan (PPL:  nan)
--> Epoch took 268.216 minutes, 64.372 sec/update
---------------------------------------------------------
Starting Epoch 22
-----------------
Gradient discriminator: 1.690838
Gradient professor: -10.992923
Loss Generator D: 2.440318
Loss Generator P: 0.385510
Gradient discriminator: 0.823901
Gradient professor: 14.895496
Loss Generator D: 2.232547
Loss Generator P: 0.291276
Gradient discriminator: 0.705982
Gradient professor: 4.471514
Loss Generator D: 2.302716
Loss Generator P: 0.430337
Gradient discriminator: 3.675073
Gradient professor: -22.682950
Loss Generator D: 1.989569
Loss Generator P: 0.372005
Gradient discriminator: 6.204446
Gradient professor: -5.685057
Loss Generator D: 2.350297
Loss Generator P: 0.244627
Gradient discriminator: 5.402634
Gradient professor: -5.539543
Loss Generator D: 2.362351
Loss Generator P: 0.292592
Gradient discriminator: 4.317036
Gradient professor: 2.963805
Loss Generator D: 2.165462
Loss Generator P: 0.292089
Gradient discriminator: -2.120580
Gradient professor: -7.644261
Loss Generator D: 1.938239
Loss Generator P: 0.266361
Gradient discriminator: -5.146245
Gradient professor: -3.543027
Loss Generator D: 1.922951
Loss Generator P: 0.362610
Gradient discriminator: -9.060000
Gradient professor: 14.913576
Loss Generator D: 2.208211
Loss Generator P: 0.426100
Generator    : Epoch:     22, update:    5260, cost:   0.426100
Gradient discriminator: 0.768377
Gradient professor: 16.810463
Loss Generator D: 2.634383
Loss Generator P: 0.405041
Gradient discriminator: -10.701257
Gradient professor: 3.832486
Loss Generator D: 2.201448
Loss Generator P: 0.280188
Gradient discriminator: -2.061036
Gradient professor: -1.703957
Loss Generator D: 2.075740
Loss Generator P: 0.402845
Gradient discriminator: 1.044973
Gradient professor: 8.677399
Loss Generator D: 2.237631
Loss Generator P: 0.357045
Gradient discriminator: -1.505642
Gradient professor: -2.740768
Loss Generator D: 2.360213
Loss Generator P: 0.225093
Gradient discriminator: -3.807928
Gradient professor: 17.354086
Loss Generator D: 2.336583
Loss Generator P: 0.226763
Gradient discriminator: 0.751793
Gradient professor: -0.375370
Loss Generator D: 2.529974
Loss Generator P: 0.251942
Gradient discriminator: 7.548982
Gradient professor: -2.791031
Loss Generator D: 1.908427
Loss Generator P: 0.323309
Gradient discriminator: -5.857906
Gradient professor: -1.570534
Loss Generator D: 2.654593
Loss Generator P: 0.313304
Gradient discriminator: 0.596778
Gradient professor: 18.161574
Loss Generator D: 2.521941
Loss Generator P: 0.306787
Generator    : Epoch:     22, update:    5270, cost:   0.306787
Gradient discriminator: -3.233218
Gradient professor: -15.692849
Loss Generator D: 2.196762
Loss Generator P: 0.281597
Gradient discriminator: -1.588541
Gradient professor: 4.021607
Loss Generator D: 2.897411
Loss Generator P: 0.262800
Gradient discriminator: 0.560123
Gradient professor: -5.281098
Loss Generator D: 2.512754
Loss Generator P: 0.240888
Gradient discriminator: -1.572019
Gradient professor: 18.749952
Loss Generator D: 2.306208
Loss Generator P: 0.423117
Gradient discriminator: -11.834137
Gradient professor: -1.845420
Loss Generator D: 2.506880
Loss Generator P: 0.395371
Gradient discriminator: -1.026468
Gradient professor: 15.186065
Loss Generator D: 2.595584
Loss Generator P: 0.288520
Gradient discriminator: -1.330374
Gradient professor: -3.795098
Loss Generator D: 2.412265
Loss Generator P: 0.202800
Gradient discriminator: 5.800109
Gradient professor: 2.116573
Loss Generator D: 2.376014
Loss Generator P: 0.235646
Gradient discriminator: -8.815712
Gradient professor: 5.435403
Loss Generator D: 2.645413
Loss Generator P: 0.225628
Gradient discriminator: 6.125757
Gradient professor: 5.372165
Loss Generator D: 2.702839
Loss Generator P: 0.219573
Generator    : Epoch:     22, update:    5280, cost:   0.219573
Gradient discriminator: 2.757609
Gradient professor: -6.680156
Loss Generator D: 2.644849
Loss Generator P: 0.220744
Gradient discriminator: 0.168668
Gradient professor: -1.264772
Loss Generator D: 2.545998
Loss Generator P: 0.218234
Gradient discriminator: 2.658671
Gradient professor: 27.529702
Loss Generator D: 3.376137
Loss Generator P: 0.367149
Gradient discriminator: -4.020162
Gradient professor: 14.138814
Loss Generator D: 2.760176
Loss Generator P: 0.439128
Gradient discriminator: -3.857943
Gradient professor: -3.206335
Loss Generator D: 2.764919
Loss Generator P: 0.266858
Gradient discriminator: -0.179734
Gradient professor: 2.581629
Loss Generator D: 2.368755
Loss Generator P: 0.214152
Gradient discriminator: -12.389042
Gradient professor: -17.400440
Loss Generator D: 2.415664
Loss Generator P: 0.211091
Gradient discriminator: 2.298206
Gradient professor: -0.859673
Loss Generator D: 2.760543
Loss Generator P: 0.247606
Gradient discriminator: -1.851006
Gradient professor: 4.436672
Loss Generator D: 2.512993
Loss Generator P: 0.215566
Gradient discriminator: -4.609576
Gradient professor: 2.643320
Loss Generator D: 2.472833
Loss Generator P: 0.417687
Generator    : Epoch:     22, update:    5290, cost:   0.417687
Gradient discriminator: -1.949135
Gradient professor: -2.459524
Loss Generator D: 2.591982
Loss Generator P: 0.299148
Gradient discriminator: 2.195296
Gradient professor: 4.414762
Loss Generator D: 2.684584
Loss Generator P: 0.307687
Gradient discriminator: -1.789551
Gradient professor: 6.155693
Loss Generator D: 2.858513
Loss Generator P: 0.263931
Gradient discriminator: -0.336321
Gradient professor: -5.685212
Loss Generator D: 2.725564
Loss Generator P: 0.208587
Gradient discriminator: -0.313711
Gradient professor: 8.307601
Loss Generator D: 2.705519
Loss Generator P: 0.344042
Gradient discriminator: -3.362923
Gradient professor: -7.677036
Loss Generator D: 2.460613
Loss Generator P: 0.294659
Gradient discriminator: -2.492383
Gradient professor: 10.713106
Loss Generator D: 2.716483
Loss Generator P: 0.249187
Gradient discriminator: -9.500672
Gradient professor: 16.635417
Loss Generator D: 2.424873
Loss Generator P: 0.309263
Gradient discriminator: 0.102120
Gradient professor: -6.364177
Loss Generator D: 2.773263
Loss Generator P: 0.416348
Gradient discriminator: -5.979786
Gradient professor: -7.440377
Loss Generator D: 2.692752
Loss Generator P: 0.270938
Generator    : Epoch:     22, update:    5300, cost:   0.270938
Validation 53 - LOSS = 1.788 (PPL: 5.975)
Calling beam-search process
Beam-search ended, took 2.17751 minutes.
Validation 53 - BLEU = 11.51, 20.8/13.5/9.5/6.6 (BP=1.000, ratio=2.987, hyp_len=12605, ref_len=4220)
Early stopping patience: 990 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 2.382966
Gradient professor: 14.046421
Loss Generator D: 2.592193
Loss Generator P: 0.312477
Gradient discriminator: 2.065849
Gradient professor: 13.976492
Loss Generator D: 3.142793
Loss Generator P: 0.290995
Gradient discriminator: -2.864625
Gradient professor: -11.328529
Loss Generator D: 2.084651
Loss Generator P: 0.243677
Gradient discriminator: 2.038504
Gradient professor: 0.710812
Loss Generator D: 2.828722
Loss Generator P: 0.337521
Gradient discriminator: 15.635598
Gradient professor: 38.878318
Loss Generator D: 2.443672
Loss Generator P: 0.295649
Gradient discriminator: -5.119361
Gradient professor: -7.528343
Loss Generator D: 2.711837
Loss Generator P: 0.235049
Gradient discriminator: -2.301663
Gradient professor: -11.583705
Loss Generator D: 2.142224
Loss Generator P: 0.218475
Gradient discriminator: 3.353872
Gradient professor: 7.687326
Loss Generator D: 2.689029
Loss Generator P: 0.199350
Gradient discriminator: -3.563893
Gradient professor: -1.927764
Loss Generator D: 2.441663
Loss Generator P: 0.221111
Gradient discriminator: 5.879718
Gradient professor: 0.132800
Loss Generator D: 2.616265
Loss Generator P: 0.287836
Generator    : Epoch:     22, update:    5310, cost:   0.287836
Gradient discriminator: -3.518359
Gradient professor: -4.812537
Loss Generator D: 2.555907
Loss Generator P: 0.288689
Gradient discriminator: 0.639873
Gradient professor: -12.465848
Loss Generator D: 2.680246
Loss Generator P: 0.415285
Gradient discriminator: -5.341104
Gradient professor: 0.569650
Loss Generator D: 2.272728
Loss Generator P: 0.298510
Gradient discriminator: -7.685795
Gradient professor: 9.995923
Loss Generator D: 2.115360
Loss Generator P: 0.248740
Gradient discriminator: 2.699177
Gradient professor: -1.598159
Loss Generator D: 2.003020
Loss Generator P: 0.395041
Gradient discriminator: -1.695567
Gradient professor: -9.107834
Loss Generator D: 1.726928
Loss Generator P: 0.263809
Gradient discriminator: 4.513024
Gradient professor: 7.390317
Loss Generator D: 1.961223
Loss Generator P: 0.282116
Gradient discriminator: -5.190927
Gradient professor: 5.880587
Loss Generator D: 2.216434
Loss Generator P: 0.203510
Gradient discriminator: 17.103654
Gradient professor: 1.048759
Loss Generator D: 1.873507
Loss Generator P: 0.361685
Gradient discriminator: 3.071629
Gradient professor: 4.178791
Loss Generator D: 2.051034
Loss Generator P: 0.255847
Generator    : Epoch:     22, update:    5320, cost:   0.255847
Gradient discriminator: -13.772868
Gradient professor: 5.381801
Loss Generator D: 2.477705
Loss Generator P: 0.227238
Gradient discriminator: 4.813818
Gradient professor: 0.356925
Loss Generator D: 2.231236
Loss Generator P: 0.194921
Gradient discriminator: 2.601458
Gradient professor: 3.979714
Loss Generator D: 2.033308
Loss Generator P: 0.245856
Gradient discriminator: 7.465686
Gradient professor: 3.066182
Loss Generator D: 1.916820
Loss Generator P: 0.344589
Gradient discriminator: 9.493146
Gradient professor: 0.326506
Loss Generator D: 1.881718
Loss Generator P: 0.228508
Gradient discriminator: 9.007283
Gradient professor: 10.192525
Loss Generator D: 1.776209
Loss Generator P: 0.244212
Gradient discriminator: 14.448846
Gradient professor: -3.003131
Loss Generator D: 1.869888
Loss Generator P: 0.230735
Gradient discriminator: 6.316096
Gradient professor: -1.113372
Loss Generator D: 2.077391
Loss Generator P: 0.304124
Gradient discriminator: 3.305518
Gradient professor: 8.483255
Loss Generator D: 1.951687
Loss Generator P: 0.150696
Gradient discriminator: -5.788351
Gradient professor: 0.139138
Loss Generator D: 2.027865
Loss Generator P: 0.198756
Generator    : Epoch:     22, update:    5330, cost:   0.198756
Gradient discriminator: 12.850200
Gradient professor: 3.305515
Loss Generator D: 2.518068
Loss Generator P: 0.210869
Gradient discriminator: -6.356786
Gradient professor: 9.508271
Loss Generator D: 2.223646
Loss Generator P: 0.184531
Gradient discriminator: -10.537715
Gradient professor: 1.265552
Loss Generator D: 2.433389
Loss Generator P: 0.194702
Gradient discriminator: 4.802539
Gradient professor: -9.379966
Loss Generator D: 2.432802
Loss Generator P: 0.174451
Gradient discriminator: 0.033836
Gradient professor: 4.597864
Loss Generator D: 2.564131
Loss Generator P: 0.156367
Gradient discriminator: 0.674517
Gradient professor: 11.515208
Loss Generator D: 2.486935
Loss Generator P: 0.168550
Gradient discriminator: 7.319811
Gradient professor: -1.918985
Loss Generator D: 2.426005
Loss Generator P: 0.225307
Gradient discriminator: 8.937418
Gradient professor: -17.999574
Loss Generator D: 2.646723
Loss Generator P: 0.311778
Gradient discriminator: -0.852241
Gradient professor: -8.528423
Loss Generator D: 2.464003
Loss Generator P: 0.220035
Gradient discriminator: 1.279045
Gradient professor: 12.478150
Loss Generator D: 2.317598
Loss Generator P: 0.346026
Generator    : Epoch:     22, update:    5340, cost:   0.346026
Gradient discriminator: -6.301704
Gradient professor: 7.613517
Loss Generator D: 2.398882
Loss Generator P: 0.244181
Gradient discriminator: 4.066156
Gradient professor: 5.760324
Loss Generator D: 2.493192
Loss Generator P: 0.296439
Gradient discriminator: -2.103949
Gradient professor: 1.143047
Loss Generator D: 2.558370
Loss Generator P: 0.199156
Gradient discriminator: 1.417403
Gradient professor: 2.627577
Loss Generator D: 2.087929
Loss Generator P: 0.175567
Gradient discriminator: -13.702056
Gradient professor: -12.434271
Loss Generator D: 2.376022
Loss Generator P: 0.202070
Gradient discriminator: -10.384350
Gradient professor: -5.622043
Loss Generator D: 2.226124
Loss Generator P: 0.231684
Gradient discriminator: 3.900108
Gradient professor: -15.747948
Loss Generator D: 2.591206
Loss Generator P: 0.262006
Gradient discriminator: -5.753201
Gradient professor: -9.271737
Loss Generator D: 2.396002
Loss Generator P: 0.193332
Gradient discriminator: 1.799118
Gradient professor: 2.517834
Loss Generator D: 2.625367
Loss Generator P: 0.187058
Gradient discriminator: -4.466436
Gradient professor: -9.922055
Loss Generator D: 2.340059
Loss Generator P: 0.217933
Generator    : Epoch:     22, update:    5350, cost:   0.217933
Gradient discriminator: -0.235117
Gradient professor: 5.123336
Loss Generator D: 1.675297
Loss Generator P: 0.278890
Gradient discriminator: 4.608194
Gradient professor: -4.616036
Loss Generator D: 2.023779
Loss Generator P: 0.240676
Gradient discriminator: 2.612392
Gradient professor: -11.788170
Loss Generator D: 1.783152
Loss Generator P: 0.188933
Gradient discriminator: -0.534496
Gradient professor: 2.198969
Loss Generator D: 1.695197
Loss Generator P: 0.268779
Gradient discriminator: 3.822222
Gradient professor: 6.483573
Loss Generator D: 2.455545
Loss Generator P: 0.156314
Gradient discriminator: 7.411170
Gradient professor: 12.121990
Loss Generator D: 1.963961
Loss Generator P: 0.273541
Gradient discriminator: -1.571940
Gradient professor: -9.160015
Loss Generator D: 1.740892
Loss Generator P: 0.171779
Gradient discriminator: -11.552065
Gradient professor: 5.883983
Loss Generator D: 2.116969
Loss Generator P: 0.219876
Gradient discriminator: 0.196595
Gradient professor: 1.178729
Loss Generator D: 1.524707
Loss Generator P: 0.261067
Gradient discriminator: -1.690225
Gradient professor: -8.956766
Loss Generator D: 1.828909
Loss Generator P: 0.258922
Generator    : Epoch:     22, update:    5360, cost:   0.258922
Gradient discriminator: 2.822657
Gradient professor: 3.413069
Loss Generator D: 2.136566
Loss Generator P: 0.280781
Gradient discriminator: 2.269000
Gradient professor: 6.506652
Loss Generator D: 2.318204
Loss Generator P: 0.212450
Gradient discriminator: 7.182699
Gradient professor: 1.009169
Loss Generator D: 2.354813
Loss Generator P: 0.148765
Gradient discriminator: -5.848024
Gradient professor: 2.551059
Loss Generator D: 1.881620
Loss Generator P: 0.160499
Gradient discriminator: 3.681503
Gradient professor: -10.958903
Loss Generator D: 1.813751
Loss Generator P: 0.256677
Gradient discriminator: -5.050725
Gradient professor: 0.442415
Loss Generator D: 2.278916
Loss Generator P: 0.311477
Gradient discriminator: 3.669514
Gradient professor: 4.463298
Loss Generator D: 2.210634
Loss Generator P: 0.128599
Gradient discriminator: -0.955168
Gradient professor: 1.115069
Loss Generator D: 2.081127
Loss Generator P: 0.302844
Gradient discriminator: -1.323290
Gradient professor: -4.608862
Loss Generator D: 1.920087
Loss Generator P: 0.163823
Gradient discriminator: -1.738876
Gradient professor: -1.233889
Loss Generator D: 1.632062
Loss Generator P: 0.211628
Generator    : Epoch:     22, update:    5370, cost:   0.211628
Gradient discriminator: -4.145608
Gradient professor: -1.751567
Loss Generator D: 1.850123
Loss Generator P: 0.238346
Gradient discriminator: 5.822106
Gradient professor: -9.678488
Loss Generator D: 1.673629
Loss Generator P: 0.279979
Gradient discriminator: 2.932343
Gradient professor: 6.999370
Loss Generator D: 1.708065
Loss Generator P: 0.246366
Gradient discriminator: -2.265600
Gradient professor: 3.900254
Loss Generator D: 1.613587
Loss Generator P: 0.327956
Gradient discriminator: 6.018263
Gradient professor: -0.160098
Loss Generator D: 1.700503
Loss Generator P: 0.262333
Gradient discriminator: 1.360064
Gradient professor: 5.952396
Loss Generator D: 1.597226
Loss Generator P: 0.276850
Gradient discriminator: 5.392492
Gradient professor: 6.317295
Loss Generator D: 1.718789
Loss Generator P: 0.244843
Gradient discriminator: -5.166372
Gradient professor: -9.123892
Loss Generator D: 1.939101
Loss Generator P: 0.311158
Gradient discriminator: 1.100597
Gradient professor: -15.549509
Loss Generator D: 1.544944
Loss Generator P: 0.348848
Gradient discriminator: 1.306234
Gradient professor: 8.031676
Loss Generator D: 1.702271
Loss Generator P: 0.268494
Generator    : Epoch:     22, update:    5380, cost:   0.268494
Gradient discriminator: -6.692223
Gradient professor: -1.256245
Loss Generator D: 1.846674
Loss Generator P: 0.215093
Gradient discriminator: 8.494596
Gradient professor: -2.394672
Loss Generator D: 2.242517
Loss Generator P: 0.263671
Gradient discriminator: -3.327939
Gradient professor: 4.222065
Loss Generator D: 1.744440
Loss Generator P: 0.228413
Gradient discriminator: 0.880049
Gradient professor: -2.424810
Loss Generator D: 2.054533
Loss Generator P: 0.360052
Gradient discriminator: -20.147901
Gradient professor: 2.654993
Loss Generator D: 1.968435
Loss Generator P: 0.215245
Gradient discriminator: 2.947862
Gradient professor: -4.572293
Loss Generator D: 2.516545
Loss Generator P: 0.191208
Gradient discriminator: -0.625409
Gradient professor: -4.342881
Loss Generator D: 2.015780
Loss Generator P: 0.195313
Gradient discriminator: -1.868168
Gradient professor: -6.849169
Loss Generator D: 2.130883
Loss Generator P: 0.167212
Gradient discriminator: 17.899566
Gradient professor: 3.092346
Loss Generator D: 2.290307
Loss Generator P: 0.290468
Gradient discriminator: -2.211651
Gradient professor: -13.097163
Loss Generator D: 2.162933
Loss Generator P: 0.267550
Generator    : Epoch:     22, update:    5390, cost:   0.267550
Gradient discriminator: -13.510678
Gradient professor: 2.244857
Loss Generator D: 1.833484
Loss Generator P: 0.231888
Gradient discriminator: 26.808744
Gradient professor: 5.799511
Loss Generator D: 1.995569
Loss Generator P: 0.254330
Gradient discriminator: 0.290153
Gradient professor: 4.948809
Loss Generator D: 1.927365
Loss Generator P: 0.330759
Gradient discriminator: 0.317327
Gradient professor: -25.243244
Loss Generator D: 2.153339
Loss Generator P: 0.267700
Gradient discriminator: -0.060704
Gradient professor: -1.823493
Loss Generator D: 1.792389
Loss Generator P: 0.332637
Gradient discriminator: 12.596732
Gradient professor: -8.871377
Loss Generator D: 2.023126
Loss Generator P: 0.281533
Gradient discriminator: -1.025863
Gradient professor: -2.823098
Loss Generator D: 2.184482
Loss Generator P: 0.204156
Gradient discriminator: -5.310725
Gradient professor: -7.221469
Loss Generator D: 2.056508
Loss Generator P: 0.242837
Gradient discriminator: 0.194633
Gradient professor: -0.804643
Loss Generator D: 2.425411
Loss Generator P: 0.245264
Gradient discriminator: 3.640561
Gradient professor: -2.303580
Loss Generator D: 2.492323
Loss Generator P: 0.188792
Generator    : Epoch:     22, update:    5400, cost:   0.188792
Validation 54 - LOSS = 1.772 (PPL: 5.881)
Calling beam-search process
Beam-search ended, took 3.53445 minutes.
Validation 54 - BLEU = 5.02, 9.4/6.0/4.1/2.8 (BP=1.000, ratio=5.222, hyp_len=22037, ref_len=4220)
Early stopping patience: 989 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -7.437454
Gradient professor: 13.334918
Loss Generator D: 2.448384
Loss Generator P: 0.335914
Gradient discriminator: 9.234331
Gradient professor: 14.503589
Loss Generator D: 1.902715
Loss Generator P: 0.309119
Gradient discriminator: 5.204594
Gradient professor: -3.386566
Loss Generator D: 2.031029
Loss Generator P: 0.274929
Gradient discriminator: 16.193259
Gradient professor: -7.096272
Loss Generator D: 1.923064
Loss Generator P: 0.244175
Gradient discriminator: 7.081002
Gradient professor: 13.487619
Loss Generator D: 2.044364
Loss Generator P: 0.338660
Gradient discriminator: -17.611196
Gradient professor: -7.425403
Loss Generator D: 2.402442
Loss Generator P: 0.201598
Gradient discriminator: -10.862146
Gradient professor: -4.130890
Loss Generator D: 2.527330
Loss Generator P: 0.281826
Gradient discriminator: 2.608776
Gradient professor: -3.436525
Loss Generator D: 2.195424
Loss Generator P: 0.204482
Gradient discriminator: 7.316209
Gradient professor: -1.491899
Loss Generator D: 1.917550
Loss Generator P: 0.172436
Gradient discriminator: 4.945096
Gradient professor: -5.831594
Loss Generator D: 1.565278
Loss Generator P: 0.324201
Generator    : Epoch:     22, update:    5410, cost:   0.324201
Gradient discriminator: 9.333321
Gradient professor: -11.651825
Loss Generator D: 1.847978
Loss Generator P: 0.278576
Gradient discriminator: 13.777465
Gradient professor: 20.803876
Loss Generator D: 1.977430
Loss Generator P: 0.327213
Gradient discriminator: -7.326133
Gradient professor: 7.865247
Loss Generator D: 1.527093
Loss Generator P: 0.350238
Gradient discriminator: 13.902218
Gradient professor: 12.180156
Loss Generator D: 2.101671
Loss Generator P: 0.349007
Gradient discriminator: 6.665633
Gradient professor: -5.963937
Loss Generator D: 1.409979
Loss Generator P: 0.416115
Gradient discriminator: 5.657055
Gradient professor: -2.885477
Loss Generator D: 1.562083
Loss Generator P: 0.323101
Gradient discriminator: 4.407452
Gradient professor: 21.445615
Loss Generator D: 1.308726
Loss Generator P: 0.354708
Gradient discriminator: 12.334190
Gradient professor: -15.179934
Loss Generator D: 1.394594
Loss Generator P: 0.232374
Gradient discriminator: 2.144187
Gradient professor: -18.033468
Loss Generator D: 1.131899
Loss Generator P: 0.255417
Gradient discriminator: 9.768149
Gradient professor: -12.623632
Loss Generator D: 1.422823
Loss Generator P: 0.311651
Generator    : Epoch:     22, update:    5420, cost:   0.311651
Gradient discriminator: -4.136147
Gradient professor: 4.369850
Loss Generator D: 1.472310
Loss Generator P: 0.196025
Gradient discriminator: 2.817447
Gradient professor: 4.333145
Loss Generator D: 1.553537
Loss Generator P: 0.254711
Gradient discriminator: 4.588787
Gradient professor: 5.332773
Loss Generator D: 2.078296
Loss Generator P: 0.230871
Gradient discriminator: 0.844389
Gradient professor: 3.257954
Loss Generator D: 2.029817
Loss Generator P: 0.151252
Gradient discriminator: -7.105774
Gradient professor: -13.798921
Loss Generator D: 2.071103
Loss Generator P: 0.191958
Gradient discriminator: 0.693913
Gradient professor: -2.761573
Loss Generator D: 2.003483
Loss Generator P: 0.278401
Gradient discriminator: -6.118800
Gradient professor: -6.624627
Loss Generator D: 2.066447
Loss Generator P: 0.312752
Gradient discriminator: 3.705011
Gradient professor: 11.150731
Loss Generator D: 2.006098
Loss Generator P: 0.419634
Gradient discriminator: 8.915676
Gradient professor: 4.299956
Loss Generator D: 2.194035
Loss Generator P: 0.378046
Gradient discriminator: 4.712259
Gradient professor: 1.184023
Loss Generator D: 2.020263
Loss Generator P: 0.200037
Generator    : Epoch:     22, update:    5430, cost:   0.200037
Gradient discriminator: 0.599908
Gradient professor: -0.064425
Loss Generator D: 2.266935
Loss Generator P: 0.225280
Gradient discriminator: 1.241872
Gradient professor: -10.497179
Loss Generator D: 2.169672
Loss Generator P: 0.224874
Gradient discriminator: 9.841715
Gradient professor: 3.415281
Loss Generator D: 2.728472
Loss Generator P: 0.233174
Gradient discriminator: 8.645426
Gradient professor: -4.512117
Loss Generator D: 2.336789
Loss Generator P: 0.383740
Gradient discriminator: -5.271669
Gradient professor: -3.060555
Loss Generator D: 2.513421
Loss Generator P: 0.351198
Gradient discriminator: 2.059556
Gradient professor: -20.851357
Loss Generator D: 2.221789
Loss Generator P: 0.206691
Gradient discriminator: 9.664597
Gradient professor: 15.559792
Loss Generator D: 2.044564
Loss Generator P: 0.269750
Gradient discriminator: -4.641759
Gradient professor: 6.225378
Loss Generator D: 1.954657
Loss Generator P: 0.360674
Gradient discriminator: -3.235168
Gradient professor: 7.457303
Loss Generator D: 2.347700
Loss Generator P: 0.321478
Gradient discriminator: 2.042817
Gradient professor: 2.731273
Loss Generator D: 2.070252
Loss Generator P: 0.323288
Generator    : Epoch:     22, update:    5440, cost:   0.323288
Gradient discriminator: 2.976639
Gradient professor: 3.238968
Loss Generator D: 2.213101
Loss Generator P: 0.328729
Gradient discriminator: 12.217698
Gradient professor: -15.181935
Loss Generator D: 1.563647
Loss Generator P: 0.237145
Gradient discriminator: 18.047960
Gradient professor: -20.684145
Loss Generator D: 2.053457
Loss Generator P: 0.409557
Gradient discriminator: 0.201113
Gradient professor: 17.815071
Loss Generator D: 2.473732
Loss Generator P: 0.398952
Gradient discriminator: 5.924896
Gradient professor: 6.256665
Loss Generator D: 1.793149
Loss Generator P: 0.216341
Gradient discriminator: 3.686629
Gradient professor: -4.453468
Loss Generator D: 2.296982
Loss Generator P: 0.305914
Gradient discriminator: 2.596205
Gradient professor: 1.066012
Loss Generator D: 2.577414
Loss Generator P: 0.269709
Gradient discriminator: 7.839917
Gradient professor: -4.725504
Loss Generator D: 2.057494
Loss Generator P: 0.342192
Gradient discriminator: 1.031801
Gradient professor: 10.668386
Loss Generator D: 2.120926
Loss Generator P: 0.283683
Gradient discriminator: 3.920745
Gradient professor: -9.604447
Loss Generator D: 2.001406
Loss Generator P: 0.299237
Generator    : Epoch:     22, update:    5450, cost:   0.299237
Gradient discriminator: 7.428242
Gradient professor: 7.209751
Loss Generator D: 2.197946
Loss Generator P: 0.300662
Gradient discriminator: -2.165911
Gradient professor: 0.884499
Loss Generator D: 1.723828
Loss Generator P: 0.231693
Gradient discriminator: 0.737154
Gradient professor: -2.230801
Loss Generator D: 2.423045
Loss Generator P: 0.265604
Gradient discriminator: -1.228428
Gradient professor: 8.282939
Loss Generator D: 1.912071
Loss Generator P: 0.225765
Gradient discriminator: 10.743121
Gradient professor: 2.378399
Loss Generator D: 2.116853
Loss Generator P: 0.203839
Gradient discriminator: 5.474398
Gradient professor: -3.418734
Loss Generator D: 2.374989
Loss Generator P: 0.177031
Gradient discriminator: -8.037802
Gradient professor: -11.635112
Loss Generator D: 2.984186
Loss Generator P: 0.278099
Gradient discriminator: 7.051886
Gradient professor: -10.361978
Loss Generator D: 2.274846
Loss Generator P: 0.358836
Gradient discriminator: 4.946704
Gradient professor: 4.613718
Loss Generator D: 1.855670
Loss Generator P: 0.249117
Gradient discriminator: -1.133835
Gradient professor: -25.937268
Loss Generator D: 1.997875
Loss Generator P: 0.331480
Generator    : Epoch:     22, update:    5460, cost:   0.331480
Gradient discriminator: 15.730132
Gradient professor: -10.286143
Loss Generator D: 1.599262
Loss Generator P: 0.365784
Gradient discriminator: -0.749890
Gradient professor: 1.679093
Loss Generator D: 2.062223
Loss Generator P: 0.319949
Gradient discriminator: -1.092888
Gradient professor: 2.757565
Loss Generator D: 2.497796
Loss Generator P: 0.250080
Gradient discriminator: -29.660366
Gradient professor: -4.108130
Loss Generator D: 2.326479
Loss Generator P: 0.220772
Gradient discriminator: -0.477588
Gradient professor: 18.383883
Loss Generator D: 2.161822
Loss Generator P: 0.253432
Gradient discriminator: -5.034927
Gradient professor: 18.792002
Loss Generator D: 1.999640
Loss Generator P: 0.372336
Gradient discriminator: -2.947525
Gradient professor: 4.890532
Loss Generator D: 2.033146
Loss Generator P: 0.268774
Gradient discriminator: -0.797664
Gradient professor: 0.052493
Loss Generator D: 2.219512
Loss Generator P: 0.227599
Gradient discriminator: 0.641988
Gradient professor: 8.170765
Loss Generator D: 2.175702
Loss Generator P: 0.230351
Gradient discriminator: 5.558700
Gradient professor: -1.370554
Loss Generator D: 2.502536
Loss Generator P: 0.211887
Generator    : Epoch:     22, update:    5470, cost:   0.211887
Gradient discriminator: 6.522507
Gradient professor: -0.553563
Loss Generator D: 2.539776
Loss Generator P: 0.278055
Gradient discriminator: 4.522104
Gradient professor: -0.434178
Loss Generator D: 2.303803
Loss Generator P: 0.268898
Gradient discriminator: -1.407392
Gradient professor: -11.980195
Loss Generator D: 2.406845
Loss Generator P: 0.287771
Gradient discriminator: 3.127349
Gradient professor: 21.158446
Loss Generator D: 2.787966
Loss Generator P: 0.242095
Gradient discriminator: 6.973922
Gradient professor: -8.046052
Loss Generator D: 2.577915
Loss Generator P: 0.200676
Gradient discriminator: 6.346771
Gradient professor: -11.506386
Loss Generator D: 2.545520
Loss Generator P: 0.307272
Gradient discriminator: -5.313908
Gradient professor: 11.068655
Loss Generator D: 2.611795
Loss Generator P: 0.215351
Gradient discriminator: -1.461845
Gradient professor: -13.262199
Loss Generator D: 2.542891
Loss Generator P: 0.241663
Gradient discriminator: 3.558304
Gradient professor: -1.907009
Loss Generator D: 2.439367
Loss Generator P: 0.276174
Gradient discriminator: 7.340087
Gradient professor: -5.089167
Loss Generator D: 2.327251
Loss Generator P: 0.222034
Generator    : Epoch:     22, update:    5480, cost:   0.222034
Gradient discriminator: -8.647483
Gradient professor: 2.912476
Loss Generator D: 2.366786
Loss Generator P: 0.335585
Gradient discriminator: -4.144776
Gradient professor: -20.584606
Loss Generator D: 1.741784
Loss Generator P: 0.373708
Gradient discriminator: 8.631572
Gradient professor: 9.676781
Loss Generator D: 1.708250
Loss Generator P: 0.417363
Gradient discriminator: -2.298346
Gradient professor: 3.909817
Loss Generator D: 1.730799
Loss Generator P: 0.204156
Gradient discriminator: 12.524820
Gradient professor: 11.280862
Loss Generator D: 1.722656
Loss Generator P: 0.338742
Gradient discriminator: 0.991228
Gradient professor: 0.725767
Loss Generator D: 1.868514
Loss Generator P: 0.219392
Gradient discriminator: -2.286011
Gradient professor: 1.680438
Loss Generator D: 2.350387
Loss Generator P: 0.162335
Gradient discriminator: -3.295595
Gradient professor: -6.236424
Loss Generator D: 2.177242
Loss Generator P: 0.283793
Gradient discriminator: -1.869093
Gradient professor: -1.023353
Loss Generator D: 1.829145
Loss Generator P: 0.218122
Gradient discriminator: 4.998847
Gradient professor: 15.175301
Loss Generator D: 2.004282
Loss Generator P: 0.200357
Generator    : Epoch:     22, update:    5490, cost:   0.200357
Gradient discriminator: 4.770035
Gradient professor: 6.280627
Loss Generator D: 1.864413
Loss Generator P: 0.228019
Gradient discriminator: -4.809833
Gradient professor: -9.321753
Loss Generator D: 1.905783
Loss Generator P: 0.254399
Gradient discriminator: 2.219420
Gradient professor: -2.266368
Loss Generator D: 1.497265
Loss Generator P: 0.225621
Gradient discriminator: 17.911773
Gradient professor: 4.323567
Loss Generator D: 1.666366
Loss Generator P: 0.268291
Gradient discriminator: 21.370077
Gradient professor: 0.290739
Loss Generator D: 1.256732
Loss Generator P: 0.272548
Gradient discriminator: 2.340489
Gradient professor: 12.431821
Loss Generator D: 1.602281
Loss Generator P: 0.189240
Gradient discriminator: 4.041439
Gradient professor: 1.554096
Loss Generator D: 1.956846
Loss Generator P: 0.209813
Gradient discriminator: 0.089408
Gradient professor: -6.816556
Loss Generator D: 2.174298
Loss Generator P: 0.176324
Gradient discriminator: 15.847693
Gradient professor: 2.781325
Loss Generator D: 1.932623
Loss Generator P: 0.203845
Gradient discriminator: 8.480584
Gradient professor: 5.908368
Loss Generator D: 2.299537
Loss Generator P: 0.119241
Generator    : Epoch:     22, update:    5500, cost:   0.119241
Validation 55 - LOSS = 1.744 (PPL: 5.723)
Calling beam-search process
Beam-search ended, took 2.58322 minutes.
Validation 55 - BLEU = 7.28, 13.2/8.6/6.0/4.1 (BP=1.000, ratio=4.310, hyp_len=18188, ref_len=4220)
Early stopping patience: 988 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 22 finished with mean loss 1.22247 (PPL: 3.39558)
--> Epoch took 435.726 minutes, 104.574 sec/update
Epoch summary of Discriminator:
--> Epoch 22 finished with mean loss nan (PPL:  nan)
--> Epoch took 435.726 minutes, 104.574 sec/update
---------------------------------------------------------
Starting Epoch 23
-----------------
Gradient discriminator: 1.269059
Gradient professor: -2.885918
Loss Generator D: 2.198678
Loss Generator P: 0.379597
Gradient discriminator: 9.228763
Gradient professor: -0.593716
Loss Generator D: 2.058577
Loss Generator P: 0.260768
Gradient discriminator: -1.774304
Gradient professor: 23.894927
Loss Generator D: 2.236353
Loss Generator P: 0.377635
Gradient discriminator: -8.170818
Gradient professor: -5.394048
Loss Generator D: 1.952264
Loss Generator P: 0.338846
Gradient discriminator: 5.708556
Gradient professor: -8.572912
Loss Generator D: 1.905720
Loss Generator P: 0.235759
Gradient discriminator: -4.626826
Gradient professor: 1.212100
Loss Generator D: 2.003103
Loss Generator P: 0.238072
Gradient discriminator: 2.868400
Gradient professor: 0.380740
Loss Generator D: 2.089204
Loss Generator P: 0.287524
Gradient discriminator: 8.002340
Gradient professor: 1.539713
Loss Generator D: 1.924174
Loss Generator P: 0.230298
Gradient discriminator: 4.398402
Gradient professor: -5.299743
Loss Generator D: 2.326899
Loss Generator P: 0.320293
Gradient discriminator: -3.248944
Gradient professor: 1.225684
Loss Generator D: 2.351810
Loss Generator P: 0.361550
Generator    : Epoch:     23, update:    5510, cost:   0.361550
Gradient discriminator: -0.026769
Gradient professor: -5.446032
Loss Generator D: 2.590368
Loss Generator P: 0.347842
Gradient discriminator: 4.215900
Gradient professor: 0.599410
Loss Generator D: 2.618711
Loss Generator P: 0.258729
Gradient discriminator: -0.025091
Gradient professor: 0.864794
Loss Generator D: 2.612089
Loss Generator P: 0.355100
Gradient discriminator: 1.075560
Gradient professor: -17.303604
Loss Generator D: 3.101926
Loss Generator P: 0.302756
Gradient discriminator: 2.181769
Gradient professor: -8.918258
Loss Generator D: 2.843874
Loss Generator P: 0.174388
Gradient discriminator: 6.356402
Gradient professor: -7.182926
Loss Generator D: 2.601805
Loss Generator P: 0.144081
Gradient discriminator: -4.541530
Gradient professor: 3.222920
Loss Generator D: 3.032747
Loss Generator P: 0.240210
Gradient discriminator: 4.278137
Gradient professor: -7.666920
Loss Generator D: 2.783372
Loss Generator P: 0.257048
Gradient discriminator: 1.057092
Gradient professor: 4.125792
Loss Generator D: 2.770120
Loss Generator P: 0.308351
Gradient discriminator: 2.129657
Gradient professor: 0.049880
Loss Generator D: 2.394002
Loss Generator P: 0.275900
Generator    : Epoch:     23, update:    5520, cost:   0.275900
Gradient discriminator: -15.653022
Gradient professor: -9.802630
Loss Generator D: 2.434541
Loss Generator P: 0.263057
Gradient discriminator: 11.661327
Gradient professor: -9.941920
Loss Generator D: 2.969768
Loss Generator P: 0.270286
Gradient discriminator: -1.233895
Gradient professor: 1.516244
Loss Generator D: 2.889573
Loss Generator P: 0.249516
Gradient discriminator: 4.583239
Gradient professor: 6.605183
Loss Generator D: 2.624983
Loss Generator P: 0.402713
Gradient discriminator: 7.747666
Gradient professor: 5.807907
Loss Generator D: 2.867486
Loss Generator P: 0.396186
Gradient discriminator: -7.834308
Gradient professor: 5.843449
Loss Generator D: 2.465134
Loss Generator P: 0.251917
Gradient discriminator: -4.195328
Gradient professor: -0.795427
Loss Generator D: 2.057639
Loss Generator P: 0.179024
Gradient discriminator: 3.398743
Gradient professor: 5.636346
Loss Generator D: 2.363926
Loss Generator P: 0.222496
Gradient discriminator: 18.113073
Gradient professor: 8.680328
Loss Generator D: 2.442319
Loss Generator P: 0.217246
Gradient discriminator: 5.796800
Gradient professor: 28.304539
Loss Generator D: 2.501674
Loss Generator P: 0.238836
Generator    : Epoch:     23, update:    5530, cost:   0.238836
Gradient discriminator: 1.484251
Gradient professor: -2.706999
Loss Generator D: 2.522953
Loss Generator P: 0.241619
Gradient discriminator: -2.047848
Gradient professor: -6.800798
Loss Generator D: 2.516249
Loss Generator P: 0.185118
Gradient discriminator: -2.314990
Gradient professor: 23.240711
Loss Generator D: 3.088873
Loss Generator P: 0.369898
Gradient discriminator: 8.287375
Gradient professor: 10.871576
Loss Generator D: 2.674315
Loss Generator P: 0.416741
Gradient discriminator: -3.701345
Gradient professor: -16.449724
Loss Generator D: 2.457370
Loss Generator P: 0.291089
Gradient discriminator: -2.178295
Gradient professor: 7.500755
Loss Generator D: 2.268320
Loss Generator P: 0.180448
Gradient discriminator: 2.043196
Gradient professor: -8.018480
Loss Generator D: 2.260267
Loss Generator P: 0.197878
Gradient discriminator: 5.842496
Gradient professor: -0.568445
Loss Generator D: 2.544915
Loss Generator P: 0.271255
Gradient discriminator: 1.319586
Gradient professor: 11.645548
Loss Generator D: 2.350457
Loss Generator P: 0.233882
Gradient discriminator: 2.629574
Gradient professor: 7.524469
Loss Generator D: 2.574806
Loss Generator P: 0.365267
Generator    : Epoch:     23, update:    5540, cost:   0.365267
Gradient discriminator: -2.771963
Gradient professor: -11.507214
Loss Generator D: 2.268565
Loss Generator P: 0.263924
Gradient discriminator: 43.081507
Gradient professor: 5.612237
Loss Generator D: 2.680626
Loss Generator P: 0.230253
Gradient discriminator: 5.482349
Gradient professor: -10.622597
Loss Generator D: 2.956050
Loss Generator P: 0.249328
Gradient discriminator: 1.322976
Gradient professor: -8.016567
Loss Generator D: 2.651961
Loss Generator P: 0.177132
Gradient discriminator: 4.645117
Gradient professor: -16.272248
Loss Generator D: 2.546071
Loss Generator P: 0.308539
Gradient discriminator: 9.672669
Gradient professor: 15.302922
Loss Generator D: 2.483473
Loss Generator P: 0.245643
Gradient discriminator: 1.630799
Gradient professor: 3.824934
Loss Generator D: 2.319643
Loss Generator P: 0.205654
Gradient discriminator: -4.212726
Gradient professor: 12.650334
Loss Generator D: 2.108731
Loss Generator P: 0.282154
Gradient discriminator: -1.949816
Gradient professor: -19.620513
Loss Generator D: 2.279111
Loss Generator P: 0.378147
Gradient discriminator: 11.041106
Gradient professor: 0.317909
Loss Generator D: 2.149129
Loss Generator P: 0.274516
Generator    : Epoch:     23, update:    5550, cost:   0.274516
Gradient discriminator: -2.361259
Gradient professor: -6.893039
Loss Generator D: 2.002265
Loss Generator P: 0.311814
Gradient discriminator: -6.922311
Gradient professor: 9.025934
Loss Generator D: 1.830965
Loss Generator P: 0.236569
Discriminator: Epoch:     23, update:    5552, cost:   0.349249
Gradient discriminator: 2.996628
Gradient professor: -1.337500
Loss Generator D: 1.499818
Loss Generator P: 0.216149
Gradient discriminator: 4.426792
Gradient professor: -11.113598
Loss Generator D: 1.868157
Loss Generator P: 0.354272
Gradient discriminator: 1.635761
Gradient professor: -24.311747
Loss Generator D: 1.793595
Loss Generator P: 0.276717
Gradient discriminator: 2.302360
Gradient professor: 17.242940
Loss Generator D: 1.979033
Loss Generator P: 0.240324
Gradient discriminator: -2.726736
Gradient professor: 2.111385
Loss Generator D: 1.774077
Loss Generator P: 0.248785
Gradient discriminator: 2.434914
Gradient professor: -0.905569
Loss Generator D: 1.897710
Loss Generator P: 0.185678
Gradient discriminator: 7.139208
Gradient professor: -9.583224
Loss Generator D: 2.313976
Loss Generator P: 0.198699
Gradient discriminator: 1.759186
Gradient professor: 8.021853
Loss Generator D: 1.790578
Loss Generator P: 0.258029
Generator    : Epoch:     23, update:    5560, cost:   0.258029
Gradient discriminator: 0.755882
Gradient professor: -9.822465
Loss Generator D: 1.725270
Loss Generator P: 0.270002
Gradient discriminator: 1.169004
Gradient professor: -4.413285
Loss Generator D: 1.903140
Loss Generator P: 0.363518
Gradient discriminator: 3.494055
Gradient professor: -9.157393
Loss Generator D: 1.866081
Loss Generator P: 0.283643
Gradient discriminator: -1.546243
Gradient professor: -13.004141
Loss Generator D: 1.833474
Loss Generator P: 0.279482
Gradient discriminator: -1.293800
Gradient professor: -12.618809
Loss Generator D: 2.183549
Loss Generator P: 0.365618
Gradient discriminator: -0.097165
Gradient professor: -10.971277
Loss Generator D: 1.660295
Loss Generator P: 0.265533
Gradient discriminator: 3.640656
Gradient professor: 8.989789
Loss Generator D: 2.064626
Loss Generator P: 0.254311
Gradient discriminator: 8.065502
Gradient professor: 3.369814
Loss Generator D: 1.887867
Loss Generator P: 0.196527
Gradient discriminator: -5.362053
Gradient professor: 13.224382
Loss Generator D: 1.773358
Loss Generator P: 0.312218
Gradient discriminator: 5.025279
Gradient professor: 6.078930
Loss Generator D: 1.772956
Loss Generator P: 0.192185
Generator    : Epoch:     23, update:    5570, cost:   0.192185
Gradient discriminator: -2.110363
Gradient professor: -12.525476
Loss Generator D: 2.080520
Loss Generator P: 0.195980
Gradient discriminator: -1.680170
Gradient professor: 11.371041
Loss Generator D: 2.047951
Loss Generator P: 0.171475
Gradient discriminator: 3.955828
Gradient professor: 4.499482
Loss Generator D: 1.959720
Loss Generator P: 0.217115
Gradient discriminator: 5.577596
Gradient professor: 5.552433
Loss Generator D: 1.846535
Loss Generator P: 0.263725
Gradient discriminator: 5.188650
Gradient professor: -15.601976
Loss Generator D: 1.754314
Loss Generator P: 0.218020
Gradient discriminator: 0.768749
Gradient professor: 3.582009
Loss Generator D: 1.625917
Loss Generator P: 0.176337
Gradient discriminator: 8.177824
Gradient professor: 1.974800
Loss Generator D: 1.927103
Loss Generator P: 0.185070
Gradient discriminator: -1.776872
Gradient professor: -0.807932
Loss Generator D: 2.062015
Loss Generator P: 0.275298
Gradient discriminator: 0.833736
Gradient professor: -0.540382
Loss Generator D: 2.086086
Loss Generator P: 0.163604
Gradient discriminator: 0.329476
Gradient professor: 3.729268
Loss Generator D: 1.893026
Loss Generator P: 0.166993
Generator    : Epoch:     23, update:    5580, cost:   0.166993
Gradient discriminator: 2.835868
Gradient professor: 13.125355
Loss Generator D: 2.088248
Loss Generator P: 0.188314
Gradient discriminator: 2.020391
Gradient professor: 0.174150
Loss Generator D: 1.784725
Loss Generator P: 0.198263
Gradient discriminator: 3.751014
Gradient professor: 8.276755
Loss Generator D: 1.666056
Loss Generator P: 0.204352
Gradient discriminator: -2.773448
Gradient professor: -9.746310
Loss Generator D: 1.870226
Loss Generator P: 0.182536
Gradient discriminator: 1.690327
Gradient professor: -12.859948
Loss Generator D: 2.026820
Loss Generator P: 0.143976
Gradient discriminator: 4.866917
Gradient professor: -0.513725
Loss Generator D: 2.014457
Loss Generator P: 0.150149
Gradient discriminator: 5.118234
Gradient professor: -13.913439
Loss Generator D: 1.701423
Loss Generator P: 0.146841
Gradient discriminator: -5.064145
Gradient professor: -9.949019
Loss Generator D: 2.054442
Loss Generator P: 0.263998
Gradient discriminator: 6.632381
Gradient professor: -13.684128
Loss Generator D: 1.946767
Loss Generator P: 0.235220
Gradient discriminator: 0.947885
Gradient professor: 23.869591
Loss Generator D: 1.572441
Loss Generator P: 0.303731
Generator    : Epoch:     23, update:    5590, cost:   0.303731
Gradient discriminator: 0.124117
Gradient professor: -3.028415
Loss Generator D: 2.178973
Loss Generator P: 0.216857
Gradient discriminator: 0.083255
Gradient professor: -4.552235
Loss Generator D: 1.934261
Loss Generator P: 0.270679
Gradient discriminator: 0.355826
Gradient professor: 0.466176
Loss Generator D: 1.529400
Loss Generator P: 0.164725
Gradient discriminator: -0.290036
Gradient professor: 0.856453
Loss Generator D: 1.309254
Loss Generator P: 0.120372
Gradient discriminator: 3.022153
Gradient professor: 9.693251
Loss Generator D: 1.514695
Loss Generator P: 0.196526
Gradient discriminator: -8.220468
Gradient professor: -12.978641
Loss Generator D: 1.495219
Loss Generator P: 0.216207
Gradient discriminator: 2.044183
Gradient professor: -16.664792
Loss Generator D: 1.481658
Loss Generator P: 0.241763
Gradient discriminator: -9.869963
Gradient professor: -2.512145
Loss Generator D: 1.756387
Loss Generator P: 0.164121
Gradient discriminator: -7.345197
Gradient professor: -0.603950
Loss Generator D: 2.023247
Loss Generator P: 0.164754
Gradient discriminator: -0.419102
Gradient professor: -1.696021
Loss Generator D: 1.787452
Loss Generator P: 0.201216
Generator    : Epoch:     23, update:    5600, cost:   0.201216
Validation 56 - LOSS = 1.749 (PPL: 5.747)
Calling beam-search process
Beam-search ended, took 2.90753 minutes.
Validation 56 - BLEU = 6.48, 11.9/7.7/5.3/3.6 (BP=1.000, ratio=4.753, hyp_len=20059, ref_len=4220)
Early stopping patience: 987 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -0.007398
Gradient professor: 16.932757
Loss Generator D: 1.469961
Loss Generator P: 0.247385
Gradient discriminator: 5.588764
Gradient professor: -11.211518
Loss Generator D: 1.958761
Loss Generator P: 0.219871
Gradient discriminator: -1.313866
Gradient professor: 9.039652
Loss Generator D: 1.860077
Loss Generator P: 0.160306
Gradient discriminator: 1.389563
Gradient professor: -3.930194
Loss Generator D: 2.129464
Loss Generator P: 0.205638
Gradient discriminator: 2.181171
Gradient professor: 6.280572
Loss Generator D: 2.069166
Loss Generator P: 0.178367
Gradient discriminator: 14.614514
Gradient professor: -11.434858
Loss Generator D: 2.270088
Loss Generator P: 0.241977
Gradient discriminator: -2.239192
Gradient professor: -7.825790
Loss Generator D: 1.956809
Loss Generator P: 0.182632
Gradient discriminator: -1.576877
Gradient professor: -8.570303
Loss Generator D: 2.251307
Loss Generator P: 0.207556
Gradient discriminator: 4.137379
Gradient professor: 8.747402
Loss Generator D: 1.986351
Loss Generator P: 0.201982
Gradient discriminator: 1.507072
Gradient professor: 4.906006
Loss Generator D: 2.055426
Loss Generator P: 0.228664
Generator    : Epoch:     23, update:    5610, cost:   0.228664
Gradient discriminator: -0.508638
Gradient professor: 4.184380
Loss Generator D: 2.680471
Loss Generator P: 0.239468
Gradient discriminator: -1.898717
Gradient professor: 3.118328
Loss Generator D: 2.287812
Loss Generator P: 0.215432
Gradient discriminator: 0.668801
Gradient professor: 15.532065
Loss Generator D: 2.486547
Loss Generator P: 0.163232
Gradient discriminator: -3.078027
Gradient professor: -0.624643
Loss Generator D: 1.791194
Loss Generator P: 0.139247
Gradient discriminator: -0.555515
Gradient professor: -0.699253
Loss Generator D: 2.327033
Loss Generator P: 0.226754
Gradient discriminator: 2.404175
Gradient professor: 3.869122
Loss Generator D: 2.648940
Loss Generator P: 0.319801
Gradient discriminator: 1.528267
Gradient professor: 6.266991
Loss Generator D: 2.210320
Loss Generator P: 0.150623
Gradient discriminator: -0.522103
Gradient professor: -17.745527
Loss Generator D: 3.170181
Loss Generator P: 0.293276
Gradient discriminator: 0.701480
Gradient professor: 2.626812
Loss Generator D: 2.809384
Loss Generator P: 0.143163
Gradient discriminator: 1.363700
Gradient professor: 3.598495
Loss Generator D: 2.516196
Loss Generator P: 0.180341
Generator    : Epoch:     23, update:    5620, cost:   0.180341
Gradient discriminator: -6.422361
Gradient professor: -9.159105
Loss Generator D: 2.226836
Loss Generator P: 0.228246
Gradient discriminator: -0.506177
Gradient professor: -14.703737
Loss Generator D: 1.733797
Loss Generator P: 0.227085
Gradient discriminator: 1.513184
Gradient professor: 6.701869
Loss Generator D: 1.476410
Loss Generator P: 0.198080
Gradient discriminator: 0.880083
Gradient professor: -0.927482
Loss Generator D: 1.575491
Loss Generator P: 0.287611
Gradient discriminator: -2.429489
Gradient professor: 3.166734
Loss Generator D: 1.568117
Loss Generator P: 0.237198
Gradient discriminator: 0.501233
Gradient professor: 8.681027
Loss Generator D: 1.846715
Loss Generator P: 0.227991
Gradient discriminator: 5.377779
Gradient professor: -17.611282
Loss Generator D: 1.614663
Loss Generator P: 0.229750
Gradient discriminator: -3.785834
Gradient professor: 11.020273
Loss Generator D: 1.865757
Loss Generator P: 0.322346
Gradient discriminator: -2.501010
Gradient professor: -0.714840
Loss Generator D: 1.551483
Loss Generator P: 0.263078
Gradient discriminator: 3.652883
Gradient professor: -12.392049
Loss Generator D: 1.801814
Loss Generator P: 0.284200
Generator    : Epoch:     23, update:    5630, cost:   0.284200
Gradient discriminator: -2.218655
Gradient professor: 0.669041
Loss Generator D: 1.572729
Loss Generator P: 0.205060
Gradient discriminator: -6.776331
Gradient professor: 3.300625
Loss Generator D: 2.416763
Loss Generator P: 0.229097
Gradient discriminator: 5.921336
Gradient professor: 8.977332
Loss Generator D: 1.852522
Loss Generator P: 0.214026
Gradient discriminator: -1.871402
Gradient professor: 3.974600
Loss Generator D: 2.240644
Loss Generator P: 0.348700
Gradient discriminator: -1.637985
Gradient professor: 19.035473
Loss Generator D: 2.030751
Loss Generator P: 0.233594
Gradient discriminator: -0.114398
Gradient professor: -10.950100
Loss Generator D: 2.892230
Loss Generator P: 0.175445
Gradient discriminator: 4.137875
Gradient professor: 5.311530
Loss Generator D: 2.449272
Loss Generator P: 0.178450
Gradient discriminator: -0.456616
Gradient professor: -2.572867
Loss Generator D: 2.315148
Loss Generator P: 0.159828
Gradient discriminator: 5.910210
Gradient professor: -2.703567
Loss Generator D: 2.497071
Loss Generator P: 0.267133
Gradient discriminator: 10.460946
Gradient professor: 1.194416
Loss Generator D: 2.345154
Loss Generator P: 0.227166
Generator    : Epoch:     23, update:    5640, cost:   0.227166
Gradient discriminator: -3.049366
Gradient professor: 3.286616
Loss Generator D: 2.030464
Loss Generator P: 0.205945
Gradient discriminator: -0.523515
Gradient professor: 11.032007
Loss Generator D: 2.671920
Loss Generator P: 0.291475
Gradient discriminator: -1.423725
Gradient professor: 18.986317
Loss Generator D: 2.448294
Loss Generator P: 0.301042
Gradient discriminator: -4.881719
Gradient professor: -10.248222
Loss Generator D: 2.094991
Loss Generator P: 0.259247
Gradient discriminator: -2.660452
Gradient professor: 3.625532
Loss Generator D: 1.877675
Loss Generator P: 0.289173
Gradient discriminator: 4.955522
Gradient professor: -4.324028
Loss Generator D: 2.474140
Loss Generator P: 0.276465
Gradient discriminator: 2.261681
Gradient professor: -14.872072
Loss Generator D: 2.538597
Loss Generator P: 0.205958
Gradient discriminator: -2.121307
Gradient professor: 1.462704
Loss Generator D: 2.272517
Loss Generator P: 0.226544
Gradient discriminator: -0.556981
Gradient professor: 2.249802
Loss Generator D: 2.336675
Loss Generator P: 0.186989
Gradient discriminator: -9.002462
Gradient professor: -9.001134
Loss Generator D: 2.316406
Loss Generator P: 0.152590
Generator    : Epoch:     23, update:    5650, cost:   0.152590
Gradient discriminator: -3.989773
Gradient professor: -8.381265
Loss Generator D: 2.675173
Loss Generator P: 0.307181
Gradient discriminator: 1.597406
Gradient professor: -0.434931
Loss Generator D: 2.306076
Loss Generator P: 0.294487
Gradient discriminator: 0.044095
Gradient professor: 1.681356
Loss Generator D: 2.323260
Loss Generator P: 0.248424
Gradient discriminator: 0.886854
Gradient professor: 3.203646
Loss Generator D: 2.521076
Loss Generator P: 0.210262
Gradient discriminator: -11.948468
Gradient professor: -7.632337
Loss Generator D: 2.562084
Loss Generator P: 0.286637
Gradient discriminator: -0.326562
Gradient professor: -6.649861
Loss Generator D: 2.183292
Loss Generator P: 0.180527
Gradient discriminator: 0.830753
Gradient professor: -13.532004
Loss Generator D: 2.519942
Loss Generator P: 0.267929
Gradient discriminator: 4.157977
Gradient professor: -5.363343
Loss Generator D: 2.467982
Loss Generator P: 0.155090
Gradient discriminator: 0.637576
Gradient professor: -7.971077
Loss Generator D: 2.261863
Loss Generator P: 0.184664
Gradient discriminator: 0.356762
Gradient professor: -4.099616
Loss Generator D: 2.325902
Loss Generator P: 0.287177
Generator    : Epoch:     23, update:    5660, cost:   0.287177
Gradient discriminator: 2.313122
Gradient professor: -5.451011
Loss Generator D: 2.664452
Loss Generator P: 0.286809
Gradient discriminator: -2.479714
Gradient professor: 16.035171
Loss Generator D: 2.495041
Loss Generator P: 0.320788
Gradient discriminator: -9.363292
Gradient professor: 7.107125
Loss Generator D: 2.508568
Loss Generator P: 0.297690
Gradient discriminator: 0.440873
Gradient professor: 21.962036
Loss Generator D: 2.196103
Loss Generator P: 0.306159
Gradient discriminator: 9.585929
Gradient professor: 6.061185
Loss Generator D: 2.399490
Loss Generator P: 0.387351
Gradient discriminator: -0.314080
Gradient professor: -12.573796
Loss Generator D: 2.332696
Loss Generator P: 0.299771
Gradient discriminator: 4.086154
Gradient professor: 8.737015
Loss Generator D: 2.274464
Loss Generator P: 0.328034
Gradient discriminator: -1.468045
Gradient professor: 12.628308
Loss Generator D: 2.320569
Loss Generator P: 0.178893
Gradient discriminator: 0.571606
Gradient professor: 7.521306
Loss Generator D: 1.989100
Loss Generator P: 0.245222
Gradient discriminator: 0.948670
Gradient professor: -1.507457
Loss Generator D: 2.047620
Loss Generator P: 0.259466
Generator    : Epoch:     23, update:    5670, cost:   0.259466
Gradient discriminator: 4.637950
Gradient professor: -1.352805
Loss Generator D: 2.104902
Loss Generator P: 0.189047
Gradient discriminator: 2.610340
Gradient professor: 6.349119
Loss Generator D: 1.554738
Loss Generator P: 0.271381
Gradient discriminator: -2.753697
Gradient professor: 6.875977
Loss Generator D: 2.038187
Loss Generator P: 0.220501
Gradient discriminator: 1.199819
Gradient professor: -2.899260
Loss Generator D: 1.793444
Loss Generator P: 0.153147
Gradient discriminator: 1.186445
Gradient professor: 4.900214
Loss Generator D: 1.858176
Loss Generator P: 0.164745
Gradient discriminator: 3.087642
Gradient professor: -14.811067
Loss Generator D: 2.212007
Loss Generator P: 0.249021
Gradient discriminator: 3.115630
Gradient professor: -9.259620
Loss Generator D: 2.048525
Loss Generator P: 0.281862
Gradient discriminator: 3.121775
Gradient professor: 6.215783
Loss Generator D: 2.260007
Loss Generator P: 0.378756
Gradient discriminator: -3.499412
Gradient professor: -17.236801
Loss Generator D: 2.357456
Loss Generator P: 0.336180
Gradient discriminator: 0.093001
Gradient professor: 20.499902
Loss Generator D: 2.166837
Loss Generator P: 0.163689
Generator    : Epoch:     23, update:    5680, cost:   0.163689
Gradient discriminator: 2.444244
Gradient professor: -0.852516
Loss Generator D: 2.410581
Loss Generator P: 0.217151
Gradient discriminator: 6.068529
Gradient professor: -4.988461
Loss Generator D: 2.258458
Loss Generator P: 0.225111
Gradient discriminator: 3.430121
Gradient professor: 5.652691
Loss Generator D: 2.396684
Loss Generator P: 0.299280
Gradient discriminator: 1.410774
Gradient professor: 0.000149
Loss Generator D: 2.199176
Loss Generator P: 0.322837
Gradient discriminator: -2.422383
Gradient professor: -0.593607
Loss Generator D: 2.557795
Loss Generator P: 0.288614
Gradient discriminator: 0.053184
Gradient professor: 7.525387
Loss Generator D: 1.907023
Loss Generator P: 0.213732
Gradient discriminator: -0.822344
Gradient professor: -11.927360
Loss Generator D: 2.138744
Loss Generator P: 0.257343
Gradient discriminator: 0.728969
Gradient professor: -3.796668
Loss Generator D: 1.893382
Loss Generator P: 0.307186
Gradient discriminator: 6.401359
Gradient professor: 6.700979
Loss Generator D: 2.354736
Loss Generator P: 0.289248
Gradient discriminator: 2.874160
Gradient professor: 8.830663
Loss Generator D: 2.123281
Loss Generator P: 0.295124
Generator    : Epoch:     23, update:    5690, cost:   0.295124
Gradient discriminator: 13.848926
Gradient professor: 6.370833
Loss Generator D: 1.816925
Loss Generator P: 0.294084
Gradient discriminator: 1.883639
Gradient professor: -4.636652
Loss Generator D: 1.731354
Loss Generator P: 0.216681
Gradient discriminator: -9.319886
Gradient professor: -15.379479
Loss Generator D: 2.262033
Loss Generator P: 0.389205
Gradient discriminator: -1.743299
Gradient professor: 15.604192
Loss Generator D: 2.141979
Loss Generator P: 0.376787
Gradient discriminator: -1.610420
Gradient professor: 9.922445
Loss Generator D: 2.400421
Loss Generator P: 0.156652
Gradient discriminator: 4.698166
Gradient professor: -4.189816
Loss Generator D: 2.575899
Loss Generator P: 0.289361
Gradient discriminator: -0.144789
Gradient professor: 0.209569
Loss Generator D: 2.708035
Loss Generator P: 0.234061
Gradient discriminator: 6.659324
Gradient professor: -11.011539
Loss Generator D: 2.043205
Loss Generator P: 0.308462
Gradient discriminator: 4.123447
Gradient professor: -6.277118
Loss Generator D: 2.314852
Loss Generator P: 0.231099
Gradient discriminator: 5.135628
Gradient professor: 0.101259
Loss Generator D: 2.717680
Loss Generator P: 0.229445
Generator    : Epoch:     23, update:    5700, cost:   0.229445
Validation 57 - LOSS = 1.736 (PPL: 5.673)
Calling beam-search process
Beam-search ended, took 2.59644 minutes.
Validation 57 - BLEU = 7.56, 14.0/8.9/6.2/4.2 (BP=1.000, ratio=4.116, hyp_len=17368, ref_len=4220)
Early stopping patience: 986 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: -6.038480
Gradient professor: 13.405658
Loss Generator D: 2.531137
Loss Generator P: 0.295363
Gradient discriminator: 4.632879
Gradient professor: 3.566102
Loss Generator D: 2.020463
Loss Generator P: 0.216325
Gradient discriminator: -1.613252
Gradient professor: 7.685068
Loss Generator D: 2.157649
Loss Generator P: 0.239286
Gradient discriminator: -5.672807
Gradient professor: -14.176462
Loss Generator D: 2.018541
Loss Generator P: 0.191315
Gradient discriminator: 6.313961
Gradient professor: 11.688946
Loss Generator D: 2.500863
Loss Generator P: 0.175565
Gradient discriminator: 0.081376
Gradient professor: 2.521732
Loss Generator D: 2.919369
Loss Generator P: 0.149163
Gradient discriminator: 2.140688
Gradient professor: -7.529345
Loss Generator D: 2.663513
Loss Generator P: 0.241875
Gradient discriminator: 2.016324
Gradient professor: 3.913261
Loss Generator D: 2.626585
Loss Generator P: 0.304622
Gradient discriminator: 6.880511
Gradient professor: 0.456994
Loss Generator D: 2.185261
Loss Generator P: 0.208544
Gradient discriminator: 2.360783
Gradient professor: -28.519348
Loss Generator D: 2.060854
Loss Generator P: 0.309070
Generator    : Epoch:     23, update:    5710, cost:   0.309070
Gradient discriminator: -2.084612
Gradient professor: -14.775192
Loss Generator D: 1.674327
Loss Generator P: 0.310006
Gradient discriminator: -1.476192
Gradient professor: 9.123260
Loss Generator D: 1.673528
Loss Generator P: 0.324704
Gradient discriminator: -5.987175
Gradient professor: 8.029013
Loss Generator D: 2.098210
Loss Generator P: 0.211243
Gradient discriminator: -0.328718
Gradient professor: 2.613051
Loss Generator D: 2.062020
Loss Generator P: 0.195686
Gradient discriminator: -3.438274
Gradient professor: 3.927406
Loss Generator D: 2.048792
Loss Generator P: 0.266804
Gradient discriminator: 4.166787
Gradient professor: 2.353723
Loss Generator D: 1.596606
Loss Generator P: 0.314902
Gradient discriminator: 3.269088
Gradient professor: 6.343771
Loss Generator D: 1.882275
Loss Generator P: 0.258681
Gradient discriminator: 4.202188
Gradient professor: -7.947099
Loss Generator D: 2.102739
Loss Generator P: 0.211246
Gradient discriminator: -2.442664
Gradient professor: 6.158291
Loss Generator D: 2.551934
Loss Generator P: 0.199540
Gradient discriminator: -0.692969
Gradient professor: 2.811261
Loss Generator D: 2.420781
Loss Generator P: 0.169445
Generator    : Epoch:     23, update:    5720, cost:   0.169445
Gradient discriminator: 10.416879
Gradient professor: -5.271542
Loss Generator D: 2.392211
Loss Generator P: 0.214876
Gradient discriminator: -1.457290
Gradient professor: -14.177956
Loss Generator D: 2.512262
Loss Generator P: 0.259105
Gradient discriminator: -3.052273
Gradient professor: -1.775106
Loss Generator D: 2.447657
Loss Generator P: 0.280356
Gradient discriminator: -1.134463
Gradient professor: -16.007069
Loss Generator D: 2.546522
Loss Generator P: 0.238565
Gradient discriminator: 4.772434
Gradient professor: 4.245424
Loss Generator D: 2.653140
Loss Generator P: 0.180634
Gradient discriminator: -1.101721
Gradient professor: -6.580361
Loss Generator D: 2.478017
Loss Generator P: 0.236019
Gradient discriminator: -4.089217
Gradient professor: 0.051699
Loss Generator D: 2.364493
Loss Generator P: 0.174996
Gradient discriminator: -0.456018
Gradient professor: -3.133939
Loss Generator D: 3.054577
Loss Generator P: 0.226456
Gradient discriminator: -4.691949
Gradient professor: -3.081766
Loss Generator D: 2.737273
Loss Generator P: 0.245140
Gradient discriminator: -0.721540
Gradient professor: -12.231121
Loss Generator D: 2.758024
Loss Generator P: 0.190841
Generator    : Epoch:     23, update:    5730, cost:   0.190841
Gradient discriminator: -5.146703
Gradient professor: -8.600625
Loss Generator D: 2.751602
Loss Generator P: 0.295064
Gradient discriminator: 2.949841
Gradient professor: -9.930283
Loss Generator D: 2.471532
Loss Generator P: 0.327280
Gradient discriminator: -0.043352
Gradient professor: -13.456834
Loss Generator D: 2.415873
Loss Generator P: 0.325069
Gradient discriminator: 7.870340
Gradient professor: 5.323483
Loss Generator D: 2.468147
Loss Generator P: 0.172025
Gradient discriminator: 3.675383
Gradient professor: -7.420724
Loss Generator D: 2.217682
Loss Generator P: 0.336877
Gradient discriminator: -2.004663
Gradient professor: -8.474136
Loss Generator D: 2.712833
Loss Generator P: 0.247462
Gradient discriminator: 2.998885
Gradient professor: 3.526676
Loss Generator D: 2.710949
Loss Generator P: 0.144091
Gradient discriminator: 0.487507
Gradient professor: -3.073560
Loss Generator D: 2.687618
Loss Generator P: 0.279540
Gradient discriminator: -1.957046
Gradient professor: -3.705464
Loss Generator D: 2.681231
Loss Generator P: 0.231299
Gradient discriminator: -3.683296
Gradient professor: 10.485024
Loss Generator D: 2.170187
Loss Generator P: 0.185891
Generator    : Epoch:     23, update:    5740, cost:   0.185891
Gradient discriminator: -6.296488
Gradient professor: -9.600453
Loss Generator D: 2.516529
Loss Generator P: 0.212430
Gradient discriminator: 3.093111
Gradient professor: 11.306422
Loss Generator D: 2.613317
Loss Generator P: 0.235529
Gradient discriminator: 3.790002
Gradient professor: 8.405020
Loss Generator D: 2.468260
Loss Generator P: 0.189407
Gradient discriminator: 1.690526
Gradient professor: -14.016781
Loss Generator D: 2.532228
Loss Generator P: 0.212451
Gradient discriminator: 11.303418
Gradient professor: 0.298959
Loss Generator D: 2.736847
Loss Generator P: 0.228950
Gradient discriminator: 4.918629
Gradient professor: -0.885242
Loss Generator D: 2.362851
Loss Generator P: 0.201875
Gradient discriminator: -0.011047
Gradient professor: -1.170985
Loss Generator D: 2.969730
Loss Generator P: 0.191067
Gradient discriminator: 16.263339
Gradient professor: 3.684611
Loss Generator D: 2.575809
Loss Generator P: 0.187958
Gradient discriminator: 6.919196
Gradient professor: -6.923873
Loss Generator D: 3.130984
Loss Generator P: 0.219920
Gradient discriminator: 2.151843
Gradient professor: -5.189548
Loss Generator D: 2.926801
Loss Generator P: 0.111334
Generator    : Epoch:     23, update:    5750, cost:   0.111334
---------------------------------------------------------
Epoch summary of Generator    :
--> Epoch 23 finished with mean loss 1.23945 (PPL: 3.45370)
--> Epoch took 466.107 minutes, 111.866 sec/update
Epoch summary of Discriminator:
--> Epoch 23 finished with mean loss 0.34925 (PPL: 1.41800)
--> Epoch took 466.107 minutes, 111.866 sec/update
---------------------------------------------------------
Starting Epoch 24
-----------------
Gradient discriminator: -2.176201
Gradient professor: -6.857472
Loss Generator D: 3.137083
Loss Generator P: 0.355883
Gradient discriminator: 2.255533
Gradient professor: -3.956767
Loss Generator D: 2.433865
Loss Generator P: 0.236103
Gradient discriminator: -0.031492
Gradient professor: 8.629187
Loss Generator D: 1.999982
Loss Generator P: 0.366015
Gradient discriminator: -6.765972
Gradient professor: -30.543688
Loss Generator D: 2.575135
Loss Generator P: 0.293054
Gradient discriminator: -0.224057
Gradient professor: -6.636009
Loss Generator D: 2.243329
Loss Generator P: 0.183245
Gradient discriminator: -0.257965
Gradient professor: -10.475252
Loss Generator D: 2.072800
Loss Generator P: 0.231645
Gradient discriminator: -6.453643
Gradient professor: -2.850540
Loss Generator D: 2.330457
Loss Generator P: 0.283994
Gradient discriminator: -1.733332
Gradient professor: -2.431971
Loss Generator D: 2.355722
Loss Generator P: 0.210436
Gradient discriminator: 7.498946
Gradient professor: -8.975198
Loss Generator D: 2.620581
Loss Generator P: 0.310499
Gradient discriminator: 0.000238
Gradient professor: 14.838807
Loss Generator D: 2.748466
Loss Generator P: 0.345959
Generator    : Epoch:     24, update:    5760, cost:   0.345959
Gradient discriminator: 6.224660
Gradient professor: 5.645026
Loss Generator D: 2.816270
Loss Generator P: 0.316616
Gradient discriminator: -2.581378
Gradient professor: -17.012881
Loss Generator D: 2.360273
Loss Generator P: 0.224700
Gradient discriminator: 4.998955
Gradient professor: 19.110645
Loss Generator D: 2.553954
Loss Generator P: 0.271206
Gradient discriminator: -2.004443
Gradient professor: -27.194817
Loss Generator D: 2.553872
Loss Generator P: 0.301516
Gradient discriminator: 0.338793
Gradient professor: -9.982370
Loss Generator D: 2.169582
Loss Generator P: 0.166598
Gradient discriminator: 11.068139
Gradient professor: 12.700374
Loss Generator D: 2.502332
Loss Generator P: 0.162210
Gradient discriminator: 15.670565
Gradient professor: -16.074522
Loss Generator D: 2.537393
Loss Generator P: 0.227548
Gradient discriminator: 1.401360
Gradient professor: -19.586141
Loss Generator D: 1.988456
Loss Generator P: 0.228489
Gradient discriminator: 4.548558
Gradient professor: -5.377903
Loss Generator D: 2.814446
Loss Generator P: 0.276932
Gradient discriminator: 2.482459
Gradient professor: -17.836653
Loss Generator D: 2.462315
Loss Generator P: 0.244970
Generator    : Epoch:     24, update:    5770, cost:   0.244970
Gradient discriminator: 0.923373
Gradient professor: -2.274019
Loss Generator D: 2.837697
Loss Generator P: 0.223280
Gradient discriminator: -1.674874
Gradient professor: -3.433384
Loss Generator D: 3.012493
Loss Generator P: 0.234316
Gradient discriminator: 5.272513
Gradient professor: 4.524186
Loss Generator D: 2.800371
Loss Generator P: 0.225355
Gradient discriminator: 3.561362
Gradient professor: 11.320190
Loss Generator D: 2.353250
Loss Generator P: 0.349949
Gradient discriminator: 2.325456
Gradient professor: 2.308483
Loss Generator D: 3.113410
Loss Generator P: 0.352923
Gradient discriminator: -8.881144
Gradient professor: -8.796207
Loss Generator D: 3.092937
Loss Generator P: 0.239749
Gradient discriminator: 44.963244
Gradient professor: -4.027096
Loss Generator D: 2.686937
Loss Generator P: 0.172484
Gradient discriminator: 13.876728
Gradient professor: -6.228262
Loss Generator D: 2.595037
Loss Generator P: 0.214187
Gradient discriminator: 5.179794
Gradient professor: 6.302090
Loss Generator D: 2.640318
Loss Generator P: 0.212966
Gradient discriminator: -11.794138
Gradient professor: -1.308477
Loss Generator D: 2.795509
Loss Generator P: 0.218734
Generator    : Epoch:     24, update:    5780, cost:   0.218734
Gradient discriminator: 4.348960
Gradient professor: -2.495822
Loss Generator D: 2.884602
Loss Generator P: 0.173946
Gradient discriminator: 0.290412
Gradient professor: 14.655405
Loss Generator D: 3.052976
Loss Generator P: 0.173224
Gradient discriminator: 1.340083
Gradient professor: 9.343273
Loss Generator D: 3.285121
Loss Generator P: 0.287272
Gradient discriminator: 0.590815
Gradient professor: -3.228554
Loss Generator D: 2.864595
Loss Generator P: 0.355996
Gradient discriminator: 3.718746
Gradient professor: 1.029439
Loss Generator D: 3.029664
Loss Generator P: 0.222354
Gradient discriminator: -8.807593
Gradient professor: -18.344564
Loss Generator D: 2.997575
Loss Generator P: 0.165631
Gradient discriminator: 0.010718
Gradient professor: -16.352387
Loss Generator D: 2.839326
Loss Generator P: 0.176576
Gradient discriminator: -7.075314
Gradient professor: -3.668266
Loss Generator D: 2.915475
Loss Generator P: 0.209708
Gradient discriminator: 0.499839
Gradient professor: 6.052370
Loss Generator D: 2.800128
Loss Generator P: 0.198309
Gradient discriminator: 3.287210
Gradient professor: 10.447348
Loss Generator D: 3.147381
Loss Generator P: 0.320608
Generator    : Epoch:     24, update:    5790, cost:   0.320608
Gradient discriminator: 4.367436
Gradient professor: 6.850577
Loss Generator D: 2.948434
Loss Generator P: 0.209018
Gradient discriminator: -4.426480
Gradient professor: -12.785587
Loss Generator D: 3.270798
Loss Generator P: 0.261230
Gradient discriminator: 4.788345
Gradient professor: -5.136006
Loss Generator D: 3.319519
Loss Generator P: 0.210995
Gradient discriminator: 6.384088
Gradient professor: -12.650414
Loss Generator D: 2.946860
Loss Generator P: 0.145904
Gradient discriminator: 2.105914
Gradient professor: -13.750719
Loss Generator D: 3.030537
Loss Generator P: 0.301220
Gradient discriminator: -5.398083
Gradient professor: -0.128213
Loss Generator D: 3.154552
Loss Generator P: 0.218634
Gradient discriminator: -0.080192
Gradient professor: 0.687107
Loss Generator D: 2.910639
Loss Generator P: 0.199439
Gradient discriminator: -1.485564
Gradient professor: 18.174062
Loss Generator D: 2.706285
Loss Generator P: 0.265227
Gradient discriminator: 0.719866
Gradient professor: -4.276005
Loss Generator D: 3.399876
Loss Generator P: 0.360813
Gradient discriminator: -1.475708
Gradient professor: -13.083167
Loss Generator D: 2.937718
Loss Generator P: 0.219288
Generator    : Epoch:     24, update:    5800, cost:   0.219288
Validation 58 - LOSS = 1.826 (PPL: 6.208)
Calling beam-search process
Beam-search ended, took 1.53110 minutes.
Validation 58 - BLEU = 18.39, 32.5/21.3/15.2/10.9 (BP=1.000, ratio=1.989, hyp_len=8392, ref_len=4220)
Early stopping patience: 985 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 0.316734
Gradient professor: 20.273573
Loss Generator D: 2.931245
Loss Generator P: 0.231582
Gradient discriminator: -10.866376
Gradient professor: -2.110503
Loss Generator D: 3.418583
Loss Generator P: 0.204912
Gradient discriminator: -1.956061
Gradient professor: -13.880309
Loss Generator D: 2.226277
Loss Generator P: 0.179999
Gradient discriminator: -3.534867
Gradient professor: -10.273169
Loss Generator D: 2.775567
Loss Generator P: 0.316527
Gradient discriminator: -2.882468
Gradient professor: 6.199884
Loss Generator D: 2.731523
Loss Generator P: 0.250298
Gradient discriminator: -2.477059
Gradient professor: 3.804575
Loss Generator D: 2.940400
Loss Generator P: 0.186284
Gradient discriminator: 6.308394
Gradient professor: -1.670077
Loss Generator D: 2.387273
Loss Generator P: 0.191235
Gradient discriminator: 3.856406
Gradient professor: -3.215257
Loss Generator D: 3.121960
Loss Generator P: 0.180907
Gradient discriminator: -0.479025
Gradient professor: -8.840997
Loss Generator D: 2.728621
Loss Generator P: 0.219688
Gradient discriminator: 1.562232
Gradient professor: -12.908869
Loss Generator D: 3.194770
Loss Generator P: 0.203635
Generator    : Epoch:     24, update:    5810, cost:   0.203635
Gradient discriminator: 2.617455
Gradient professor: -7.861823
Loss Generator D: 2.546998
Loss Generator P: 0.250651
Gradient discriminator: 4.001620
Gradient professor: -7.811757
Loss Generator D: 1.897261
Loss Generator P: 0.318380
Gradient discriminator: 5.402125
Gradient professor: 0.672558
Loss Generator D: 1.645710
Loss Generator P: 0.300879
Gradient discriminator: -1.925939
Gradient professor: 17.400760
Loss Generator D: 1.888120
Loss Generator P: 0.259389
Gradient discriminator: -1.915119
Gradient professor: 4.602095
Loss Generator D: 1.875088
Loss Generator P: 0.311953
Gradient discriminator: -1.876640
Gradient professor: -21.937213
Loss Generator D: 1.904223
Loss Generator P: 0.290449
Gradient discriminator: -9.192498
Gradient professor: 20.024718
Loss Generator D: 1.637614
Loss Generator P: 0.265240
Gradient discriminator: 0.385312
Gradient professor: 3.311108
Loss Generator D: 1.482349
Loss Generator P: 0.203657
Gradient discriminator: 3.609661
Gradient professor: -0.472866
Loss Generator D: 1.344001
Loss Generator P: 0.302902
Gradient discriminator: 7.825116
Gradient professor: -1.649445
Loss Generator D: 1.520438
Loss Generator P: 0.220193
Generator    : Epoch:     24, update:    5820, cost:   0.220193
Gradient discriminator: 0.015642
Gradient professor: 12.527727
Loss Generator D: 1.640772
Loss Generator P: 0.180410
Gradient discriminator: 4.222225
Gradient professor: -5.877521
Loss Generator D: 2.201536
Loss Generator P: 0.152080
Gradient discriminator: 4.045551
Gradient professor: 1.892383
Loss Generator D: 1.804892
Loss Generator P: 0.223397
Gradient discriminator: 9.609684
Gradient professor: -4.825329
Loss Generator D: 1.681557
Loss Generator P: 0.229246
Gradient discriminator: 2.751316
Gradient professor: 1.252149
Loss Generator D: 1.673860
Loss Generator P: 0.194995
Gradient discriminator: -2.090478
Gradient professor: 13.343972
Loss Generator D: 1.932452
Loss Generator P: 0.169460
Gradient discriminator: 0.913085
Gradient professor: -1.836393
Loss Generator D: 1.263318
Loss Generator P: 0.205443
Gradient discriminator: 3.243974
Gradient professor: 8.591219
Loss Generator D: 1.516943
Loss Generator P: 0.290588
Gradient discriminator: -2.439117
Gradient professor: 6.541110
Loss Generator D: 2.082276
Loss Generator P: 0.124353
Gradient discriminator: 0.827640
Gradient professor: 1.649666
Loss Generator D: 2.021242
Loss Generator P: 0.144387
Generator    : Epoch:     24, update:    5830, cost:   0.144387
Gradient discriminator: 1.105793
Gradient professor: 2.247502
Loss Generator D: 1.178524
Loss Generator P: 0.177306
Gradient discriminator: 0.569742
Gradient professor: 12.048148
Loss Generator D: 1.380466
Loss Generator P: 0.148581
Gradient discriminator: 8.636849
Gradient professor: -2.087661
Loss Generator D: 2.204884
Loss Generator P: 0.184456
Gradient discriminator: -0.527238
Gradient professor: -6.726470
Loss Generator D: 1.592160
Loss Generator P: 0.142458
Gradient discriminator: -0.905581
Gradient professor: -2.027527
Loss Generator D: 1.628362
Loss Generator P: 0.120478
Gradient discriminator: -1.424904
Gradient professor: 5.091092
Loss Generator D: 1.752742
Loss Generator P: 0.165350
Gradient discriminator: 3.045670
Gradient professor: 1.975146
Loss Generator D: 0.952479
Loss Generator P: 0.145519
Gradient discriminator: -3.739260
Gradient professor: -3.140537
Loss Generator D: 1.644801
Loss Generator P: 0.255178
Gradient discriminator: 1.569483
Gradient professor: 2.389489
Loss Generator D: 1.592029
Loss Generator P: 0.201125
Gradient discriminator: -3.969348
Gradient professor: 5.740766
Loss Generator D: 1.311695
Loss Generator P: 0.270889
Generator    : Epoch:     24, update:    5840, cost:   0.270889
Gradient discriminator: -4.092541
Gradient professor: 1.476643
Loss Generator D: 1.994736
Loss Generator P: 0.186953
Gradient discriminator: -0.168081
Gradient professor: 3.281510
Loss Generator D: 2.124672
Loss Generator P: 0.256513
Gradient discriminator: 8.429207
Gradient professor: 2.455925
Loss Generator D: 2.267412
Loss Generator P: 0.193478
Gradient discriminator: 4.092954
Gradient professor: 3.717746
Loss Generator D: 2.207457
Loss Generator P: 0.107714
Gradient discriminator: 7.778701
Gradient professor: 6.956073
Loss Generator D: 2.366295
Loss Generator P: 0.185880
Gradient discriminator: -2.270593
Gradient professor: -22.355901
Loss Generator D: 1.680424
Loss Generator P: 0.209811
Gradient discriminator: -0.011883
Gradient professor: -6.144459
Loss Generator D: 2.061175
Loss Generator P: 0.191733
Gradient discriminator: 3.508803
Gradient professor: -4.144425
Loss Generator D: 2.317652
Loss Generator P: 0.203254
Gradient discriminator: -1.861918
Gradient professor: -2.895463
Loss Generator D: 2.124641
Loss Generator P: 0.141919
Gradient discriminator: -5.191757
Gradient professor: -17.038003
Loss Generator D: 2.355987
Loss Generator P: 0.228876
Generator    : Epoch:     24, update:    5850, cost:   0.228876
Gradient discriminator: 1.391057
Gradient professor: -8.937917
Loss Generator D: 1.308142
Loss Generator P: 0.285039
Gradient discriminator: 18.665232
Gradient professor: -10.863259
Loss Generator D: 2.261135
Loss Generator P: 0.212864
Gradient discriminator: 0.163132
Gradient professor: 5.993219
Loss Generator D: 1.795862
Loss Generator P: 0.165993
Gradient discriminator: -3.039494
Gradient professor: -19.384441
Loss Generator D: 1.656232
Loss Generator P: 0.183369
Gradient discriminator: 8.623648
Gradient professor: -4.568919
Loss Generator D: 2.093417
Loss Generator P: 0.127103
Gradient discriminator: -15.000436
Gradient professor: -6.476895
Loss Generator D: 1.970920
Loss Generator P: 0.206694
Gradient discriminator: -0.050232
Gradient professor: -2.385825
Loss Generator D: 1.828686
Loss Generator P: 0.152856
Gradient discriminator: -1.929628
Gradient professor: -5.656403
Loss Generator D: 1.785355
Loss Generator P: 0.200673
Gradient discriminator: 2.539584
Gradient professor: -10.978949
Loss Generator D: 1.768601
Loss Generator P: 0.198388
Gradient discriminator: 2.191650
Gradient professor: -1.163220
Loss Generator D: 1.915303
Loss Generator P: 0.189403
Generator    : Epoch:     24, update:    5860, cost:   0.189403
Gradient discriminator: -4.114096
Gradient professor: -2.863082
Loss Generator D: 2.640406
Loss Generator P: 0.219914
Gradient discriminator: -3.950698
Gradient professor: 7.797176
Loss Generator D: 2.569054
Loss Generator P: 0.169659
Gradient discriminator: -1.114504
Gradient professor: 6.397095
Loss Generator D: 2.317757
Loss Generator P: 0.118108
Gradient discriminator: -4.760865
Gradient professor: 3.856685
Loss Generator D: 2.579768
Loss Generator P: 0.150381
Gradient discriminator: 1.993835
Gradient professor: -16.371329
Loss Generator D: 2.449337
Loss Generator P: 0.218629
Gradient discriminator: 0.156594
Gradient professor: -7.841524
Loss Generator D: 2.558433
Loss Generator P: 0.273151
Gradient discriminator: -1.176013
Gradient professor: 0.179571
Loss Generator D: 2.314955
Loss Generator P: 0.117070
Gradient discriminator: 2.210759
Gradient professor: 4.160945
Loss Generator D: 3.488302
Loss Generator P: 0.242674
Gradient discriminator: 0.355836
Gradient professor: 5.864655
Loss Generator D: 3.003869
Loss Generator P: 0.145695
Gradient discriminator: -1.493346
Gradient professor: -3.885670
Loss Generator D: 2.713579
Loss Generator P: 0.193168
Generator    : Epoch:     24, update:    5870, cost:   0.193168
Gradient discriminator: 3.159846
Gradient professor: -5.992141
Loss Generator D: 2.789634
Loss Generator P: 0.227693
Gradient discriminator: 2.932597
Gradient professor: 3.893892
Loss Generator D: 2.677731
Loss Generator P: 0.215769
Gradient discriminator: -0.032449
Gradient professor: 0.297181
Loss Generator D: 2.729678
Loss Generator P: 0.162261
Gradient discriminator: 0.582955
Gradient professor: 5.303014
Loss Generator D: 2.874485
Loss Generator P: 0.248957
Gradient discriminator: -3.963741
Gradient professor: 16.614407
Loss Generator D: 2.548974
Loss Generator P: 0.258577
Gradient discriminator: -4.419929
Gradient professor: 7.974620
Loss Generator D: 2.849644
Loss Generator P: 0.223659
Gradient discriminator: -0.971470
Gradient professor: -8.067349
Loss Generator D: 2.633290
Loss Generator P: 0.253741
Gradient discriminator: -5.979793
Gradient professor: -9.253931
Loss Generator D: 3.007199
Loss Generator P: 0.244751
Gradient discriminator: 5.027999
Gradient professor: 9.328864
Loss Generator D: 2.876399
Loss Generator P: 0.278871
Gradient discriminator: -0.256612
Gradient professor: -5.054253
Loss Generator D: 2.956529
Loss Generator P: 0.251652
Generator    : Epoch:     24, update:    5880, cost:   0.251652
Gradient discriminator: 0.291411
Gradient professor: 5.024212
Loss Generator D: 2.871949
Loss Generator P: 0.184988
Gradient discriminator: 0.046450
Gradient professor: -3.523670
Loss Generator D: 3.048998
Loss Generator P: 0.182148
Gradient discriminator: 2.550221
Gradient professor: -0.066808
Loss Generator D: 2.114895
Loss Generator P: 0.191120
Gradient discriminator: 2.975917
Gradient professor: -10.871638
Loss Generator D: 2.708358
Loss Generator P: 0.282827
Gradient discriminator: 10.926798
Gradient professor: 1.570205
Loss Generator D: 2.228604
Loss Generator P: 0.211954
Gradient discriminator: -1.413201
Gradient professor: -2.519261
Loss Generator D: 2.687483
Loss Generator P: 0.171881
Gradient discriminator: 8.186379
Gradient professor: -6.541335
Loss Generator D: 3.051057
Loss Generator P: 0.184851
Gradient discriminator: -8.148846
Gradient professor: -9.305059
Loss Generator D: 2.788801
Loss Generator P: 0.160766
Gradient discriminator: 0.134356
Gradient professor: 7.953995
Loss Generator D: 3.077657
Loss Generator P: 0.262014
Gradient discriminator: -4.702686
Gradient professor: 8.692684
Loss Generator D: 2.550441
Loss Generator P: 0.217727
Generator    : Epoch:     24, update:    5890, cost:   0.217727
Gradient discriminator: 6.617651
Gradient professor: 8.671553
Loss Generator D: 2.420952
Loss Generator P: 0.175736
Gradient discriminator: 11.801785
Gradient professor: 1.835489
Loss Generator D: 2.444583
Loss Generator P: 0.253999
Gradient discriminator: -7.513651
Gradient professor: 27.791240
Loss Generator D: 2.290955
Loss Generator P: 0.318931
Gradient discriminator: 6.018000
Gradient professor: -3.985223
Loss Generator D: 2.165298
Loss Generator P: 0.235009
Gradient discriminator: 0.569463
Gradient professor: -0.675729
Loss Generator D: 1.764126
Loss Generator P: 0.267690
Gradient discriminator: -1.578923
Gradient professor: -13.127594
Loss Generator D: 1.868611
Loss Generator P: 0.224470
Gradient discriminator: 7.119064
Gradient professor: -8.209076
Loss Generator D: 2.277783
Loss Generator P: 0.185263
Gradient discriminator: -1.106711
Gradient professor: 3.246546
Loss Generator D: 1.700892
Loss Generator P: 0.210790
Gradient discriminator: 3.272973
Gradient professor: 21.571500
Loss Generator D: 1.941781
Loss Generator P: 0.221809
Gradient discriminator: 7.234465
Gradient professor: -6.334338
Loss Generator D: 2.253713
Loss Generator P: 0.147438
Generator    : Epoch:     24, update:    5900, cost:   0.147438
Validation 59 - LOSS = 1.803 (PPL: 6.071)
Calling beam-search process
Beam-search ended, took 2.26847 minutes.
Validation 59 - BLEU = 7.49, 13.9/8.9/6.1/4.2 (BP=1.000, ratio=4.044, hyp_len=17064, ref_len=4220)
Early stopping patience: 984 validation left
--> Current BEST BLEU = 18.700 at validation 43
--> Current BEST LOSS = 1.602 (PPL: 4.965) at validation 21
--> This is model: attention_GAN_gradient-e512-i512-o512-r1024-adadelta_1e+00-bs80-bleu-each100_do_d0.0-gc1-init_xavier-s1234.3
Gradient discriminator: 1.171507
Gradient professor: -23.514569
Loss Generator D: 2.348444
Loss Generator P: 0.249765
Gradient discriminator: 13.309069
Gradient professor: -6.092828
Loss Generator D: 2.214128
Loss Generator P: 0.254473
Gradient discriminator: -4.341743
Gradient professor: -18.109961
Loss Generator D: 2.340947
Loss Generator P: 0.231208
Gradient discriminator: -2.091371
Gradient professor: 3.836168
Loss Generator D: 2.474623
Loss Generator P: 0.184512
Gradient discriminator: 0.533602
Gradient professor: 7.626785
Loss Generator D: 2.608654
Loss Generator P: 0.283130
Gradient discriminator: 4.787450
Gradient professor: -9.213151
Loss Generator D: 2.418068
Loss Generator P: 0.171393
Gradient discriminator: -3.090879
Gradient professor: -11.363662
Loss Generator D: 2.662419
Loss Generator P: 0.224782
Gradient discriminator: -2.525606
Gradient professor: -0.034429
Loss Generator D: 2.296609
Loss Generator P: 0.142429
Gradient discriminator: -0.778351
Gradient professor: 4.502901
Loss Generator D: 2.427907
Loss Generator P: 0.150290
Gradient discriminator: -6.291901
Gradient professor: -14.413368
Loss Generator D: 2.039866
Loss Generator P: 0.288056
Generator    : Epoch:     24, update:    5910, cost:   0.288056
Gradient discriminator: -2.873272
Gradient professor: 3.269155
Loss Generator D: 2.459810
Loss Generator P: 0.242201
Gradient discriminator: -3.006041
Gradient professor: -1.434739
Loss Generator D: 2.465149
Loss Generator P: 0.266319
Gradient discriminator: -1.962963
Gradient professor: 11.432064
Loss Generator D: 2.378970
Loss Generator P: 0.251740
Gradient discriminator: -5.876586
Gradient professor: 15.389253
Loss Generator D: 2.289137
Loss Generator P: 0.266437
Gradient discriminator: 12.746494
Gradient professor: -11.928052
Loss Generator D: 2.413975
Loss Generator P: 0.362645
Gradient discriminator: -1.858243
Gradient professor: 1.512711
Loss Generator D: 2.679486
Loss Generator P: 0.252874
Gradient discriminator: 0.388886
Gradient professor: 19.136630
Loss Generator D: 2.374583
Loss Generator P: 0.302952
Gradient discriminator: 4.274793
Gradient professor: -1.082377
Loss Generator D: 2.424827
Loss Generator P: 0.136661
Gradient discriminator: 3.584905
Gradient professor: -11.390180
Loss Generator D: 1.950071
Loss Generator P: 0.206674
Gradient discriminator: 1.262456
Gradient professor: -6.460095
Loss Generator D: 2.185993
Loss Generator P: 0.253782
Generator    : Epoch:     24, update:    5920, cost:   0.253782
Gradient discriminator: 4.105906
Gradient professor: 1.447700
Loss Generator D: 2.395584
Loss Generator P: 0.179540
Gradient discriminator: 5.681761
Gradient professor: 2.391877
Loss Generator D: 1.995990
Loss Generator P: 0.183839
Gradient discriminator: 6.983979
Gradient professor: 10.125646
Loss Generator D: 2.635304
Loss Generator P: 0.192433
Gradient discriminator: 2.046805
Gradient professor: -2.073723
Loss Generator D: 2.731310
Loss Generator P: 0.115400
Gradient discriminator: -0.129857
Gradient professor: -1.634509
Loss Generator D: 2.698688
Loss Generator P: 0.156911
Gradient discriminator: -0.879596
Gradient professor: -5.879268
Loss Generator D: 2.842497
Loss Generator P: 0.234173
Gradient discriminator: 3.224893
Gradient professor: -2.727722
Loss Generator D: 2.116831
Loss Generator P: 0.259005
Gradient discriminator: 13.165049
Gradient professor: 7.447221
Loss Generator D: 3.054825
Loss Generator P: 0.341977
Gradient discriminator: 7.611564
Gradient professor: -0.846005
Loss Generator D: 3.061507
Loss Generator P: 0.304415
Gradient discriminator: -2.228404
Gradient professor: -1.949425
Loss Generator D: 2.997406
Loss Generator P: 0.159709
Generator    : Epoch:     24, update:    5930, cost:   0.159709
Gradient discriminator: -1.153996
Gradient professor: 2.777903
Loss Generator D: 2.726486
Loss Generator P: 0.202286
Gradient discriminator: -3.001745
Gradient professor: -6.747052
Loss Generator D: 2.560683
Loss Generator P: 0.200943
Gradient discriminator: -0.178439
Gradient professor: 7.690866
Loss Generator D: 2.884119
Loss Generator P: 0.239185
